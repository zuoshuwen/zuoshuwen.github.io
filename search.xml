<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>学习资源索引</title>
    <url>/index/</url>
    <content><![CDATA[<h2 id="综合"><a href="#综合" class="headerlink" title="综合"></a>综合</h2><p><a href="https://hardcore.feishu.cn/docs/doccngKKrYQWSYu4Rr3puVq20wc">硬核课堂</a><br><a href="https://strikefreedom.top/">strikefreedom</a></p>
<h2 id="Go"><a href="#Go" class="headerlink" title="Go"></a>Go</h2><p><a href="https://lessisbetter.site/">Go语言充电站</a><br><a href="https://eddycjy.com/">煎鱼</a><br><a href="https://lailin.xyz/">mohuishou</a></p>
]]></content>
  </entry>
  <entry>
    <title>数据结构与算法系列文章索引</title>
    <url>/datastruct-algorithm/a/</url>
    <content><![CDATA[<h1 id="学习资料"><a href="#学习资料" class="headerlink" title="学习资料"></a>学习资料</h1><p><a href="http://gk.link/a/10txE">极客时间专栏《数据结构与算法之美》</a><br><a href="http://gk.link/a/10txH">极客时间专栏《算法面试通关40讲》</a><br><a href="https://u.jd.com/6MG4eU3">书籍《算法》第四版</a><br><a href="https://u.jd.com/6D6C87m">书籍《数据结构与算法之美》</a></p>
<h1 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h1><p>大部分的数据结构基本上都是由数组或者链表演变而来</p>
<h3 id="数据库"><a href="#数据库" class="headerlink" title="数据库"></a>数据库</h3><p><strong>MySQL</strong> B+</p>
<p><strong>MongoDB</strong> B</p>
<p><strong>Redis</strong> Skip List</p>
<p><strong>Memcache</strong> Hash</p>
<p><strong>TiDB</strong> LSM Tree</p>
<h3 id="树"><a href="#树" class="headerlink" title="树"></a>树</h3><p><strong>基数树</strong> golang的web框架echo和gin都使用了radix tree作为路由查找的算法</p>
<h1 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h1><h3 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h3><p>TCP流量控制</p>
<h3 id="进程-线程"><a href="#进程-线程" class="headerlink" title="进程/线程"></a>进程/线程</h3><p><a href="https://zhuanlan.zhihu.com/p/97071815">详解操作系统内核对线程的调度算法</a></p>
<h3 id="分布式缓存"><a href="#分布式缓存" class="headerlink" title="分布式缓存"></a>分布式缓存</h3><p><a href="https://segmentfault.com/a/1190000021199728">图解一致性哈希算法</a><br><a href="http://blog.codinglabs.org/articles/consistent-hashing.html">一致性哈希算法及其在分布式系统中的应用</a><br><a href="https://github.com/RJ/ketama">https://github.com/RJ/ketama</a></p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>文章索引</tag>
      </tags>
  </entry>
  <entry>
    <title>设计模式文章索引</title>
    <url>/design-pattern/a/</url>
    <content><![CDATA[<h1 id="学习资料"><a href="#学习资料" class="headerlink" title="学习资料"></a>学习资料</h1><p><a href="http://gk.link/a/10txN">极客时间专栏《设计模式之美》</a></p>
<h1 id="面向对象"><a href="#面向对象" class="headerlink" title="面向对象"></a>面向对象</h1><ul>
<li>面向对象的四大特性：封装、抽象、继承、多态</li>
<li>面向对象编程与面向过程编程的区别和联系</li>
<li>面向对象分析、面向对象设计、面向对象编程</li>
<li>接口和抽象类的区别以及各自的应用场景</li>
<li>基于接口而非实现编程的设计思想</li>
<li>多用组合少用继承的设计思想</li>
<li>面向过程的贫血模型和面向对象的充血模型、失血模型</li>
</ul>
<h1 id="设计原则"><a href="#设计原则" class="headerlink" title="设计原则"></a>设计原则</h1><ul>
<li>SOLID 原则 -SRP 单一职责原则</li>
<li>SOLID 原则 -OCP 开闭原则</li>
<li>SOLID 原则 -LSP 里式替换原则</li>
<li>SOLID 原则 -ISP 接口隔离原则</li>
<li>SOLID 原则 -DIP 依赖倒置原则<ul>
<li>控制反转、依赖反转、依赖注入</li>
</ul>
</li>
<li>DRY 原则</li>
<li>KISS 原则</li>
<li>YAGNI 原则</li>
<li>LOD 法则</li>
</ul>
<h1 id="设计模式"><a href="#设计模式" class="headerlink" title="设计模式"></a>设计模式</h1><h1 id="编程规范"><a href="#编程规范" class="headerlink" title="编程规范"></a>编程规范</h1><h1 id="重构技巧"><a href="#重构技巧" class="headerlink" title="重构技巧"></a>重构技巧</h1><h1 id="COW"><a href="#COW" class="headerlink" title="COW"></a>COW</h1><p><strong>参考</strong><br><a href="https://chunlife.top/2019/09/03/copy-on-write%E6%8A%80%E6%9C%AF/">copy-on-write技术</a><br><a href="https://juejin.cn/post/6844903702373859335">COW奶牛！Copy On Write机制了解一下</a><br><a href="https://chunlife.top/2019/09/03/copy-on-write%E6%8A%80%E6%9C%AF/">copy-on-write技术</a></p>
<p>写入时复制（英语：Copy-on-write，简称COW）是一种计算机程序设计领域的优化策略。</p>
<p>其核心思想是，如果有多个调用者（callers）同时请求相同资源（如内存或磁盘上的数据存储），他们会共同获取相同的指针指向相同的资源，直到某个调用者试图修改资源的内容时，系统才会真正复制一份专用副本（private copy）给该调用者，而其他调用者所见到的最初的资源仍然保持不变。这过程对其他的调用者都是透明的（transparently）。此作法主要的优点是如果调用者没有修改该资源，就不会有副本（private copy）被创建，因此多个调用者只是读取操作时可以共享同一份资源。</p>
<h3 id="Linux"><a href="#Linux" class="headerlink" title="Linux"></a>Linux</h3><p>fork()之后，kernel把父进程中所有的内存页的权限都设为read-only，然后子进程的地址空间指向父进程。当父子进程都只读内存时，相安无事。当其中某个进程写内存时，CPU硬件检测到内存页是read-only的，于是触发页异常中断（page-fault），陷入kernel的一个中断例程。中断例程中，kernel就会把触发的异常的页复制一份，于是父子进程各自持有独立的一份。</p>
<h3 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h3><p>redis 有两种方式持久化，一种是 RDB，一种是AOF。<br>在 RDB 中，想要触发持久化操作，可以执行 save、bgsave 命令，或者通过配置文件自动触发，其中 bgsave 的方式，就是 fork 一个子进程来做持久化工作。<br>最初，父进程和子进程拥有相同的内存空间地址，而如果父进程这个时候有写操作，因为内存页设置为 read-only 了，所以会触发 page-fault，父进程中修改数据所在的那个内存页会被指向到新的内存空间地址，而子进程读的还是修改之前的数据。</p>
<p>有坑吗？有的<br>如果全量更新数据恰好处于 rdb 持久化任务过程中，内存可能就会翻倍。</p>
<p><a href="https://www.cnblogs.com/javazhiyin/p/11425060.html">10分钟彻底理解Redis的持久化机制：RDB和AOF</a><br><a href="https://www.cnblogs.com/javazhiyin/p/12985656.html">看完这篇还不懂Redis的RDB持久化，你们来打我！</a></p>
<h3 id="docker"><a href="#docker" class="headerlink" title="docker"></a>docker</h3><p>所有驱动都用到的技术——写时复制（CoW）。CoW就是copy-on-write，表示只在需要写时才去复制，这个是针对已有文件的修改场景。比如基于一个image启动多个Container，如果为每个Container都去分配一个image一样的文件系统，那么将会占用大量的磁盘空间。而CoW技术可以让所有的容器共享image的文件系统，所有数据都从image中读取，只有当要对文件进行写操作时，才从image里把要写的文件复制到自己的文件系统进行修改。所以无论有多少个容器共享同一个image，所做的写操作都是对从image中复制到自己的文件系统中的复本上进行，并不会修改image的源文件，且多个容器操作同一个文件，会在每个容器的文件系统里生成一个复本，每个容器修改的都是自己的复本，相互隔离，相互不影响。使用CoW可以有效的提高磁盘的利用率。</p>
<h3 id="Nginx"><a href="#Nginx" class="headerlink" title="Nginx"></a>Nginx</h3><h3 id="更新配置文件"><a href="#更新配置文件" class="headerlink" title="更新配置文件"></a>更新配置文件</h3><p>比较适用于读多写少的场景，且允许更新有稍许的延迟，复制旧数据到新数据后，修改配置，在利用原子操作进行替换，无锁访问共享数据。<br>既然互斥锁会造成阻塞，那么读写锁呢？<br>下面这段话适合 go 并发编程<br>我们知道读写锁中不互斥的只有”读读”，如果一个资源被上了写锁，其它线程过来读，还是会阻塞的，但是COW方案不会这样。<br>使用COW，就是为了避免使用锁<br>空间换时间</p>
<h3 id="文件系统"><a href="#文件系统" class="headerlink" title="文件系统"></a>文件系统</h3><p>Copy-on-write在对数据进行修改的时候，不会直接在原来的数据位置上进行操作，而是重新找个位置修改，这样的好处是一旦系统突然断电，重启之后不需要做Fsck。好处就是能保证数据的完整性，掉电的话容易恢复。<br>比如说：要修改数据块A的内容，先把A读出来，写到B块里面去。如果这时候断电了，原来A的内容还在！</p>
]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>文章索引</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式系列文章索引</title>
    <url>/distributed/a/</url>
    <content><![CDATA[<h1 id="学习资料"><a href="#学习资料" class="headerlink" title="学习资料"></a>学习资料</h1><p><a href="https://hardcore.feishu.cn/docs/doccngKKrYQWSYu4Rr3puVq20wc">硬核课堂</a><br><a href="http://gk.link/a/10tCq">极客时间《分布式协议与算法实战》</a></p>
<h2 id="拜占庭将军"><a href="#拜占庭将军" class="headerlink" title="拜占庭将军"></a>拜占庭将军</h2><h2 id="分布式理论"><a href="#分布式理论" class="headerlink" title="分布式理论"></a>分布式理论</h2><h3 id="CAP"><a href="#CAP" class="headerlink" title="CAP"></a>CAP</h3><h3 id="一致性-ACID"><a href="#一致性-ACID" class="headerlink" title="一致性 ACID"></a>一致性 ACID</h3><h3 id="可用性-BASE"><a href="#可用性-BASE" class="headerlink" title="可用性 BASE"></a>可用性 BASE</h3><h1 id="Paxos"><a href="#Paxos" class="headerlink" title="Paxos"></a>Paxos</h1><h1 id="Raft"><a href="#Raft" class="headerlink" title="Raft"></a>Raft</h1><p>Raft 算法属于 Multi-Paxos 算法，它是在兰伯特 Multi-Paxos 思想的基础上，做了一些简化和限制，比如增加了日志必须是连续的，只支持领导者、跟随者和候选人三种状态，在理解和算法实现上都相对容易许多。</p>
<p>Raft 算法是现在分布式系统开发首选的共识算法</p>
<p>如果要用一句话概括 Raft 算法，我觉得是这样的：从本质上说，Raft 算法是通过一切以领导者为准的方式，实现一系列值的共识和各节点日志的一致。</p>
<h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><h2 id="角色"><a href="#角色" class="headerlink" title="角色"></a>角色</h2><h3 id="领导者（Leader）"><a href="#领导者（Leader）" class="headerlink" title="领导者（Leader）"></a>领导者（Leader）</h3><p>蛮不讲理的霸道总裁，一切以我为准，平常的主要工作内容就是 3 部分，处理写请求、管理日志复制和不断地发送心跳信息，通知其他节点“我是领导者，我还活着，你们现在不要发起新的选举，找个新领导者来替代我。”</p>
<h3 id="跟随者（Follower）"><a href="#跟随者（Follower）" class="headerlink" title="跟随者（Follower）"></a>跟随者（Follower）</h3><p>就相当于普通群众，默默地接收和处理来自领导者的消息，当等待领导者心跳信息超时的时候，就主动站出来，推荐自己当候选人。</p>
<h3 id="候选人（Candidate）"><a href="#候选人（Candidate）" class="headerlink" title="候选人（Candidate）"></a>候选人（Candidate）</h3><p>候选人将向其他节点发送请求投票（RequestVote）RPC 消息，通知其他节点来投票，如果赢得了大多数选票，就晋升当领导者。</p>
<h2 id="选举"><a href="#选举" class="headerlink" title="选举"></a>选举</h2><h3 id="发送心跳"><a href="#发送心跳" class="headerlink" title="发送心跳"></a>发送心跳</h3><p>Raft 算法实现了随机超时时间的特性。也就是说，每个节点等待领导者节点心跳信息的超时时间间隔是随机的。通过上面的图片你可以看到，集群中没有领导者，而节点 A 的等待超时时间最小（150ms），它会最先因为没有等到领导者的心跳信息，发生超时。<br>这个时候，节点 A 就增加自己的任期编号，并推举自己为候选人，先给自己投上一张选票，然后向其他节点发送请求投票 RPC 消息，请它们选举自己为领导者。</p>
<h3 id="请求投票（RequestVote）"><a href="#请求投票（RequestVote）" class="headerlink" title="请求投票（RequestVote）"></a>请求投票（RequestVote）</h3><p>RPC，是由候选人在选举期间发起，通知各节点进行投票；</p>
<h3 id="任期编号（term）"><a href="#任期编号（term）" class="headerlink" title="任期编号（term）"></a>任期编号（term）</h3><p>推举自己为候选人时，会增加自己的任期号；<br>发现自己的任期编号比其他节点小，那么它会立即恢复成跟随者状态，那么它会更新自己的编号到较大的编号值；<br>接收到一个包含较小的任期编号值的请求投票消息，那么它会直接拒绝这个请求；</p>
<h3 id="日志复制（AppendEntries）"><a href="#日志复制（AppendEntries）" class="headerlink" title="日志复制（AppendEntries）"></a>日志复制（AppendEntries）</h3><p>RPC，是由领导者发起，用来复制日志和提供心跳消息；<br>就算任期编号大的节点，如果最后一条日志项对应的任期编号小于其它节点，请求投票也会被拒绝；</p>
<h3 id="脑裂"><a href="#脑裂" class="headerlink" title="脑裂"></a>脑裂</h3><p>脑裂情况是无效状态，通过随机超时，来重新选举</p>
<h3 id="投票"><a href="#投票" class="headerlink" title="投票"></a>投票</h3><p>每个任期（term）只能投票一次</p>
<h2 id="日志复制"><a href="#日志复制" class="headerlink" title="日志复制"></a>日志复制</h2><h3 id="日志项"><a href="#日志项" class="headerlink" title="日志项"></a>日志项</h3><p>日志项是一种数据格式，它主要包含用户指定的数据，也就是指令（Command），还包含一些附加信息，比如索引值（Log index）、任期编号（Term）</p>
<h3 id="第一阶段，日志项预执行：日志复制"><a href="#第一阶段，日志项预执行：日志复制" class="headerlink" title="第一阶段，日志项预执行：日志复制"></a>第一阶段，日志项预执行：日志复制</h3><p>首先，领导者进入第一阶段，通过日志复制（AppendEntries）RPC 消息，将日志项复制到集群其他节点上。<br>接着，如果领导者接收到大多数的“复制成功”响应后，它将日志项应用到它的状态机，并返回成功给客户端。如果领导者没有接收到大多数的“复制成功”响应，那么就返回错误给客户端。</p>
<h3 id="第二阶段，心跳或者新的日志复制带有日志项索引值：状态机"><a href="#第二阶段，心跳或者新的日志复制带有日志项索引值：状态机" class="headerlink" title="第二阶段，心跳或者新的日志复制带有日志项索引值：状态机"></a>第二阶段，心跳或者新的日志复制带有日志项索引值：状态机</h3><p>这是 Raft 中的一个优化，领导者不直接发送消息通知其他节点应用指定日志项。因为领导者的日志复制 RPC 消息或心跳消息，包含了当前最大的，将会被提交（Commit）的日志项索引值。所以通过日志复制 RPC 消息或心跳消息，跟随者就可以知道领导者的日志提交位置信息。<br>因此，当其他节点接受领导者的心跳消息，或者新的日志复制 RPC 消息后，就会将这条日志项应用到它的状态机。而这个优化，降低了处理客户端请求的延迟，将二阶段提交优化为了一段提交，降低了一半的消息延迟。</p>
<h3 id="一致性维护"><a href="#一致性维护" class="headerlink" title="一致性维护"></a>一致性维护</h3><p>首先，领导者通过日志复制 RPC 的一致性检查，找到跟随者节点上，与自己相同日志项的最大索引值。也就是说，这个索引值之前的日志，领导者和跟随者是一致的，之后的日志是不一致的了。<br>然后，领导者强制跟随者更新覆盖的不一致日志项，实现日志的一致。</p>
<h1 id="Gossip"><a href="#Gossip" class="headerlink" title="Gossip"></a>Gossip</h1><h1 id="Quorum"><a href="#Quorum" class="headerlink" title="Quorum"></a>Quorum</h1><h1 id="PBFT"><a href="#PBFT" class="headerlink" title="PBFT"></a>PBFT</h1><h1 id="PoW"><a href="#PoW" class="headerlink" title="PoW"></a>PoW</h1><h1 id="ZAB"><a href="#ZAB" class="headerlink" title="ZAB"></a>ZAB</h1><h1 id="TCC"><a href="#TCC" class="headerlink" title="TCC"></a>TCC</h1><h1 id="延伸"><a href="#延伸" class="headerlink" title="延伸"></a>延伸</h1><p>拜占庭容错算法<br>口信消息型<br>签名消息型<br>数字货币的区块链技术中</p>
<p>非拜占庭容错算法<br>解决的是分布式的系统中存在故障，但不存在恶意节点的场景下的共识问题</p>
]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>文章索引</tag>
      </tags>
  </entry>
  <entry>
    <title>Go系列文章索引</title>
    <url>/golang/a/</url>
    <content><![CDATA[<h1 id="学习资料"><a href="#学习资料" class="headerlink" title="学习资料"></a>学习资料</h1><p><a href="http://gk.link/a/10txP">极客时间《GO并发编程实战课》</a><br><a href="http://gk.link/a/10txQ">极客时间《Go语言从入门到实战》</a><br><a href="http://gk.link/a/10txR">极客时间《Go语言核心36讲》</a><br><a href="http://gk.link/a/10o2G">极客时间《Go语言编程模式实战》</a><br><a href="http://gk.link/a/10sIo">极客时间《Go进阶训练营》</a><br><a href="https://learnku.com/docs/effective-go/2020">电子书《高效的 Go 编程 Effective Go》</a><br><a href="https://lessisbetter.site/">博客《Go语言充电站》</a><br><a href="https://eddycjy.com/">博客《煎鱼》</a><br><a href="https://lailin.xyz/">博客《mohuishou》</a><br><a href="http://gk.link/a/10sIo">极客时间《go进阶训练营》</a></p>
<h1 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h1><p><strong>参考</strong></p>
<p><strong>笔记</strong></p>
<ol>
<li><input type="checkbox" disabled checked="checked"><a href="/golang/datastruct-arrayslice/" title="Go数据结构之数组与切片">Go数据结构之数组与切片</a></li>
<li><del>Go数据结构之Map</del></li>
</ol>
<h1 id="面向对象"><a href="#面向对象" class="headerlink" title="面向对象"></a>面向对象</h1><p><strong>参考</strong></p>
<p><strong>笔记</strong></p>
<ol>
<li><input type="checkbox" disabled ><a href="/golang/oop/" title="Go面向对象">Go面向对象</a></li>
</ol>
<h1 id="Runtime"><a href="#Runtime" class="headerlink" title="Runtime"></a>Runtime</h1><p><strong>参考</strong></p>
<p><strong>笔记</strong></p>
<ol>
<li><input type="checkbox" disabled ><a href="/golang/scheduling/" title="GoMPG与调度">GoMPG与调度</a></li>
<li><input type="checkbox" disabled ><a href="/golang/memory-alloc/" title="Go内存管理、分配">Go内存管理、分配</a></li>
<li><input type="checkbox" disabled ><a href="/golang/memory-gc/" title="Go内存GC">Go内存GC</a></li>
<li><input type="checkbox" disabled ><a href="/golang/memory-leak-escape/" title="Go内存泄漏、逃逸">Go内存泄漏、逃逸</a></li>
</ol>
<h1 id="并发编程"><a href="#并发编程" class="headerlink" title="并发编程"></a>并发编程</h1><p>启动 goroutine 应该在方法外，不应该在方法里面，并发行为，交给调用者。<br>搞清楚channel什么时候退出，控制这个channel的退出，并发扔给调用者，这三个关键点<br>log.Fatal()不能随便用，因为会导致defer不能执行</p>
<p><strong>参考</strong></p>
<p><strong>笔记</strong></p>
<ol>
<li><input type="checkbox" disabled checked="checked"><a href="/golang/concurrent-programme/" title="并发编程">并发编程</a></li>
<li><input type="checkbox" disabled checked="checked"><a href="/golang/ipc-mutex/" title="Go并发编程之传统同步—(1)互斥锁">Go并发编程之传统同步—(1)互斥锁</a></li>
<li><input type="checkbox" disabled checked="checked"><a href="/golang/ipc-cond/" title="Go并发编程之传统同步—(2)条件变量">Go并发编程之传统同步—(2)条件变量</a></li>
<li><input type="checkbox" disabled checked="checked"><a href="/golang/ipc-atomic/" title="Go并发编程之传统同步—(3)原子操作">Go并发编程之传统同步—(3)原子操作</a></li>
<li><input type="checkbox" disabled ><a href="/golang/ipc-waitgrouponce/" title="Go并发编程之任务协作—(1)WaitGroup、Once">Go并发编程之任务协作—(1)WaitGroup、Once</a></li>
<li><input type="checkbox" disabled ><a href="/golang/ipc-errgroup/" title="Go并发编程之任务协作—(1)ErrGroup">Go并发编程之任务协作—(1)ErrGroup</a></li>
<li><input type="checkbox" disabled ><a href="/golang/ipc-context/" title="Go并发编程之任务协作—(2)Context">Go并发编程之任务协作—(2)Context</a></li>
<li><input type="checkbox" disabled ><a href="/golang/ipc-map/" title="Go并发编程之数据共享—(1)Map">Go并发编程之数据共享—(1)Map</a></li>
<li><input type="checkbox" disabled ><a href="/golang/ipc-pool/" title="Go并发编程之数据共享—(2)Pool">Go并发编程之数据共享—(2)Pool</a></li>
<li><input type="checkbox" disabled ><a href="/golang/ipc-channel/" title="Go并发编程之终极武器—channel">Go并发编程之终极武器—channel</a></li>
<li><input type="checkbox" disabled >data race</li>
<li>singleflight</li>
</ol>
<h1 id="并发模型"><a href="#并发模型" class="headerlink" title="并发模型"></a>并发模型</h1><h1 id="项目工程"><a href="#项目工程" class="headerlink" title="项目工程"></a>项目工程</h1><p><strong>参考</strong><br><a href="https://github.com/golang-standards/project-layout/blob/master/README_zh.md">project-layout</a></p>
<h3 id="错误处理"><a href="#错误处理" class="headerlink" title="错误处理"></a>错误处理</h3><p><strong>参考</strong><br><a href="https://lailin.xyz/post/go-training-03.html">Go错误处理最佳实践</a></p>
<h3 id="幂等"><a href="#幂等" class="headerlink" title="幂等"></a>幂等</h3><p>幂等：客户端要进行版本号创建与更新，并且按接口区分，对于同一个接口，只有在 response 返回时，才更新于接口对应的版本号。所以当用户连续两次点击的时候，还没有任何response返回，版本号肯定是一样的。</p>
<h3 id="gomod"><a href="#gomod" class="headerlink" title="gomod"></a>gomod</h3><p>开启了gomod 项目就不要放在 src 目录下，一定要拿出来</p>
<h3 id="开源项目"><a href="#开源项目" class="headerlink" title="开源项目"></a>开源项目</h3><p><a href="https://github.com/LyricTian/gin-admin">gin-admin</a></p>
<h1 id="编程模式"><a href="#编程模式" class="headerlink" title="编程模式"></a>编程模式</h1><p>选项模式</p>
<h1 id="go-module"><a href="#go-module" class="headerlink" title="go module"></a>go module</h1><p><a href="https://colobu.com/2019/09/23/review-go-module-again/">https://colobu.com/2019/09/23/review-go-module-again/</a></p>
<h1 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h1><p>1.无锁编程<br>2. <a href="https://www.jianshu.com/p/1390dbf87471">Go语言学习之——if else</a></p>
]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>文章索引</tag>
      </tags>
  </entry>
  <entry>
    <title>并发编程</title>
    <url>/golang/concurrent-programme/</url>
    <content><![CDATA[<h1 id="并发编程"><a href="#并发编程" class="headerlink" title="并发编程"></a>并发编程</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在开始学习 Go 特性的并发编程之前，先来简单了解一些基础概念，这对理解学习 Go 并发模型会有一些帮助。</p>
<span id="more"></span>

<h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><h3 id="内核态"><a href="#内核态" class="headerlink" title="内核态"></a>内核态</h3><p>也被称为内核空间，是系统内核的运行空间，与用户空间隔离。控制计算机的硬件资源。</p>
<h3 id="用户态"><a href="#用户态" class="headerlink" title="用户态"></a>用户态</h3><p>也被称为用户空间，代码运行在较低的特权级别上，不能直接访问内核空间和硬件设备。</p>
<h3 id="系统调用"><a href="#系统调用" class="headerlink" title="系统调用"></a>系统调用</h3><p>用户空间不能直接调用系统资源，必须通过调用系统接口，由内核完成相关指令。</p>
<h3 id="进程"><a href="#进程" class="headerlink" title="进程"></a>进程</h3><p>进程是操作系统分配资源的最小单元。</p>
<h3 id="线程"><a href="#线程" class="headerlink" title="线程"></a>线程</h3><p>有时也被称为轻量级进程（LWP），是被系统独立调度和分派的基本单位，线程自己不拥有系统资源，只拥有一点儿在运行中必不可少的资源，但它可与同属一个进程的其它线程共享进程所拥有的全部资源。</p>
<h3 id="KSE"><a href="#KSE" class="headerlink" title="KSE"></a>KSE</h3><p>理论上说 Linux 内核是没有线程这个概念的，只有内核调度实体（Kernal Scheduling Entry）这个概念。</p>
<h3 id="协程"><a href="#协程" class="headerlink" title="协程"></a>协程</h3><p>有时也被称为微线程（Coroutine），只不过这个线程是用户态的，不需要操作系统参与。</p>
<p>调度过程示例：</p>
<ol>
<li>coroutine A 进行 网络I/O，使用 write() 发送数据后调用 read() 等待数据的返回，但是不一定什么时候能够读到数据，所以将 Socket Fd 放入 EventLoop 中。</li>
<li>coroutine A 让出 CPU 给 其它 coroutine 使用 —— <strong>挂起（yield）</strong></li>
<li>待 read() 有返回数据后，继续执行 coroutine A  —— <strong>恢复（resume）</strong></li>
</ol>
<p><em>EventLoop：无限循环着的事件分发器，一旦有事件发生，它就会回调预先定义好的回调函数，完成事件的处理。</em></p>
<h3 id="线程模型"><a href="#线程模型" class="headerlink" title="线程模型"></a>线程模型</h3><h4 id="用户级线程"><a href="#用户级线程" class="headerlink" title="用户级线程"></a>用户级线程</h4><p><strong>M:1</strong> 多个用户空间的线程，对应一个内核空间的 KSE。</p>
<h4 id="系统级线程"><a href="#系统级线程" class="headerlink" title="系统级线程"></a>系统级线程</h4><p><strong>1:1</strong> 1个用户空间的线程，对应1个内核空间的 KSE。</p>
<h4 id="两级线程模型（混合式线程模型）"><a href="#两级线程模型（混合式线程模型）" class="headerlink" title="两级线程模型（混合式线程模型）"></a>两级线程模型（混合式线程模型）</h4><p><strong>M:N</strong> 多个用户空间的线程，对应多个内核空间的 KSE。</p>
<h3 id="并发模型"><a href="#并发模型" class="headerlink" title="并发模型"></a>并发模型</h3><p>并发模型指定了系统中的线程如何通过协作来完成分配给它们的作业。不同的并发模型采用不同的方式拆分作业，同时线程间的协作和交互方式也不相同。</p>
<p>常见的有：</p>
<ul>
<li>线程&amp;锁</li>
<li>Actor</li>
<li>CSP</li>
<li>Lambda 架构</li>
</ul>
<h3 id="并发模型—CSP"><a href="#并发模型—CSP" class="headerlink" title="并发模型—CSP"></a>并发模型—CSP</h3><p>Communicating Sequential Processes 通信顺序进程。</p>
<p>看这个名字就能知道，在CSP模型中主角是<strong>通信</strong>。</p>
<blockquote>
<p>channel：进行通信的并发模型。<br>worker：channel 两端的发送者/接收者。</p>
</blockquote>
<p>worker 之间不直接彼此联系，而是通过 channel 进行消息发送和接收。</p>
<p>在并发模型中，经常和 CSP 一起讨论的是 Actor 模型。</p>
<h3 id="GO-线程模型"><a href="#GO-线程模型" class="headerlink" title="GO 线程模型"></a>GO 线程模型</h3><p>Go 参考了<strong>两级线程模型</strong>，设计出了 MPG 线程模型。</p>
<h4 id="M"><a href="#M" class="headerlink" title="M"></a>M</h4><p>machine</p>
<p>用户空间内的线程，与 KSE 一一对应，可以理解为 M 代表了 内核线程。</p>
<h4 id="P"><a href="#P" class="headerlink" title="P"></a>P</h4><p>processor</p>
<p>可以理解为用户代码逻辑的处理器，Go 代码片段所必需的上下文环境。</p>
<h4 id="G"><a href="#G" class="headerlink" title="G"></a>G</h4><p>goroutine</p>
<p>Go 代码片段的封装。</p>
<div class="code-wrapper"><pre><code class="hljs actionscript">go <span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-params">()</span></span>&#123;
<span class="hljs-comment">//  ...</span>
&#125;()</code></pre></div>


<h3 id="GO并发模型"><a href="#GO并发模型" class="headerlink" title="GO并发模型"></a>GO并发模型</h3><h4 id="channel"><a href="#channel" class="headerlink" title="channel"></a>channel</h4><p>参考了 <strong>CSP并发模型</strong>。</p>
<h2 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h2><h3 id="goroutine-与-coroutine-的区别"><a href="#goroutine-与-coroutine-的区别" class="headerlink" title="goroutine 与 coroutine 的区别"></a>goroutine 与 coroutine 的区别</h3><h4 id="coroutine"><a href="#coroutine" class="headerlink" title="coroutine"></a>coroutine</h4><p>运行机制属于协作式任务处理，始终顺序执行。</p>
<h4 id="goroutine"><a href="#goroutine" class="headerlink" title="goroutine"></a>goroutine</h4><p>运行机制属于抢占式任务处理，可能发生并行执行。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol>
<li>Go 的并发模型参考了 CSP并发模型，采用 channel 进行通信。</li>
<li>Go 的线程模型参考了两级线程模型，设计出了 MPG 模型。</li>
<li>goroutine 与 coroutine 的区别就是前者可能发生并行执行，后者始终顺序执行。</li>
</ol>
<div class="note note-success">
            <p>并发编程三大特性（并发安全的三个重要指标）——原子性、可见性、有序性</p>
          </div>

<div class="note note-success">
            <p>并发、并行不是一回事儿</p>
          </div>

<h1 id="CPU、内存"><a href="#CPU、内存" class="headerlink" title="CPU、内存"></a>CPU、内存</h1><h2 id="CPU-Cache"><a href="#CPU-Cache" class="headerlink" title="CPU Cache"></a>CPU Cache</h2><p>CPU Cache，是位于 CPU 与 内存 之间的临时存储，要比直接读取内存快；除了速度快，CPU 还会根据一些规则 预热数据，以 Cache line 为单位存储在 CPU Cache 中。<br>CPU Cache 可以分为一级缓存（L1），二级缓存（L2），三级缓存（L3）。</p>
<h3 id="相关文章"><a href="#相关文章" class="headerlink" title="相关文章"></a>相关文章</h3><p><a href="https://www.cnblogs.com/cyfonly/p/5800758.html">https://www.cnblogs.com/cyfonly/p/5800758.html</a></p>
<h3 id="相关问题"><a href="#相关问题" class="headerlink" title="相关问题"></a>相关问题</h3><p>下面的代码有什么问题？<br>没有用到 cpu cache 加速</p>
<h2 id="可见性：由-CPU-Cache-所带来的问题"><a href="#可见性：由-CPU-Cache-所带来的问题" class="headerlink" title="可见性：由 CPU Cache 所带来的问题"></a>可见性：由 CPU Cache 所带来的问题</h2><p>为了解决 CPU 读取内存速度慢的问题，所以增加了CPU缓存，但这也导致了可见性问题。<br>可见性的意思就是线程A修改了一个东西，要对线程B可见。</p>
<h3 id="缓存一致性"><a href="#缓存一致性" class="headerlink" title="缓存一致性"></a>缓存一致性</h3><p>由于 CPU Cache 导致内存不一致的问题，叫做 False sharing，为了解决了这个问题，CPU Cache 引入了缓存一致性协议 MESI。</p>
<h3 id="相关文章-1"><a href="#相关文章-1" class="headerlink" title="相关文章"></a>相关文章</h3><p><a href="https://www.cnblogs.com/cyfonly/p/5800758.html">https://www.cnblogs.com/cyfonly/p/5800758.html</a></p>
<h2 id="有序性：重排所引发的问题"><a href="#有序性：重排所引发的问题" class="headerlink" title="有序性：重排所引发的问题"></a>有序性：重排所引发的问题</h2><p>重排存在于两种情况，如下：<br>CPU重排：会对读写指令进行重排，也可以说是内存重排。<br>编译器重排：编译器在生成指令序列时和CPU执行指令序列时，有可能重排序。</p>
<h3 id="相关文章-2"><a href="#相关文章-2" class="headerlink" title="相关文章"></a>相关文章</h3><p><a href="https://segmentfault.com/a/1190000011458941">https://segmentfault.com/a/1190000011458941</a></p>
<h2 id="happens-before"><a href="#happens-before" class="headerlink" title="happens-before"></a>happens-before</h2><p>为了解决可见性，提出了 happens-before 原则，来指导多线程内存共享层面的设计。</p>
<p>下面是原则描述，但具体的规则指定，各个语言不同。</p>
<ul>
<li>如果一个操作 happens-before 另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前。</li>
<li>两个操作之间存在 happens-before 关系，并不意味着一定要按照 happens-before 原则制定的顺序来执行。如果重排序之后的执行结果与按照 happens-before 关系来执行的结果一致，那么这种重排序并不非法。</li>
</ul>
<h3 id="相关文章-3"><a href="#相关文章-3" class="headerlink" title="相关文章"></a>相关文章</h3><p><a href="https://golang.org/ref/mem">https://golang.org/ref/mem</a><br><a href="https://www.jianshu.com/p/5e44168f47a3">https://www.jianshu.com/p/5e44168f47a3</a><br><a href="https://tiancaiamao.gitbooks.io/go-internals/content/zh/10.1.html">https://tiancaiamao.gitbooks.io/go-internals/content/zh/10.1.html</a><br><a href="https://segmentfault.com/a/1190000021829769">https://segmentfault.com/a/1190000021829769</a><br><a href="https://segmentfault.com/a/1190000011458941">https://segmentfault.com/a/1190000011458941</a><br><a href="https://blog.csdn.net/q5706503/article/details/84994964">https://blog.csdn.net/q5706503/article/details/84994964</a><br><a href="https://www.jianshu.com/p/ba9114542bb7">https://www.jianshu.com/p/ba9114542bb7</a></p>
<h2 id="内存屏障"><a href="#内存屏障" class="headerlink" title="内存屏障"></a>内存屏障</h2><p>内存屏障（Memory Barriers、fence）是一种底层原语。</p>
<p>上面说过，CPU Cache 提高了内存读写性能，但是导致了可见性的相关问题，所以 happens-before 提供了一种原则，提供给编程语言底层在内存管理、并发安全方面的设计。<br>上面还说过，编译器重排、CPU重排，所以，内存屏障也分为编译器屏障和CPU内存屏障。</p>
<p>CPU 级别的指令支持，它要求：barrier 指令要求所有对内存的操作都必须要“扩散”到 memory 之后才能继续执行其他对 memory 的操作。<br>比如在 Go 语言中，atomic 标准库的 CAS（比较并交换），两个操作合二为一，保证原子且有序。</p>
<h4 id="相关文章-4"><a href="#相关文章-4" class="headerlink" title="相关文章"></a>相关文章</h4><p><a href="https://www.jianshu.com/p/89b3e128ebd0?utm_campaign=studygolang.com&utm_medium=studygolang.com&utm_source=studygolang.com">https://www.jianshu.com/p/89b3e128ebd0?utm_campaign=studygolang.com&amp;utm_medium=studygolang.com&amp;utm_source=studygolang.com</a><br><a href="https://lday.me/2017/11/04/0016_what_is_memory_barriers/">https://lday.me/2017/11/04/0016_what_is_memory_barriers/</a></p>
<h2 id="原子性"><a href="#原子性" class="headerlink" title="原子性"></a>原子性</h2><p>可以理解为，计算机中最小粒度的操作。</p>
<p>a = b 是原子操作吗？答案是：非原子操作<br>因为 a = b 实际为两步：先取出 b 的值，再赋值给 a。</p>
<p>继续讨论<br>在第一步，取出 b 的值，是原子操作吗？<br>如果涉及内存访问，就算只有一条汇编指令的在多核系统上也不一定是原子操作。为啥这么说呢，因为：</p>
<p>32位系统CPU一次可处理32位数据，即一次处理4个字节(4 * 8 bit)。<br>64位系统CPU一次可处理64位数据，即一次处理8个字节(8 * 8 bit)。</p>
<p>go的内存模型就是为了解决 single（64位系统处理8字节，确实是原子的，但是不是可见的，因为有cacheline,cpu的应对方法就是mesi，go的方法就是内存屏障）</p>
<p><a href="https://www.cnblogs.com/yeyang/p/13576636.html">https://www.cnblogs.com/yeyang/p/13576636.html</a></p>
]]></content>
      <categories>
        <category>golang</category>
      </categories>
  </entry>
  <entry>
    <title>Go数据结构之数组与切片</title>
    <url>/golang/datastruct-arrayslice/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>数组的长度是声明的时候就固定好的，后面不可能变大，而且长度和容量相等。</p>
<p>切片的长度和容量后面可以随着元素增多而增长，但是容量不可能小于长度。</p>
<span id="more"></span>

<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><h3 id="声明-amp-初始化"><a href="#声明-amp-初始化" class="headerlink" title="声明&amp;初始化"></a>声明&amp;初始化</h3><p>在 Go 中声明即初始化，如果在声明的时候没有初始化值，那么就会赋值为声明类型的「零值」。</p>
<div class="code-wrapper"><pre><code class="hljs reasonml">func <span class="hljs-constructor">TestDemo1(<span class="hljs-params">t</span> <span class="hljs-operator">*</span><span class="hljs-params">testing</span>.T)</span> &#123;
	<span class="hljs-comment">// 数组</span>
	var array1 <span class="hljs-literal">[<span class="hljs-number">5</span>]</span><span class="hljs-built_in">int</span>        <span class="hljs-comment">// 只需设置长度，后面不可变</span>
	var array2 = <span class="hljs-keyword">new</span>(<span class="hljs-literal">[<span class="hljs-number">5</span>]</span><span class="hljs-built_in">int</span>) <span class="hljs-comment">// 返回指针</span>

	<span class="hljs-comment">// 切片</span>
	var slice1 <span class="hljs-literal">[]</span><span class="hljs-built_in">int</span>
	var slice2 = make(<span class="hljs-literal">[]</span><span class="hljs-built_in">int</span>, <span class="hljs-number">5</span>, <span class="hljs-number">5</span>) <span class="hljs-comment">// 设置长度、容量，后面可变</span>

	t.<span class="hljs-constructor">Log(<span class="hljs-string">&quot;array1 val:&quot;</span>, <span class="hljs-params">array1</span>)</span>      <span class="hljs-comment">// [0 0 0 0 0]</span>
	t.<span class="hljs-constructor">Log(<span class="hljs-string">&quot;array1 len:&quot;</span>, <span class="hljs-params">len</span>(<span class="hljs-params">array1</span>)</span>) <span class="hljs-comment">// 5</span>
	t.<span class="hljs-constructor">Log(<span class="hljs-string">&quot;array1 cap:&quot;</span>, <span class="hljs-params">cap</span>(<span class="hljs-params">array1</span>)</span>) <span class="hljs-comment">// 5</span>

	fmt.<span class="hljs-constructor">Println(<span class="hljs-string">&quot;&quot;</span>)</span>

	t.<span class="hljs-constructor">Log(<span class="hljs-string">&quot;array2 val:&quot;</span>, <span class="hljs-params">array2</span>)</span>      <span class="hljs-comment">// &amp;[0 0 0 0 0]</span>
	t.<span class="hljs-constructor">Log(<span class="hljs-string">&quot;array2 len:&quot;</span>, <span class="hljs-params">len</span>(<span class="hljs-params">array2</span>)</span>) <span class="hljs-comment">// 5</span>
	t.<span class="hljs-constructor">Log(<span class="hljs-string">&quot;array2 cap:&quot;</span>, <span class="hljs-params">cap</span>(<span class="hljs-params">array2</span>)</span>) <span class="hljs-comment">// 5</span>

	fmt.<span class="hljs-constructor">Println(<span class="hljs-string">&quot;&quot;</span>)</span>

	t.<span class="hljs-constructor">Log(<span class="hljs-string">&quot;slice1 val:&quot;</span>, <span class="hljs-params">slice1</span>)</span>      <span class="hljs-comment">// []</span>
	t.<span class="hljs-constructor">Log(<span class="hljs-string">&quot;slice1 len:&quot;</span>, <span class="hljs-params">len</span>(<span class="hljs-params">slice1</span>)</span>) <span class="hljs-comment">// 0</span>
	t.<span class="hljs-constructor">Log(<span class="hljs-string">&quot;slice1 cap:&quot;</span>, <span class="hljs-params">cap</span>(<span class="hljs-params">slice1</span>)</span>) <span class="hljs-comment">// 0</span>

	fmt.<span class="hljs-constructor">Println(<span class="hljs-string">&quot;&quot;</span>)</span>

	t.<span class="hljs-constructor">Log(<span class="hljs-string">&quot;slice2 val:&quot;</span>, <span class="hljs-params">slice2</span>)</span>      <span class="hljs-comment">// [0 0 0 0 0]</span>
	t.<span class="hljs-constructor">Log(<span class="hljs-string">&quot;slice2 len:&quot;</span>, <span class="hljs-params">len</span>(<span class="hljs-params">slice2</span>)</span>) <span class="hljs-comment">// 5</span>
	t.<span class="hljs-constructor">Log(<span class="hljs-string">&quot;slice2 cap:&quot;</span>, <span class="hljs-params">cap</span>(<span class="hljs-params">slice2</span>)</span>) <span class="hljs-comment">// 5</span>
&#125;</code></pre></div>

<p>在声明的时候就初始化：</p>
<div class="code-wrapper"><pre><code class="hljs reasonml">func <span class="hljs-constructor">TestDemo2(<span class="hljs-params">t</span> <span class="hljs-operator">*</span><span class="hljs-params">testing</span>.T)</span> &#123;
	<span class="hljs-comment">// 数组</span>
	var array1 = <span class="hljs-literal">[<span class="hljs-number">5</span>]</span><span class="hljs-built_in">int</span>&#123;<span class="hljs-number">4</span>: <span class="hljs-number">1</span>, <span class="hljs-number">2</span>: <span class="hljs-number">5</span>&#125;
	var array2 = <span class="hljs-literal">[<span class="hljs-operator">...</span>]</span><span class="hljs-built_in">int</span>&#123;<span class="hljs-number">4</span>: <span class="hljs-number">1</span>, <span class="hljs-number">2</span>: <span class="hljs-number">5</span>&#125;

	<span class="hljs-comment">// 切片</span>
	var slice1 = <span class="hljs-literal">[]</span><span class="hljs-built_in">int</span>&#123;<span class="hljs-number">4</span>: <span class="hljs-number">1</span>, <span class="hljs-number">2</span>: <span class="hljs-number">5</span>&#125;
	var slice2 = array1<span class="hljs-literal">[:]</span> <span class="hljs-comment">// 从数组截取来的切片</span>

	t.<span class="hljs-constructor">Log(<span class="hljs-string">&quot;array1 val:&quot;</span>, <span class="hljs-params">array1</span>)</span>      <span class="hljs-comment">// [0 0 5 0 1]</span>
	t.<span class="hljs-constructor">Log(<span class="hljs-string">&quot;array1 len:&quot;</span>, <span class="hljs-params">len</span>(<span class="hljs-params">array1</span>)</span>) <span class="hljs-comment">// 5</span>
	t.<span class="hljs-constructor">Log(<span class="hljs-string">&quot;array1 cap:&quot;</span>, <span class="hljs-params">cap</span>(<span class="hljs-params">array1</span>)</span>) <span class="hljs-comment">// 5</span>

	fmt.<span class="hljs-constructor">Println(<span class="hljs-string">&quot;&quot;</span>)</span>

	t.<span class="hljs-constructor">Log(<span class="hljs-string">&quot;array2 val:&quot;</span>, <span class="hljs-params">array2</span>)</span>      <span class="hljs-comment">// [0 0 5 0 1]</span>
	t.<span class="hljs-constructor">Log(<span class="hljs-string">&quot;array2 len:&quot;</span>, <span class="hljs-params">len</span>(<span class="hljs-params">array2</span>)</span>) <span class="hljs-comment">// 5</span>
	t.<span class="hljs-constructor">Log(<span class="hljs-string">&quot;array2 cap:&quot;</span>, <span class="hljs-params">cap</span>(<span class="hljs-params">array2</span>)</span>) <span class="hljs-comment">// 5</span>

	fmt.<span class="hljs-constructor">Println(<span class="hljs-string">&quot;&quot;</span>)</span>

	t.<span class="hljs-constructor">Log(<span class="hljs-string">&quot;slice1 val:&quot;</span>, <span class="hljs-params">slice1</span>)</span>      <span class="hljs-comment">// [0 0 5 0 1]</span>
	t.<span class="hljs-constructor">Log(<span class="hljs-string">&quot;slice1 len:&quot;</span>, <span class="hljs-params">len</span>(<span class="hljs-params">slice1</span>)</span>) <span class="hljs-comment">// 5</span>
	t.<span class="hljs-constructor">Log(<span class="hljs-string">&quot;slice1 cap:&quot;</span>, <span class="hljs-params">cap</span>(<span class="hljs-params">slice1</span>)</span>) <span class="hljs-comment">// 5</span>

	fmt.<span class="hljs-constructor">Println(<span class="hljs-string">&quot;&quot;</span>)</span>

	t.<span class="hljs-constructor">Log(<span class="hljs-string">&quot;slice2 val:&quot;</span>, <span class="hljs-params">slice2</span>)</span>      <span class="hljs-comment">// [0 0 5 0 1]</span>
	t.<span class="hljs-constructor">Log(<span class="hljs-string">&quot;slice2 len:&quot;</span>, <span class="hljs-params">len</span>(<span class="hljs-params">slice2</span>)</span>) <span class="hljs-comment">// 5</span>
	t.<span class="hljs-constructor">Log(<span class="hljs-string">&quot;slice2 cap:&quot;</span>, <span class="hljs-params">cap</span>(<span class="hljs-params">slice2</span>)</span>) <span class="hljs-comment">// 5</span>
&#125;</code></pre></div>


<h3 id="添加-amp-更新元素值"><a href="#添加-amp-更新元素值" class="headerlink" title="添加&amp;更新元素值"></a>添加&amp;更新元素值</h3><p>数组因为长度固定，且的值都是初始化好了的，所以只有更新。</p>
<p>切片更新操作和数据一样，只不过新增元素只能通过 append() 方法。</p>
<blockquote>
<p>append()：将元素追加大切片的末尾，如果容量不够，会进行扩容。</p>
</blockquote>
<div class="code-wrapper"><pre><code class="hljs reasonml">func <span class="hljs-constructor">TestDemo3(<span class="hljs-params">t</span> <span class="hljs-operator">*</span><span class="hljs-params">testing</span>.T)</span> &#123;
	<span class="hljs-comment">// 数组</span>
	var array1 = <span class="hljs-literal">[<span class="hljs-number">5</span>]</span><span class="hljs-built_in">int</span>&#123;<span class="hljs-number">4</span>: <span class="hljs-number">1</span>, <span class="hljs-number">2</span>: <span class="hljs-number">5</span>&#125;
	array1<span class="hljs-literal">[<span class="hljs-number">0</span>]</span> = <span class="hljs-number">100</span> <span class="hljs-comment">// 更新</span>
	array1<span class="hljs-literal">[<span class="hljs-number">4</span>]</span> = <span class="hljs-number">100</span> <span class="hljs-comment">// 更新</span>

	<span class="hljs-comment">// 切片</span>
	var slice1 = <span class="hljs-literal">[]</span><span class="hljs-built_in">int</span>&#123;<span class="hljs-number">4</span>: <span class="hljs-number">1</span>, <span class="hljs-number">2</span>: <span class="hljs-number">5</span>&#125;
	array1<span class="hljs-literal">[<span class="hljs-number">4</span>]</span> = <span class="hljs-number">100</span> <span class="hljs-comment">// 更新</span>
	<span class="hljs-comment">//array1[5] = 100 // 报错</span>
	slice1 = append(slice1, <span class="hljs-number">1</span>) <span class="hljs-comment">// 切片增加元素只能使用此方法</span>

	t.<span class="hljs-constructor">Log(<span class="hljs-string">&quot;array1 val:&quot;</span>, <span class="hljs-params">array1</span>)</span>      <span class="hljs-comment">// [100 0 5 0 100]</span>
	t.<span class="hljs-constructor">Log(<span class="hljs-string">&quot;array1 len:&quot;</span>, <span class="hljs-params">len</span>(<span class="hljs-params">array1</span>)</span>) <span class="hljs-comment">// 5</span>
	t.<span class="hljs-constructor">Log(<span class="hljs-string">&quot;array1 cap:&quot;</span>, <span class="hljs-params">cap</span>(<span class="hljs-params">array1</span>)</span>) <span class="hljs-comment">// 5</span>

	fmt.<span class="hljs-constructor">Println(<span class="hljs-string">&quot;&quot;</span>)</span>

	t.<span class="hljs-constructor">Log(<span class="hljs-string">&quot;slice1 val:&quot;</span>, <span class="hljs-params">slice1</span>)</span>      <span class="hljs-comment">// [0 0 5 0 1 1]</span>
	t.<span class="hljs-constructor">Log(<span class="hljs-string">&quot;slice1 len:&quot;</span>, <span class="hljs-params">len</span>(<span class="hljs-params">slice1</span>)</span>) <span class="hljs-comment">// 6</span>
	t.<span class="hljs-constructor">Log(<span class="hljs-string">&quot;slice1 cap:&quot;</span>, <span class="hljs-params">cap</span>(<span class="hljs-params">slice1</span>)</span>) <span class="hljs-comment">// 10</span>
&#125;</code></pre></div>


<h3 id="表达式"><a href="#表达式" class="headerlink" title="表达式"></a>表达式</h3><p>数组与切片，都可以使用表达式截取，截取之后的数据它的类型为切片。</p>
<div class="code-wrapper"><pre><code class="hljs awk"><span class="hljs-keyword">func</span> TestDemo4(t *testing.T) &#123;
	array1 := [<span class="hljs-number">10</span>]int&#123;<span class="hljs-number">9</span>, <span class="hljs-number">1</span>, <span class="hljs-number">7</span>, <span class="hljs-number">3</span>, <span class="hljs-number">0</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">2</span>, <span class="hljs-number">8</span>, <span class="hljs-number">4</span>&#125;

	slice1 := array1[<span class="hljs-number">3</span>:]              <span class="hljs-regexp">//</span> 从 index <span class="hljs-number">3</span> 取到 index end
	t.Log(<span class="hljs-string">&quot;slice1 val:&quot;</span>, slice1)      <span class="hljs-regexp">//</span> [<span class="hljs-number">3</span> <span class="hljs-number">0</span> <span class="hljs-number">5</span> <span class="hljs-number">6</span> <span class="hljs-number">2</span> <span class="hljs-number">8</span> <span class="hljs-number">4</span>]
	t.Log(<span class="hljs-string">&quot;slice1 len:&quot;</span>, len(slice1)) <span class="hljs-regexp">//</span> <span class="hljs-number">7</span>
	t.Log(<span class="hljs-string">&quot;slice1 cap:&quot;</span>, cap(slice1)) <span class="hljs-regexp">//</span> <span class="hljs-number">7</span>

	fmt.Println(<span class="hljs-string">&quot;&quot;</span>)

	slice2 := array1[<span class="hljs-number">3</span>:<span class="hljs-number">4</span>]             <span class="hljs-regexp">//</span> 从 index <span class="hljs-number">3</span> 取到 index <span class="hljs-number">4</span>
	t.Log(<span class="hljs-string">&quot;slice2 val:&quot;</span>, slice2)      <span class="hljs-regexp">//</span> [<span class="hljs-number">3</span>]
	t.Log(<span class="hljs-string">&quot;slice2 len:&quot;</span>, len(slice2)) <span class="hljs-regexp">//</span> <span class="hljs-number">1</span>
	t.Log(<span class="hljs-string">&quot;slice2 cap:&quot;</span>, cap(slice2)) <span class="hljs-regexp">//</span> <span class="hljs-number">7</span>

	fmt.Println(<span class="hljs-string">&quot;&quot;</span>)

	slice3 := array1[<span class="hljs-number">3</span>:<span class="hljs-number">6</span>:<span class="hljs-number">6</span>]           <span class="hljs-regexp">//</span> 从 index <span class="hljs-number">3</span> 取到 index <span class="hljs-number">6</span>，容量取到 index <span class="hljs-number">6</span>
	t.Log(<span class="hljs-string">&quot;slice3 val:&quot;</span>, slice3)      <span class="hljs-regexp">//</span> [<span class="hljs-number">3</span> <span class="hljs-number">0</span> <span class="hljs-number">5</span>]
	t.Log(<span class="hljs-string">&quot;slice3 len:&quot;</span>, len(slice3)) <span class="hljs-regexp">//</span> <span class="hljs-number">3</span>
	t.Log(<span class="hljs-string">&quot;slice3 cap:&quot;</span>, cap(slice3)) <span class="hljs-regexp">//</span> <span class="hljs-number">3</span>

	fmt.Println(<span class="hljs-string">&quot;&quot;</span>)

	slice4 := array1[<span class="hljs-number">3</span>:<span class="hljs-number">6</span>:<span class="hljs-number">9</span>]           <span class="hljs-regexp">//</span> 从 index <span class="hljs-number">3</span> 取到 index <span class="hljs-number">6</span>，容量取到 index <span class="hljs-number">9</span>
	t.Log(<span class="hljs-string">&quot;slice4 val:&quot;</span>, slice4)      <span class="hljs-regexp">//</span> [<span class="hljs-number">3</span> <span class="hljs-number">0</span> <span class="hljs-number">5</span>]
	t.Log(<span class="hljs-string">&quot;slice4 len:&quot;</span>, len(slice4)) <span class="hljs-regexp">//</span> <span class="hljs-number">3</span>
	t.Log(<span class="hljs-string">&quot;slice4 cap:&quot;</span>, cap(slice4)) <span class="hljs-regexp">//</span> <span class="hljs-number">6</span>
&#125;</code></pre></div>

<h3 id="遍历"><a href="#遍历" class="headerlink" title="遍历"></a>遍历</h3><p>使用 for、range</p>
<div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestDemo5</span><span class="hljs-params">(t *testing.T)</span></span> &#123;
	array1 := [...]<span class="hljs-keyword">int</span>&#123;<span class="hljs-number">9</span>, <span class="hljs-number">1</span>, <span class="hljs-number">7</span>, <span class="hljs-number">3</span>, <span class="hljs-number">0</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">2</span>, <span class="hljs-number">8</span>, <span class="hljs-number">4</span>&#125;
	slice1 := <span class="hljs-built_in">make</span>([]<span class="hljs-keyword">int</span>, <span class="hljs-number">5</span>, <span class="hljs-number">5</span>)
	<span class="hljs-keyword">for</span> k, v := <span class="hljs-keyword">range</span> array1 &#123;
		fmt.Println(k, <span class="hljs-string">&quot;-&quot;</span>, v)
	&#125;
	fmt.Println()
	<span class="hljs-keyword">for</span> k, v := <span class="hljs-keyword">range</span> slice1 &#123;
		fmt.Println(k, <span class="hljs-string">&quot;-&quot;</span>, v)
	&#125;
&#125;</code></pre></div>

<h3 id="比较"><a href="#比较" class="headerlink" title="比较"></a>比较</h3><p>数组与数组可以使用 == 比较，不能与 nil 比较</p>
<p>切片与切片不能使用 == 比较，可以使用 reflect.DeepEqual 比较，可以与 nil 比较</p>
<div class="code-wrapper"><pre><code class="hljs jboss-cli">func TestDemo6<span class="hljs-params">(t *testing.T)</span> &#123;
	array1 := [<span class="hljs-string">...</span>]int&#123;9, 1, 7, 3, 0, 5, 6, 2, 8, 4&#125;
	array2 := [<span class="hljs-string">...</span>]int&#123;9, 1, 7, 3, 0, 5, 6, 2, 8, 9&#125;
	array3 := [<span class="hljs-string">...</span>]int&#123;9, 1, 7, 3, 0, 5, 6, 2, 8, 9&#125;

	t.Logf<span class="hljs-params">(&quot;<span class="hljs-attr">array1</span> == array2 %t\n&quot;, <span class="hljs-attr">array1</span> == array2)</span> <span class="hljs-string">//</span> <span class="hljs-literal">false</span>
	t.Logf<span class="hljs-params">(&quot;<span class="hljs-attr">array2</span> == array3 %t\n&quot;, <span class="hljs-attr">array2</span> == array3)</span> <span class="hljs-string">//</span> <span class="hljs-literal">true</span>
	<span class="hljs-string">//t.Logf</span><span class="hljs-params">(&quot;%t\n&quot;, <span class="hljs-attr">array2</span> == nil)</span> <span class="hljs-string">//</span> 会报错，数组不能与nil比

	slice1 := make<span class="hljs-params">([]int, 5, 5)</span>
	var slice2 []int
	slice3 := []int&#123;4: 0&#125;

	<span class="hljs-string">//</span> t.Logf<span class="hljs-params">(&quot;%t\n&quot;, <span class="hljs-attr">slice1</span> == slice2)</span> <span class="hljs-string">//</span> 会报错，切片与切片不能比
	t.Logf<span class="hljs-params">(&quot;<span class="hljs-attr">slice1</span> == nil %t\n&quot;, <span class="hljs-attr">slice1</span> == nil)</span> <span class="hljs-string">//</span> <span class="hljs-literal">false</span>
	t.Logf<span class="hljs-params">(&quot;<span class="hljs-attr">slice2</span> == nil %t\n&quot;, <span class="hljs-attr">slice2</span> == nil)</span> <span class="hljs-string">//</span> <span class="hljs-literal">true</span>
	t.Logf<span class="hljs-params">(&quot;<span class="hljs-attr">slice3</span> == nil %t\n&quot;, <span class="hljs-attr">slice3</span> == nil)</span> <span class="hljs-string">//</span> <span class="hljs-literal">false</span>

	t.Logf<span class="hljs-params">(&quot;<span class="hljs-attr">slice1</span> == slice2 %t\n&quot;, reflect.DeepEqual(slice1, slice2)</span>) <span class="hljs-string">//</span> <span class="hljs-literal">false</span>
	t.Logf<span class="hljs-params">(&quot;<span class="hljs-attr">slice2</span> == slice3 %t\n&quot;, reflect.DeepEqual(slice2, slice3)</span>) <span class="hljs-string">//</span> <span class="hljs-literal">false</span>
	t.Logf<span class="hljs-params">(&quot;<span class="hljs-attr">slice1</span> == slice3 %t\n&quot;, reflect.DeepEqual(slice1, slice3)</span>) <span class="hljs-string">//</span> <span class="hljs-literal">true</span>
&#125;</code></pre></div>


<h3 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h3><p>需使用 append()、切片表达式 结合来完成</p>
<div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestDemo7</span><span class="hljs-params">(t *testing.T)</span></span> &#123;
	slice1 := []<span class="hljs-keyword">int</span>&#123;<span class="hljs-number">9</span>, <span class="hljs-number">1</span>, <span class="hljs-number">7</span>, <span class="hljs-number">3</span>, <span class="hljs-number">0</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">2</span>, <span class="hljs-number">8</span>, <span class="hljs-number">4</span>&#125;
	slice1 = <span class="hljs-built_in">append</span>(slice1[:<span class="hljs-number">2</span>], slice1[<span class="hljs-number">3</span>:]...)
	t.Log(slice1)
&#125;</code></pre></div>


<h2 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h2><h3 id="数组与切片的关系"><a href="#数组与切片的关系" class="headerlink" title="数组与切片的关系"></a>数组与切片的关系</h3><p><strong>数组为值类型，切片为引用类型</strong>，他们又有何关系呢？</p>
<p>程序示例：</p>
<div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestDemo8</span><span class="hljs-params">(t *testing.T)</span></span> &#123;
	array1 := [<span class="hljs-number">10</span>]<span class="hljs-keyword">int</span>&#123;<span class="hljs-number">9</span>, <span class="hljs-number">1</span>, <span class="hljs-number">7</span>, <span class="hljs-number">3</span>, <span class="hljs-number">0</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">2</span>, <span class="hljs-number">8</span>, <span class="hljs-number">4</span>&#125;

	slice1 := array1[:]

	t.Log(<span class="hljs-string">&quot;slice1 val:&quot;</span>, slice1)      <span class="hljs-comment">// [9 1 7 3 0 5 6 2 8 4]</span>
	t.Log(<span class="hljs-string">&quot;slice1 len:&quot;</span>, <span class="hljs-built_in">len</span>(slice1)) <span class="hljs-comment">// 10</span>
	t.Log(<span class="hljs-string">&quot;slice1 cap:&quot;</span>, <span class="hljs-built_in">cap</span>(slice1)) <span class="hljs-comment">// 10</span>

	array1[<span class="hljs-number">9</span>] = <span class="hljs-number">96969696</span> <span class="hljs-comment">// array1 的修改会影响到 slice1</span>

	fmt.Println(<span class="hljs-string">&quot;&quot;</span>)

	t.Log(<span class="hljs-string">&quot;slice1 val:&quot;</span>, slice1)      <span class="hljs-comment">// [9 1 7 3 0 5 6 2 8 96969696]</span>
	t.Log(<span class="hljs-string">&quot;slice1 len:&quot;</span>, <span class="hljs-built_in">len</span>(slice1)) <span class="hljs-comment">// 10</span>
	t.Log(<span class="hljs-string">&quot;slice1 cap:&quot;</span>, <span class="hljs-built_in">cap</span>(slice1)) <span class="hljs-comment">// 10</span>
&#125;</code></pre></div>
<p>在这个示例程序中，可以说 slice1 是 array1 的引用。</p>
<p>不光是在示例程序中，这种在数组上通过表达式截取出的切片，为数组的引用，就算在程序中，直接声明一个新切片（var slice1 []int），在切片的底层实现，其实也是引用了一个数组。</p>
<p>他们的关系就是：<strong>数组是切片的底层实现，切片是数组的引用。</strong></p>
<h3 id="切片扩容"><a href="#切片扩容" class="headerlink" title="切片扩容"></a>切片扩容</h3><p>在示例程序 TestDemo8 中，slice1 会一直引用 array1 么？</p>
<p>一般情况下是这样，但有种情况下引用会发生变化，就是在 slice 发生扩容的情况下</p>
<div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestDemo9</span><span class="hljs-params">(t *testing.T)</span></span> &#123;
	array1 := [<span class="hljs-number">10</span>]<span class="hljs-keyword">int</span>&#123;<span class="hljs-number">9</span>, <span class="hljs-number">1</span>, <span class="hljs-number">7</span>, <span class="hljs-number">3</span>, <span class="hljs-number">0</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">2</span>, <span class="hljs-number">8</span>, <span class="hljs-number">4</span>&#125;
	slice1 := array1[:] <span class="hljs-comment">// 从 array1 截取出 slice1</span>

	t.Log(<span class="hljs-string">&quot;slice1 val:&quot;</span>, slice1)      <span class="hljs-comment">// [9 1 7 3 0 5 6 2 8 4]</span>
	t.Log(<span class="hljs-string">&quot;slice1 len:&quot;</span>, <span class="hljs-built_in">len</span>(slice1)) <span class="hljs-comment">// 10</span>
	t.Log(<span class="hljs-string">&quot;slice1 cap:&quot;</span>, <span class="hljs-built_in">cap</span>(slice1)) <span class="hljs-comment">// 10</span>

	slice1 = <span class="hljs-built_in">append</span>(slice1, <span class="hljs-number">9</span>) <span class="hljs-comment">// 进行扩容后，slice1 指向了新的底层数组，不在是 array1 的引用</span>
	array1[<span class="hljs-number">9</span>] = <span class="hljs-number">96969696</span>

	fmt.Println(<span class="hljs-string">&quot;&quot;</span>)

	t.Log(<span class="hljs-string">&quot;slice1 val:&quot;</span>, slice1)      <span class="hljs-comment">// [9 1 7 3 0 5 6 2 8 4 9]</span>
	t.Log(<span class="hljs-string">&quot;slice1 len:&quot;</span>, <span class="hljs-built_in">len</span>(slice1)) <span class="hljs-comment">// 11</span>
	t.Log(<span class="hljs-string">&quot;slice1 cap:&quot;</span>, <span class="hljs-built_in">cap</span>(slice1)) <span class="hljs-comment">// 20</span>
&#125;</code></pre></div>
<p>当切片添加新元素，发现容量不够时，会开辟一个新的底层数组，然后把旧数组的数据和添加的新元素一并拷贝到新数组中。</p>
<h4 id="扩容策略："><a href="#扩容策略：" class="headerlink" title="扩容策略："></a>扩容策略：</h4><ul>
<li>首先判断，如果新申请容量（cap）大于2倍的旧容量（old.cap），最终容量（newcap）就是新申请的容量（cap）</li>
<li>否则判断，如果旧切片的长度小于1024，则最终容量(newcap)就是旧容量(old.cap)的两倍，即（newcap=doublecap）</li>
<li>否则判断，如果旧切片长度大于等于1024，则最终容量（newcap）从旧容量（old.cap）开始循环增加原来的 1/4，即（newcap=old.cap,for {newcap += newcap/4}）直到最终容量（newcap）大于等于新申请的容量(cap)，即（newcap &gt;= cap）</li>
<li>如果最终容量（cap）计算值溢出，则最终容量（cap）就是新申请容量（cap）</li>
</ul>
<h3 id="深复制"><a href="#深复制" class="headerlink" title="深复制"></a>深复制</h3><p>靠扩容解决引用问题，显得不是那么优雅。</p>
<p>可以使用 copy() 进行深复制</p>
<div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestDemo10</span><span class="hljs-params">(t *testing.T)</span></span> &#123;
	array1 := [<span class="hljs-number">10</span>]<span class="hljs-keyword">int</span>&#123;<span class="hljs-number">9</span>, <span class="hljs-number">1</span>, <span class="hljs-number">7</span>, <span class="hljs-number">3</span>, <span class="hljs-number">0</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">2</span>, <span class="hljs-number">8</span>, <span class="hljs-number">4</span>&#125;

	<span class="hljs-keyword">var</span> slice1 = <span class="hljs-built_in">make</span>([]<span class="hljs-keyword">int</span>, <span class="hljs-number">10</span>, <span class="hljs-number">10</span>)
	<span class="hljs-built_in">copy</span>(slice1, array1[:]) <span class="hljs-comment">// 深复制，slice1 不会引用 array1</span>
	array1[<span class="hljs-number">9</span>] = <span class="hljs-number">96969696</span>

	t.Log(<span class="hljs-string">&quot;slice1 val:&quot;</span>, slice1)      <span class="hljs-comment">// [9 1 7 3 0 5 6 2 8 4]</span>
	t.Log(<span class="hljs-string">&quot;slice1 len:&quot;</span>, <span class="hljs-built_in">len</span>(slice1)) <span class="hljs-comment">// 10</span>
	t.Log(<span class="hljs-string">&quot;slice1 cap:&quot;</span>, <span class="hljs-built_in">cap</span>(slice1)) <span class="hljs-comment">// 10</span>

	fmt.Println(<span class="hljs-string">&quot;&quot;</span>)

	t.Log(<span class="hljs-string">&quot;array1 val:&quot;</span>, array1)      <span class="hljs-comment">// [9 1 7 3 0 5 6 2 8 96969696]</span>
	t.Log(<span class="hljs-string">&quot;array1 len:&quot;</span>, <span class="hljs-built_in">len</span>(array1)) <span class="hljs-comment">// 10</span>
	t.Log(<span class="hljs-string">&quot;array1 cap:&quot;</span>, <span class="hljs-built_in">cap</span>(array1)) <span class="hljs-comment">// 10</span>
&#125;</code></pre></div>


<h3 id="传递"><a href="#传递" class="headerlink" title="传递"></a>传递</h3><p>切片，如果不使用 copy() 进行深复制出一个新的切片，直接传递过去的切片底层还是同一个数组，当然，append() 发生了扩容之后，就不会是同一个数组了。</p>
<p>数组，直接传递会变成两个数组，如果运用了指针，会指向同一个。</p>
<div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestDemo11</span><span class="hljs-params">(t *testing.T)</span></span> &#123;
	<span class="hljs-comment">// 切片，底层引用的还是同一个数组</span>
	slice1 := []<span class="hljs-keyword">int</span>&#123;<span class="hljs-number">9</span>, <span class="hljs-number">1</span>, <span class="hljs-number">7</span>, <span class="hljs-number">3</span>, <span class="hljs-number">0</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">2</span>, <span class="hljs-number">8</span>, <span class="hljs-number">4</span>&#125;
	<span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(v []<span class="hljs-keyword">int</span>)</span></span> &#123;
		<span class="hljs-comment">//v = append(v, 20) // 扩容后底层数组就变了</span>
		v[<span class="hljs-number">0</span>] = <span class="hljs-number">99999</span>
		t.Log(v)
	&#125;(slice1)
	time.Sleep(<span class="hljs-number">1</span> * time.Second)
	t.Log(<span class="hljs-string">&quot;slice1&quot;</span>, slice1) <span class="hljs-comment">// slice1 [99999 1 7 3 0 5 6 2 8 4]</span>

	fmt.Println()

	<span class="hljs-comment">// 切片，copy() 深复制后，底层不是同一个数组</span>
	slice2 := []<span class="hljs-keyword">int</span>&#123;<span class="hljs-number">9</span>, <span class="hljs-number">1</span>, <span class="hljs-number">7</span>, <span class="hljs-number">3</span>, <span class="hljs-number">0</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">2</span>, <span class="hljs-number">8</span>, <span class="hljs-number">4</span>&#125;
	slice2Copy := <span class="hljs-built_in">make</span>([]<span class="hljs-keyword">int</span>, <span class="hljs-number">10</span>, <span class="hljs-number">10</span>)
	<span class="hljs-built_in">copy</span>(slice2Copy, slice2)
	<span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(v []<span class="hljs-keyword">int</span>)</span></span> &#123;
		v[<span class="hljs-number">0</span>] = <span class="hljs-number">99999</span>
	&#125;(slice2Copy)
	time.Sleep(<span class="hljs-number">1</span> * time.Second)
	t.Log(<span class="hljs-string">&quot;slice2&quot;</span>, slice2) <span class="hljs-comment">// slice2 [9 1 7 3 0 5 6 2 8 4]</span>

	fmt.Println()

	<span class="hljs-comment">// 数组，不是同一个</span>
	array1 := [<span class="hljs-number">10</span>]<span class="hljs-keyword">int</span>&#123;<span class="hljs-number">9</span>, <span class="hljs-number">1</span>, <span class="hljs-number">7</span>, <span class="hljs-number">3</span>, <span class="hljs-number">0</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">2</span>, <span class="hljs-number">8</span>, <span class="hljs-number">4</span>&#125;
	<span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(v [10]<span class="hljs-keyword">int</span>)</span></span> &#123;
		v[<span class="hljs-number">0</span>] = <span class="hljs-number">99999</span>
	&#125;(array1)
	time.Sleep(<span class="hljs-number">1</span> * time.Second)
	t.Log(<span class="hljs-string">&quot;array1&quot;</span>, array1) <span class="hljs-comment">// array1 [9 1 7 3 0 5 6 2 8 4]</span>
	fmt.Println()

	<span class="hljs-comment">// 数组，同一个</span>
	array2 := [<span class="hljs-number">10</span>]<span class="hljs-keyword">int</span>&#123;<span class="hljs-number">9</span>, <span class="hljs-number">1</span>, <span class="hljs-number">7</span>, <span class="hljs-number">3</span>, <span class="hljs-number">0</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">2</span>, <span class="hljs-number">8</span>, <span class="hljs-number">4</span>&#125;
	<span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(v *[10]<span class="hljs-keyword">int</span>)</span></span> &#123;
		v[<span class="hljs-number">0</span>] = <span class="hljs-number">99999</span>
	&#125;(&amp;array2)
	time.Sleep(<span class="hljs-number">1</span> * time.Second)
	t.Log(<span class="hljs-string">&quot;array2&quot;</span>, array2) <span class="hljs-comment">// array2 [99999 1 7 3 0 5 6 2 8 4]</span>

	fmt.Println()

	<span class="hljs-comment">// 数组 同一个</span>
	array3 := <span class="hljs-built_in">new</span>([<span class="hljs-number">10</span>]<span class="hljs-keyword">int</span>)
	<span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(v *[10]<span class="hljs-keyword">int</span>)</span></span> &#123;
		v[<span class="hljs-number">0</span>] = <span class="hljs-number">99999</span>
	&#125;(array3)
	time.Sleep(<span class="hljs-number">1</span> * time.Second)
	t.Log(<span class="hljs-string">&quot;array3&quot;</span>, array3) <span class="hljs-comment">// array3 &amp;[99999 0 0 0 0 0 0 0 0 0]</span>
&#125;</code></pre></div>
<p>效果和下面一样</p>
<div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestDemo12</span><span class="hljs-params">(t *testing.T)</span></span> &#123;
	array1 := [<span class="hljs-number">10</span>]<span class="hljs-keyword">int</span>&#123;<span class="hljs-number">9</span>, <span class="hljs-number">1</span>, <span class="hljs-number">7</span>, <span class="hljs-number">3</span>, <span class="hljs-number">0</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">2</span>, <span class="hljs-number">8</span>, <span class="hljs-number">4</span>&#125;
	array2 := array1
	array2[<span class="hljs-number">0</span>] = <span class="hljs-number">999</span>
	t.Log(<span class="hljs-string">&quot;array1&quot;</span>, array1) <span class="hljs-comment">// array1 [9 1 7 3 0 5 6 2 8 4]</span>
	t.Log(<span class="hljs-string">&quot;array2&quot;</span>, array2) <span class="hljs-comment">// array2 [999 1 7 3 0 5 6 2 8 4]</span>

	fmt.Println()

	slice1 := []<span class="hljs-keyword">int</span>&#123;<span class="hljs-number">9</span>, <span class="hljs-number">1</span>, <span class="hljs-number">7</span>, <span class="hljs-number">3</span>, <span class="hljs-number">0</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">2</span>, <span class="hljs-number">8</span>, <span class="hljs-number">4</span>&#125;
	slice2 := slice1
	slice2[<span class="hljs-number">0</span>] = <span class="hljs-number">999</span>
	t.Log(<span class="hljs-string">&quot;slice1&quot;</span>, slice1) <span class="hljs-comment">// slice1 [999 1 7 3 0 5 6 2 8 4]</span>
	t.Log(<span class="hljs-string">&quot;slice2&quot;</span>, slice2) <span class="hljs-comment">// slice2 [999 1 7 3 0 5 6 2 8 4]</span>
&#125;</code></pre></div>


<h3 id="数组"><a href="#数组" class="headerlink" title="数组"></a>数组</h3><p>一段连续的内存空间。</p>
<h3 id="make"><a href="#make" class="headerlink" title="make"></a>make</h3><p>make 只能用于 slice、map、channel，返回的初始化后的（非零）值。</p>
<h3 id="引用类型"><a href="#引用类型" class="headerlink" title="引用类型"></a>引用类型</h3><ul>
<li>切片</li>
<li>字典</li>
<li>通道</li>
<li>函数</li>
</ul>
<h3 id="值类型"><a href="#值类型" class="headerlink" title="值类型"></a>值类型</h3><ul>
<li>数组</li>
<li>基础数据类型</li>
<li>结构体类型</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol>
<li>切片是数组的引用，数组是切片的底层实现。</li>
<li>数组的长度(len)等于容量(cap)，切片的长度(len)小于等于容量(cap)。</li>
<li>数组声明的时候默认就会初始化，值为类型的「零值」；切片声明的时候，如果不初始化，值是 nil。</li>
<li>使用 copy() 深复制解决引用问题。</li>
</ol>
<p><a href="https://github.com/zuoshuwen/go-example/blob/master/e005/a01_test.go">文章示例代码</a></p>
]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>数组</tag>
        <tag>切片</tag>
      </tags>
  </entry>
  <entry>
    <title>Go并发编程之传统同步—(3)原子操作</title>
    <url>/golang/ipc-atomic/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>之前文章中介绍的互斥锁虽然能够保证同串行化，但是却保证不了执行过程中的中断。<br>要么成功、要么失败，没有中断的情况，我们叫它叫原子性，这种由硬件 CPU 提供支持的特性，是非常可靠的。</p>
<p><a href="https://baike.baidu.com/item/%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C">百度百科</a>上关于原子操作的介绍。</p>
<span id="more"></span>

<h2 id="原子操作"><a href="#原子操作" class="headerlink" title="原子操作"></a>原子操作</h2><p>由 sync/atomic 包提供操作支持。</p>
<h3 id="加法（add）"><a href="#加法（add）" class="headerlink" title="加法（add）"></a>加法（add）</h3><p>实现累加</p>
<div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestDemo1</span><span class="hljs-params">(t *testing.T)</span></span> &#123;
	<span class="hljs-keyword">var</span> counter <span class="hljs-keyword">int64</span> = <span class="hljs-number">0</span>

	<span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">100</span>; i++ &#123;
		<span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;
			atomic.AddInt64(&amp;counter, <span class="hljs-number">1</span>)
		&#125;()
	&#125;

	time.Sleep(<span class="hljs-number">2</span> * time.Second)
	log.Println(<span class="hljs-string">&quot;counter:&quot;</span>, atomic.LoadInt64(&amp;counter))
&#125;</code></pre></div>
<p>结果</p>
<div class="code-wrapper"><pre><code class="hljs asciidoc"><span class="hljs-section">=== RUN   TestDemo1</span>
2020/10/11 00:24:56 counter: 100
<span class="hljs-bullet">--- </span>PASS: TestDemo1 (2.00s)
PASS</code></pre></div>


<h3 id="减法（add）"><a href="#减法（add）" class="headerlink" title="减法（add）"></a>减法（add）</h3><p>对于做减法，是没有直接提供的方法的，而 Add（-1）这种是不能对 uint 类型使用的，可以通过补码的方式实现</p>
<div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestDemo2</span><span class="hljs-params">(t *testing.T)</span></span> &#123;
	<span class="hljs-keyword">var</span> counter <span class="hljs-keyword">uint64</span> = <span class="hljs-number">100</span>

	<span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">100</span>; i++ &#123;
		<span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;
			atomic.AddUint64(&amp;counter, ^<span class="hljs-keyword">uint64</span>(-(<span class="hljs-number">-1</span>)<span class="hljs-number">-1</span>))
		&#125;()
	&#125;

	time.Sleep(<span class="hljs-number">2</span> * time.Second)
	log.Println(<span class="hljs-string">&quot;counter:&quot;</span>, atomic.LoadUint64(&amp;counter))
&#125;</code></pre></div>
<p>结果</p>
<div class="code-wrapper"><pre><code class="hljs asciidoc"><span class="hljs-section">=== RUN   TestDemo2</span>
2020/10/11 00:32:05 counter: 0
<span class="hljs-bullet">--- </span>PASS: TestDemo2 (2.00s)
PASS</code></pre></div>


<h3 id="比较并交换（compare-and-swap，简称-CAS）"><a href="#比较并交换（compare-and-swap，简称-CAS）" class="headerlink" title="比较并交换（compare and swap，简称 CAS）"></a>比较并交换（compare and swap，简称 CAS）</h3><p>并发编程中，在没有使用互斥锁的前提下，对共享数据先取出做判断，再根据判断的结果做后续操作，必然是会出问题的，使用 CAS 可以避免这种问题。</p>
<div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestDemo3</span><span class="hljs-params">(t *testing.T)</span></span> &#123;
	<span class="hljs-keyword">var</span> first <span class="hljs-keyword">int64</span> = <span class="hljs-number">0</span>

	<span class="hljs-keyword">for</span> i := <span class="hljs-number">1</span>; i &lt;= <span class="hljs-number">10000</span>; i++ &#123;
		<span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(i <span class="hljs-keyword">int</span>)</span></span> &#123;
			<span class="hljs-keyword">if</span> atomic.CompareAndSwapInt64(&amp;first, <span class="hljs-number">0</span>, <span class="hljs-keyword">int64</span>(i)) &#123;
				log.Println(<span class="hljs-string">&quot;抢先运行的是 goroutine&quot;</span>, i)
			&#125;
		&#125;(i)
	&#125;

	time.Sleep(<span class="hljs-number">2</span> * time.Second)
	log.Println(<span class="hljs-string">&quot;num:&quot;</span>, atomic.LoadInt64(&amp;first))
&#125;</code></pre></div>
<p>结果</p>
<div class="code-wrapper"><pre><code class="hljs asciidoc"><span class="hljs-section">=== RUN   TestDemo3</span>
2020/10/11 00:42:10 抢先运行的是 goroutine 3
2020/10/11 00:42:12 num: 3
<span class="hljs-bullet">--- </span>PASS: TestDemo3 (2.01s)
PASS</code></pre></div>


<h3 id="加载（load）"><a href="#加载（load）" class="headerlink" title="加载（load）"></a>加载（load）</h3><p>加载操作在进行时只会有一个，不会有其它的读写操作同时进行。</p>
<div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestDemo4</span><span class="hljs-params">(t *testing.T)</span></span> &#123;
	<span class="hljs-keyword">var</span> counter <span class="hljs-keyword">int64</span> = <span class="hljs-number">0</span>

	<span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">100</span>; i++ &#123;
		<span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;
			atomic.AddInt64(&amp;counter, <span class="hljs-number">1</span>)
			log.Println(<span class="hljs-string">&quot;counter:&quot;</span>, atomic.LoadInt64(&amp;counter))
		&#125;()
	&#125;

	time.Sleep(<span class="hljs-number">2</span> * time.Second)
&#125;</code></pre></div>


<h3 id="存储（store）"><a href="#存储（store）" class="headerlink" title="存储（store）"></a>存储（store）</h3><p>存储操作在进行时只会有一个，不会有其它的读写操作同时进行。</p>
<div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestDemo5</span><span class="hljs-params">(t *testing.T)</span></span> &#123;
	<span class="hljs-keyword">var</span> counter <span class="hljs-keyword">int64</span> = <span class="hljs-number">0</span>

	<span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">10</span>; i++ &#123;
		<span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(i <span class="hljs-keyword">int</span>)</span></span> &#123;
			atomic.StoreInt64(&amp;counter, <span class="hljs-keyword">int64</span>(i))
			log.Println(<span class="hljs-string">&quot;counter:&quot;</span>, atomic.LoadInt64(&amp;counter))
		&#125;(i)
	&#125;

	time.Sleep(<span class="hljs-number">2</span> * time.Second)
&#125;</code></pre></div>


<h3 id="交换（swap）"><a href="#交换（swap）" class="headerlink" title="交换（swap）"></a>交换（swap）</h3><p>swap 方法返回被替换之前的旧值。</p>
<div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestDemo6</span><span class="hljs-params">(t *testing.T)</span></span> &#123;
	<span class="hljs-keyword">var</span> counter <span class="hljs-keyword">int64</span> = <span class="hljs-number">0</span>

	<span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">10</span>; i++ &#123;
		<span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(i <span class="hljs-keyword">int</span>)</span></span> &#123;
			log.Println(<span class="hljs-string">&quot;counter old:&quot;</span>, atomic.SwapInt64(&amp;counter, <span class="hljs-keyword">int64</span>(i)))
		&#125;(i)
	&#125;

	time.Sleep(<span class="hljs-number">2</span> * time.Second)
&#125;</code></pre></div>
<p>结果</p>
<div class="code-wrapper"><pre><code class="hljs groovy">=== RUN   TestDemo6
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">11</span> <span class="hljs-number">00</span>:<span class="hljs-number">43</span>:<span class="hljs-number">36</span> counter <span class="hljs-attr">old:</span> <span class="hljs-number">0</span>
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">11</span> <span class="hljs-number">00</span>:<span class="hljs-number">43</span>:<span class="hljs-number">36</span> counter <span class="hljs-attr">old:</span> <span class="hljs-number">9</span>
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">11</span> <span class="hljs-number">00</span>:<span class="hljs-number">43</span>:<span class="hljs-number">36</span> counter <span class="hljs-attr">old:</span> <span class="hljs-number">5</span>
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">11</span> <span class="hljs-number">00</span>:<span class="hljs-number">43</span>:<span class="hljs-number">36</span> counter <span class="hljs-attr">old:</span> <span class="hljs-number">1</span>
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">11</span> <span class="hljs-number">00</span>:<span class="hljs-number">43</span>:<span class="hljs-number">36</span> counter <span class="hljs-attr">old:</span> <span class="hljs-number">2</span>
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">11</span> <span class="hljs-number">00</span>:<span class="hljs-number">43</span>:<span class="hljs-number">36</span> counter <span class="hljs-attr">old:</span> <span class="hljs-number">3</span>
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">11</span> <span class="hljs-number">00</span>:<span class="hljs-number">43</span>:<span class="hljs-number">36</span> counter <span class="hljs-attr">old:</span> <span class="hljs-number">6</span>
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">11</span> <span class="hljs-number">00</span>:<span class="hljs-number">43</span>:<span class="hljs-number">36</span> counter <span class="hljs-attr">old:</span> <span class="hljs-number">4</span>
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">11</span> <span class="hljs-number">00</span>:<span class="hljs-number">43</span>:<span class="hljs-number">36</span> counter <span class="hljs-attr">old:</span> <span class="hljs-number">7</span>
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">11</span> <span class="hljs-number">00</span>:<span class="hljs-number">43</span>:<span class="hljs-number">36</span> counter <span class="hljs-attr">old:</span> <span class="hljs-number">0</span>
--- <span class="hljs-attr">PASS:</span> TestDemo6 (<span class="hljs-number">2.00</span>s)
PASS</code></pre></div>


<h3 id="原子值（value）"><a href="#原子值（value）" class="headerlink" title="原子值（value）"></a>原子值（value）</h3><p>value是一个结构体，内部值定义为 interface{}，所以它是可以接受任何类型的值。</p>
<p>第一次赋值的时候，原子值的类型就确认了，后面不能赋值其它类型的值。</p>
<div class="code-wrapper"><pre><code class="hljs reasonml">func <span class="hljs-constructor">TestDemo7(<span class="hljs-params">t</span> <span class="hljs-operator">*</span><span class="hljs-params">testing</span>.T)</span> &#123;
	var value atomic.Value
	var counter uint64 = <span class="hljs-number">1</span>

	value.<span class="hljs-constructor">Store(<span class="hljs-params">counter</span>)</span>
	log.<span class="hljs-constructor">Println(<span class="hljs-string">&quot;counter:&quot;</span>, <span class="hljs-params">value</span>.Load()</span>)

	value.<span class="hljs-constructor">Store(<span class="hljs-params">uint64</span>(10)</span>)
	log.<span class="hljs-constructor">Println(<span class="hljs-string">&quot;counter:&quot;</span>, <span class="hljs-params">value</span>.Load()</span>)

	value.<span class="hljs-constructor">Store(100)</span> <span class="hljs-comment">// 引发 panic</span>
	log.<span class="hljs-constructor">Println(<span class="hljs-string">&quot;counter:&quot;</span>, <span class="hljs-params">value</span>.Load()</span>)

	time.<span class="hljs-constructor">Sleep(2 <span class="hljs-operator">*</span> <span class="hljs-params">time</span>.Second)</span>
&#125;</code></pre></div>
<p>结果</p>
<div class="code-wrapper"><pre><code class="hljs awk">=== RUN   TestDemo7
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">11</span> <span class="hljs-number">10</span>:<span class="hljs-number">14</span>:<span class="hljs-number">58</span> counter: <span class="hljs-number">0</span>
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">11</span> <span class="hljs-number">10</span>:<span class="hljs-number">14</span>:<span class="hljs-number">58</span> counter: <span class="hljs-number">10</span>
--- FAIL: TestDemo7 (<span class="hljs-number">0.00</span>s)
panic: sync/atomic: store of inconsistently typed value into Value [recovered]
	panic: sync/atomic: store of inconsistently typed value into Value
                ...
Process finished with <span class="hljs-keyword">exit</span> code <span class="hljs-number">1</span></code></pre></div>


<h2 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h2><h3 id="无锁编程"><a href="#无锁编程" class="headerlink" title="无锁编程"></a>无锁编程</h3><p><em>此处暂时先介绍一下，后面有机会出文章再一起学习进步。</em></p>
<p>放弃互斥锁，采用原子操作，常见方法有以下几种：</p>
<h4 id="针对计数器"><a href="#针对计数器" class="headerlink" title="针对计数器"></a>针对计数器</h4><p>可以使用例如上面介绍的 Add 方法。</p>
<h4 id="单生产、消费者"><a href="#单生产、消费者" class="headerlink" title="单生产、消费者"></a>单生产、消费者</h4><p>单生产者、单消费者可以做到免锁访问环形缓冲区（Ring Buffer）。<br>比如，Linux kernel 中的 kfifo 的实现。</p>
<h4 id="RCU（Read-Copy-Update）"><a href="#RCU（Read-Copy-Update）" class="headerlink" title="RCU（Read Copy Update）"></a>RCU（Read Copy Update）</h4><p>新旧副本切换机制，对于旧副本可以采用延迟释放的做法。</p>
<h4 id="CAS（Compare-And-Swap）"><a href="#CAS（Compare-And-Swap）" class="headerlink" title="CAS（Compare And Swap）"></a>CAS（Compare And Swap）</h4><p>如无锁栈，无锁队列等待</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol>
<li>原子操作性能是高于互斥锁的，但带来的复杂性也会提高，真正用好并不容易。</li>
<li>互斥锁、条件变量，方法内部的实现也都用到了原子操作，特别是CAS。</li>
</ol>
<p><a href="https://github.com/zuoshuwen/go-example/blob/master/e003/a01_test.go">文章示例代码</a></p>
]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>同步</tag>
        <tag>原子操作</tag>
      </tags>
  </entry>
  <entry>
    <title>Go并发编程之终极武器—channel</title>
    <url>/golang/ipc-channel/</url>
    <content><![CDATA[<p>三种状态<br>nil，未初始化的状态，只进行了声明，或者手动赋值为nil<br>active，正常的channel，可读或者可写<br>closed，已关闭，千万不要误认为关闭channel后，channel的值是nil</p>
<p>三种操作<br>读<br>写<br>关闭</p>
<p>panic的三种操作<br>close()已关闭的channel<br>close()nil的channel<br>写已关闭的channel</p>
<p>关闭一定要在发送方</p>
<p>_,ok=ch<br>和 range ch 来判断 通道是否关闭。<br>*注意，看到好多人说关闭之后就会从中返回，其实不太准确，应该说是，把所有数据都读取完之后，才会退出</p>
<p>使用无缓冲的时候要特别注意，在运行时的逻辑上，向channel发送消息后，后面的逻辑没有接收操作了，那就会报死锁错误。<br>解决办法：</p>
<ol>
<li>有缓冲的：加个缓冲就可以了</li>
<li>无缓冲的：消费最后那次发送</li>
</ol>
]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>同步</tag>
      </tags>
  </entry>
  <entry>
    <title>Go并发编程之传统同步—(2)条件变量</title>
    <url>/golang/ipc-cond/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>回顾上篇文章 <a href="/golang/ipc-mutex/" title="Go并发编程之传统同步—(1)互斥锁">Go并发编程之传统同步—(1)互斥锁</a> 其中说到，同步最终是为了达到以下两种目的：</p>
<blockquote>
<ul>
<li><strong>维持共享数据一致性，并发安全</strong></li>
<li><strong>控制流程管理，更好的协同工作</strong></li>
</ul>
</blockquote>
<p>示例程序通过使用互斥锁，达到了数据一致性目的，那么流程管理应该怎么做呢？</p>
<span id="more"></span>

<h2 id="传统同步"><a href="#传统同步" class="headerlink" title="传统同步"></a>传统同步</h2><h3 id="条件变量"><a href="#条件变量" class="headerlink" title="条件变量"></a>条件变量</h3><p>上篇文章的示例程序，仅仅实现了累加功能，但在现实的工作场景中，需求往往不可能这么简单，现在扩展一下这个程序，给它加上累减的功能。</p>
<p>加上了累减的示例程序，可以抽象的理解为一个固定容量的“储水池”，可以注水、排水。</p>
<h4 id="仅用互斥锁"><a href="#仅用互斥锁" class="headerlink" title="仅用互斥锁"></a>仅用互斥锁</h4><p>当水注满以后，停止注水，开始排水，当水排空以后，开始注水，反反复复…</p>
<div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestDemo1</span><span class="hljs-params">(t *testing.T)</span></span> &#123;
	<span class="hljs-keyword">var</span> mut sync.Mutex
	maxSize := <span class="hljs-number">10</span>
	counter := <span class="hljs-number">0</span>

	<span class="hljs-comment">// 排水口</span>
	<span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;
		<span class="hljs-keyword">for</span> &#123;
			mut.Lock()
			<span class="hljs-keyword">if</span> counter == maxSize &#123;
				<span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt; maxSize; i++ &#123;
					counter--
					log.Printf(<span class="hljs-string">&quot;OUTPUT counter = %d&quot;</span>, counter)
				&#125;
			&#125;
			mut.Unlock()
			time.Sleep(<span class="hljs-number">1</span> * time.Second)
		&#125;
	&#125;()

	<span class="hljs-comment">// 注水口</span>
	<span class="hljs-keyword">for</span> &#123;
		mut.Lock()
		<span class="hljs-keyword">if</span> counter == <span class="hljs-number">0</span> &#123;
			<span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt; maxSize; i++ &#123;
				counter++
				log.Printf(<span class="hljs-string">&quot; INPUT counter = %d&quot;</span>, counter)
			&#125;
		&#125;
		mut.Unlock()
		time.Sleep(<span class="hljs-number">1</span> * time.Second)
	&#125;
&#125;</code></pre></div>
<p>结果</p>
<div class="code-wrapper"><pre><code class="hljs awk">=== RUN   TestDemo1
                ···
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">06</span> <span class="hljs-number">13</span>:<span class="hljs-number">52</span>:<span class="hljs-number">50</span>  INPUT counter = <span class="hljs-number">8</span>
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">06</span> <span class="hljs-number">13</span>:<span class="hljs-number">52</span>:<span class="hljs-number">50</span>  INPUT counter = <span class="hljs-number">9</span>
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">06</span> <span class="hljs-number">13</span>:<span class="hljs-number">52</span>:<span class="hljs-number">50</span>  INPUT counter = <span class="hljs-number">10</span>
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">06</span> <span class="hljs-number">13</span>:<span class="hljs-number">52</span>:<span class="hljs-number">50</span> OUTPUT counter = <span class="hljs-number">9</span>
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">06</span> <span class="hljs-number">13</span>:<span class="hljs-number">52</span>:<span class="hljs-number">50</span> OUTPUT counter = <span class="hljs-number">8</span>
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">06</span> <span class="hljs-number">13</span>:<span class="hljs-number">52</span>:<span class="hljs-number">50</span> OUTPUT counter = <span class="hljs-number">7</span>
                ···</code></pre></div>
<p>看着没有什么问题，一切正常，但就是这样工作的策略效率太低。</p>
<h4 id="优化互斥锁"><a href="#优化互斥锁" class="headerlink" title="优化互斥锁"></a>优化互斥锁</h4><p>优化策略，不用等注满水再排水，也不用放空之后，再注水，注水口和排水口一起工作。</p>
<div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestDemo2</span><span class="hljs-params">(t *testing.T)</span></span> &#123;
	<span class="hljs-keyword">var</span> mut sync.Mutex
	maxSize := <span class="hljs-number">10</span>
	counter := <span class="hljs-number">0</span>

	<span class="hljs-comment">// 排水口</span>
	<span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;
		<span class="hljs-keyword">for</span> &#123;
			mut.Lock()
			<span class="hljs-keyword">if</span> counter != <span class="hljs-number">0</span> &#123;
				counter--
			&#125;
			log.Printf(<span class="hljs-string">&quot;OUTPUT counter = %d&quot;</span>, counter)
			mut.Unlock()
			time.Sleep(<span class="hljs-number">5</span> * time.Second) <span class="hljs-comment">// 为了演示效果，睡眠5秒</span>
		&#125;
	&#125;()

	<span class="hljs-comment">// 注水口</span>
	<span class="hljs-keyword">for</span> &#123;
		mut.Lock()
		<span class="hljs-keyword">if</span> counter != maxSize &#123;
			counter++
		&#125;
		log.Printf(<span class="hljs-string">&quot; INPUT counter = %d&quot;</span>, counter)
		mut.Unlock()
		time.Sleep(<span class="hljs-number">1</span> * time.Second) <span class="hljs-comment">// 为了演示效果，睡眠1秒</span>
	&#125;
&#125;</code></pre></div>
<p>结果</p>
<div class="code-wrapper"><pre><code class="hljs awk">=== RUN   TestDemo2
                ···
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">06</span> <span class="hljs-number">14</span>:<span class="hljs-number">11</span>:<span class="hljs-number">46</span>  INPUT counter = <span class="hljs-number">7</span>
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">06</span> <span class="hljs-number">14</span>:<span class="hljs-number">11</span>:<span class="hljs-number">47</span>  INPUT counter = <span class="hljs-number">8</span>
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">06</span> <span class="hljs-number">14</span>:<span class="hljs-number">11</span>:<span class="hljs-number">48</span> OUTPUT counter = <span class="hljs-number">7</span>
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">06</span> <span class="hljs-number">14</span>:<span class="hljs-number">11</span>:<span class="hljs-number">48</span>  INPUT counter = <span class="hljs-number">8</span>
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">06</span> <span class="hljs-number">14</span>:<span class="hljs-number">11</span>:<span class="hljs-number">49</span>  INPUT counter = <span class="hljs-number">9</span>
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">06</span> <span class="hljs-number">14</span>:<span class="hljs-number">11</span>:<span class="hljs-number">50</span>  INPUT counter = <span class="hljs-number">10</span>
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">06</span> <span class="hljs-number">14</span>:<span class="hljs-number">11</span>:<span class="hljs-number">51</span>  INPUT counter = <span class="hljs-number">10</span>
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">06</span> <span class="hljs-number">14</span>:<span class="hljs-number">11</span>:<span class="hljs-number">52</span>  INPUT counter = <span class="hljs-number">10</span>
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">06</span> <span class="hljs-number">14</span>:<span class="hljs-number">11</span>:<span class="hljs-number">53</span> OUTPUT counter = <span class="hljs-number">9</span>
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">06</span> <span class="hljs-number">14</span>:<span class="hljs-number">11</span>:<span class="hljs-number">53</span>  INPUT counter = <span class="hljs-number">10</span>
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">06</span> <span class="hljs-number">14</span>:<span class="hljs-number">11</span>:<span class="hljs-number">54</span>  INPUT counter = <span class="hljs-number">10</span>
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">06</span> <span class="hljs-number">14</span>:<span class="hljs-number">11</span>:<span class="hljs-number">55</span>  INPUT counter = <span class="hljs-number">10</span>
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">06</span> <span class="hljs-number">14</span>:<span class="hljs-number">11</span>:<span class="hljs-number">56</span>  INPUT counter = <span class="hljs-number">10</span>
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">06</span> <span class="hljs-number">14</span>:<span class="hljs-number">11</span>:<span class="hljs-number">57</span>  INPUT counter = <span class="hljs-number">10</span>
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">06</span> <span class="hljs-number">14</span>:<span class="hljs-number">11</span>:<span class="hljs-number">58</span> OUTPUT counter = <span class="hljs-number">9</span>
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">06</span> <span class="hljs-number">14</span>:<span class="hljs-number">11</span>:<span class="hljs-number">58</span>  INPUT counter = <span class="hljs-number">10</span>
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">06</span> <span class="hljs-number">14</span>:<span class="hljs-number">11</span>:<span class="hljs-number">59</span>  INPUT counter = <span class="hljs-number">10</span>
                ···</code></pre></div>
<p>通过日志输出，可以看到程序达到了需求，运作正常。</p>
<p>但是，通过日志输出发现，当排水口效率低下的时候，注水口一直在轮询，这里频繁的上锁操作造成的开销很是浪费。</p>
<h4 id="条件变量：单发通知"><a href="#条件变量：单发通知" class="headerlink" title="条件变量：单发通知"></a>条件变量：单发通知</h4><p>那有没有什么好的办法，省去不必要的轮询？如果注水口和排水口能互相“通知”就好了！这个功能，<strong>条件变量</strong>可以做到。</p>
<p>条件变量总是与互斥锁组合使用，除了可以使用 Lock、Unlock，还有如下三个方法：</p>
<blockquote>
<ul>
<li>Wait 等待通知</li>
<li>Signal 单发通知</li>
<li>Broadcast 广播通知</li>
</ul>
</blockquote>
<div class="code-wrapper"><pre><code class="hljs awk"><span class="hljs-keyword">func</span> TestDemo3(t *testing.T) &#123;
	cond := sync.NewCond(new(sync.Mutex)) <span class="hljs-regexp">//</span> 初始化条件变量
	maxSize := <span class="hljs-number">10</span>
	counter := <span class="hljs-number">0</span>

	<span class="hljs-regexp">//</span> 排水口
	go <span class="hljs-keyword">func</span>() &#123;
		<span class="hljs-keyword">for</span> &#123;
			cond.L.Lock() <span class="hljs-regexp">//</span> 上锁
			<span class="hljs-keyword">if</span> counter == <span class="hljs-number">0</span> &#123; <span class="hljs-regexp">//</span> 没水了
				cond.Wait() <span class="hljs-regexp">//</span> 啥时候来水？等通知！
			&#125;
			counter--
			log.Printf(<span class="hljs-string">&quot;OUTPUT counter = %d&quot;</span>, counter)
			cond.Signal() <span class="hljs-regexp">//</span> 单发通知：已排水
			cond.L.Unlock() <span class="hljs-regexp">//</span> 解锁
			time.Sleep(<span class="hljs-number">5</span> * time.Second) <span class="hljs-regexp">//</span> 为了演示效果，睡眠<span class="hljs-number">5</span>秒
		&#125;
	&#125;()

	<span class="hljs-regexp">//</span> 注水口
	<span class="hljs-keyword">for</span> &#123;
		cond.L.Lock() <span class="hljs-regexp">//</span> 上锁
		<span class="hljs-keyword">if</span> counter == maxSize &#123; <span class="hljs-regexp">//</span> 水满了
			cond.Wait() <span class="hljs-regexp">//</span> 啥时候排水？等待通知！
		&#125;
		counter++
		log.Printf(<span class="hljs-string">&quot; INPUT counter = %d&quot;</span>, counter)
		cond.Signal() <span class="hljs-regexp">//</span> 单发通知：已来水
		cond.L.Unlock() <span class="hljs-regexp">//</span> 解锁
		time.Sleep(<span class="hljs-number">1</span> * time.Second) <span class="hljs-regexp">//</span> 为了演示效果，睡眠<span class="hljs-number">1</span>秒
	&#125;
&#125;</code></pre></div>
<p>结果</p>
<div class="code-wrapper"><pre><code class="hljs awk">=== RUN   TestDemo3
                ···
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">06</span> <span class="hljs-number">14</span>:<span class="hljs-number">51</span>:<span class="hljs-number">22</span>  INPUT counter = <span class="hljs-number">7</span>
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">06</span> <span class="hljs-number">14</span>:<span class="hljs-number">51</span>:<span class="hljs-number">23</span>  INPUT counter = <span class="hljs-number">8</span>
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">06</span> <span class="hljs-number">14</span>:<span class="hljs-number">51</span>:<span class="hljs-number">24</span> OUTPUT counter = <span class="hljs-number">7</span>
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">06</span> <span class="hljs-number">14</span>:<span class="hljs-number">51</span>:<span class="hljs-number">24</span>  INPUT counter = <span class="hljs-number">8</span>
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">06</span> <span class="hljs-number">14</span>:<span class="hljs-number">51</span>:<span class="hljs-number">25</span>  INPUT counter = <span class="hljs-number">9</span>
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">06</span> <span class="hljs-number">14</span>:<span class="hljs-number">51</span>:<span class="hljs-number">26</span>  INPUT counter = <span class="hljs-number">10</span>
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">06</span> <span class="hljs-number">14</span>:<span class="hljs-number">51</span>:<span class="hljs-number">29</span> OUTPUT counter = <span class="hljs-number">9</span>
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">06</span> <span class="hljs-number">14</span>:<span class="hljs-number">51</span>:<span class="hljs-number">29</span>  INPUT counter = <span class="hljs-number">10</span>
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">06</span> <span class="hljs-number">14</span>:<span class="hljs-number">51</span>:<span class="hljs-number">34</span> OUTPUT counter = <span class="hljs-number">9</span>
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">06</span> <span class="hljs-number">14</span>:<span class="hljs-number">51</span>:<span class="hljs-number">34</span>  INPUT counter = <span class="hljs-number">10</span>
                ···</code></pre></div>
<p>通过日志输出，可以看出来，注水口没有一直轮询了，而是等到排水口发通知后，再进行注水，注水口一直再等排水口。那么新的问题又来了，如何提高排水口的效率呢？</p>
<h4 id="条件变量：广播通知"><a href="#条件变量：广播通知" class="headerlink" title="条件变量：广播通知"></a>条件变量：广播通知</h4><p>多制造出一个排水口，提高排水效率。</p>
<p>那就不能继续使用单发通知了（Signal），因为单发通知只会通知到一个等待（Wait），针对多等待的这种情况，就需要使用广播通知（Broadcast）。</p>
<div class="code-wrapper"><pre><code class="hljs awk"><span class="hljs-keyword">func</span> TestDemo4(t *testing.T) &#123;
	cond := sync.NewCond(new(sync.Mutex)) <span class="hljs-regexp">//</span> 初始化条件变量
	maxSize := <span class="hljs-number">10</span>
	counter := <span class="hljs-number">0</span>

	<span class="hljs-regexp">//</span> 排水口 <span class="hljs-number">1</span>
	go <span class="hljs-keyword">func</span>() &#123;
		<span class="hljs-keyword">for</span> &#123;
			cond.L.Lock() <span class="hljs-regexp">//</span> 上锁
			<span class="hljs-keyword">if</span> counter == <span class="hljs-number">0</span> &#123; <span class="hljs-regexp">//</span> 没水了
			<span class="hljs-regexp">//</span><span class="hljs-keyword">for</span> counter == <span class="hljs-number">0</span> &#123; <span class="hljs-regexp">//</span> 没水了
				cond.Wait() <span class="hljs-regexp">//</span> 啥时候来水？等通知！
			&#125;
			counter--
			log.Printf(<span class="hljs-string">&quot;OUTPUT A counter = %d&quot;</span>, counter)
			cond.Broadcast() <span class="hljs-regexp">//</span> 单发通知：已排水
			cond.L.Unlock() <span class="hljs-regexp">//</span> 解锁
			<span class="hljs-regexp">//</span>time.Sleep(<span class="hljs-number">2</span> * time.Second) <span class="hljs-regexp">//</span> 为了演示效果，睡眠<span class="hljs-number">5</span>秒
		&#125;
	&#125;()

	<span class="hljs-regexp">//</span> 排水口 <span class="hljs-number">2</span>
	go <span class="hljs-keyword">func</span>() &#123;
		<span class="hljs-keyword">for</span> &#123;
			cond.L.Lock() <span class="hljs-regexp">//</span> 上锁
			<span class="hljs-keyword">if</span> counter == <span class="hljs-number">0</span> &#123; <span class="hljs-regexp">//</span> 没水了
			<span class="hljs-regexp">//</span><span class="hljs-keyword">for</span> counter == <span class="hljs-number">0</span> &#123; <span class="hljs-regexp">//</span> 没水了
				cond.Wait() <span class="hljs-regexp">//</span> 啥时候来水？等通知！
			&#125;
			counter--
			log.Printf(<span class="hljs-string">&quot;OUTPUT B counter = %d&quot;</span>, counter)
			cond.Broadcast() <span class="hljs-regexp">//</span> 单发通知：已排水
			cond.L.Unlock() <span class="hljs-regexp">//</span> 解锁
			<span class="hljs-regexp">//</span>time.Sleep(<span class="hljs-number">2</span> * time.Second) <span class="hljs-regexp">//</span> 为了演示效果，睡眠<span class="hljs-number">5</span>秒
		&#125;
	&#125;()

	<span class="hljs-regexp">//</span> 注水口
	<span class="hljs-keyword">for</span> &#123;
		cond.L.Lock() <span class="hljs-regexp">//</span> 上锁
		<span class="hljs-keyword">if</span> counter == maxSize &#123; <span class="hljs-regexp">//</span> 水满了
		<span class="hljs-regexp">//</span><span class="hljs-keyword">for</span> counter == maxSize &#123; <span class="hljs-regexp">//</span> 水满了
			cond.Wait() <span class="hljs-regexp">//</span> 啥时候排水？等待通知！
		&#125;
		counter++
		log.Printf(<span class="hljs-string">&quot; INPUT   counter = %d&quot;</span>, counter)
		cond.Broadcast() <span class="hljs-regexp">//</span> 单发通知：已来水
		cond.L.Unlock() <span class="hljs-regexp">//</span> 解锁
		<span class="hljs-regexp">//</span>time.Sleep(<span class="hljs-number">1</span> * time.Second) <span class="hljs-regexp">//</span> 为了演示效果，睡眠<span class="hljs-number">1</span>秒
	&#125;
&#125;</code></pre></div>
<p>结果</p>
<div class="code-wrapper"><pre><code class="hljs awk">=== RUN   TestDemo4
                ···
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">07</span> <span class="hljs-number">20</span>:<span class="hljs-number">57</span>:<span class="hljs-number">30</span> OUTPUT B counter = <span class="hljs-number">2</span>
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">07</span> <span class="hljs-number">20</span>:<span class="hljs-number">57</span>:<span class="hljs-number">30</span> OUTPUT B counter = <span class="hljs-number">1</span>
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">07</span> <span class="hljs-number">20</span>:<span class="hljs-number">57</span>:<span class="hljs-number">30</span> OUTPUT B counter = <span class="hljs-number">0</span>
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">07</span> <span class="hljs-number">20</span>:<span class="hljs-number">57</span>:<span class="hljs-number">30</span> OUTPUT A counter = -<span class="hljs-number">1</span>
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">07</span> <span class="hljs-number">20</span>:<span class="hljs-number">57</span>:<span class="hljs-number">30</span> OUTPUT A counter = -<span class="hljs-number">2</span>
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">07</span> <span class="hljs-number">20</span>:<span class="hljs-number">57</span>:<span class="hljs-number">30</span> OUTPUT A counter = -<span class="hljs-number">3</span>
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">07</span> <span class="hljs-number">20</span>:<span class="hljs-number">57</span>:<span class="hljs-number">30</span> OUTPUT A counter = -<span class="hljs-number">4</span>
                ···
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">07</span> <span class="hljs-number">20</span>:<span class="hljs-number">57</span>:<span class="hljs-number">31</span> OUTPUT B counter = -<span class="hljs-number">7605</span>
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">07</span> <span class="hljs-number">20</span>:<span class="hljs-number">57</span>:<span class="hljs-number">31</span>  INPUT   counter = -<span class="hljs-number">7604</span>
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">07</span> <span class="hljs-number">20</span>:<span class="hljs-number">57</span>:<span class="hljs-number">31</span> OUTPUT A counter = -<span class="hljs-number">7605</span>
<span class="hljs-number">2020</span><span class="hljs-regexp">/10/</span><span class="hljs-number">07</span> <span class="hljs-number">20</span>:<span class="hljs-number">57</span>:<span class="hljs-number">31</span> OUTPUT A counter = -<span class="hljs-number">7606</span>
                ···</code></pre></div>
<p>通过日志输出可以看到，刚开始的时候还很正常，到后面的时候就变成负值了，一直在负增长，What？</p>
<p>在 <a href="/golang/ipc-mutex/" title="Go并发编程之传统同步—(1)互斥锁">Go并发编程之传统同步—(1)互斥锁</a> 文章中，程序因为没有加上互斥锁，出现过 counter 值异常的情况。</p>
<p>但这次程序这次加了互斥锁，按理说形成了一个临界区应该是没有问题了，所以问题应该不是出在临界区上，难道问题出在 <strong>Wait</strong> 上？</p>
<p>通过IDE<strong>追踪一下Wait的源码</strong></p>
<div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Cond)</span> <span class="hljs-title">Wait</span><span class="hljs-params">()</span></span> &#123;
	<span class="hljs-comment">// 检查 c 是否是被复制的，如果是就 panic</span>
	c.checker.check()
	<span class="hljs-comment">// 将当前 goroutine 加入等待队列</span>
	t := runtime_notifyListAdd(&amp;c.notify)
	c.L.Unlock()
	<span class="hljs-comment">// 等待当前 goroutine 被唤醒</span>
	runtime_notifyListWait(&amp;c.notify, t)
	c.L.Lock()
&#125;</code></pre></div>
<p>原来 Wait 内部的执行流程是，先执行了解锁，然后进入等待状态，接到通知之后，再执行加锁操作。</p>
<p>那按照这个代码逻辑结合输出日志，走一程序遍流程，看看能不能复现出 counter 为负值的情况：</p>
<blockquote>
<ol>
<li><p>注水口将 counter 累加到 10 之后，发送广播通知（Broadcast）。</p>
</li>
<li><p>goroutine A 在“第1步”之前的时候进入了等待通知（Wait），现在接收到了广播通知（Broadcast），从 runtime_notifyListWait() 返回，并且成功执行了加锁（Lock）操作。</p>
</li>
<li><p>goroutine B 在“第1步”之前的时候进入了等待通知（Wait），现在接收到了广播通知（Broadcast），从 runtime_notifyListWait() 返回，在执行加锁（Lock）操作的时候，发现 goroutine A 先抢占了临界区，所以一直阻塞在 c.L.Lock()。</p>
</li>
<li><p>goroutine A 虽然完成任务后会释放锁，但是每次也成功将锁抢占，所以就这样 一直将 counter 减到了 0，然后发送广播通知（Broadcast）、解锁（Unlock）。</p>
</li>
<li><p>goroutine B 在 goroutine A 解锁后，成功获得锁并从 Lock 方法中返回，接下来跳出 Wait 方法、跳出 if 判断，执行 counter–（0–），这时候 counter 的值是 -1</p>
</li>
</ol>
</blockquote>
<p>图示</p>
<p><img src="/images/golang/ipc-cond-01.jpg" alt="ipc-cond-01"></p>
<p>问题就出现在第五步，只要 goroutine B 加锁成功的时候，再判断一下 counter 是否为 0 就好了。</p>
<p>所以将 if counter == 0 改成 for counter == 0，这样上面的“第五步”就变成了</p>
<blockquote>
<p>5.goroutine B 在 goroutine A 解锁后，成功加锁（Lock）并从阻塞总返回，接下来跳出 Wait 方法、再次进入 for 循环，判断 counter == 0 结果为真，再次进入等待（Wait）。</p>
</blockquote>
<p>代码做出相应的修改后，再执行看结果，没有问题了。</p>
<h2 id="延伸"><a href="#延伸" class="headerlink" title="延伸"></a>延伸</h2><h3 id="发送通知"><a href="#发送通知" class="headerlink" title="发送通知"></a>发送通知</h3><p>等待通知（Wait）肯定是要在临界区里面的，那发送通知（Signal、Broadcast）在哪里更好呢？</p>
<div class="code-wrapper"><pre><code class="hljs stylus"><span class="hljs-function"><span class="hljs-title">Luck</span><span class="hljs-params">()</span></span>
<span class="hljs-function"><span class="hljs-title">Wait</span><span class="hljs-params">()</span></span>
<span class="hljs-function"><span class="hljs-title">Broadcast</span><span class="hljs-params">()</span></span><span class="hljs-comment">// Signal()</span>
<span class="hljs-function"><span class="hljs-title">Unlock</span><span class="hljs-params">()</span></span>

<span class="hljs-comment">// 或者</span>

<span class="hljs-function"><span class="hljs-title">Luck</span><span class="hljs-params">()</span></span>
<span class="hljs-function"><span class="hljs-title">Wait</span><span class="hljs-params">()</span></span>
<span class="hljs-function"><span class="hljs-title">Unlock</span><span class="hljs-params">()</span></span>
<span class="hljs-function"><span class="hljs-title">Broadcast</span><span class="hljs-params">()</span></span><span class="hljs-comment">// Signal()</span>

<span class="hljs-comment">// 两种写法都不会报错 </span></code></pre></div>

<p>在 go 的发送通知方法（Broadcast、Signal）上有这么一段话：</p>
<blockquote>
<p>// It is allowed but not required for the caller to hold c.L<br>// during the call.</p>
</blockquote>
<p>在我以往的 C 多线程开发的时候，发送通知总是在锁中的：</p>
<div class="code-wrapper"><pre><code class="hljs reasonml">pthread<span class="hljs-constructor">_mutex_lock(&amp;<span class="hljs-params">thread</span>-&gt;<span class="hljs-params">mutex</span>)</span>;
<span class="hljs-comment">//              ...</span>
pthread<span class="hljs-constructor">_cond_signal(&amp;<span class="hljs-params">thread</span>-&gt;<span class="hljs-params">cond</span>)</span>;
pthread<span class="hljs-constructor">_mutex_unlock(&amp;<span class="hljs-params">thread</span>-&gt;<span class="hljs-params">mutex</span>)</span>;</code></pre></div>
<p>在 <a href="https://linux.die.net/man/3/pthread_cond_signal">man</a> 手册中有写到：</p>
<blockquote>
<p>The pthread_cond_broadcast() or pthread_cond_signal() functions may be called by a thread whether or not it currently owns the mutex that threads calling pthread_cond_wait() or pthread_cond_timedwait() have associated with the condition variable during their waits; however, if predictable scheduling behavior is required, then that mutex shall be locked by the thread calling pthread_cond_broadcast() or pthread_cond_signal().</p>
</blockquote>
<p>个人对此并没有什么见解，就不乱下定论了，有想法的小伙伴可以在文章下面留言，一起讨论。</p>
<h3 id="等待通知"><a href="#等待通知" class="headerlink" title="等待通知"></a>等待通知</h3><p>消息通知是有即时性的，如果没有 goroutine 在等待通知，那么这次通知直接被丢弃。</p>
<h3 id="kubernetes"><a href="#kubernetes" class="headerlink" title="kubernetes"></a>kubernetes</h3><p><a href="https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/client-go/tools/cache/fifo.go">https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/client-go/tools/cache/fifo.go</a></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol>
<li>Wait() 内会执行解锁、等待、加锁。</li>
<li>Wait() 必须在 for 循环里面。</li>
<li>Wait() 方法会把当前的 goroutine 添加到通知队列的队尾。</li>
<li>单发通知，唤醒通知队列第一个排队的 goroutine。</li>
<li>广播通知，唤醒通知队列里面全部的 goroutine。</li>
<li>程序示例只是为了演示效果，实际的开发中，生产者和消费者应该是异步消费，不应该使用同一个互斥锁。</li>
</ol>
<p><a href="https://github.com/zuoshuwen/go-example/blob/master/e002/a01_test.go">文章示例代码</a></p>
]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>同步</tag>
        <tag>条件变量</tag>
      </tags>
  </entry>
  <entry>
    <title>Go并发编程之任务协作—(2)Context</title>
    <url>/golang/ipc-context/</url>
    <content><![CDATA[<h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><ul>
<li>根 Context：通过 context.Background() 创建</li>
<li>子 Context: 通过 context.WithCancel(parentContext) 创建<ul>
<li>ctx, cancel := context.WithCancel(context.Background())</li>
</ul>
</li>
<li>当前 Context 被取消时，其它的子 context 都会被取消</li>
<li>接收取消通知 &lt;-ctx.Done()</li>
</ul>
<p>只执行一次</p>
<div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;
	timer := time.NewTimer(time.Second * <span class="hljs-number">5</span>)
	data := []<span class="hljs-keyword">int</span>&#123;<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">10</span>, <span class="hljs-number">999</span>, <span class="hljs-number">8</span>, <span class="hljs-number">345</span>, <span class="hljs-number">7</span>, <span class="hljs-number">98</span>, <span class="hljs-number">33</span>, <span class="hljs-number">66</span>, <span class="hljs-number">77</span>, <span class="hljs-number">88</span>, <span class="hljs-number">68</span>, <span class="hljs-number">96</span>&#125;
	dataLen := <span class="hljs-built_in">len</span>(data)
	size := <span class="hljs-number">3</span>
	target := <span class="hljs-number">345</span>
	ctx, cancel := context.WithCancel(context.Background())
	resultChan := <span class="hljs-built_in">make</span>(<span class="hljs-keyword">chan</span> <span class="hljs-keyword">bool</span>)
	<span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt; dataLen; i += size &#123;
		end := i + size
		<span class="hljs-keyword">if</span> end &gt;= dataLen &#123;
			end = dataLen - <span class="hljs-number">1</span>
		&#125;
		<span class="hljs-keyword">go</span> SearchTarget(ctx, data[i:end], target, resultChan)
	&#125;
	<span class="hljs-keyword">select</span> &#123;
	<span class="hljs-keyword">case</span> &lt;-timer.C:
		fmt.Fprintln(os.Stderr, <span class="hljs-string">&quot;Timeout! Not Found&quot;</span>)
		cancel()
	<span class="hljs-keyword">case</span> &lt;- resultChan:
		fmt.Fprintf(os.Stdout, <span class="hljs-string">&quot;Found it!\n&quot;</span>)
		cancel()
	&#125;

	time.Sleep(time.Second * <span class="hljs-number">2</span>)
&#125;

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">SearchTarget</span><span class="hljs-params">(ctx context.Context, data []<span class="hljs-keyword">int</span>, target <span class="hljs-keyword">int</span>, resultChan <span class="hljs-keyword">chan</span> <span class="hljs-keyword">bool</span>)</span></span> &#123;
	<span class="hljs-keyword">for</span> _, v := <span class="hljs-keyword">range</span> data &#123;
		<span class="hljs-keyword">select</span> &#123;
		<span class="hljs-keyword">case</span> &lt;- ctx.Done():
			fmt.Fprintf(os.Stdout, <span class="hljs-string">&quot;Task cancelded! \n&quot;</span>)
			<span class="hljs-keyword">return</span>
		<span class="hljs-keyword">default</span>:
		&#125;
		<span class="hljs-comment">// 模拟一个耗时查找，这里只是比对值，真实开发中可以是其他操作</span>
		fmt.Fprintf(os.Stdout, <span class="hljs-string">&quot;v: %d \n&quot;</span>, v)
		time.Sleep(time.Millisecond * <span class="hljs-number">1500</span>)
		<span class="hljs-keyword">if</span> target == v &#123;
			resultChan &lt;- <span class="hljs-literal">true</span>
			<span class="hljs-keyword">return</span>
		&#125;
	&#125;
&#125;</code></pre></div>

<p>gin</p>
<div class="code-wrapper"><pre><code class="hljs go">
</code></pre></div>]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>同步</tag>
      </tags>
  </entry>
  <entry>
    <title>Go并发编程之任务协作—(1)ErrGroup</title>
    <url>/golang/ipc-errgroup/</url>
    <content><![CDATA[<p><code>func WithContext(ctx context.Context) (*Group, context.Context)</code></p>
<p><code>func (g *Group) Go(f func() error)</code></p>
<p><code>func (g *Group) Wait() error</code></p>
<p><code>&lt;-errContext.Done()</code></p>
<div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;
	g, ctx := errgroup.WithContext(context.Background())

	mux := http.NewServeMux()
	mux.HandleFunc(<span class="hljs-string">&quot;/ping&quot;</span>, <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(w http.ResponseWriter, r *http.Request)</span></span> &#123;
		w.Write([]<span class="hljs-keyword">byte</span>(<span class="hljs-string">&quot;pong&quot;</span>))
	&#125;)

	<span class="hljs-comment">// 模拟单个服务错误退出</span>
	serverOut := <span class="hljs-built_in">make</span>(<span class="hljs-keyword">chan</span> <span class="hljs-keyword">struct</span>&#123;&#125;)
	mux.HandleFunc(<span class="hljs-string">&quot;/shutdown&quot;</span>, <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(w http.ResponseWriter, r *http.Request)</span></span> &#123;
		serverOut &lt;- <span class="hljs-keyword">struct</span>&#123;&#125;&#123;&#125;
	&#125;)

	server := http.Server&#123;
		Handler: mux,
		Addr:    <span class="hljs-string">&quot;:8080&quot;</span>,
	&#125;

	<span class="hljs-comment">// g1</span>
	<span class="hljs-comment">// g1 退出了所有的协程都能退出么？</span>
	<span class="hljs-comment">// g1 退出后, context 将不再阻塞，g2, g3 都会随之退出</span>
	<span class="hljs-comment">// 然后 main 函数中的 g.Wait() 退出，所有协程都会退出</span>
	g.Go(<span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span> <span class="hljs-title">error</span></span> &#123;
		<span class="hljs-keyword">return</span> server.ListenAndServe()
	&#125;)

	<span class="hljs-comment">// g2</span>
	<span class="hljs-comment">// g2 退出了所有的协程都能退出么？</span>
	<span class="hljs-comment">// g2 退出时，调用了 shutdown，g1 会退出</span>
	<span class="hljs-comment">// g2 退出后, context 将不再阻塞，g3 会随之退出</span>
	<span class="hljs-comment">// 然后 main 函数中的 g.Wait() 退出，所有协程都会退出</span>
	g.Go(<span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span> <span class="hljs-title">error</span></span> &#123;
		<span class="hljs-keyword">select</span> &#123;
		<span class="hljs-keyword">case</span> &lt;-ctx.Done():
			log.Println(<span class="hljs-string">&quot;errgroup exit...&quot;</span>)
		<span class="hljs-keyword">case</span> &lt;-serverOut:
			log.Println(<span class="hljs-string">&quot;server will out...&quot;</span>)
		&#125;

		timeoutCtx, cancel := context.WithTimeout(context.Background(), <span class="hljs-number">3</span>*time.Second)
		<span class="hljs-comment">// 这里不是必须的，但是如果使用 _ 的话静态扫描工具会报错，加上也无伤大雅</span>
		<span class="hljs-keyword">defer</span> cancel()

		log.Println(<span class="hljs-string">&quot;shutting down server...&quot;</span>)
		<span class="hljs-keyword">return</span> server.Shutdown(timeoutCtx)
	&#125;)

	<span class="hljs-comment">// g3</span>
	<span class="hljs-comment">// g3 捕获到 os 退出信号将会退出</span>
	<span class="hljs-comment">// g3 退出了所有的协程都能退出么？</span>
	<span class="hljs-comment">// g3 退出后, context 将不再阻塞，g2 会随之退出</span>
	<span class="hljs-comment">// g2 退出时，调用了 shutdown，g1 会退出</span>
	<span class="hljs-comment">// 然后 main 函数中的 g.Wait() 退出，所有协程都会退出</span>
	g.Go(<span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span> <span class="hljs-title">error</span></span> &#123;
		quit := <span class="hljs-built_in">make</span>(<span class="hljs-keyword">chan</span> os.Signal, <span class="hljs-number">0</span>)
		signal.Notify(quit, syscall.SIGINT, syscall.SIGTERM)

		<span class="hljs-keyword">select</span> &#123;
		<span class="hljs-keyword">case</span> &lt;-ctx.Done():
			<span class="hljs-keyword">return</span> ctx.Err()
		<span class="hljs-keyword">case</span> sig := &lt;-quit:
			<span class="hljs-keyword">return</span> errors.Errorf(<span class="hljs-string">&quot;get os signal: %v&quot;</span>, sig)
		&#125;
	&#125;)

	fmt.Printf(<span class="hljs-string">&quot;errgroup exiting: %+v\n&quot;</span>, g.Wait())
&#125;</code></pre></div>]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>同步</tag>
      </tags>
  </entry>
  <entry>
    <title>Go并发编程之数据共享—(1)Map</title>
    <url>/golang/ipc-map/</url>
    <content><![CDATA[<h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><p><code>func (*Map) Delete</code><br><code>func (*Map) Load</code><br><code>func (*Map) LoadAndDelete</code><br><code>func (*Map) LoadOrStore</code><br><code>func (*Map) Range</code><br><code>func (*Map) Store</code></p>
]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>同步</tag>
      </tags>
  </entry>
  <entry>
    <title>Go并发编程之传统同步—(1)互斥锁</title>
    <url>/golang/ipc-mutex/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>先回顾一下，在 C 或者其它编程语言的并发编程中，主要存在两种<strong>通信</strong>（IPC）：</p>
<blockquote>
<ul>
<li><strong>进程间通信</strong>：管道、消息队列、信号等</li>
<li><strong>线程间通信</strong>：互斥锁、条件变量等</li>
</ul>
</blockquote>
<p>利用以上通信手段采取的同步措施，最终是为了达到以下两种目的：</p>
<blockquote>
<ul>
<li><strong>维持共享数据一致性，并发安全</strong></li>
<li><strong>控制流程管理，更好的协同工作</strong></li>
</ul>
</blockquote>
<p>Go语言中除了保留了传统的同步支持，还提供了特有的 CSP 并发编程模型。</p>
<span id="more"></span>

<h2 id="传统同步"><a href="#传统同步" class="headerlink" title="传统同步"></a>传统同步</h2><h3 id="互斥锁"><a href="#互斥锁" class="headerlink" title="互斥锁"></a>互斥锁</h3><p>接下来通过一个“做累加”的示例程序，展示<strong>竞争状态</strong>（race condition）。</p>
<h4 id="不加锁"><a href="#不加锁" class="headerlink" title="不加锁"></a>不加锁</h4><p>开启 5000 个 goroutine，让每个 goroutine 给 counter 加 1，最终在所有 goroutine 都完成任务时 counter 的值应该为 5000，先试下不加锁的示例程序表现如何</p>
<div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestDemo1</span><span class="hljs-params">(t *testing.T)</span></span> &#123;
	counter := <span class="hljs-number">0</span>
	<span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">5000</span>; i++ &#123;
		<span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;
			counter++
		&#125;()
	&#125;
	time.Sleep(<span class="hljs-number">1</span> * time.Second)
	t.Logf(<span class="hljs-string">&quot;counter = %d&quot;</span>, counter)
&#125;</code></pre></div>
<p>结果</p>
<div class="code-wrapper"><pre><code class="hljs asciidoc"><span class="hljs-section">=== RUN   TestDemo1</span>
<span class="hljs-code">    a1_test.go:18: counter = 4663</span>
<span class="hljs-bullet">--- </span>PASS: TestDemo1 (1.00s)
PASS</code></pre></div>
<p>多试几次，结果一直是小于 5000 的不定值。<br>竞争状态下程序行为的图像表示<br><img src="/images/golang/ipc-mutex-01.jpg" alt="ipc-mutex-01"></p>
<h4 id="加锁"><a href="#加锁" class="headerlink" title="加锁"></a>加锁</h4><p>将刚刚的代码稍作改动</p>
<div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestDemo2</span><span class="hljs-params">(t *testing.T)</span></span> &#123;
	<span class="hljs-keyword">var</span> mut sync.Mutex <span class="hljs-comment">// 声明锁</span>
	counter := <span class="hljs-number">0</span>
	<span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">5000</span>; i++ &#123;
		<span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;
			mut.Lock() <span class="hljs-comment">// 加锁</span>
			counter++
			mut.Unlock() <span class="hljs-comment">// 解锁</span>
		&#125;()
	&#125;
	time.Sleep(<span class="hljs-number">1</span> * time.Second)
	t.Logf(<span class="hljs-string">&quot;counter = %d&quot;</span>, counter)
&#125;</code></pre></div>
<p>结果</p>
<div class="code-wrapper"><pre><code class="hljs asciidoc"><span class="hljs-section">=== RUN   TestDemo2</span>
<span class="hljs-code">    a1_test.go:35: counter = 5000</span>
<span class="hljs-bullet">--- </span>PASS: TestDemo2 (1.01s)
PASS</code></pre></div>
<p>counter = 5000，返回的结果对了。</p>
<p>这就是<strong>互斥锁</strong>，在代码上创建一个<strong>临界区</strong>（critical section），保证串行操作（同一时间只有一个 goroutine 执行临界区代码）。</p>
<h4 id="阻塞"><a href="#阻塞" class="headerlink" title="阻塞"></a>阻塞</h4><p>那么互斥锁是怎么串行的呢？把每一步的执行过程打印出来看下</p>
<div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestDemo3</span><span class="hljs-params">(t *testing.T)</span></span> &#123;
	<span class="hljs-keyword">var</span> mut sync.Mutex
	counter := <span class="hljs-number">0</span>
	<span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;
		mut.Lock()
		log.Println(<span class="hljs-string">&quot;goroutine B Lock&quot;</span>)
		counter = <span class="hljs-number">1</span>
		log.Println(<span class="hljs-string">&quot;goroutine B counter =&quot;</span>, counter)
		time.Sleep(<span class="hljs-number">5</span> * time.Second)
		mut.Unlock()
		log.Println(<span class="hljs-string">&quot;goroutine B Unlock&quot;</span>)
	&#125;()
	time.Sleep(<span class="hljs-number">1</span> * time.Second)
	mut.Lock()
	log.Println(<span class="hljs-string">&quot;goroutine A Lock&quot;</span>)
	counter = <span class="hljs-number">2</span>
	log.Println(<span class="hljs-string">&quot;goroutine A counter =&quot;</span>, counter)
	mut.Unlock()
	log.Println(<span class="hljs-string">&quot;goroutine A Unlock&quot;</span>)
&#125;</code></pre></div>
<p>结果</p>
<div class="code-wrapper"><pre><code class="hljs awk">=== RUN   TestDemo3
<span class="hljs-number">2020</span><span class="hljs-regexp">/09/</span><span class="hljs-number">30</span> <span class="hljs-number">22</span>:<span class="hljs-number">14</span>:<span class="hljs-number">00</span> goroutine B Lock
<span class="hljs-number">2020</span><span class="hljs-regexp">/09/</span><span class="hljs-number">30</span> <span class="hljs-number">22</span>:<span class="hljs-number">14</span>:<span class="hljs-number">00</span> goroutine B counter = <span class="hljs-number">1</span>
<span class="hljs-number">2020</span><span class="hljs-regexp">/09/</span><span class="hljs-number">30</span> <span class="hljs-number">22</span>:<span class="hljs-number">14</span>:<span class="hljs-number">05</span> goroutine B Unlock
<span class="hljs-number">2020</span><span class="hljs-regexp">/09/</span><span class="hljs-number">30</span> <span class="hljs-number">22</span>:<span class="hljs-number">14</span>:<span class="hljs-number">05</span> goroutine A Lock
<span class="hljs-number">2020</span><span class="hljs-regexp">/09/</span><span class="hljs-number">30</span> <span class="hljs-number">22</span>:<span class="hljs-number">14</span>:<span class="hljs-number">05</span> goroutine A counter = <span class="hljs-number">2</span>
<span class="hljs-number">2020</span><span class="hljs-regexp">/09/</span><span class="hljs-number">30</span> <span class="hljs-number">22</span>:<span class="hljs-number">14</span>:<span class="hljs-number">05</span> goroutine A Unlock
--- PASS: TestDemo3 (<span class="hljs-number">5.00</span>s)
PASS</code></pre></div>
<p>通过每个操作记录下来的时间可以看出，goroutine A 的 Lock 一直阻塞到了 goroutine B 的 Unlock。<br><img src="/images/golang/ipc-mutex-02.jpg" alt="ipc-mutex-01"></p>
<h4 id="解锁"><a href="#解锁" class="headerlink" title="解锁"></a>解锁</h4><p>这时候有个疑问，那 goroutine B 上的锁，goroutine A 能解锁吗？修改一下刚才的代码，试一下</p>
<div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestDemo5</span><span class="hljs-params">(t *testing.T)</span></span> &#123;
	<span class="hljs-keyword">var</span> mut sync.Mutex
	counter := <span class="hljs-number">0</span>
	<span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;
		mut.Lock()
		log.Println(<span class="hljs-string">&quot;goroutine B Lock&quot;</span>)
		counter = <span class="hljs-number">1</span>
		log.Println(<span class="hljs-string">&quot;goroutine B counter =&quot;</span>, counter)
		time.Sleep(<span class="hljs-number">5</span> * time.Second)
		<span class="hljs-comment">//mut.Unlock()</span>
		<span class="hljs-comment">//log.Println(&quot;goroutine B Unlock&quot;)</span>
	&#125;()
	time.Sleep(<span class="hljs-number">1</span> * time.Second)
	mut.Unlock()
	log.Println(<span class="hljs-string">&quot;goroutine A Unlock&quot;</span>)
	counter = <span class="hljs-number">2</span>
	log.Println(<span class="hljs-string">&quot;goroutine A counter =&quot;</span>, counter)
	time.Sleep(<span class="hljs-number">2</span> * time.Second)
&#125;</code></pre></div>
<p>结果</p>
<div class="code-wrapper"><pre><code class="hljs asciidoc"><span class="hljs-section">=== RUN   TestDemo5</span>
2020/09/30 22:15:03 goroutine B Lock
2020/09/30 22:15:03 goroutine B counter = 1
2020/09/30 22:15:04 goroutine A Unlock
2020/09/30 22:15:04 goroutine A counter = 2
<span class="hljs-bullet">--- </span>PASS: TestDemo5 (3.01s)
PASS</code></pre></div>
<p>测试通过，未报错，counter 的值也被成功修改，证明B上的锁，是可以被A解开的。</p>
<p>再进一步，goroutine A 不解锁，直接修改已经被 goroutine B 锁住的 counter 的值可以吗？试一下</p>
<div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestDemo6</span><span class="hljs-params">(t *testing.T)</span></span> &#123;
	<span class="hljs-keyword">var</span> mut sync.Mutex
	counter := <span class="hljs-number">0</span>
	<span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;
		mut.Lock()
		log.Println(<span class="hljs-string">&quot;goroutine B Lock&quot;</span>)
		counter = <span class="hljs-number">1</span>
		log.Println(<span class="hljs-string">&quot;goroutine B counter =&quot;</span>, counter)
		time.Sleep(<span class="hljs-number">5</span> * time.Second)
		mut.Unlock()
		log.Println(<span class="hljs-string">&quot;goroutine B Unlock&quot;</span>)
	&#125;()
	time.Sleep(<span class="hljs-number">1</span> * time.Second)
	<span class="hljs-comment">//log.Println(&quot;goroutine A Unlock&quot;)</span>
	<span class="hljs-comment">//mut.Unlock()</span>
	counter = <span class="hljs-number">2</span>
	log.Println(<span class="hljs-string">&quot;goroutine A counter =&quot;</span>, counter)
	time.Sleep(<span class="hljs-number">10</span> * time.Second)
&#125;</code></pre></div>
<p>结果</p>
<div class="code-wrapper"><pre><code class="hljs asciidoc"><span class="hljs-section">=== RUN   TestDemo6</span>
2020/09/30 22:15:43 goroutine B Lock
2020/09/30 22:15:43 goroutine B counter = 1
2020/09/30 22:15:44 goroutine A counter = 2
2020/09/30 22:15:48 goroutine B Unlock
<span class="hljs-bullet">--- </span>PASS: TestDemo6 (11.00s)
PASS</code></pre></div>
<p>测试通过，未报错，证明B上的锁，A可以不用解锁直接改。</p>
<h2 id="延伸"><a href="#延伸" class="headerlink" title="延伸"></a>延伸</h2><h3 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h3><h3 id="锁的两种通常处理方式"><a href="#锁的两种通常处理方式" class="headerlink" title="锁的两种通常处理方式"></a>锁的两种通常处理方式</h3><ul>
<li>一种是没有获取到锁的线程就一直循环等待判断该资源是否已经释放锁，这种锁叫做<strong>自旋锁</strong>，它不用将线程阻塞起来(NON-BLOCKING)；</li>
<li>还有一种处理方式就是把自己阻塞起来，等待重新调度请求，这种叫做互斥锁。</li>
</ul>
<h3 id="饥饿模式"><a href="#饥饿模式" class="headerlink" title="饥饿模式"></a>饥饿模式</h3><p>当互斥锁不断地试图获得一个永远无法获得的锁时，它可能会遇到饥饿问题。<br>在版本1.9中，Go通过添加一个新的饥饿模式来解决先前的问题，所有等待锁定超过一毫秒的 goroutine，也称为有界等待，将被标记为饥饿。当标记为饥饿时，解锁方法现在将把锁直接移交给第一位等待着。</p>
<h3 id="读写锁"><a href="#读写锁" class="headerlink" title="读写锁"></a>读写锁</h3><p>读写锁和上面的多也差不多，有这么几种情况</p>
<ul>
<li>在写锁已被锁定的情况下试图锁定写锁，会阻塞当前的 goroutine。</li>
<li>在写锁已被锁定的情况下试图锁定读锁，会阻塞当前的 goroutine。</li>
<li>在读锁已被锁定的情况下试图锁定写锁，会阻塞当前的 goroutine。</li>
<li>在读锁已被锁定的情况下试图锁定读锁，不会阻塞当前的 goroutine。</li>
</ul>
<h3 id="panic错误"><a href="#panic错误" class="headerlink" title="panic错误"></a>panic错误</h3><p>无论是互斥锁还是读写锁在程序运行时一定是成对的，不然就会引发不可恢复的panic。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol>
<li>锁一定要用对地方，特别是要注意Lock产生的阻塞对性能的影响。</li>
<li>在各种程序的逻辑分支下，都要确保锁的成对出现。</li>
<li>读写锁是对互斥锁的一个扩展，提高了程序的可读性。</li>
<li>临界区是需要每个 goroutine 主动遵守的，说白了就是每个 goroutine 的代码都存在 Lock。</li>
</ol>
<p><a href="https://github.com/zuoshuwen/go-example/blob/master/e001/a01_test.go">文章示例代码</a></p>
]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>同步</tag>
        <tag>互斥锁</tag>
      </tags>
  </entry>
  <entry>
    <title>Go并发编程之数据共享—(2)Pool</title>
    <url>/golang/ipc-pool/</url>
    <content><![CDATA[<h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><p><code>func (*Pool) Get</code><br><code>func (*Pool) Put</code></p>
]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>同步</tag>
      </tags>
  </entry>
  <entry>
    <title>Go并发编程之任务协作—(1)WaitGroup、Once</title>
    <url>/golang/ipc-waitgrouponce/</url>
    <content><![CDATA[<h1 id="WaitGroup"><a href="#WaitGroup" class="headerlink" title="WaitGroup"></a>WaitGroup</h1><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p><code>func (*WaitGroup) Add</code><br><code>func (*WaitGroup) Done</code><br><code>func (*WaitGroup) Wait</code></p>
<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-keyword">var</span> wg sync.WaitGroup
<span class="hljs-comment">//...</span>
wg.Add(<span class="hljs-number">1</span>)
<span class="hljs-comment">//...</span>
wg.Done()
<span class="hljs-comment">//...</span>
wg.Wait()</code></pre></div>

<p>好先统一 Add，再并发 Done，最后 Wait。</p>
<h1 id="Once"><a href="#Once" class="headerlink" title="Once"></a>Once</h1><h2 id="方法-1"><a href="#方法-1" class="headerlink" title="方法"></a>方法</h2><p><code>func (*Once) Do</code></p>
<h2 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h2><div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-keyword">var</span> once sync.Once
once.Do(<span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;
<span class="hljs-comment">//...</span>
&#125;)</code></pre></div>


]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>同步</tag>
      </tags>
  </entry>
  <entry>
    <title>Go内存管理、分配</title>
    <url>/golang/memory-alloc/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>本文是以 go 1.15 为基础编写，而就在我写这篇文章的时候，go master 分支已经发生了与 1.15 不同的变化，可能在 1.16 及以后的源码会与文章内容有些出入，但总体差异应该不会太大，比如申请内存的流程、内存的模型设计，所以这篇文章应该不会很快过时。</p>
<h1 id="系统内存"><a href="#系统内存" class="headerlink" title="系统内存"></a>系统内存</h1><h2 id="虚拟内存"><a href="#虚拟内存" class="headerlink" title="虚拟内存"></a>虚拟内存</h2><p><img src="/images/golang/memory-manage-vm-01.png" alt="虚拟内存"><br>虚拟内存是计算机系统内存管理的一种技术。它使得应用程序认为它拥有连续的可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。<br>目前，大多数操作系统都使用了虚拟内存，如Windows家族的“虚拟内存”；Linux的“交换空间”等。</p>
<ul>
<li>访问内存，实际访问的是虚拟内存</li>
<li>虚拟内存通过页表查看，当前要访问的虚拟内存地址，是否已经加载到了物理内存，如果已经在物理内存，则取物理内存数据，如果没有对应的物理内存，则从磁盘加载数据到物理内存，并把物理内存地址和虚拟内存地址更新到页表。</li>
<li>每个进程都要各自的虚拟内存，内存的并发访问问题的粒度从多进程级别，可以降低到多线程级别。</li>
</ul>
<h2 id="堆、栈"><a href="#堆、栈" class="headerlink" title="堆、栈"></a>堆、栈</h2><p><img src="/images/golang/memory-manage-vm-02.png" alt="堆、栈"></p>
<h3 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h3><ul>
<li>栈在高地址，从高地址向低地址增长；堆在低地址，从低地址向高地址增长。</li>
<li>栈的内存不需要回收；堆需要回收，无论是主动free、垃圾回收。</li>
<li>栈上的内存有更好的局部性；堆上内存访访问2块数据可能在不同的页上。</li>
<li>栈是操作系统管理的；堆是用户管理的</li>
<li>栈是静态内存分配；堆是动态内存分配</li>
</ul>
<h3 id="栈还有以下特点"><a href="#栈还有以下特点" class="headerlink" title="栈还有以下特点"></a>栈还有以下特点</h3><ul>
<li>LIFO，每当一个函数声明一个新变量时，它就被“推”到堆栈的最顶层块上。然后，每当一个函数退出时，最上面的块就会被清除</li>
<li>每个线程一个 stack</li>
</ul>
<h1 id="TCMalloc"><a href="#TCMalloc" class="headerlink" title="TCMalloc"></a>TCMalloc</h1><p><img src="/images/golang/memory-manage-tcmalloc-01.png" alt="TCMalloc"></p>
<p>内存分配策略的实现，我们也可以叫它内存分配器，相当于在用户编写的程序与虚拟内存中间建立了”内存池”，而避免手写内存池。</p>
<p>下面是比较成熟的内存池实现库</p>
<ul>
<li>glibc 的 ptmalloc2</li>
<li>google 的 tcmalloc</li>
<li>facebook 的 jemalloc</li>
</ul>
<p>Golang 正是使用了 <a href="http://goog-perftools.sourceforge.net/doc/tcmalloc.html">TCMalloc</a> 的设计思想。</p>
<h2 id="Page"><a href="#Page" class="headerlink" title="Page"></a>Page</h2><p>操作系统对内存管理以页为单位，TCMalloc 也是这样，只不过 TCMalloc 里的 Page 大小与操作系统里的大小并不一定相等，而是倍数关系，x64 下 Page 大小是 8KB。</p>
<h2 id="Span"><a href="#Span" class="headerlink" title="Span"></a>Span</h2><p>一组连续的 Page 被称为 Span，比如可以有 2 个页大小的 Span，也可以有 16 页大小的 Span，Span 比 Page 高一个层级，是为了方便管理一定大小的内存区域，Span 是 TCMalloc 中内存管理的基本单位。</p>
<h2 id="ThreadCache"><a href="#ThreadCache" class="headerlink" title="ThreadCache"></a>ThreadCache</h2><p>每个线程各自的 Cache，一个Cache包含多个空闲内存块链表，每个链表连接的都是内存块，同一个链表上内存块的大小是相同的，也可以说按内存块大小，给内存块分了个类，这样可以根据申请的内存大小，快速从合适的链表选择空闲内存块。由于每个线程有自己的 ThreadCache，所以 ThreadCache 访问是无锁的。</p>
<h2 id="CentralCache"><a href="#CentralCache" class="headerlink" title="CentralCache"></a>CentralCache</h2><p>是所有线程共享的缓存，也是保存的空闲内存块链表，链表的数量与 ThreadCache 中链表数量相同，当 ThreadCache 内存块不足时，可以从 CentralCache 取，当 ThreadCache 内存块多时，可以放回 CentralCache。由于 CentralCache 是共享的，所以它的访问是要加锁的。</p>
<h2 id="PageHeap"><a href="#PageHeap" class="headerlink" title="PageHeap"></a>PageHeap</h2><p>PageHeap 是堆内存的抽象，PageHeap 存的也是若干链表，链表保存的是 Span，当 CentralCache 没有内存的时，会从 PageHeap 取，把1个 Span 拆成若干内存块，添加到对应大小的链表中，当 CentralCache 内存多的时候，会放回 PageHeap。毫无疑问，PageHeap 也是要加锁的。</p>
<h2 id="对象大小"><a href="#对象大小" class="headerlink" title="对象大小"></a>对象大小</h2><ul>
<li>小对象大小：0~256KB</li>
<li>中对象大小：257~1024kb</li>
<li>大对象大小：&gt; 1024kb</li>
</ul>
<h1 id="GoMalloc"><a href="#GoMalloc" class="headerlink" title="GoMalloc"></a>GoMalloc</h1><p><img src="/images/golang/memory-manage-gomalloc-01.png" alt="Golang内存管理"></p>
<h2 id="大小维度"><a href="#大小维度" class="headerlink" title="大小维度"></a>大小维度</h2><h2 id="object-size"><a href="#object-size" class="headerlink" title="object size"></a>object size</h2><p>是申请对象的大小，比如，申请一个 8byte object size。</p>
<h2 id="size-class"><a href="#size-class" class="headerlink" title="size class"></a>size class</h2><p>8byte-到32kb<br><code>object size</code> 的分类、级别，比如 8b ~ 16b，16 ~ 32b，32b ~ 48b …，共 67 个<br>在代码中是这样的：</p>
<div class="code-wrapper"><pre><code class="hljs go">_NumSizeClasses = <span class="hljs-number">67</span></code></pre></div>

<h2 id="span-class"><a href="#span-class" class="headerlink" title="span class"></a>span class</h2><p><code>span</code> 的分类、级别，共 134 个，是 size class 的一倍<br>在代码中是这样的：</p>
<div class="code-wrapper"><pre><code class="hljs go">numSpanClasses = _NumSizeClasses &lt;&lt; <span class="hljs-number">1</span></code></pre></div>
<p>其中 67 个是 scan (对象中含有指针的），另外 67 个是 noscan（对象中不含有指针的）</p>
<h1 id="分配器结构"><a href="#分配器结构" class="headerlink" title="分配器结构"></a>分配器结构</h1><h2 id="page"><a href="#page" class="headerlink" title="page"></a>page</h2><p>与 TCMalloc 中的 Page 定义相同。</p>
<h2 id="mspan"><a href="#mspan" class="headerlink" title="mspan"></a>mspan</h2><p>与 TCMalloc 中的 Span 定义相同。<br>在代码中是这样的：</p>
<div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-keyword">type</span> mspan <span class="hljs-keyword">struct</span> &#123;
    allocBits  *gcBits
	gcmarkBits *gcBits
&#125;</code></pre></div>

<h2 id="mcache"><a href="#mcache" class="headerlink" title="mcache"></a>mcache</h2><p>与 TCMalloc 中的 ThreadCache 定义相同，但在 Golang 中每个 P（MPG中的P）拥有独立的 mcache，可以做到无锁访问。<br>在 mcache 中缓存着 134 个 mspan， 在代码中是这样的：</p>
<div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-keyword">type</span> mcache <span class="hljs-keyword">struct</span> &#123;
    alloc [numSpanClasses]*mspan</code></pre></div>

<h2 id="mcentral"><a href="#mcentral" class="headerlink" title="mcentral"></a>mcentral</h2><p>所有 P 的共享缓存，访问是要加锁的。<br>在代码中是这样的：</p>
<div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-keyword">type</span> mcentral <span class="hljs-keyword">struct</span> &#123;
    nonempty mSpanList <span class="hljs-comment">// 有空闲对象的 mspan 链表</span>
	empty    mSpanList <span class="hljs-comment">// 没有空闲对象或 span 已经被 mcache 缓存的 span 链表</span></code></pre></div>
<p>那 mcentral 有多少个呢？往下看 mheap</p>
<h2 id="mheap"><a href="#mheap" class="headerlink" title="mheap"></a>mheap</h2><p>mcentral 被 mheap 所管理，也是 134 个</p>
<div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-keyword">type</span> mheap <span class="hljs-keyword">struct</span> &#123;
    arenas [<span class="hljs-number">1</span> &lt;&lt; arenaL1Bits]*[<span class="hljs-number">1</span> &lt;&lt; arenaL2Bits]*heapArena
    
    central [numSpanClasses]<span class="hljs-keyword">struct</span> &#123;
    mcentral mcentral
    pad      [cpu.CacheLinePadSize - unsafe.Sizeof(mcentral&#123;&#125;)%cpu.CacheLinePadSize]<span class="hljs-keyword">byte</span>
    &#125;</code></pre></div>

<h2 id="pageCache"><a href="#pageCache" class="headerlink" title="pageCache"></a>pageCache</h2><p>在向mheap申请small内存的时候，会先访问 P 中的 pcache，P 结构如下：</p>
<div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-keyword">type</span> p <span class="hljs-keyword">struct</span> &#123;
    pcache      pageCache
&#125;</code></pre></div>
<p>pageCache结构如下</p>
<div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-keyword">type</span> pageCache <span class="hljs-keyword">struct</span> &#123;
	base  <span class="hljs-keyword">uintptr</span> <span class="hljs-comment">// base address of the chunk</span>
	cache <span class="hljs-keyword">uint64</span>  <span class="hljs-comment">// 64-bit bitmap representing free pages (1 means free)</span>
	scav  <span class="hljs-keyword">uint64</span>  <span class="hljs-comment">// 64-bit bitmap representing scavenged pages (1 means scavenged)</span>
&#125;</code></pre></div>

<h2 id="fixalloc"><a href="#fixalloc" class="headerlink" title="fixalloc"></a>fixalloc</h2><p>基于自由列表的固定大小的分配器</p>
<h1 id="分配流程"><a href="#分配流程" class="headerlink" title="分配流程"></a>分配流程</h1><h2 id="小内存"><a href="#小内存" class="headerlink" title="小内存"></a>小内存</h2><p>mcache-&gt;mcentral-&gt;mheap位图查找-&gt;pageCache → mheap基数树查找→操作系统分配</p>
<h2 id="大内存"><a href="#大内存" class="headerlink" title="大内存"></a>大内存</h2><p>大对象是大小大于32KB的内存，不与 mcache 和 mcentral 沟通，并直接通过 mheap 进行分配。经历mheap基数树查找→操作系统分配 的过程。每一个大对象是一个特殊的span, 它的class是0。</p>
<h2 id="寻找-span"><a href="#寻找-span" class="headerlink" title="寻找 span"></a>寻找 span</h2><ol>
<li>计算对象所需内存大小size</li>
<li>根据size到size class映射，计算出所需的size class</li>
<li>根据size class和对象是否包含指针计算出span class</li>
<li>获取该span class指向的span。</li>
</ol>
<p>以分配一个不包含指针的，大小为24Byte的对象为例。</p>
<p>根据映射表：</p>
<div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-comment">// class  bytes/obj  bytes/span  objects  tail waste  max waste</span>
<span class="hljs-comment">//     1          8        8192     1024           0     87.50%</span>
<span class="hljs-comment">//     2         16        8192      512           0     43.75%</span>
<span class="hljs-comment">//     3         32        8192      256           0     46.88%</span>
<span class="hljs-comment">//     4         48        8192      170          32     31.52%</span>
<span class="hljs-comment">//     5         64        8192      128           0     23.44%</span>
<span class="hljs-comment">//     6         80        8192      102          32     19.07%</span>
<span class="hljs-comment">//     7         96        8192       85          32     15.95%</span>
<span class="hljs-comment">//     8        112        8192       73          16     13.56%</span>
<span class="hljs-comment">//     9        128        8192       64           0     11.72%</span>
<span class="hljs-comment">//    10        144        8192       56         128     11.82%</span>
<span class="hljs-comment">//    11        160        8192       51          32      9.73%</span></code></pre></div>
<p>size class 3，它的对象大小范围是(16,32]Byte，24Byte刚好在此区间，所以此对象的size class为3。<br>Size class到span class的计算如下：</p>
<div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-comment">// noscan为true代表对象不包含指针</span>
<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">makeSpanClass</span><span class="hljs-params">(sizeclass <span class="hljs-keyword">uint8</span>, noscan <span class="hljs-keyword">bool</span>)</span> <span class="hljs-title">spanClass</span></span> &#123;
	<span class="hljs-keyword">return</span> spanClass(sizeclass&lt;&lt;<span class="hljs-number">1</span>) | spanClass(bool2int(noscan))
&#125;</code></pre></div>
<p>所以，对应的span class为：</p>
<div class="code-wrapper"><pre><code class="hljs go">span class = <span class="hljs-number">3</span> &lt;&lt; <span class="hljs-number">1</span> | <span class="hljs-number">1</span> = <span class="hljs-number">7</span></code></pre></div>
<p>所以该对象需要的是span class 7指向的span。</p>
<h1 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h1><p>在 GO 目前的版本中，内存管理使用了 位图（bitmap）、基数树（radix tree）。</p>
<h2 id="BitMap"><a href="#BitMap" class="headerlink" title="BitMap"></a>BitMap</h2><p>图（Bitmap），即位（Bit）的集合，是一种数据结构，可用于记录大量的0-1状态，在很多地方都会用到，比如Linux内核（如inode，磁盘块）、Bloom Filter算法等，其优势是可以在一个非常高的空间利用率下保存大量0-1状态。<br>BitMap算法的核心思想是用bit数组来记录0-1两种状态，然后再将具体数据映射到这个比特数组的具体位置，这个比特位设置成0表示数据不存在，设置成1表示数据存在。<br>BitMap算在在大量数据查询、去重等应用场景中使用的比较多，这个算法具有比较高的空间利用率。<br>在《编程珠玑》第一章中，就有利用bitmap进行大量文件的排序。<br>JDK<br>google</p>
<p>应该是GC的时候使用。</p>
<h2 id="前缀树"><a href="#前缀树" class="headerlink" title="前缀树"></a>前缀树</h2><p><img src="/images/golang/memory-manage-trie-01.png" alt="前缀树"><br>在计算机科学中，trie，又称前缀树或字典树，是一种有序树，用于保存关联数组，其中的键通常是字符串。与二叉查找树不同，键不是直接保存在节点中，而是由节点在树中的位置决定。一个节点的所有子孙都有相同的前缀，也就是这个节点对应的字符串，而根节点对应空字符串。一般情况下，不是所有的节点都有对应的值，只有叶子节点和部分内部节点所对应的键才有相关的值。<br>应用场景<br>trie树常用于搜索提示。如当输入一个网址，可以自动搜索出可能的选择。当没有完全匹配的搜索结果，可以返回前缀最相似的可能。</p>
<h2 id="基数树"><a href="#基数树" class="headerlink" title="基数树"></a>基数树</h2><p><img src="/images/golang/memory-manage-radix-01.png" alt="基数树"><br>在计算机科学中，基数树，或称Patricia trie/tree，或crit bit tree，压缩前缀树，是一种更节省空间的Trie（前缀树）。对于基数树的每个节点，如果该节点是唯一的子树的话，就和父节点合并。<br>应用场景<br>用于IP 路由。 信息检索中用于文本文档的倒排索引。</p>
<h2 id="go-内存管理中的位图、基数树"><a href="#go-内存管理中的位图、基数树" class="headerlink" title="go 内存管理中的位图、基数树"></a>go 内存管理中的位图、基数树</h2><p>在Go1.12的时候,Go语言采用了 Treap 进行内存的管理，Treap 是一种引入了随机数的二叉树搜索树，其实现简单，并且引入的随机数以及必要时的旋转保证了比较好的平衡特性。</p>
<h3 id="mspan-的实现-基数树（radix-tree）"><a href="#mspan-的实现-基数树（radix-tree）" class="headerlink" title="mspan 的实现 基数树（radix tree）"></a>mspan 的实现 基数树（radix tree）</h3><p>管理线性的地址空间的位图结构叫做基数树<br>mpagealloc.go</p>
<h1 id="文件"><a href="#文件" class="headerlink" title="文件"></a>文件</h1><ul>
<li>mpagealloc.go：Page allocator、radix tree</li>
<li>malloc.go：mallocgc() 申请内存的入口</li>
</ul>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>bitmap 管理内存页<br>radix tree 内存管理的结构</p>
<h1 id="参考借鉴"><a href="#参考借鉴" class="headerlink" title="参考借鉴"></a>参考借鉴</h1><p><a href="https://lessisbetter.site/2019/07/06/go-memory-allocation/">Go内存分配那些事，就这么简单！</a><br><a href="https://www.bilibili.com/video/av288263284/">GopherCon 2020: Michael Knyszek - Evolving the Go Memory Manager’s RAM</a><br><a href="https://juejin.cn/post/6844903769201704973">漫画：什么是Bitmap算法？</a><br><a href="http://c.biancheng.net/view/1270.html">什么是虚拟内存，虚拟内存及其作用详解</a></p>
]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>内存管理</tag>
        <tag>内存分配</tag>
      </tags>
  </entry>
  <entry>
    <title>Go内存GC</title>
    <url>/golang/memory-gc/</url>
    <content><![CDATA[<h1 id="GC"><a href="#GC" class="headerlink" title="GC"></a>GC</h1><p>Golang 一直都在高速发展，每次版本迭代，内存管理相关方面都会有所变化。</p>
<h2 id="释放内存"><a href="#释放内存" class="headerlink" title="释放内存"></a>释放内存</h2><h3 id="1-手动管理"><a href="#1-手动管理" class="headerlink" title="1. 手动管理"></a>1. 手动管理</h3><p>代表语言有 C、C++，需要调用 alloc, realloc, calloc, free 等函数</p>
<h3 id="2-垃圾回收（GC）"><a href="#2-垃圾回收（GC）" class="headerlink" title="2. 垃圾回收（GC）"></a>2. 垃圾回收（GC）</h3><p>在计算机科学中，垃圾回收（英语：Garbage Collection，缩写为GC）是指一种自动的存储器管理机制。当某个程序占用的一部分内存空间不再被这个程序访问时，这个程序会借助垃圾回收算法向操作系统归还这部分内存空间。垃圾回收器可以减轻程序员的负担，也减少程序中的错误。垃圾回收最早起源于LISP语言。</p>
<h4 id="2-1-标记和扫描GC-Mark-sweep"><a href="#2-1-标记和扫描GC-Mark-sweep" class="headerlink" title="2.1 标记和扫描GC(Mark-sweep)"></a>2.1 标记和扫描GC(Mark-sweep)</h4><p>代表语言有 Golang<br>标记和扫描GC，也称为跟踪GC。<br>它通常是一个两阶段的算法，首先将仍然被引用的对象标记为“活的”，然后在下一阶段释放不活的对象的内存。从根变量开始遍历所有引用的对象，标记引用的对象，没有被标记的进行回收</p>
<ul>
<li>优点：解决了引用计数的缺点。</li>
<li>缺点：需要 STW，暂时停掉程序运行。</li>
</ul>
<h4 id="2-2-引用计数GC"><a href="#2-2-引用计数GC" class="headerlink" title="2.2 引用计数GC"></a>2.2 引用计数GC</h4><p>代表语言有 PHP, Perl, and Python<br>在这种方法中，每个对象获得一个引用计数，该引用计数随着对它的引用的改变而增加或减少，当计数变为零时，垃圾收集就完成了，缺点是不能处理循环引用。</p>
<ul>
<li>优点：对象回收快，不会出现内存耗尽或达到某个阈值时才回收。</li>
<li>缺点：不能很好的处理循环引用，而实时维护引用计数也是有损耗的。</li>
</ul>
<h4 id="2-3-标记-压缩-Mark-compact"><a href="#2-3-标记-压缩-Mark-compact" class="headerlink" title="2.3 标记-压缩(Mark-compact)"></a>2.3 标记-压缩(Mark-compact)</h4><h4 id="2-4-半空间复制（Semispace-copy）"><a href="#2-4-半空间复制（Semispace-copy）" class="headerlink" title="2.4 半空间复制（Semispace copy）"></a>2.4 半空间复制（Semispace copy）</h4><h4 id="2-5-分代GC"><a href="#2-5-分代GC" class="headerlink" title="2.5 分代GC"></a>2.5 分代GC</h4><p>代表语言 Java，按照对象生命周期长短划分不同的代空间，生命周期长的放入老年代，短的放入新生代，不同代有不同的回收算法和回收频率。</p>
<ul>
<li>优点：回收性能好</li>
<li>缺点：算法复杂</li>
</ul>
<h2 id="STW"><a href="#STW" class="headerlink" title="STW"></a>STW</h2><p>STW 阶段指的是程序暂停所有运行中的协程，否则不会开始垃圾回收阶段。<br>最开始的时候，在垃圾回收阶段只有一个协程执行垃圾回收。<br>目前 并发GC，垃圾回收阶段用户协程与垃圾回收协程并发执行。STW时间，小于100微妙。</p>
<p>尽管 STW 如今已经优化到了半毫秒级别以下，但这个程序被卡死原因是由于需要进入 STW 导致的。原因在于，GC 在需要进入 STW 时，需要通知并让所有的用户态代码停止，但是 for {} 所在的 goroutine 永远都不会被中断，从而始终无法进入 STW 阶段。实际实践中也是如此，当程序的某个 goroutine 长时间得不到停止，强行拖慢进入 STW 的时机，这种情况下造成的影响（卡死）是非常可怕的。好在自 Go 1.14 之后，这类 goroutine 能够被异步地抢占，从而使得进入 STW 的时间不会超过抢占信号触发的周期，程序也不会因为仅仅等待一个 goroutine 的停止而停顿在进入 STW 之前的操作上。</p>
<p>stop the world, GC 的一些阶段需要停止所有的 mutator 以确定当前的引用关系。这便是很多人对 GC 担心的来源，这也是 GC 算法优化的重点。</p>
<p>在垃圾回收机制 (GC) 中，”Stop the World” (STW) 是一个重要阶段。顾名思义， 在 “Stop the World” 阶段， 当前运行的所有程序将被暂停， 扫描内存的 root 节点和添加写屏障 (write barrier) 。</p>
<p>处理器 P (无论是正在运行代码的处理器还是已在 idle 列表中的处理器)， 都会被被标记成停止状态 (stopped)， 不再运行任何代码。 调度器把每个处理器的 M  从各自对应的处理器 P 分离出来， 放到 idle 列表中去。<br>对于 Goroutine 本身， 他们会被放到一个全局队列中等待</p>
<h2 id="三色标记"><a href="#三色标记" class="headerlink" title="三色标记"></a>三色标记</h2><ol>
<li>灰色：对象还在标记队列中等待</li>
<li>黑色：对象已被标记，gcmarkBits 对应位为 1 – 该对象不会在本次 GC 中被回收</li>
<li>白色：对象未被标记，gcmarkBits 对应位为 0 – 该对象将会在本次 GC 中被清理</li>
</ol>
<p><img src="/images/golang/memory-manage-gc-01.png" alt="三色标记法"></p>
<p>通过上图，应该对三色标记法有了一个比较直观的了解，那么我们现在来讲讲原理。简单的讲，就是标记内存中那些还在使用中（即被引用了）的部分，而内存中不再使用（即未被引用）的部分，就是要回收的垃圾，需要将其回收，以供后续内存分配使用。上图中的 A、B、D 就是被引用正在使用的内存，而C、F、E 曾经被使用过，但现在没有任何对象引用，就需要被回收掉。</p>
<p>而 Root 区域主要是程序运行到当前时刻的栈和全局数据区域，是实时正在使用到的内存，当然应该优先标记。而考虑到内存块中存放的可能是指针，所以还需要递归的进行标记，待全部标记完后，就会对未被标记的内存进行回收。</p>
<h2 id="内存标记"><a href="#内存标记" class="headerlink" title="内存标记"></a>内存标记</h2><p>golang 中采用 span 数据结构管理内存，span 中维护了一个个内存块，并由一个位图 allocBits 表示内存块的分配情况，而上文中提到的 gcmarkBits 是记录每块内存块被引用情况的。</p>
<p><img src="/images/golang/memory-manage-gc-02.png" alt="内存标记"></p>
<p>如上图，allocBits 记录了每块内存的分配情况，而 gcmarkBits 记录了每块内存的标记情况。在标记阶段会对每块内存进行标记，有对象引用的内存标记为 1，没有对象引用的为 0。而 allocBits 和 gcmarkBits 的数据结构是完全一样的，在结束标记后，将 allocBits 指向 gcmarkBits，则有标记的才是存活的，这样就完成了内存回收。而 gcmarkBits 则会在下次标记时重新分配内存。</p>
<h1 id="Mark-amp-Sweep"><a href="#Mark-amp-Sweep" class="headerlink" title="Mark &amp; Sweep"></a>Mark &amp; Sweep</h1><ol>
<li>Stop the World</li>
<li>Mark：通过 Root 和 Root 直接间接访问到的对象， 来寻找所有可达的对象，并进行标记。</li>
<li>Sweep：对堆对象迭代，已标记的对象置位标记。所有未标记的对象加入freelist， 可用于再分配。</li>
<li>Start the World</li>
</ol>
<p>这个算法最大的问题是 GC 执行期间需要把整个程序完全暂停，朴素的 Mark Sweep 是整体 STW，并且分配速度慢，内存碎片率高。</p>
<h2 id="写屏障"><a href="#写屏障" class="headerlink" title="写屏障"></a>写屏障</h2><p>并发回收的屏障技术归根结底就是在利用内存写屏障来保证强三色不变性和弱三色不变性。早期的 Go 团队实践中选择了从提出较早的 Dijkstra 插入屏障出发， 不可避免的在为了保证强三色不变性的情况下，需要对栈进行重扫。 而在后期的实践中，Go 团队提出了将 Dijkstra 和 Yuasa 屏障结合的混合屏障， 将强三色不变性进行了弱化，从而消除了对栈的重新扫描这一硬性要求，使得在未来实现全面并发 GC 成为可能。</p>
<h2 id="垃圾回收优化"><a href="#垃圾回收优化" class="headerlink" title="垃圾回收优化"></a>垃圾回收优化</h2><p>在前文中提到，golang 的垃圾回收算法属于 标记-清除，是需要 STW 的。STW 就是 Stop The World 的意思，在 golang 中就是要停掉所有的 goroutine，专心进行垃圾回收，待垃圾回收结束后再恢复 goroutine。而 STW 时间的长短直接影响了应用的执行，如果时间过长，那将是灾难性的。为了缩短 STW 时间，golang 不对优化垃圾回收算法，其中写屏障（Write Barrier）和辅助GC（Mutator Assist）就是两种优化垃圾回收的方法。</p>
<ul>
<li>写屏障（Write Barrier）：上面说到的 STW 的目的是防止 GC 扫描时内存变化引起的混乱，而写屏障就是让 goroutine 与 GC 同时运行的手段，虽然不能完全消除 STW，但是可以大大减少 STW 的时间。写屏障在 GC 的特定时间开启，开启后指针传递时会把指针标记，即本轮不回收，下次 GC 时再确定。</li>
<li>辅助 GC（Mutator Assist）：为了防止内存分配过快，在 GC 执行过程中，GC 过程中 mutator 线程会并发运行，而 mutator assist 机制会协助 GC 做一部分的工作。</li>
</ul>
<h2 id="垃圾回收触发机制"><a href="#垃圾回收触发机制" class="headerlink" title="垃圾回收触发机制"></a>垃圾回收触发机制</h2><ol>
<li>内存分配量达到阈值：每次内存分配都会检查当前内存分配量是否达到阈值，如果达到阈值则触发 GC。阈值 = 上次 GC 内存分配量 * 内存增长率，内存增长率由环境变量 GOGC 控制，默认为 100，即每当内存扩大一倍时启动 GC。</li>
<li>定时触发 GC：默认情况下，2分钟触发一次 GC，该间隔由 src/runtime/proc.go 中的 forcegcperiod 声明。</li>
<li>手动触发 GC：在代码中，可通过使用 runtime.GC() 手动触发 GC。</li>
</ol>
<h2 id="GC-优化建议"><a href="#GC-优化建议" class="headerlink" title="GC 优化建议"></a>GC 优化建议</h2><p>由上文可知，GC 性能是与对象数量有关的，对象越多 GC 性能越差，对程序的影响也越大。所以在开发中要尽量减少对象分配个数，采用对象复用、将小对象组合成大对象或采用小数据类型（如使用 int8 代替 int）等。</p>
<h2 id="建议"><a href="#建议" class="headerlink" title="建议"></a>建议</h2><p>一门编程语言的垃圾回收机制会直接影响使用其开发应用的性能。在日常开发工作中也因注意到其作用，有助于开发出高性能的应用，这也是 GC 常常在面试中被问到的原因。同时，了解 GC 对了解内存管理也很有帮助。</p>
<h1 id="参考借鉴"><a href="#参考借鉴" class="headerlink" title="参考借鉴"></a>参考借鉴</h1><p><a href="https://developer.aliyun.com/article/775798">浅析 Golang 垃圾回收机制</a></p>
]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>GC</tag>
        <tag>垃圾回收</tag>
      </tags>
  </entry>
  <entry>
    <title>Go内存泄漏、逃逸</title>
    <url>/golang/memory-leak-escape/</url>
    <content><![CDATA[<h1 id="内存泄漏"><a href="#内存泄漏" class="headerlink" title="内存泄漏"></a>内存泄漏</h1><p><a href="https://segmentfault.com/a/1190000019222661">实战Go内存泄露</a></p>
<h1 id="内存逃逸"><a href="#内存逃逸" class="headerlink" title="内存逃逸"></a>内存逃逸</h1><h2 id="关于-堆和栈"><a href="#关于-堆和栈" class="headerlink" title="关于 堆和栈"></a>关于 堆和栈</h2><p>栈 可以简单得理解成一次函数调用内部申请到的内存，它们会随着函数的返回把内存还给系统。</p>
<div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">F</span><span class="hljs-params">()</span></span> &#123;
	temp := <span class="hljs-built_in">make</span>([]<span class="hljs-keyword">int</span>, <span class="hljs-number">0</span>, <span class="hljs-number">20</span>)
	...
&#125;</code></pre></div>
<p>类似于上面代码里面的temp变量，只是内函数内部申请的临时变量，并不会作为返回值返回，它就是被编译器申请到栈里面。</p>
<p>申请到 栈内存 好处：函数返回直接释放，不会引起垃圾回收，对性能没有影响。</p>
<div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">F</span><span class="hljs-params">()</span> []<span class="hljs-title">int</span></span>&#123;
	a := <span class="hljs-built_in">make</span>([]<span class="hljs-keyword">int</span>, <span class="hljs-number">0</span>, <span class="hljs-number">20</span>)
	<span class="hljs-keyword">return</span> a
&#125;</code></pre></div>
<p>而上面这段代码，申请的代码一模一样，但是申请后作为返回值返回了，编译器会认为变量之后还会被使用，当函数返回之后并不会将其内存归还，那么它就会被申请到 堆 上面了。</p>
<p>申请到堆上面的内存才会引起垃圾回收，如果这个过程（特指垃圾回收不断被触发）过于高频就会导致 gc 压力过大，程序性能出问题。</p>
<p>我们再看看如下几个例子：</p>
<div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">F</span><span class="hljs-params">()</span></span> &#123;
	a := <span class="hljs-built_in">make</span>([]<span class="hljs-keyword">int</span>, <span class="hljs-number">0</span>, <span class="hljs-number">20</span>)     <span class="hljs-comment">// 栈 空间小</span>
	b := <span class="hljs-built_in">make</span>([]<span class="hljs-keyword">int</span>, <span class="hljs-number">0</span>, <span class="hljs-number">20000</span>) <span class="hljs-comment">// 堆 空间过大</span>
 
	l := <span class="hljs-number">20</span>
	c := <span class="hljs-built_in">make</span>([]<span class="hljs-keyword">int</span>, <span class="hljs-number">0</span>, l) <span class="hljs-comment">// 堆 动态分配不定空间</span>
&#125;</code></pre></div>
<p>像是 b 这种 即使是临时变量，申请过大也会在堆上面申请。<br>对于 c 编译器对于这种不定长度的申请方式，也会在堆上面申请，即使申请的长度很短。</p>
<h2 id="逃逸分析（Escape-analysis）"><a href="#逃逸分析（Escape-analysis）" class="headerlink" title="逃逸分析（Escape analysis）"></a>逃逸分析（Escape analysis）</h2><p>所谓逃逸分析（Escape analysis）是指由编译器决定内存分配的位置，不需要程序员指定。</p>
<p>在函数中申请一个新的对象：</p>
<ul>
<li>如果分配 在栈中，则函数执行结束可自动将内存回收；</li>
<li>如果分配在堆中，则函数执行结束可交给GC（垃圾回收）处理;<br>注意，对于函数外部没有引用的对象，也有可能放到堆中，比如内存过大超过栈的存储能力。</li>
</ul>
<h2 id="逃逸场景（什么情况才分配到堆中）"><a href="#逃逸场景（什么情况才分配到堆中）" class="headerlink" title="逃逸场景（什么情况才分配到堆中）"></a>逃逸场景（什么情况才分配到堆中）</h2><h3 id="指针逃逸"><a href="#指针逃逸" class="headerlink" title="指针逃逸"></a>指针逃逸</h3><p>Go可以返回局部变量指针，这其实是一个典型的变量逃逸案例，示例代码如下：</p>
<div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-keyword">package</span> main

<span class="hljs-keyword">type</span> Student <span class="hljs-keyword">struct</span> &#123;
    Name <span class="hljs-keyword">string</span>
    Age  <span class="hljs-keyword">int</span>
&#125;

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">StudentRegister</span><span class="hljs-params">(name <span class="hljs-keyword">string</span>, age <span class="hljs-keyword">int</span>)</span> *<span class="hljs-title">Student</span></span> &#123;
    s := <span class="hljs-built_in">new</span>(Student) <span class="hljs-comment">//局部变量s逃逸到堆</span>

    s.Name = name
    s.Age = age

    <span class="hljs-keyword">return</span> s
&#125;

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;
    StudentRegister(<span class="hljs-string">&quot;Jim&quot;</span>, <span class="hljs-number">18</span>)
&#125;</code></pre></div>
<p>虽然 在函数 StudentRegister() 内部 s 为局部变量，其值通过函数返回值返回，s 本身为一指针，其指向的内存地址不会是栈而是堆，这就是典型的逃逸案例。</p>
<p>终端运行命令查看逃逸分析日志：<br><code>go build -gcflags=-m</code><br>可见在StudentRegister()函数中，也即代码第9行显示”escapes to heap”，代表该行内存分配发生了逃逸现象。</p>
<h3 id="栈空间不足逃逸（空间开辟过大）"><a href="#栈空间不足逃逸（空间开辟过大）" class="headerlink" title="栈空间不足逃逸（空间开辟过大）"></a>栈空间不足逃逸（空间开辟过大）</h3><div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-keyword">package</span> main

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Slice</span><span class="hljs-params">()</span></span> &#123;
    s := <span class="hljs-built_in">make</span>([]<span class="hljs-keyword">int</span>, <span class="hljs-number">1000</span>, <span class="hljs-number">1000</span>)

    <span class="hljs-keyword">for</span> index, _ := <span class="hljs-keyword">range</span> s &#123;
        s[index] = index
    &#125;
&#125;

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;
    Slice()
&#125;</code></pre></div>
<p>上面代码Slice()函数中分配了一个1000个长度的切片，是否逃逸取决于栈空间是否足够大。 直接查看编译提示，如下：</p>
<p>所以只是1000的长度还不足以发生逃逸现象。然后就x10倍吧</p>
<div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-keyword">package</span> main

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Slice</span><span class="hljs-params">()</span></span> &#123;
    s := <span class="hljs-built_in">make</span>([]<span class="hljs-keyword">int</span>, <span class="hljs-number">10000</span>, <span class="hljs-number">10000</span>)

    <span class="hljs-keyword">for</span> index, _ := <span class="hljs-keyword">range</span> s &#123;
        s[index] = index
    &#125;
&#125;

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;
    Slice()
&#125;</code></pre></div>
<p>分析如下：<br>当切片长度扩大到10000时就会逃逸。<br>实际上当栈空间不足以存放当前对象时或无法判断当前切片长度时会将对象分配到堆中。</p>
<h3 id="动态类型逃逸（不确定长度大小）"><a href="#动态类型逃逸（不确定长度大小）" class="headerlink" title="动态类型逃逸（不确定长度大小）"></a>动态类型逃逸（不确定长度大小）</h3><p>很多函数参数为interface类型，比如fmt.Println(a …interface{})，编译期间很难确定其参数的具体类型，也能产生逃逸。</p>
<p>如下代码所示：</p>
<div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-keyword">package</span> main

<span class="hljs-keyword">import</span> <span class="hljs-string">&quot;fmt&quot;</span>

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;
    s := <span class="hljs-string">&quot;Escape&quot;</span>
    fmt.Println(s)
&#125;</code></pre></div>
<div class="code-wrapper"><pre><code class="hljs shell">D:\SourceCode\GoExpert\src&gt;go build -gcflags=-m
<span class="hljs-meta">#</span><span class="bash"> _/D_/SourceCode/GoExpert/src</span>
.\main.go:7: s escapes to heap
.\main.go:7: main ... argument does not escape</code></pre></div>
<p>又或者像前面提到的例子：</p>
<div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">F</span><span class="hljs-params">()</span></span> &#123;
	a := <span class="hljs-built_in">make</span>([]<span class="hljs-keyword">int</span>, <span class="hljs-number">0</span>, <span class="hljs-number">20</span>)     <span class="hljs-comment">// 栈 空间小</span>
	b := <span class="hljs-built_in">make</span>([]<span class="hljs-keyword">int</span>, <span class="hljs-number">0</span>, <span class="hljs-number">20000</span>) <span class="hljs-comment">// 堆 空间过大 逃逸</span>
 
	l := <span class="hljs-number">20</span>
	c := <span class="hljs-built_in">make</span>([]<span class="hljs-keyword">int</span>, <span class="hljs-number">0</span>, l) <span class="hljs-comment">// 堆 动态分配不定空间 逃逸</span>
&#125;</code></pre></div>
<h3 id="闭包引用对象逃逸"><a href="#闭包引用对象逃逸" class="headerlink" title="闭包引用对象逃逸"></a>闭包引用对象逃逸</h3><p>Fibonacci数列的函数：</p>
<div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-keyword">package</span> main

<span class="hljs-keyword">import</span> <span class="hljs-string">&quot;fmt&quot;</span>

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Fibonacci</span><span class="hljs-params">()</span> <span class="hljs-title">func</span><span class="hljs-params">()</span> <span class="hljs-title">int</span></span> &#123;
    a, b := <span class="hljs-number">0</span>, <span class="hljs-number">1</span>
    <span class="hljs-keyword">return</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span> <span class="hljs-title">int</span></span> &#123;
        a, b = b, a+b
        <span class="hljs-keyword">return</span> a
    &#125;
&#125;

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;
    f := Fibonacci()

    <span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">10</span>; i++ &#123;
        fmt.Printf(<span class="hljs-string">&quot;Fibonacci: %d\n&quot;</span>, f())
    &#125;
&#125;</code></pre></div>
<p>输出如下：</p>
<div class="code-wrapper"><pre><code class="hljs shell">~/go/src/gitHub/test/pool  go run main.go
Fibonacci: 1
Fibonacci: 1
Fibonacci: 2
Fibonacci: 3
Fibonacci: 5
Fibonacci: 8
Fibonacci: 13
Fibonacci: 21
Fibonacci: 34
Fibonacci: 55</code></pre></div>
<p>逃逸如下：</p>
<div class="code-wrapper"><pre><code class="hljs shell"> ~/go/src/gitHub/test/pool  go build -gcflags=-m
<span class="hljs-meta">#</span><span class="bash"> gitHub/<span class="hljs-built_in">test</span>/pool</span>
./main.go:7:9: can inline Fibonacci.func1
./main.go:7:9: func literal escapes to heap
./main.go:7:9: func literal escapes to heap
./main.go:8:10: &amp;b escapes to heap
./main.go:6:5: moved to heap: b
./main.go:8:13: &amp;a escapes to heap
./main.go:6:2: moved to heap: a
./main.go:17:34: f() escapes to heap
./main.go:17:13: main ... argument does not escape</code></pre></div>
<p>Fibonacci()函数中原本属于局部变量的a和b由于闭包的引用，不得不将二者放到堆上，以致产生逃逸。</p>
<h2 id="逃逸分析的作用是什么呢？"><a href="#逃逸分析的作用是什么呢？" class="headerlink" title="逃逸分析的作用是什么呢？"></a>逃逸分析的作用是什么呢？</h2><ul>
<li>逃逸分析的好处是为了减少gc的压力，不逃逸的对象分配在栈上，当函数返回时就回收了资源，不需要gc标记清除。</li>
<li>逃逸分析完后可以确定哪些变量可以分配在栈上，栈的分配比堆快，性能好(逃逸的局部变量会在堆上分配 ,而没有发生逃逸的则有编译器在栈上分配)。</li>
<li>同步消除，如果你定义的对象的方法上有同步锁，但在运行时，却只有一个线程在访问，此时逃逸分析后的机器码，会去掉同步锁运行。</li>
</ul>
<h2 id="逃逸总结："><a href="#逃逸总结：" class="headerlink" title="逃逸总结："></a>逃逸总结：</h2><ul>
<li>栈上分配内存比在堆中分配内存有更高的效率</li>
<li>栈上分配的内存不需要GC处理</li>
<li>堆上分配的内存使用完毕会交给GC处理</li>
<li>逃逸分析目的是决定内分配地址是栈还是堆</li>
<li>逃逸分析在编译阶段完成</li>
</ul>
<h2 id="提问：函数传递指针真的比传值效率高吗？"><a href="#提问：函数传递指针真的比传值效率高吗？" class="headerlink" title="提问：函数传递指针真的比传值效率高吗？"></a>提问：函数传递指针真的比传值效率高吗？</h2><p>我们知道传递指针可以减少底层值的拷贝，可以提高效率，但是如果拷贝的数据量小，由于指针传递会产生逃逸，可能会使用堆，也可能会增加GC的负担，所以传递指针不一定是高效的。<br>在官网 (golang.org) FAQ 上有一个关于变量分配的问题如下：<br>From a correctness standpoint, you don’t need to know. Each variable in Go exists as long as there are references to it. The storage location chosen by the implementation is irrelevant to the semantics of the language.</p>
<p>The storage location does have an effect on writing efficient programs. When possible, the Go compilers will allocate variables that are local to a function in that function’s stack frame.</p>
<p>However, if the compiler cannot prove that the variable is not referenced after the function returns, then the compiler must allocate the variable on the garbage-collected heap to avoid dangling pointer errors. Also, if a local variable is very large, it might make more sense to store it on the heap rather than the stack.</p>
<p>In the current compilers, if a variable has its address taken, that variable is a candidate for allocation on the heap. However, a basic escape analysis recognizes some cases when such variables will not live past the return from the function and can reside on the stack.</p>
<p>翻译如下：</p>
<p>如何得知变量是分配在栈（stack）上还是堆（heap）上？</p>
<p>准确地说，你并不需要知道。Golang 中的变量只要被引用就一直会存活，存储在堆上还是栈上由内部实现决定而和具体的语法没有关系。</p>
<p>知道变量的存储位置确实和效率编程有关系。如果可能，Golang 编译器会将函数的局部变量分配到函数栈帧（stack frame）上。 然而，如果编译器不能确保变量在函数 return之后不再被引用，编译器就会将变量分配到堆上。而且，如果一个局部变量非常大，那么它也应该被分配到堆上而不是栈上。</p>
<p>当前情况下，如果一个变量被取地址，那么它就有可能被分配到堆上。然而，还要对这些变量做逃逸分析，如果函数return之后，变量不再被引用，则将其分配到栈上。</p>
<h1 id="内存碎片"><a href="#内存碎片" class="headerlink" title="内存碎片"></a>内存碎片</h1><h1 id="内存优化"><a href="#内存优化" class="headerlink" title="内存优化"></a>内存优化</h1>]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>Go内存泄漏、逃逸</tag>
      </tags>
  </entry>
  <entry>
    <title>Go面向对象</title>
    <url>/golang/oop/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>关于 Go 是不是面向对象语言的讨论一直喋喋不休，但讨论的结果并不重要，重要的是验证它的过程。</p>
<p>每门语言都有它独特的设计思想或者语言哲学，我们不能被过往的经验、传统概念所困住，能够使用它更优雅的解决问题，才是一门优秀编程语言价值的体现，至于它到底是白猫还是黑猫，也就没那么重要了。</p>
<span id="more"></span>

<h1 id="面向对象特征"><a href="#面向对象特征" class="headerlink" title="面向对象特征"></a>面向对象特征</h1><p>先从大家都熟知的四大特性入手。</p>
<h2 id="封装"><a href="#封装" class="headerlink" title="封装"></a>封装</h2><p>封装也叫作信息隐藏或者数据访问保护。类通过暴露有限的访问接口，授权外部仅能通过类提供的方式来访问内部信息或者数据。它需要编程语言提供权限访问控制语法来支持，例如 Java 中的 private、protected、public 关键字。封装特性存在的意义，一方面是保护数据不被随意修改，提高代码的可维护性；另一方面是仅暴露有限的必要接口，提高类的易用性。</p>
<h3 id="Go的封装"><a href="#Go的封装" class="headerlink" title="Go的封装"></a>Go的封装</h3><p>Go语言只有一种控制可见性的手段：大写首字母的标识符会从定义它们的包中被导出，小写字母的则不会。这种限制包内成员的方式同样适用于struct或者一个类型的方法。因而如果我们想要封装一个对象，我们必须将其定义为一个struct。</p>
<div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-keyword">package</span> main

<span class="hljs-keyword">import</span> <span class="hljs-string">&quot;fmt&quot;</span>

<span class="hljs-comment">// 重点在大小写，结构体名称、属性</span>
<span class="hljs-keyword">type</span> Html <span class="hljs-keyword">struct</span> &#123;
	Data <span class="hljs-keyword">string</span>
&#125;

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(h *Html)</span> <span class="hljs-title">read</span><span class="hljs-params">(path <span class="hljs-keyword">string</span>)</span></span> &#123;
	h.Data = <span class="hljs-string">&quot;sown&quot;</span>
&#125;

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(h *Html)</span> <span class="hljs-title">format</span><span class="hljs-params">()</span> <span class="hljs-title">string</span></span> &#123;
	<span class="hljs-keyword">return</span> <span class="hljs-string">&quot;&lt;html&gt;&quot;</span> + h.Data + <span class="hljs-string">&quot;&lt;/html&gt;&quot;</span>
&#125;

<span class="hljs-keyword">type</span> xml <span class="hljs-keyword">struct</span> &#123;
	data <span class="hljs-keyword">string</span>
&#125;

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(x *xml)</span> <span class="hljs-title">read</span><span class="hljs-params">(path <span class="hljs-keyword">string</span>)</span></span> &#123;
	x.data = <span class="hljs-string">&quot;sown&quot;</span>
&#125;

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(x *xml)</span> <span class="hljs-title">format</span><span class="hljs-params">()</span> <span class="hljs-title">string</span></span> &#123;
	<span class="hljs-keyword">return</span> <span class="hljs-string">&quot;&lt;xml&gt;&quot;</span> + x.data + <span class="hljs-string">&quot;&lt;/xml&gt;&quot;</span>
&#125;

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;
	h := Html&#123;&#125;
	h.read(<span class="hljs-string">&quot;./xml&quot;</span>)
	fmt.Println(h.format())
	
	x := xml&#123;&#125;
	x.read(<span class="hljs-string">&quot;./xml&quot;</span>)
	fmt.Println(x.format())
&#125;</code></pre></div>

<h2 id="抽象"><a href="#抽象" class="headerlink" title="抽象"></a>抽象</h2><p>封装主要讲如何隐藏信息、保护数据，那抽象就是讲如何隐藏方法的具体实现，让使用者只需要关心方法提供了哪些功能，不需要知道这些功能是如何实现的。抽象可以通过接口类或者抽象类来实现，但也并不需要特殊的语法机制来支持。抽象存在的意义，一方面是提高代码的可扩展性、维护性，修改实现不需要改变定义，减少代码的改动范围；另一方面，它也是处理复杂系统的有效手段，能有效地过滤掉不必要关注的信息。</p>
<p>我看网上有人用空结构体实现抽象类，我并不提倡这样做，遵循go的”面向接口编程”</p>
<div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-keyword">package</span> main

<span class="hljs-keyword">import</span> <span class="hljs-string">&quot;fmt&quot;</span>

<span class="hljs-comment">// 定义接口</span>
<span class="hljs-keyword">type</span> I <span class="hljs-keyword">interface</span> &#123;
	read(<span class="hljs-keyword">string</span>)
	format() <span class="hljs-keyword">string</span>
&#125;

<span class="hljs-keyword">type</span> Html <span class="hljs-keyword">struct</span> &#123;
	Data <span class="hljs-keyword">string</span>
&#125;

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(h *Html)</span> <span class="hljs-title">read</span><span class="hljs-params">(path <span class="hljs-keyword">string</span>)</span></span> &#123;
	h.Data = <span class="hljs-string">&quot;sown&quot;</span>
&#125;

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(h *Html)</span> <span class="hljs-title">format</span><span class="hljs-params">()</span> <span class="hljs-title">string</span></span> &#123;
	<span class="hljs-keyword">return</span> <span class="hljs-string">&quot;&lt;html&gt;&quot;</span> + h.Data + <span class="hljs-string">&quot;&lt;/html&gt;&quot;</span>
&#125;

<span class="hljs-keyword">type</span> xml <span class="hljs-keyword">struct</span> &#123;
	data <span class="hljs-keyword">string</span>
&#125;

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(x *xml)</span> <span class="hljs-title">read</span><span class="hljs-params">(path <span class="hljs-keyword">string</span>)</span></span> &#123;
	x.data = <span class="hljs-string">&quot;sown&quot;</span>
&#125;

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(x *xml)</span> <span class="hljs-title">format</span><span class="hljs-params">()</span> <span class="hljs-title">string</span></span> &#123;
	<span class="hljs-keyword">return</span> <span class="hljs-string">&quot;&lt;xml&gt;&quot;</span> + x.data + <span class="hljs-string">&quot;&lt;/xml&gt;&quot;</span>
&#125;

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;
	h := Html&#123;&#125;
	h.read(<span class="hljs-string">&quot;./xml&quot;</span>)
	fmt.Println(h.format())

	x := xml&#123;&#125;
	x.read(<span class="hljs-string">&quot;./xml&quot;</span>)
	fmt.Println(x.format())
&#125;</code></pre></div>

<h2 id="继承"><a href="#继承" class="headerlink" title="继承"></a>继承</h2><p>继承是用来表示类之间的 is-a 关系，分为两种模式：单继承和多继承。单继承表示一个子类只继承一个父类，多继承表示一个子类可以继承多个父类。为了实现继承这个特性，编程语言需要提供特殊的语法机制来支持。继承主要是用来解决代码复用的问题。</p>
<p>继承是用来表示类之间的 is-a 关系，比如猫是一种哺乳动物。从继承关系上来讲，继承可以分为两种模式，单继承和多继承。单继承表示一个子类只继承一个父类，多继承表示一个子类可以继承多个父类，比如猫既是哺乳动物，又是爬行动物。</p>
<p>继承最大的一个好处就是代码复用。<br>如果我们再上升一个思维层面，去思考继承这一特性，非常符合人类的认知，而且，从设计的角度来说，也有一种结构美感。比如，子承父业，父债子偿。</p>
<p>如果继承层次过深过复杂，就会导致代码可读性、可维护性变差。举个🌰，如果让你穿越过去，寻找你爷爷的爷爷的爷爷的爷爷，然后一定要劝他搬到京城附近安家，这样你现在就不用每天996了。很显然，找人就已经很难了，再把居住的属性给改了，未知的事情就更多了，后来有没有你都是回事儿了（不过~，这样好像也确实摆脱996了）…</p>
<p>所以，有人提出来一种设计思想，就是”多用组合少用继承”。</p>
<p>那么 GO 可以实现继承吗？</p>
<h3 id="Go的单继承（组合）"><a href="#Go的单继承（组合）" class="headerlink" title="Go的单继承（组合）"></a>Go的单继承（组合）</h3><div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-keyword">package</span> main

<span class="hljs-keyword">import</span> (
	<span class="hljs-string">&quot;fmt&quot;</span>
)

<span class="hljs-keyword">type</span> file <span class="hljs-keyword">struct</span> &#123;
	data <span class="hljs-keyword">string</span>
&#125;

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(f *file)</span> <span class="hljs-title">read</span><span class="hljs-params">()</span></span> &#123;
	f.data = <span class="hljs-string">&quot;sown&quot;</span>
&#125;

<span class="hljs-keyword">type</span> Html <span class="hljs-keyword">struct</span> &#123;
	file <span class="hljs-comment">//重点在这</span>
&#125;

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(h *Html)</span> <span class="hljs-title">format</span><span class="hljs-params">()</span> <span class="hljs-title">string</span></span> &#123;
	<span class="hljs-keyword">return</span> h.data
&#125;

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;
	h := Html&#123;&#125;
	h.read() <span class="hljs-comment">//重点在这，等同于 h.file.read()</span>
	fmt.Println(h.format())
&#125;</code></pre></div>

<h3 id="Go的多继承（组合）"><a href="#Go的多继承（组合）" class="headerlink" title="Go的多继承（组合）"></a>Go的多继承（组合）</h3><div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-keyword">package</span> main

<span class="hljs-keyword">import</span> (
	<span class="hljs-string">&quot;fmt&quot;</span>
)

<span class="hljs-keyword">type</span> file <span class="hljs-keyword">struct</span> &#123;
	data <span class="hljs-keyword">string</span>
&#125;

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(f *file)</span> <span class="hljs-title">read</span><span class="hljs-params">()</span></span> &#123;
	f.data = <span class="hljs-string">&quot;file&quot;</span>
&#125;

<span class="hljs-keyword">type</span> db <span class="hljs-keyword">struct</span> &#123;
	data <span class="hljs-keyword">string</span>
&#125;

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(d *db)</span> <span class="hljs-title">read</span><span class="hljs-params">()</span></span> &#123;
	d.data = <span class="hljs-string">&quot;db&quot;</span>
&#125;

<span class="hljs-keyword">type</span> Html <span class="hljs-keyword">struct</span> &#123;
	file
	db
&#125;

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(h *Html)</span> <span class="hljs-title">format</span><span class="hljs-params">(data <span class="hljs-keyword">string</span>)</span> <span class="hljs-title">string</span></span> &#123;
	<span class="hljs-keyword">return</span> <span class="hljs-string">&quot;&lt;html&gt;&quot;</span> + data + <span class="hljs-string">&quot;&lt;/html&gt;&quot;</span>
&#125;

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;
	h := Html&#123;&#125;
	h.file.read() <span class="hljs-comment">//继承（组合）file</span>
	fmt.Println(h.format(h.file.data))

	h.db.read() <span class="hljs-comment">//继承（组合）db</span>
	fmt.Println(h.format(h.db.data))
&#125;</code></pre></div>

<h3 id="继承（组合）的方法调用注意"><a href="#继承（组合）的方法调用注意" class="headerlink" title="继承（组合）的方法调用注意"></a>继承（组合）的方法调用注意</h3><p>其实这里的要注意的问题，不是语法问题，而是要注意在Go中继承并非其他语言中的继承，而是利用组合代替了继承。</p>
<div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-keyword">package</span> main

<span class="hljs-keyword">import</span> (
	<span class="hljs-string">&quot;fmt&quot;</span>
	<span class="hljs-string">&quot;io/ioutil&quot;</span>
	<span class="hljs-string">&quot;os&quot;</span>
)

<span class="hljs-keyword">type</span> file <span class="hljs-keyword">struct</span> &#123;
	data <span class="hljs-keyword">string</span>
&#125;

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(f *file)</span> <span class="hljs-title">read</span><span class="hljs-params">()</span> <span class="hljs-title">string</span></span> &#123;
	<span class="hljs-keyword">return</span> f.format() <span class="hljs-comment">//&lt;-----重点在这里</span>
&#125;

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(f *file)</span> <span class="hljs-title">format</span><span class="hljs-params">()</span> <span class="hljs-title">string</span></span> &#123;
	<span class="hljs-keyword">return</span> <span class="hljs-string">&quot;file.format&quot;</span>
&#125;

<span class="hljs-keyword">type</span> Html <span class="hljs-keyword">struct</span> &#123;
	file
&#125;

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(h *Html)</span> <span class="hljs-title">format</span><span class="hljs-params">()</span> <span class="hljs-title">string</span></span> &#123;
	<span class="hljs-keyword">return</span> <span class="hljs-string">&quot;html.format&quot;</span>
&#125;

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;
	h := Html&#123;&#125;
	content := h.read()
	fmt.Println(content) <span class="hljs-comment">//file.format</span>
&#125;</code></pre></div>

<h2 id="多态"><a href="#多态" class="headerlink" title="多态"></a>多态</h2><p>多态是指子类可以替换父类，在实际的代码运行过程中，调用子类的方法实现。多态这种特性也需要编程语言提供特殊的语法机制来实现，比如继承、接口类、duck-typing。多态可以提高代码的扩展性和复用性，是很多设计模式、设计原则、编程技巧的代码实现基础。</p>
<div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-keyword">package</span> main

<span class="hljs-keyword">import</span> (
	<span class="hljs-string">&quot;fmt&quot;</span>
)

<span class="hljs-keyword">type</span> i <span class="hljs-keyword">interface</span> &#123;
	format(content <span class="hljs-keyword">string</span>) <span class="hljs-keyword">string</span>
&#125;

<span class="hljs-comment">// 重点在这里</span>
<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">format</span><span class="hljs-params">(content <span class="hljs-keyword">string</span>, i i)</span> <span class="hljs-title">string</span></span> &#123;
	<span class="hljs-keyword">return</span> i.format(content)
&#125;

<span class="hljs-keyword">type</span> Html <span class="hljs-keyword">struct</span> &#123;
&#125;

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(h *Html)</span> <span class="hljs-title">format</span><span class="hljs-params">(content <span class="hljs-keyword">string</span>)</span> <span class="hljs-title">string</span></span> &#123;
	<span class="hljs-keyword">return</span> <span class="hljs-string">&quot;&lt;html&gt;&quot;</span> + content + <span class="hljs-string">&quot;&lt;/html&gt;&quot;</span>
&#125;

<span class="hljs-keyword">type</span> Xml <span class="hljs-keyword">struct</span> &#123;
&#125;

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(x *Xml)</span> <span class="hljs-title">format</span><span class="hljs-params">(content <span class="hljs-keyword">string</span>)</span> <span class="hljs-title">string</span></span> &#123;
	<span class="hljs-keyword">return</span> <span class="hljs-string">&quot;&lt;xml&gt;&quot;</span> + content + <span class="hljs-string">&quot;&lt;/xml&gt;&quot;</span>
&#125;

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;
	h := &amp;Html&#123;&#125;
	x := &amp;Xml&#123;&#125;
	fmt.Println(format(<span class="hljs-string">&quot;sown&quot;</span>, h)) <span class="hljs-comment">//&lt;html&gt;sown&lt;/html&gt;</span>
	fmt.Println(format(<span class="hljs-string">&quot;sown&quot;</span>, x)) <span class="hljs-comment">//&lt;xml&gt;sown&lt;/xml&gt;</span>
&#125;</code></pre></div>

<h1 id="Go特性"><a href="#Go特性" class="headerlink" title="Go特性"></a>Go特性</h1><h2 id="方法的定义：关于指针、值复制"><a href="#方法的定义：关于指针、值复制" class="headerlink" title="方法的定义：关于指针、值复制"></a>方法的定义：关于指针、值复制</h2><p>第一种定义方式在实例对应方法被调用时，实例的成员会进行值复制。<br>第二种方法被调用时，避免了内存拷贝。</p>
<div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-keyword">package</span> main

<span class="hljs-keyword">import</span> <span class="hljs-string">&quot;fmt&quot;</span>

<span class="hljs-keyword">type</span> Html <span class="hljs-keyword">struct</span> &#123;
	Data <span class="hljs-keyword">string</span>
&#125;

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(h Html)</span> <span class="hljs-title">read</span><span class="hljs-params">()</span></span> &#123;
	h.Data = <span class="hljs-string">&quot;sown&quot;</span>
&#125;

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(h Html)</span> <span class="hljs-title">format</span><span class="hljs-params">()</span> <span class="hljs-title">string</span></span> &#123;
	<span class="hljs-keyword">return</span> <span class="hljs-string">&quot;&lt;html&gt;&quot;</span> + h.Data + <span class="hljs-string">&quot;&lt;/html&gt;&quot;</span>
&#125;

<span class="hljs-keyword">type</span> xml <span class="hljs-keyword">struct</span> &#123;
	data <span class="hljs-keyword">string</span>
&#125;

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(x *xml)</span> <span class="hljs-title">read</span><span class="hljs-params">()</span></span> &#123;
	x.data = <span class="hljs-string">&quot;sown&quot;</span>
&#125;

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(x *xml)</span> <span class="hljs-title">format</span><span class="hljs-params">()</span> <span class="hljs-title">string</span></span> &#123;
	<span class="hljs-keyword">return</span> <span class="hljs-string">&quot;&lt;xml&gt;&quot;</span> + x.data + <span class="hljs-string">&quot;&lt;/xml&gt;&quot;</span>
&#125;

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;
	h := Html&#123;&#125;
	h.read()
	fmt.Println(h.format())	<span class="hljs-comment">//结果是&lt;html&gt;&lt;/html&gt;，期望是&lt;html&gt;sown&lt;/html&gt;</span>

	x := xml&#123;&#125;
	x.read()
	fmt.Println(x.format())	<span class="hljs-comment">//结果是&lt;xml&gt;sown&lt;/html&gt;</span>
&#125;</code></pre></div>
<h2 id="声明为接口类型"><a href="#声明为接口类型" class="headerlink" title="声明为接口类型"></a>声明为接口类型</h2><p>接口中只能定义方法签名，不能包含成员变量。声明一个实例变量为接口类型，这个实例的方法外部将无法访问成员变量。</p>
<div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-keyword">package</span> main

<span class="hljs-keyword">import</span> <span class="hljs-string">&quot;fmt&quot;</span>

<span class="hljs-keyword">type</span> I <span class="hljs-keyword">interface</span> &#123;
	read()
	format() <span class="hljs-keyword">string</span>
&#125;

<span class="hljs-keyword">type</span> xml <span class="hljs-keyword">struct</span> &#123;
	data <span class="hljs-keyword">string</span>
&#125;

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(x *xml)</span> <span class="hljs-title">read</span><span class="hljs-params">()</span></span> &#123;
	x.data = <span class="hljs-string">&quot;sown&quot;</span>
&#125;

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(x *xml)</span> <span class="hljs-title">format</span><span class="hljs-params">()</span> <span class="hljs-title">string</span></span> &#123;
	<span class="hljs-keyword">return</span> <span class="hljs-string">&quot;&lt;xml&gt;&quot;</span> + x.data + <span class="hljs-string">&quot;&lt;/xml&gt;&quot;</span>
&#125;

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;
	<span class="hljs-keyword">var</span> x I <span class="hljs-comment">//这里声明接口类型</span>
	x = &amp;xml&#123;&#125;
	x.read()
	x.data = <span class="hljs-string">&quot;nwos&quot;</span> <span class="hljs-comment">//这里报错</span>
	fmt.Println(x.format())
&#125;</code></pre></div>

<h2 id="方法集"><a href="#方法集" class="headerlink" title="方法集"></a>方法集</h2><p>先看如下代码：</p>
<div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-keyword">package</span> main

<span class="hljs-keyword">import</span> <span class="hljs-string">&quot;fmt&quot;</span>

<span class="hljs-keyword">type</span> I <span class="hljs-keyword">interface</span> &#123;
	read()
	format() <span class="hljs-keyword">string</span>
&#125;

<span class="hljs-keyword">type</span> Html <span class="hljs-keyword">struct</span> &#123;
	Data <span class="hljs-keyword">string</span>
&#125;

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(h Html)</span> <span class="hljs-title">read</span><span class="hljs-params">()</span></span> &#123;
	h.Data = <span class="hljs-string">&quot;sown&quot;</span>
&#125;

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(h Html)</span> <span class="hljs-title">format</span><span class="hljs-params">()</span> <span class="hljs-title">string</span></span> &#123;
	<span class="hljs-keyword">return</span> <span class="hljs-string">&quot;&lt;html&gt;&quot;</span> + h.Data + <span class="hljs-string">&quot;&lt;/html&gt;&quot;</span>
&#125;

<span class="hljs-keyword">type</span> xml <span class="hljs-keyword">struct</span> &#123;
	data <span class="hljs-keyword">string</span>
&#125;

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(x *xml)</span> <span class="hljs-title">read</span><span class="hljs-params">()</span></span> &#123;
	x.data = <span class="hljs-string">&quot;sown&quot;</span>
&#125;

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(x *xml)</span> <span class="hljs-title">format</span><span class="hljs-params">()</span> <span class="hljs-title">string</span></span> &#123;
	<span class="hljs-keyword">return</span> <span class="hljs-string">&quot;&lt;xml&gt;&quot;</span> + x.data + <span class="hljs-string">&quot;&lt;/xml&gt;&quot;</span>
&#125;

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;
	<span class="hljs-keyword">var</span> h I
	h = Html&#123;&#125;
	h.read()
	fmt.Println(h.format())

	<span class="hljs-keyword">var</span> x I
	x = xml&#123;&#125; <span class="hljs-comment">// 这里报错</span>
	x.read()
	fmt.Println(x.format())
&#125;</code></pre></div>
<p>输出如下：</p>
<div class="note note-danger">
            <p>./main.go:41:4: cannot use xml literal (type xml) as type I in assignment:<br>xml does not implement I (format method has pointer receiver)</p>
          </div>
<p>为什么会这样呢？ 首先说几个定义：</p>
<blockquote>
<p>Pointer Receiver：(t T)，例如 <code>func (x xml) read()</code><br>Value Receiver：(t *T)，例如 <code>func (x *xml) read()</code></p>
</blockquote>
<p>方法集 Method set：</p>
<table>
<thead>
<tr>
<th>Values</th>
<th>Methods Receivers</th>
</tr>
</thead>
<tbody><tr>
<td>T</td>
<td>(t T)</td>
</tr>
<tr>
<td>*T</td>
<td>(t T) and (t *T)</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>Methods Receivers</th>
<th>Values</th>
</tr>
</thead>
<tbody><tr>
<td>(t T)</td>
<td>T and *T</td>
</tr>
<tr>
<td>(t *T)</td>
<td>*T</td>
</tr>
</tbody></table>
<p><strong>为什么T和*T具有不同的方法集？</strong></p>
<blockquote>
<p>如Go规范所述，类型的方法集T由具有接收器类型的所有方法组成T，而相应的指针类型*T的方法集由具有接收器*T或 的所有方法组成T。这意味着的方法集*T 包括的方法集T，但不包括相反的方法集。</p>
<p>之所以出现这种区别，是因为如果接口值包含指针*T，则方法调用可以通过取消引用指针来获取值，但是如果接口值包含value T，则方法调用就没有安全的方法来获取指针。（这样做将允许一种方法修改接口内部值的内容，这是语言规范所不允许的。）</p>
<p>即使在编译器可以将值的地址传递给方法的情况下，如果方法修改了该值，则更改也将在调用方中丢失。作为一个例子，如果该Write方法 bytes.Buffer 中使用的值接收器，而不是一个指针，这样的代码：</p>
<p>var buf bytes.Buffer<br>io.Copy(buf，os.Stdin)</p>
<p>会将标准输入复制到的副本中buf，而不是复制到buf自身中。这几乎从来不是期望的行为。</p>
</blockquote>
<p>来自<a href="https://golang.org/doc/faq#Functions_methods">https://golang.org/doc/faq#Functions_methods</a></p>
<blockquote>
<ol>
<li><p>如果您有a *T，则可以调用具有接收器类型的*T方法以及具有接收器类型的方法T（<a href="https://golang.org/ref/spec#Method_sets">Method Sets</a>）。</p>
</li>
<li><p>如果具有a T并且它是<a href="https://golang.org/ref/spec#Address_operators">可寻址</a>的，则可以调用具有接收器类型的*T方法以及具有接收器类型T的方法，因为该方法调用t.Meth()将等效于(&amp;t).Meth()（<a href="https://golang.org/ref/spec#Calls">Calls</a>）。</p>
</li>
<li><p>如果您有一个T且无法寻址，则只能调用接收者类型为T而不是的方法*T。</p>
</li>
<li><p>如果您有一个接口I，并且I方法集中的某些或全部方法由接收者为的方法提供*T（其余部分由接收者为的方法提供T），则*T满足该接口I，但T不满足。这是因为*T的方法集包括T，但不是（反过来说又回到了第一点）。</p>
</li>
</ol>
<p>简而言之，您可以将方法与值接收器混合使用，将方法与指针接收器混合使用，并将它们与包含值和指针的变量一起使用，而不必担心哪个是哪个。两者都可以使用，并且语法相同。但是，如果需要使用带有指针接收器的方法来满足一个接口，则只能将一个指针分配给该接口-值将无效。</p>
</blockquote>
<p>来自<a href="https://stackoverflow.com/questions/33587227/method-sets-pointer-vs-value-receiver">https://stackoverflow.com/questions/33587227/method-sets-pointer-vs-value-receiver</a></p>
<h2 id=""><a href="#" class="headerlink" title=""></a></h2><div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-keyword">type</span> People <span class="hljs-keyword">struct</span> &#123;
    Name <span class="hljs-keyword">string</span>
&#125;

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(p People)</span> <span class="hljs-title">String</span><span class="hljs-params">()</span> <span class="hljs-title">string</span></span> &#123;
    <span class="hljs-keyword">return</span> fmt.Sprintf(<span class="hljs-string">&quot;print: %v&quot;</span>, p)
&#125;

<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;
    p := &amp;People&#123;&#125;
    p.String()
&#125;</code></pre></div>

<h1 id="开源学习"><a href="#开源学习" class="headerlink" title="开源学习"></a>开源学习</h1><h1 id="延伸"><a href="#延伸" class="headerlink" title="延伸"></a>延伸</h1><h2 id="面向过程"><a href="#面向过程" class="headerlink" title="面向过程"></a>面向过程</h2><h2 id="面向协议"><a href="#面向协议" class="headerlink" title="面向协议"></a>面向协议</h2><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>组合代替继承<br>面向接口编程<br>倾向于使用小的接口定义，很多接口只包含一个方法<br>较大的接口定义，可以由多个小接口定义组合而成<br>只依赖于必要功能的最小接口</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>Tips</p>
<ol>
<li>为什么在 object_oriented_a_test.go 中， var c D = &amp;Demo{} 可以，而 var c D = Demo{} 不行？<br>value method 情况下没有任何的错误。<br>主要的情况是在 method 为 pointer 时：<br>如果 定义&amp;初始化 的时候，使用了 接口类型，那么等号右边必须是 &amp;<br>两种情况：<br>如果 接口定义 被 接口实现，实现的方法中是有 * 的，那么实例化时，必须使用 &amp; 或 new，否则将会报错。 如果 接口定义 未 接口实现，实现的方法中是无 * 的，那么实例化时，就无所谓，并不会报错。<br>解析：<br>value method 可以被 pointer和 value 对象调用，而 pointer method 只能被 pointer 对象调用。 原因是：pointer method 会修改对象的值，而 value method 不会，所以如果在一个 value 对象上调用 pointer method，编译器会对原来的值做一份拷贝(参考函数传参规范)，并在拷贝后的值上执行函数，那么如果函数有修改原 receiver 的值，则修改的行为都发生在拷贝的值上，而不会影响原值，这个错误很隐蔽不容易被调试发现，因此 Go 决定放弃这个错误发生的可能性，直接不支持 pointer method 被 value 对象调用。<br>示例代码</li>
<li>结构体嵌套（组合），为什么不能识别被嵌入结构体的属性？<br>如果定义为 *，那么初始化的时候必须为 &amp;<br>示例代码</li>
<li>NewDemoC 和 &amp;DemoC{} 区别？<br>如果结构体是空的，那么哪种实例化的指针值都是一样的，因为返回的都是零值。<br>如果不是空结构体，那么哪种实例化的指针都是不一样的。<br>示例代码</li>
<li>为什么结构体可以写 * ，而接口不能写 * ？<br>执行代码会出现”type *PaymentStrategy is pointer to interface, not interface)“错误，原因是因为”PaymentStrategy”是interface而不是struct，不能用指针方式传递。<br>示例代码</li>
</ol>
<p>MySQL连接池</p>
<p>databas/sql和go-sql-driver的源码，出现这个错误之后官方提供的方法是会进行两次的重连操作，如果两次重连都没有成功，就创建一个新的SQL链接，所以出现这个错误日志没什么影响，当然最好的做法是设置一下链接的空闲超时时间，设置的比Mysql服务器超时时间 SetConnMaxLifetime() 短就可以了，设置了这个之后就不会报这个错误了。当然不设也可以，设置了的话程序处理会更优雅一点！</p>
]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>面向对象</tag>
        <tag>OOP</tag>
      </tags>
  </entry>
  <entry>
    <title>GoMPG与调度</title>
    <url>/golang/scheduling/</url>
    <content><![CDATA[<h1 id="调度"><a href="#调度" class="headerlink" title="调度"></a>调度</h1><h2 id="宏观关系"><a href="#宏观关系" class="headerlink" title="宏观关系"></a>宏观关系</h2><p><img src="/images/golang/scheduling-mpg-01.png" alt="MPG关系图"><br><img src="/images/golang/scheduling-mpg-02.png" alt="MPG关系图"><br><img src="/images/golang/scheduling-mpg-03.png" alt="MPG关系图"></p>
<h2 id="核心容器"><a href="#核心容器" class="headerlink" title="核心容器"></a>核心容器</h2><table>
<thead>
<tr>
<th>名称</th>
<th>源码</th>
<th>说明</th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td>全局M列表</td>
<td>runtime.allm</td>
<td>所有M的单链表</td>
<td>创建之后先进全局，随即进行初始化</td>
</tr>
<tr>
<td>全局P列表</td>
<td>runtime.allp</td>
<td>所有P的数组</td>
<td>创建之后先进全局，随即进行初始化</td>
</tr>
<tr>
<td>全局G列表</td>
<td>runtime.allgs</td>
<td>所有P的切片</td>
<td>创建之后先进全局，随即进行初始化</td>
</tr>
<tr>
<td>调度器的空闲M列表</td>
<td>runtime.sched.midle</td>
<td>空闲M的单链表</td>
<td>暂时不用；用时再取</td>
</tr>
<tr>
<td>调度器的空闲P列表</td>
<td>runtime.sched.midle</td>
<td>空闲P的单链表</td>
<td>P不在关联M，P中可运行G为空，加入该列表；M需要P关联，从此列表取；</td>
</tr>
<tr>
<td>调度器的可运行G队列</td>
<td>runtime.sched.runq.head；runtime.sched.runq.tail</td>
<td>可运行的G队列</td>
<td>如果P的可运行G队列满，加入此队列</td>
</tr>
<tr>
<td>调度器的自由G列表</td>
<td>runtime.sched.gFree.stack(有栈)；runtime.sched.gFree.noStack (无栈)</td>
<td>自由的G的两个单链表</td>
<td>本地P自由G列表缺G，此列表给补；本地P自由G列表满G，此列表收取；</td>
</tr>
<tr>
<td>P的可运行G队列</td>
<td>runtime.p.runq；runtime.p.runqhead；runtime.p.runqtail</td>
<td>P中的可运行G的队列</td>
<td>调度器初始化过的G，加入该队列</td>
</tr>
<tr>
<td>P的自由G列表</td>
<td>runtime.p.gfree</td>
<td>P中的自由G的单链表</td>
<td>包含一些已经运行完成的G；go启用G，先从此处寻找现成的G；</td>
</tr>
</tbody></table>
<h2 id="M"><a href="#M" class="headerlink" title="M"></a>M</h2><h3 id="结构体成员"><a href="#结构体成员" class="headerlink" title="结构体成员"></a>结构体成员</h3><table>
<thead>
<tr>
<th>名称</th>
<th>类型</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>g0</td>
<td>*g</td>
<td>特殊的 goroutine，在 runtime 启动之初创建的，用于执行一些运行时任务</td>
</tr>
<tr>
<td>mstartfn</td>
<td>func()</td>
<td>在新的 M 上启动特殊任务（系统监控、GC辅助、M自旋）</td>
</tr>
<tr>
<td>curg</td>
<td>*g</td>
<td>当前 M 正在运行的 G 的指针</td>
</tr>
<tr>
<td>p</td>
<td>puintptr</td>
<td>当前 M 正在关联的那个 P</td>
</tr>
<tr>
<td>nextp</td>
<td>puintptr</td>
<td>暂存与当前 M 有潜在关联的 P（预连）</td>
</tr>
<tr>
<td>spinning</td>
<td>bool</td>
<td>是否在寻找可运行的 G，寻找过程中 M 自旋</td>
</tr>
<tr>
<td>lockedg</td>
<td>*g</td>
<td>当前 M 锁定的 G</td>
</tr>
</tbody></table>
<h2 id="P"><a href="#P" class="headerlink" title="P"></a>P</h2><h3 id="状态"><a href="#状态" class="headerlink" title="状态"></a>状态</h3><table>
<thead>
<tr>
<th>状态</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>Pidle</td>
<td>当前 P 未与任何 M 关联</td>
</tr>
<tr>
<td>Prunning</td>
<td>当前 P 正在于 M 关联</td>
</tr>
<tr>
<td>Psyscall</td>
<td>当前 P 中的运行的那个 G 正在进行系统调用</td>
</tr>
<tr>
<td>Pgcstop</td>
<td>运行时系统需要停止调度。例如，运行时系统正在垃圾回收的某些步骤前，就会试图把runtime.allp（全局 P 列表）都置于此状态</td>
</tr>
<tr>
<td>Pdead</td>
<td>当前 P 已经不会再被使用。例如，运行过程中，通过 runtime.GOMAXPROCS 函数减少了 p 的最大数量</td>
</tr>
</tbody></table>
<p><img src="/images/golang/scheduling-p-status-01.png" alt="P状态流转"></p>
<h2 id="G"><a href="#G" class="headerlink" title="G"></a>G</h2><h3 id="状态-1"><a href="#状态-1" class="headerlink" title="状态"></a>状态</h3><table>
<thead>
<tr>
<th>状态</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>Gidle</td>
<td>刚被新分配，但还未初始化</td>
</tr>
<tr>
<td>Grunnable</td>
<td>可运行队列中等待运行</td>
</tr>
<tr>
<td>Grunning</td>
<td>运行</td>
</tr>
<tr>
<td>Gsyscall</td>
<td>执行某个系统调用</td>
</tr>
<tr>
<td>Gwaiting</td>
<td>阻塞</td>
</tr>
<tr>
<td>Gdead</td>
<td>闲置</td>
</tr>
<tr>
<td>Gcopystack</td>
<td>栈被移动，移动的原因可能是栈的扩展或收缩</td>
</tr>
<tr>
<td>Gscan</td>
<td>组合状态，发生在 GC 扫描</td>
</tr>
</tbody></table>
<p><img src="/images/golang/scheduling-g-status-01.png" alt="G状态流转"></p>
<h2 id="MPG调度"><a href="#MPG调度" class="headerlink" title="MPG调度"></a>MPG调度</h2><p><img src="/images/golang/scheduling-mpg-04.png" alt="MPG调度"></p>
<ol>
<li>我们通过 go func () 来创建一个 goroutine</li>
<li>有两个存储 G 的队列，一个是局部调度器 P 的本地队列、一个是全局 G 队列。新创建的 G 会先保存在 P 的本地队列中，如果 P 的本地队列已经满了就会保存在全局的队列中</li>
<li>G 只能运行在 M 中，一个 M 必须持有一个 P，M 与 P 是 1：1 的关系。M 会从 P 的本地队列弹出一个可执行状态的 G 来执行，如果 P 的本地队列为空，就会想其他的 MP 组合偷取一个可执行的 G 来执行</li>
<li>一个 M 调度 G 执行的过程是一个循环机制</li>
<li>当 M 执行某一个 G 时候如果发生了 syscall 或则其余阻塞操作，M 会阻塞，如果当前有一些 G 在执行，runtime 会把这个线程 M 从 P 中摘除 (detach)，然后再创建一个新的操作系统的线程 (如果有空闲的线程可用就复用空闲线程) 来服务于这个 P</li>
<li>当 M 系统调用结束时候，这个 G 会尝试获取一个空闲的 P 执行，并放入到这个 P 的本地队列。如果获取不到 P，那么这个线程 M 变成休眠状态， 加入到空闲线程中，然后这个 G 会被放入全局队列中</li>
</ol>
<h2 id="一些细节"><a href="#一些细节" class="headerlink" title="一些细节"></a>一些细节</h2><h3 id="work-stealing"><a href="#work-stealing" class="headerlink" title="work stealing"></a>work stealing</h3><p>当本线程无可运行的 G 时，尝试从其他线程绑定的 P 偷取 G，而不是销毁线程。</p>
<h3 id="syscall"><a href="#syscall" class="headerlink" title="syscall"></a>syscall</h3><p>当G被阻塞在某个系统调用上时，此时G会阻塞在_Gsyscall状态，M也处于block on syscall状态，此时的M可被抢占调度：执行该G的M会与P解绑，而P则尝试与其它idle的M绑定，继续执行其它G。如果没有其它idle的M，但P的Local队列中仍然有G需要执行，则创建一个新的M；当系统调用完成后，G会重新尝试获取一个idle的P进入它的Local队列恢复执行，如果没有idle的P，G会被标记为runnable加入到Global队列。</p>
<h3 id="handoff"><a href="#handoff" class="headerlink" title="handoff"></a>handoff</h3><ol>
<li><p>利用并行<br>GOMAXPROCS 设置 P 的数量，最多有 GOMAXPROCS 个线程分布在多个 CPU 上同时运行。GOMAXPROCS 也限制了并发的程度，比如 GOMAXPROCS = 核数/2，则最多利用了一半的 CPU 核进行并行</p>
</li>
<li><p>抢占<br>在 coroutine 中要等待一个协程主动让出 CPU 才执行下一个协程，在 Go 中，一个 goroutine 最多占用 CPU 10ms，防止其他 goroutine 被饿死，这就是 goroutine 不同于 coroutine 的一个地方<br>异步抢占，注册 sigurg 信号，通过sysmon 检测，对 M 对应的线程发送信号，触发注册的 handler，它往当前 G 的 PC 中插入一条指令(调用某个方法)，在处理完 handler，G 恢复后，自己把自己推到了 global queue 中。</p>
</li>
<li><p>全局 G 队列<br>在新的调度器中依然有全局 G 队列，但功能已经被弱化了，当 M 执行 work stealing 从其他 P 偷不到 G 时，它可以从全局 G 队列获取 G</p>
</li>
</ol>
<h3 id="gopark"><a href="#gopark" class="headerlink" title="gopark"></a>gopark</h3><p>系统调用；<br>channel读写条件不满足；<br>抢占式调度时间片结束；</p>
<p>解除当前goroutine的m的绑定关系，将当前goroutine状态机切换为等待状态；<br>调用一次schedule()函数，在局部调度器P发起一轮新的调度。</p>
<h3 id="sysmon"><a href="#sysmon" class="headerlink" title="sysmon"></a>sysmon</h3><p>P的数量影响了同时运行go代码的协程数. 如果P被占用很久, 就会影响调度. sysmon协程的一个功能就是进行抢占.<br>sysmon协程是在go runtime初始化之后, 执行用户编写的代码之前, 由runtime启动的不与任何P绑定, 直接由一个M执行的协程. 类似于 linux中的执行一些系统任务的内核线程.<br>可认为是10ms执行一次. (初始运行间隔为20us(微秒), sysmon运行1ms后逐渐翻倍, 最终每10ms运行一次. 如果有发生过抢占成功, 则又恢复成 初始20us的运行间隔, 如此循环)</p>
<p>sysmon 也叫监控线程，它无需 P 也可以运行，他是一个死循环，每20us~10ms循环一次，循环完一次就 sleep 一会，为什么会是一个变动的周期呢，主要是避免空转，如果每次循环都没什么需要做的事，那么 sleep 的时间就会加大。<br>释放闲置超过5分钟的 span 物理内存；<br>如果超过2分钟没有垃圾回收，强制执行；<br>将长时间未处理的 netpoll 添加到全局队列；<br>向长时间运行的 G 任务发出抢占调度；<br>收回因 syscall 长时间阻塞的 P；</p>
<h3 id="mcall"><a href="#mcall" class="headerlink" title="mcall"></a>mcall</h3><p>mcall在golang需要进行协程切换时被调用，用来保存被切换出去协程的信息，并在当前线程的g0协程堆栈上执行新的函数。一般情况下，会在新函数中执行一次schedule()来挑选新的协程来运行。接下来我们就看看mcall的实现。</p>
<h3 id="M-的状态"><a href="#M-的状态" class="headerlink" title="M 的状态"></a>M 的状态</h3><p>当M2线程在syscall返回后变得空闲时。如何处理这个空闲的M2线程。从理论上讲，如果线程完成了所需的操作，则应将其销毁，然后再安排进程中的其他线程到CPU上执行。这就是我们通常所说的操作系统中线程的“抢占式调度”。</p>
<p>考虑上述syscall中的情况。如果我们销毁了M2线程，而同时M3线程即将进入syscall。此时，在OS创建新的内核线程并将其调度执行之前，我们无法处理可运行的goroutine。频繁的线程前抢占操作不仅会增加OS的负载，而且对于性能要求更高的程序几乎是不可接受的。</p>
<p>因此，为了适当地利用操作系统的资源并防止频繁的线程抢占给操作系统带来的负担，我们不会销毁内核线程M2，而是使其执行自旋操作并以备将来使用。尽管这看起来是在浪费一些资源。但是，与线程之间的频繁抢占以及频繁的创建和销毁操作相比，“空闲线程”要付出的代价更少。</p>
<p>Spinning Thread(自旋线程) — 例如，在具有一个内核线程M（1）和一个逻辑处理器（P）的Go程序中，如果正在执行的M被syscall阻塞，则运行时会请求与P数量相同的“Spinning Threads”以允许等待的可运行goroutine继续执行。因此，在此期间，内核线程的数量M将大于P的数量（自旋线程+阻塞线程）。因此，即使将runtime.GOMAXPROCS的值设置为1，程序也将处于多线程状态。</p>
<p>m 取到 g 了，判断如果 m 是自旋状态，则从自旋到非自旋，在没有自旋状态的 m 的情况下，再多创建一个新的自旋状态的 m</p>
<h3 id="阻塞"><a href="#阻塞" class="headerlink" title="阻塞"></a>阻塞</h3><p>在channel上发送和接收<br>每个channel都有一个recvq(waitq)，用于存储试图从该channel读取数据而阻塞的goroutine。Sendq(waitq)存储试图将数据发送到channel而被阻止的goroutine。</p>
<p>网络I/O操作<br>底层使用epoll，不会阻塞</p>
<p>阻塞的系统调用<br>当G被阻塞在某个系统调用上时，此时G会阻塞在_Gsyscall状态，M也处于block on syscall状态，此时的M可被抢占调度：执行该G的M会与P解绑，而P则尝试与其它idle的M绑定，继续执行其它G。如果没有其它idle的M，但P的Local队列中仍然有G需要执行，则创建一个新的M；当系统调用完成后，G会重新尝试获取一个idle的P进入它的Local队列恢复执行，如果没有idle的P，G会被标记为runnable加入到Global队列。</p>
<p>使用定时器<br>抢占式调度来解决这个问题。只要你这个任务执行超过一定的时间（10ms），那么这个任务就会被标识为可抢占的，那么别的goroutine就可以抢先进来执行。只要下次这个goroutine进行函数调用，那么就会被强占，同时也会保护现场，然后重新放入P的本地队列里面等待下次执行。（sysmon完成监控）<br>通过向线程发送系统信号的方式来中断 M 的执行，进而达到抢占的目的。</p>
<p>使用互斥锁<br>当互斥锁不断地试图获得一个永远无法获得的锁时，它可能会遇到饥饿问题。<br>在版本1.9中，Go通过添加一个新的饥饿模式来解决先前的问题，所有等待锁定超过一毫秒的 goroutine，也称为有界等待，将被标记为饥饿。当标记为饥饿时，解锁方法现在将把锁直接移交给第一位等待着。</p>
<h3 id="如何停止长时间占用资源的g，信号协作"><a href="#如何停止长时间占用资源的g，信号协作" class="headerlink" title="如何停止长时间占用资源的g，信号协作"></a>如何停止长时间占用资源的g，信号协作</h3><p>发送系统信号，中断<br>异步抢占，注册 sigurg 信号，通过sysmon 检测，对 M 对应的线程发送信号，触发注册的 handler，它往当前 G 的 PC 中插入一条指令(调用某个方法)，在处理完 handler，G 恢复后，自己把自己推到了 global queue 中。</p>
<h3 id="g0"><a href="#g0" class="headerlink" title="g0"></a>g0</h3><ul>
<li>Go 基于两种断点将 G 调度到线程上：<br>当 G 阻塞时：系统调用、互斥锁或 chan。阻塞的 G 进入睡眠模式/进入队列，并允许Go 安排和运行等待其他的 G。<br>在函数调用期间，如果 G 必须扩展其堆栈。这个断点允许 Go 调度另一个 G 并避免运行 G 占用CPU。<br>在这两种情况下，运行调度程序的 g0 将当前G 替换为另一个 G，即 ready to run。然后，选择的 G 替换 g0 并在线程上运行。与常规 G 相反，g0 有一个固定和更大的栈。</li>
<li>Defer 函数的分配</li>
<li>GC 收集，比如 STW、扫描 G 的堆栈和标记、清楚操作</li>
<li>栈扩容，当需要的时候，由 g0 进行扩栈操作</li>
</ul>
<p><a href="https://xie.infoq.cn/article/3e533bf31a08f8dd2f62f6011">https://xie.infoq.cn/article/3e533bf31a08f8dd2f62f6011</a></p>
]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>MPG</tag>
        <tag>调度</tag>
        <tag>线程</tag>
        <tag>goroutine</tag>
        <tag>并发</tag>
        <tag>CSP</tag>
      </tags>
  </entry>
  <entry>
    <title>微服务系列文章索引</title>
    <url>/microservices/a/</url>
    <content><![CDATA[<h1 id="学习资料"><a href="#学习资料" class="headerlink" title="学习资料"></a>学习资料</h1><p><a href="http://gk.link/a/10sIo">极客时间《go进阶训练营》</a><br><a href="http://gk.link/a/10tCs">极客时间《从0开始学架构》</a><br><a href="http://gk.link/a/10tCC">极客时间《Service Mesh实战》</a><br>DDD</p>
<h1 id="RPC"><a href="#RPC" class="headerlink" title="RPC"></a>RPC</h1><ol>
<li>gRPC</li>
</ol>
<h1 id="基础设施建设"><a href="#基础设施建设" class="headerlink" title="基础设施建设"></a>基础设施建设</h1><ol>
<li>部署与测试多集群，多租户</li>
<li>服务注册、发现、负载均衡</li>
<li>API网关</li>
</ol>
<h1 id="高可用设计"><a href="#高可用设计" class="headerlink" title="高可用设计"></a>高可用设计</h1><ol>
<li>隔离</li>
</ol>
<p><strong>参考</strong><br><a href="https://lailin.xyz/post/go-training-week6-usability-1-bulkhe.html">Go可用性(一) 隔离设计</a></p>
<ol start="2">
<li><a href="/microservices/ha-limit/" title="限流">限流</a><input type="checkbox" disabled ></li>
<li>降级</li>
<li>熔断</li>
<li>超时</li>
<li>重试</li>
</ol>
<h1 id="设计方案"><a href="#设计方案" class="headerlink" title="设计方案"></a>设计方案</h1><p>CQRS<br>海量评论</p>
<h1 id="架构模式"><a href="#架构模式" class="headerlink" title="架构模式"></a>架构模式</h1><p>CQRS<br>Pipeline</p>
]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>文章索引</tag>
      </tags>
  </entry>
  <entry>
    <title>限流</title>
    <url>/microservices/ha-limit/</url>
    <content><![CDATA[<p>令牌桶<br>正常我的系统处理一个请求需要100ms，那么就每100ms往桶里面放令牌，也就是每秒10个，速率为10，设置桶大小为20。<br>每隔100ms往桶里面放token，一直放到满。<br>如果满着的，则丢弃这个token，不满继续定时放。<br>允许突发，也就是满桶10个令牌同时被拿走。<br><code>NewLimiter(10, 20);</code></p>
<p>漏桶<br>uber 的 <a href="https://pkg.go.dev/go.uber.org/ratelimit">ratelimit</a></p>
<p>过载保护、单机限流、分布式限流、熔断</p>
<p><a href="https://lailin.xyz/post/go-training-week6-4-leaky-bucket.html">Go可用性(四) 限流3: 漏桶算法</a></p>
<p>max-min fairness 最大最小分配算法。DRF</p>
<p>健康指标计算</p>
<p>流量整形</p>
<p>熔断<br>服务端(被调用方)一直拒绝也是消耗资源的，所以有时候需要客户端（调用方）采取熔断来给服务端减轻压力，避免雪上加霜。<br>hystrix、<br>google sre max(0, (requests - K * accepts) / (requests + 1))</p>
]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>可用性</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式共识算法Raft实现之Etcd</title>
    <url>/etcd/a/</url>
    <content><![CDATA[<h1 id="学习资料"><a href="#学习资料" class="headerlink" title="学习资料"></a>学习资料</h1><p><a href="https://etcd.io/docs/">etcd doc</a><br><a href="https://hardcore.feishu.cn/docs/doccnMRVFcMWn1zsEYBrbsDf8De#">Raft -论文导读 与 ETCD源码解读</a><br><a href="https://www.zhihu.com/column/c_1382353468817117184">etcd-源码学习</a><br><a href="https://lessisbetter.site/tags/Raft/">Etcd Raft架构设计和源码剖析</a></p>
<h2 id="raft"><a href="#raft" class="headerlink" title="raft"></a>raft</h2><h2 id="node"><a href="#node" class="headerlink" title="node"></a>node</h2><h2 id="log"><a href="#log" class="headerlink" title="log"></a>log</h2><h2 id="docker-image"><a href="#docker-image" class="headerlink" title="docker image"></a>docker image</h2><p><a href="https://registry.hub.docker.com/r/bitnami/etcd">https://registry.hub.docker.com/r/bitnami/etcd</a></p>
<h2 id="安装使用"><a href="#安装使用" class="headerlink" title="安装使用"></a>安装使用</h2><p><a href="https://www.huweihuang.com/kubernetes-notes/etcd/etcdctl-v3.html">www.huweihuang.com</a><br><a href="https://segmentfault.com/a/1190000040203666">GO 中 ETCD 的编码案例分享</a><br><a href="https://doczhcn.gitbook.io/etcd/index/index-1/configuration">配置</a><br><a href="https://doczhcn.gitbook.io/etcd/index/index-1/container">在容器内运行 etcd 集群</a><br><a href="https://doczhcn.gitbook.io/etcd/index/index-1/clustering">搭建 etcd 集群</a><br><a href="https://zhuanlan.zhihu.com/p/260019277">ubuntu+docker搭建etcd集群</a><br><a href="https://github.com/zuoshuwen/example/etcd">docker example etcd</a></p>
]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>etcd</tag>
        <tag>raft</tag>
      </tags>
  </entry>
  <entry>
    <title>网络编程文章索引</title>
    <url>/netprogram/a/</url>
    <content><![CDATA[<h1 id="学习资料"><a href="#学习资料" class="headerlink" title="学习资料"></a>学习资料</h1><p><a href="http://gk.link/a/10txL">极客时间《网络编程实战》</a><br><a href="">微信公众号《开发内功修炼》</a><br><a href="">PDF《理解了实现再谈网络性能》</a><br><a href="">书籍《TCP/IP网络编程》</a><br><a href="https://u.jd.com/6D6qdVu">书籍《UNIX环境高级编程（第三版）》</a><br><a href="https://app.yinxiang.com/fx/7e601cad-6501-4fe7-8e4e-f0fbd9d02c4b">https://app.yinxiang.com/fx/7e601cad-6501-4fe7-8e4e-f0fbd9d02c4b</a></p>
<h1 id="进程模型"><a href="#进程模型" class="headerlink" title="进程模型"></a>进程模型</h1><h3 id="PPC"><a href="#PPC" class="headerlink" title="PPC"></a>PPC</h3><h3 id="Prefork"><a href="#Prefork" class="headerlink" title="Prefork"></a>Prefork</h3><h3 id="TPC"><a href="#TPC" class="headerlink" title="TPC"></a>TPC</h3><h3 id="Prethread"><a href="#Prethread" class="headerlink" title="Prethread"></a>Prethread</h3><h3 id="Reactor"><a href="#Reactor" class="headerlink" title="Reactor"></a>Reactor</h3><p>IO多路复用+进程/线程 池</p>
<h4 id="单-Reactor-单进程-线程"><a href="#单-Reactor-单进程-线程" class="headerlink" title="单 Reactor 单进程/线程"></a>单 Reactor 单进程/线程</h4><h4 id="单-Reactor-多线程"><a href="#单-Reactor-多线程" class="headerlink" title="单 Reactor 多线程**"></a>单 Reactor 多线程**</h4><h4 id="多-Reactor-多进程-线程"><a href="#多-Reactor-多进程-线程" class="headerlink" title="多 Reactor 多进程/线程**"></a>多 Reactor 多进程/线程**</h4><h3 id="Proactor"><a href="#Proactor" class="headerlink" title="Proactor"></a>Proactor</h3><h1 id="IO模型"><a href="#IO模型" class="headerlink" title="IO模型"></a>IO模型</h1><h3 id="同步"><a href="#同步" class="headerlink" title="同步"></a>同步</h3><h4 id="Blocking-IO-阻塞I-O"><a href="#Blocking-IO-阻塞I-O" class="headerlink" title="Blocking IO - 阻塞I O"></a>Blocking IO - 阻塞I O</h4><h4 id="Nonblocking-IO-非阻塞IO"><a href="#Nonblocking-IO-非阻塞IO" class="headerlink" title="Nonblocking IO - 非阻塞IO"></a>Nonblocking IO - 非阻塞IO</h4><h4 id="IO-multiplexing-IO-多路复用"><a href="#IO-multiplexing-IO-多路复用" class="headerlink" title="IO multiplexing - IO 多路复用"></a>IO multiplexing - IO 多路复用</h4><h3 id="异步"><a href="#异步" class="headerlink" title="异步"></a>异步</h3><h4 id="Signal-driven-IO-信号驱动式IO（异步阻塞）"><a href="#Signal-driven-IO-信号驱动式IO（异步阻塞）" class="headerlink" title="Signal-driven IO - 信号驱动式IO（异步阻塞）"></a>Signal-driven IO - 信号驱动式IO（异步阻塞）</h4><h4 id="Asynchronous-IO-异步IO"><a href="#Asynchronous-IO-异步IO" class="headerlink" title="Asynchronous IO - 异步IO"></a>Asynchronous IO - 异步IO</h4><h1 id="并发模型"><a href="#并发模型" class="headerlink" title="并发模型"></a>并发模型</h1><h3 id="线程与锁"><a href="#线程与锁" class="headerlink" title="线程与锁"></a>线程与锁</h3><h3 id="函数式编程"><a href="#函数式编程" class="headerlink" title="函数式编程"></a>函数式编程</h3><h3 id="Clojure之道——分离标识与状态"><a href="#Clojure之道——分离标识与状态" class="headerlink" title="Clojure之道——分离标识与状态"></a>Clojure之道——分离标识与状态</h3><h3 id="actor"><a href="#actor" class="headerlink" title="actor"></a>actor</h3><h3 id="通信顺序进程-CSP"><a href="#通信顺序进程-CSP" class="headerlink" title="通信顺序进程 CSP"></a>通信顺序进程 CSP</h3><p>CSP vs Actor<br>CSP 通过 channel 进行通信，更松耦合。<br>GO 中的 channel 有容量限制并且独立于处理 goroutine，如 Erlang、Actor 模式中的 mailbox 容量是无限的，接收进程也总是被动的处理消息。</p>
<h3 id="数据级并行"><a href="#数据级并行" class="headerlink" title="数据级并行"></a>数据级并行</h3><h3 id="Lambda架构"><a href="#Lambda架构" class="headerlink" title="Lambda架构"></a>Lambda架构</h3><h1 id="C语言同步函数"><a href="#C语言同步函数" class="headerlink" title="C语言同步函数"></a>C语言同步函数</h1><h3 id="互斥锁"><a href="#互斥锁" class="headerlink" title="互斥锁"></a>互斥锁</h3><p>int pthread_mutex_init(pthread_mutex_t * __restrict, const pthread_mutexattr_t * _Nullable __restrict);：初始化<br>int pthread_mutex_destroy(pthread_mutex_t *)：销毁<br>int pthread_mutex_lock(pthread_mutex_t *)：加锁<br>int pthread_mutex_unlock(pthread_mutex_t *)：解锁</p>
<h3 id="条件变量"><a href="#条件变量" class="headerlink" title="条件变量"></a>条件变量</h3><p>int pthread_cond_init(pthread_cond_t * __restrict, const pthread_condattr_t * _Nullable __restrict)：初始化<br>int pthread_cond_destroy(pthread_cond_t *)：销毁<br>int pthread_cond_wait(pthread_cond_t * __restrict, pthread_mutex_t * __restrict)：等待<br>int pthread_cond_signal(pthread_cond_t *)：发送单发通知<br>int pthread_cond_broadcast(pthread_cond_t *)：发送广播通知</p>
<h3 id="线程创建"><a href="#线程创建" class="headerlink" title="线程创建"></a>线程创建</h3><p>int pthread_create(pthread_t _Nullable * _Nonnull __restrict, const pthread_attr_t * _Nullable __restrict, void * _Nullable (* _Nonnull)(void * _Nullable), void * _Nullable __restrict)：创建</p>
<h1 id="http2"><a href="#http2" class="headerlink" title="http2"></a>http2</h1><p>http2最大的不同就是 服务端可以给客户端发请求，最大的好处就是 少了 很多 客户端对服务端的试探、询问，客户端直接就告诉服务端，应该在什么时间的时候通知我就OK了，仔细想想，这像不像epoll的事件注册中的 边缘触发。</p>
]]></content>
      <categories>
        <category>网络编程</category>
      </categories>
      <tags>
        <tag>文章索引</tag>
      </tags>
  </entry>
  <entry>
    <title>Mysql文章索引</title>
    <url>/mysql/a/</url>
    <content><![CDATA[<h1 id="学习资料"><a href="#学习资料" class="headerlink" title="学习资料"></a>学习资料</h1><p><a href="http://gk.link/a/10sVJ">极客时间《MySQL实战45讲》</a><br><a href="https://u.jd.com/6w6S0IY">书籍《高性能MySQL（第三版）》</a></p>
<h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><h3 id="连接器"><a href="#连接器" class="headerlink" title="连接器"></a>连接器</h3><p>长连接 ➕ <span class="label label-info">mysql_reset_connection</span><br>如果你用的是 MySQL 5.7 或更新版本，可以在每次执行一个比较大的操作后，通过执行 mysql_reset_connection 来重新初始化连接资源。<br>这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。</p>
<h3 id="查询缓存"><a href="#查询缓存" class="headerlink" title="查询缓存"></a>查询缓存</h3><p>建议不要使用缓存，因为失效频繁</p>
<span class="label label-info">query_cache_type=DEMAND</span>
<p>这样对于默认的 SQL 语句都不使用查询缓存。</p>
<span class="label label-info">SQL_CACHE</span>
<p>对于你确定要使用查询缓存的语句，可以用 SQL_CACHE 显式指定<br><code>select SQL_CACHE * from T where ID=10；</code></p>
<h3 id="分析器"><a href="#分析器" class="headerlink" title="分析器"></a>分析器</h3><p>词法分析、语法分析，包括表字段是否存在</p>
<h3 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h3><p>选择索引</p>
<h3 id="执行器"><a href="#执行器" class="headerlink" title="执行器"></a>执行器</h3><p>执行查询的权限</p>
<h3 id="存储引擎"><a href="#存储引擎" class="headerlink" title="存储引擎"></a>存储引擎</h3><p><img src="/images/mysql/logical-architecture.png" alt="MySQL逻辑架构图"></p>
<h2 id="事务特征"><a href="#事务特征" class="headerlink" title="事务特征"></a>事务特征</h2><h3 id="原子性（Atomicity）"><a href="#原子性（Atomicity）" class="headerlink" title="原子性（Atomicity）"></a>原子性（Atomicity）</h3><h3 id="一致性（Consistency）"><a href="#一致性（Consistency）" class="headerlink" title="一致性（Consistency）"></a>一致性（Consistency）</h3><h3 id="隔离性（Isolation）"><a href="#隔离性（Isolation）" class="headerlink" title="隔离性（Isolation）"></a>隔离性（Isolation）</h3><h3 id="持久性（Durability）"><a href="#持久性（Durability）" class="headerlink" title="持久性（Durability）"></a>持久性（Durability）</h3><h2 id="隔离级别"><a href="#隔离级别" class="headerlink" title="隔离级别"></a>隔离级别</h2><span class="label label-info">transaction-isolation</span>
<p>用来设置隔离级别</p>
<h3 id="读未提交（read-uncommitted）"><a href="#读未提交（read-uncommitted）" class="headerlink" title="读未提交（read uncommitted）"></a>读未提交（read uncommitted）</h3><p>一个事务还没提交时，它做的变更就能被别的事务看到。</p>
<h3 id="读提交（read-committed）"><a href="#读提交（read-committed）" class="headerlink" title="读提交（read committed）"></a>读提交（read committed）</h3><p>一个事务提交之后，它做的变更才会被其他事务看到。</p>
<h3 id="可重复读"><a href="#可重复读" class="headerlink" title="可重复读"></a>可重复读</h3><p>一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。</p>
<p>如果是可重复读隔离级别，事务 T 启动的时候会创建一个视图 read-view，之后事务 T 执行期间，即使有其他事务修改了数据，事务 T 看到的仍然跟在启动时看到的一样。也就是说，一个在可重复读隔离级别下执行的事务，好像与世无争，不受外界影响。</p>
<h3 id="串行化"><a href="#串行化" class="headerlink" title="串行化"></a>串行化</h3><p>“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。</p>
<h2 id="隔离问题"><a href="#隔离问题" class="headerlink" title="隔离问题"></a>隔离问题</h2><h3 id="脏读（dirty-read）"><a href="#脏读（dirty-read）" class="headerlink" title="脏读（dirty read）"></a>脏读（dirty read）</h3><h3 id="不可重复读（non-repeatable-read）"><a href="#不可重复读（non-repeatable-read）" class="headerlink" title="不可重复读（non-repeatable read）"></a>不可重复读（non-repeatable read）</h3><h3 id="幻读（phantom-read）"><a href="#幻读（phantom-read）" class="headerlink" title="幻读（phantom read）"></a>幻读（phantom read）</h3><h2 id="事务隔离的实现"><a href="#事务隔离的实现" class="headerlink" title="事务隔离的实现"></a>事务隔离的实现</h2><p>MVCC</p>
<h2 id="事务起点"><a href="#事务起点" class="headerlink" title="事务起点"></a>事务起点</h2><p>begin/start transaction 命令并不是一个事务的起点，在执行到它们之后的第一个操作 InnoDB 表的语句，事务才真正启动。<br>如果你想要马上启动一个事务，可以使用 start transaction with consistent snapshot 这个命令。<br>第一种启动方式，一致性视图是在执行第一个快照读语句时创建的；<br>第二种启动方式，一致性视图是在执行 start transaction with consistent snapshot 时创建的。</p>
<h2 id="事务的启动方式"><a href="#事务的启动方式" class="headerlink" title="事务的启动方式"></a>事务的启动方式</h2><h3 id="1-显式启动事务语句"><a href="#1-显式启动事务语句" class="headerlink" title="1. 显式启动事务语句"></a>1. 显式启动事务语句</h3><span class="label label-info">set autocommit=1</span>
<p>通过显式语句的方式来启动事务<br>begin 或 start transaction。配套的提交语句是 commit，回滚语句是 rollback。</p>
<span class="label label-info">commit work and chain</span>
<p>如果执行 commit work and chain，则是提交事务并自动启动下一个事务，这样也省去了再次执行 begin 语句的开销。同时带来的好处是从程序开发的角度明确地知道每个语句是否处于事务中。</p>
<h3 id="2-隐式启动事务语句"><a href="#2-隐式启动事务语句" class="headerlink" title="2. 隐式启动事务语句"></a>2. 隐式启动事务语句</h3><span class="label label-info">set autocommit=0</span>
<p>这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个 select 语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行 commit 或 rollback 语句，或者断开连接。</p>
<div class="note note-success">
            <p>推荐autocommit=1</p>
          </div>

<div class="note note-warning">
            <p>select是只读的，这也需要事务？</p><p>select是只读的没问题。<br>但是如果你的select是在autocommit=0的情况下去执行的，也就是这样：<br>set autocommit=0;<br>select * from t;<br>这个时候这个select语句也会开启一个事务，如果你不执行commit;那么这个事务就一直开启着。虽然这一个只读的事务。<br>上面两个命令等价于你显示的开启事务没有提交，像下面这样：<br>begin;<br>select * from t;</p>
          </div>

<div class="note note-danger">
            <p>长事务<br>set autocommit=0 ➕  长连接 容易导致长事务</p><p>在 information_schema 库的 innodb_trx 这个表中查询长事务，比如下面这个语句，用于查找持续时间超过 60s 的事务。<br>select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))&gt;60</p>
          </div>


<h2 id="WAL"><a href="#WAL" class="headerlink" title="WAL"></a>WAL</h2><div class="note note-info">
            <p>Write-Ahead Logging，先写日志，再写磁盘。</p>
          </div>


<h2 id="crash-safe"><a href="#crash-safe" class="headerlink" title="crash-safe"></a>crash-safe</h2><div class="note note-info">
            <p>数据库发生异常重启，之前提交的记录都不会丢失</p>
          </div>


<h2 id="两阶段提交（prepare、commit）"><a href="#两阶段提交（prepare、commit）" class="headerlink" title="两阶段提交（prepare、commit）"></a>两阶段提交（prepare、commit）</h2><p>简单的 update 语句时的内部流程</p>
<ol>
<li>执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。</li>
<li>执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。</li>
<li>引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。</li>
<li>执行器生成这个操作的 binlog，并把 binlog 写入磁盘。</li>
<li>执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。</li>
</ol>
<p><img src="/images/mysql/2pc-update.png" alt="两阶段提交-update语句执行"></p>
<h2 id="redo-log（重做日志）"><a href="#redo-log（重做日志）" class="headerlink" title="redo log（重做日志）"></a>redo log（重做日志）</h2><div class="note note-info">
            <p>InnoDB 引擎特有的日志，WAL 机制、拥有 crash-safe。</p>
          </div>

<span class="label label-info">innodb_flush_log_at_trx_commit</span>
<p>参数设置成 1 的时候，表示每次事务的 redo log 都直接持久化到磁盘。这个参数我建议你设置成 1，这样可以保证 MySQL 异常重启之后数据不丢失。</p>
<p><img src="/images/mysql/redo-log-struct.png" alt="redo log 结构图"></p>
<h2 id="刷脏页（flush）"><a href="#刷脏页（flush）" class="headerlink" title="刷脏页（flush）"></a>刷脏页（flush）</h2><h3 id="触发机制"><a href="#触发机制" class="headerlink" title="触发机制"></a>触发机制</h3><ol>
<li>redo log 写满了</li>
<li>空闲</li>
<li>正常关闭</li>
</ol>
<h2 id="页（page）"><a href="#页（page）" class="headerlink" title="页（page）"></a>页（page）</h2><p>你知道的，InnoDB 的数据是按数据页为单位来读写的。也就是说，当需要读一条记录的时候，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整体读入内存。在 InnoDB 中，每个数据页的大小默认是 16KB。</p>
<h2 id="脏页"><a href="#脏页" class="headerlink" title="脏页"></a>脏页</h2><p>当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。</p>
<h2 id="干净页"><a href="#干净页" class="headerlink" title="干净页"></a>干净页</h2><p>内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。</p>
<h2 id="binlog（归档日志）"><a href="#binlog（归档日志）" class="headerlink" title="binlog（归档日志）"></a>binlog（归档日志）</h2><div class="note note-info">
            <p>Server 层自己的日志。</p>
          </div>

<h3 id="statement"><a href="#statement" class="headerlink" title="statement"></a>statement</h3><p>有些 statement 格式的 binlog 可能会导致主备不一致。<br>比如你用一个 delete 语句删掉 10 万行数据，用 statement 的话就是一个 SQL 语句被记录到 binlog 中，占用几十个字节的空间。</p>
<h3 id="row"><a href="#row" class="headerlink" title="row"></a>row</h3><p>row 格式的缺点是，很占空间。<br>但如果用 row 格式的 binlog，就要把这 10 万条记录都写到 binlog 中。这样做，不仅会占用更大的空间，同时写 binlog 也要耗费 IO 资源，影响执行速度。</p>
<h3 id="mixed"><a href="#mixed" class="headerlink" title="mixed"></a>mixed</h3><p>所以，MySQL 就取了个折中方案，也就是有了 mixed 格式的 binlog。mixed 格式的意思是，MySQL 自己会判断这条 SQL 语句是否可能引起主备不一致，如果有可能，就用 row 格式，否则就用 statement 格式。<br>也就是说，mixed 格式可以利用 statment 格式的优点，同时又避免了数据不一致的风险。</p>
<span class="label label-info">sync_binlog</span>
<p>这个参数设置成 1 的时候，表示每次事务的 binlog 都持久化到磁盘。这个参数我也建议你设置成 1，这样可以保证 MySQL 异常重启之后 binlog 不丢失。</p>
<h2 id="删表找回"><a href="#删表找回" class="headerlink" title="删表找回"></a>删表找回</h2><ol>
<li>首先，找到最近的一次全量备份，如果你运气好，可能就是昨天晚上的一个备份，从这个备份恢复到临时库；</li>
<li>然后，从备份的时间点开始，将备份的 binlog 依次取出来，重放到中午误删表之前的那个时刻。</li>
</ol>
<h2 id="一致性读视图（consistent-read-view）"><a href="#一致性读视图（consistent-read-view）" class="headerlink" title="一致性读视图（consistent read view）"></a>一致性读视图（consistent read view）</h2><p>InnoDB 在实现 MVCC 时用到的一致性读视图，即 consistent read view，用于支持 RC（Read Committed，读提交）和 RR（Repeatable Read，可重复读）隔离级别的实现。</p>
<p>这个视图数组和高水位，就组成了当前事务的一致性视图（read-view）</p>
<p>在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。</p>
<ul>
<li>在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。</li>
<li>在“读提交”隔离级别下，这个视图是在每个 SQL 语句开始执行的时候创建的。</li>
<li>这里需要注意的是，“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；</li>
<li>而“串行化”隔离级别下直接用加锁的方式来避免并行访问。</li>
</ul>
<h2 id="多版本控制（MVCC）"><a href="#多版本控制（MVCC）" class="headerlink" title="多版本控制（MVCC）"></a>多版本控制（MVCC）</h2><p>read-view<br>undo log<br>当前读 current read<br>两阶段锁协议</p>
<h3 id="row-trx-id"><a href="#row-trx-id" class="headerlink" title="row trx_id"></a>row trx_id</h3><p>InnoDB 里面每个事务有一个唯一的事务 ID，叫作 transaction id。它是在事务开始的时候向 InnoDB 的事务系统申请的，是按申请顺序严格递增的。<br>而每行数据也都是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本，并且把 transaction id 赋值给这个数据版本的事务 ID，记为 row trx_id。</p>
<ol>
<li>如果落在绿色部分，表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的；</li>
<li>如果落在红色部分，表示这个版本是由将来启动的事务生成的，是肯定不可见的；</li>
<li>如果落在黄色部分，那就包括两种情况<br>a. 若 row trx_id 在数组中，表示这个版本是由还没提交的事务生成的，不可见；<br>b. 若 row trx_id 不在数组中，表示这个版本是已经提交了的事务生成的，可见。</li>
</ol>
<h2 id="undo-log（回滚日志）"><a href="#undo-log（回滚日志）" class="headerlink" title="undo log（回滚日志）"></a>undo log（回滚日志）</h2><p>语句更新会生成 undo log（回滚日志）<br>实际上，图 2 中的三个虚线箭头，就是 undo log；而 V1、V2、V3 并不是物理上真实存在的，而是每次需要的时候根据当前版本和 undo log 计算出来的。比如，需要 V2 的时候，就是通过 V4 依次执行 U3、U2 算出来。</p>
<h2 id="当前读"><a href="#当前读" class="headerlink" title="当前读"></a>当前读</h2><p>更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）</p>
<h2 id="重要的一讲"><a href="#重要的一讲" class="headerlink" title="重要的一讲"></a>重要的一讲</h2><p>(事务隔离)[<a href="https://time.geekbang.org/column/article/70562]">https://time.geekbang.org/column/article/70562]</a></p>
<h2 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h2><h3 id="聚簇索引"><a href="#聚簇索引" class="headerlink" title="聚簇索引"></a>聚簇索引</h3><h3 id="非聚簇索引"><a href="#非聚簇索引" class="headerlink" title="非聚簇索引"></a>非聚簇索引</h3><h3 id="回表"><a href="#回表" class="headerlink" title="回表"></a>回表</h3><h3 id="索引覆盖"><a href="#索引覆盖" class="headerlink" title="索引覆盖"></a>索引覆盖</h3><h3 id="最左前缀原则"><a href="#最左前缀原则" class="headerlink" title="最左前缀原则"></a>最左前缀原则</h3><h3 id="索引下推"><a href="#索引下推" class="headerlink" title="索引下推"></a>索引下推</h3><h2 id="DML"><a href="#DML" class="headerlink" title="DML"></a>DML</h2><p>增删改数据</p>
<h2 id="DDL"><a href="#DDL" class="headerlink" title="DDL"></a>DDL</h2><p>加字段等修改表结构</p>
<h2 id="全局锁"><a href="#全局锁" class="headerlink" title="全局锁"></a>全局锁</h2><span class="label label-info">Flush tables with read lock</span>
<p>FTWRL 全局锁的典型使用场景是，做全库逻辑备份</p>
<h3 id="FTWRL"><a href="#FTWRL" class="headerlink" title="FTWRL"></a>FTWRL</h3><p>对于 MyISAM 这种不支持事务的引擎，如果备份过程中有更新，总是只能取到最新的数据，那么就破坏了备份的一致性。这时，我们就需要使用 FTWRL 命令了。</p>
<h3 id="一致性视图"><a href="#一致性视图" class="headerlink" title="一致性视图"></a>一致性视图</h3><p>对于 InnoDB 引擎，mysqldump 使用参数–single-transaction，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于 MVCC 的支持，这个过程中数据是可以正常更新的。</p>
<h2 id="表级锁"><a href="#表级锁" class="headerlink" title="表级锁"></a>表级锁</h2><h3 id="表锁"><a href="#表锁" class="headerlink" title="表锁"></a>表锁</h3><p>lock tables 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。</p>
<h3 id="元数据锁（MDL）"><a href="#元数据锁（MDL）" class="headerlink" title="元数据锁（MDL）"></a>元数据锁（MDL）</h3><span class="label label-info">meta data lock</span>
<p>一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做变更，删了一列，那么查询线程拿到的结果跟表结构对不上，肯定是不行的。</p>
<h2 id="如何安全地给小表加字段？"><a href="#如何安全地给小表加字段？" class="headerlink" title="如何安全地给小表加字段？"></a>如何安全地给小表加字段？</h2><p>首先我们要解决长事务，事务不提交，就会一直占着 MDL 锁。<br>比较理想的机制是，在 alter table 语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到 MDL 写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者 DBA 再通过重试命令重复这个过程。</p>
<div class="code-wrapper"><pre><code class="hljs sql"><span class="hljs-keyword">ALTER</span> <span class="hljs-keyword">TABLE</span> tbl_name NOWAIT <span class="hljs-keyword">add</span> <span class="hljs-keyword">column</span> ...
<span class="hljs-keyword">ALTER</span> <span class="hljs-keyword">TABLE</span> tbl_name WAIT N <span class="hljs-keyword">add</span> <span class="hljs-keyword">column</span> ...</code></pre></div>


<h2 id="查看事务"><a href="#查看事务" class="headerlink" title="查看事务"></a>查看事务</h2><p>information_schema 库的 innodb_trx 表中，你可以查到当前执行中的事务</p>
<h2 id="行锁"><a href="#行锁" class="headerlink" title="行锁"></a>行锁</h2><h2 id="两阶段锁协议"><a href="#两阶段锁协议" class="headerlink" title="两阶段锁协议"></a>两阶段锁协议</h2><p>在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。</p>
<h2 id="行锁建议"><a href="#行锁建议" class="headerlink" title="行锁建议"></a>行锁建议</h2><p>如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。</p>
<h2 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h2><span class="label label-info">innodb_lock_wait_timeout</span>
<p>一种策略是，直接进入等待，直到超时。</p>
<span class="label label-info">innodb_deadlock_detect</span>
<p>另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。</p>
<h2 id="count"><a href="#count" class="headerlink" title="count"></a>count</h2><p>对于 count(主键 id) 来说，InnoDB 引擎会遍历整张表，把每一行的 id 值都取出来，返回给 server 层。server 层拿到 id 后，判断是不可能为空的，就按行累加。对于 count(1) 来说，InnoDB 引擎遍历整张表，但不取值。server 层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。单看这两个用法的差别的话，你能对比出来，count(1) 执行得要比 count(主键 id) 快。因为从引擎返回 id 会涉及到解析数据行，以及拷贝字段值的操作。对于 count(字段) 来说：如果这个“字段”是定义为 not null 的话，一行行地从记录里面读出这个字段，判断不能为 null，按行累加；如果这个“字段”定义允许为 null，那么执行的时候，判断到有可能是 null，还要把值取出来再判断一下，不是 null 才累加。也就是前面的第一条原则，server 层要什么字段，InnoDB 就返回什么字段。但是 count(<em>) 是例外，并不会把全部字段取出来，而是专门做了优化，不取值。count(</em>) 肯定不是 null，按行累加。</p>
<h2 id="间隙锁-Gap-Lock"><a href="#间隙锁-Gap-Lock" class="headerlink" title="间隙锁 (Gap Lock)"></a>间隙锁 (Gap Lock)</h2><p>InnoDB 只好引入新的锁，也就是间隙锁 (Gap Lock)。</p>
<h2 id="next-key-lock"><a href="#next-key-lock" class="headerlink" title="next-key lock"></a>next-key lock</h2><p>间隙锁和行锁合称 next-key lock</p>
]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>文章索引</tag>
      </tags>
  </entry>
  <entry>
    <title>方案文章索引</title>
    <url>/program/a/</url>
    <content><![CDATA[<ol>
<li>秒杀</li>
<li>朋友圈</li>
<li>聊天系统</li>
<li>游戏体力与消耗</li>
<li>定时任务限制</li>
<li>海量日志</li>
<li>动态短信发送</li>
</ol>
<p>QPS<br><a href="https://segmentfault.com/a/1190000010844969">https://segmentfault.com/a/1190000010844969</a></p>
]]></content>
      <categories>
        <category>方案</category>
      </categories>
      <tags>
        <tag>方案</tag>
      </tags>
  </entry>
  <entry>
    <title>Redash Gunicorn 超时</title>
    <url>/python/gunicorn-timeout/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>最近总有用户反馈说Redash下载比较大的Excel就会出现“失败 - 服务器出现问题”，而且每次从点了下载到出现错误提示时间都是差不多的。我先查看了Nginx的error日志，显示 <code>upstream prematurely closed connection while sending to client</code>，第一反应应该是超时导致的。</p>
<span id="more"></span>

<h2 id="1-修改Redash配置"><a href="#1-修改Redash配置" class="headerlink" title="1. 修改Redash配置"></a>1. 修改Redash配置</h2><ul>
<li>.env文件修改log级别为调试 <code>REDASH_LOG_LEVEL=&quot;DEBUG&quot;</code></li>
<li>.env文件加上超时配置 <code>REDASH_BIGQUERY_HTTP_TIMEOUT=600</code></li>
<li>Redash的启动命令后面增加 <code>-t 600</code> 参数。<br>10分钟应该够用了！重启redash进程后，进行尝试试，不好使！好吧，也许是配置参数写错了，那改成 <code>--timeout 600</code> 再试一下，发现还不好使！继续。。。</li>
</ul>
<h2 id="2-修改Nginx配置"><a href="#2-修改Nginx配置" class="headerlink" title="2. 修改Nginx配置"></a>2. 修改Nginx配置</h2><ul>
<li>请求超时：keepalive_timeout、client_header_timeout、client_body_timeout</li>
<li>后端服务器处理请求的时间设置：proxy_connect_timeout、proxy_read_timeout<br>重启Nginx，下载还是失败！！！看来不是超时导致的了？！</li>
</ul>
<h2 id="3-查看进程使用的资源"><a href="#3-查看进程使用的资源" class="headerlink" title="3. 查看进程使用的资源"></a>3. 查看进程使用的资源</h2><p>先执行：<br><code>top</code><br>再尝试下载操作，发现名叫<code>gunicorn</code>（Redash的server是用gunicorn启动的）的<code>COMMAND</code>CPU占用CPU到了100%，并且持续一定时间后，进程消失，新的进程启动后，CPU占用恢复正常值。那接下来就看看此进程都执行了哪些操作。</p>
<h2 id="4-进程跟踪"><a href="#4-进程跟踪" class="headerlink" title="4. 进程跟踪"></a>4. 进程跟踪</h2><p>跟踪CPU占用超高的 <code>gunicorn</code> 进程：</p>
<div class="code-wrapper"><pre><code class="hljs gams"><span class="hljs-symbol">$</span> strace -T -tt -e trace=<span class="hljs-keyword">all</span> -p 进程ID</code></pre></div>
<p>显式进程一直在 <code>read</code>、<code>write</code> 的系统调用，最后一行输出<br><code>+++ killed by SIGKILL +++</code><br>后，跟踪就停止了。难道是触发了系统的<code>ulimit</code>限制，然后被系统杀掉了？</p>
<h2 id="5-设置ulimit参数"><a href="#5-设置ulimit参数" class="headerlink" title="5. 设置ulimit参数"></a>5. 设置ulimit参数</h2><p>设置 <code>gunicorn</code> 运行用户的 <code>ulimit</code>，重新尝试，没有解决。看来也不是这个问题。。。那是被谁 <code>kill</code> 掉的呢？</p>
<h2 id="6-捕捉kill信号"><a href="#6-捕捉kill信号" class="headerlink" title="6. 捕捉kill信号"></a>6. 捕捉kill信号</h2><p>使用 <code>auditctl</code>，添加捕捉规则：</p>
<div class="code-wrapper"><pre><code class="hljs awk">$ auditctl -a <span class="hljs-keyword">exit</span>,always -F arch=b64 -S kill -F a1=<span class="hljs-number">9</span></code></pre></div>
<p>进行下载文件操作，等待进程被杀死之后，显式捕捉到结果：</p>
<div class="code-wrapper"><pre><code class="hljs powershell"><span class="hljs-variable">$</span> ausearch <span class="hljs-literal">-sc</span> <span class="hljs-built_in">kill</span></code></pre></div>
<p>输出：</p>
<div class="code-wrapper"><pre><code class="hljs apache"><span class="hljs-attribute">time</span>-&gt;Fri Dec  <span class="hljs-number">6</span> <span class="hljs-number">16</span>:<span class="hljs-number">13</span>:<span class="hljs-number">26</span> <span class="hljs-number">2019</span>
<span class="hljs-attribute">type</span>=PROCTITLE msg=audit(<span class="hljs-number">1575620006</span>.<span class="hljs-number">444</span>:<span class="hljs-number">103711</span>): proctitle=<span class="hljs-number">2</span>F<span class="hljs-number">6</span>F<span class="hljs-number">70742</span>F<span class="hljs-number">6</span>D<span class="hljs-number">6</span>F<span class="hljs-number">64756</span>C<span class="hljs-number">65732</span>F<span class="hljs-number">7265646173682</span>D<span class="hljs-number">372</span>E<span class="hljs-number">302</span>E<span class="hljs-number">302</span>F<span class="hljs-number">7265646173682</span>F<span class="hljs-number">62696</span>E<span class="hljs-number">2</span>F<span class="hljs-number">707974686</span>F<span class="hljs-number">6</span>E<span class="hljs-number">322</span>E<span class="hljs-number">37002</span>F<span class="hljs-number">6</span>F<span class="hljs-number">70742</span>F<span class="hljs-number">7265646173682</span>F<span class="hljs-number">7265646173682</span>F<span class="hljs-number">62696</span>E<span class="hljs-number">2</span>F<span class="hljs-number">67756</span>E<span class="hljs-number">69636</span>F<span class="hljs-number">726</span>E<span class="hljs-number">002</span>D<span class="hljs-number">62003132372</span>E<span class="hljs-number">302</span>E<span class="hljs-number">302</span>E<span class="hljs-number">313</span>A<span class="hljs-number">35303030002</span>D<span class="hljs-number">2</span>D<span class="hljs-number">6</span>E<span class="hljs-number">616</span>D<span class="hljs-number">6500726564617368002</span>D<span class="hljs-number">770034002</span>D<span class="hljs-number">2</span>D<span class="hljs-number">6</span>D<span class="hljs-number">61782</span>D<span class="hljs-number">726571756573</span>
<span class="hljs-attribute">type</span>=OBJ_PID msg=audit(<span class="hljs-number">1575620006</span>.<span class="hljs-number">444</span>:<span class="hljs-number">103711</span>): opid=<span class="hljs-number">11646</span> oauid=<span class="hljs-number">0</span> ouid=<span class="hljs-number">1001</span> oses=<span class="hljs-number">14406</span> ocomm=<span class="hljs-string">&quot;gunicorn&quot;</span>
<span class="hljs-attribute">type</span>=SYSCALL msg=audit(<span class="hljs-number">1575620006</span>.<span class="hljs-number">444</span>:<span class="hljs-number">103711</span>): arch=c<span class="hljs-number">000003</span>e syscall=<span class="hljs-number">62</span> success=yes exit=<span class="hljs-number">0</span> a<span class="hljs-number">0</span>=<span class="hljs-number">2</span>d<span class="hljs-number">7</span>e a<span class="hljs-number">1</span>=<span class="hljs-number">9</span> a<span class="hljs-number">2</span>=<span class="hljs-number">0</span> a<span class="hljs-number">3</span>=<span class="hljs-number">0</span> items=<span class="hljs-number">0</span> ppid=<span class="hljs-number">11490</span> pid=<span class="hljs-number">11494</span> auid=<span class="hljs-number">0</span> uid=<span class="hljs-number">1001</span> gid=<span class="hljs-number">1001</span> euid=<span class="hljs-number">1001</span> suid=<span class="hljs-number">1001</span> fsuid=<span class="hljs-number">1001</span> egid=<span class="hljs-number">1001</span> sgid=<span class="hljs-number">1001</span> fsgid=<span class="hljs-number">1001</span> tty=(none) ses=<span class="hljs-number">14406</span> comm=<span class="hljs-string">&quot;gunicorn&quot;</span> exe=<span class="hljs-string">&quot;/opt/modules/redash-7.0.0/redash/bin/python2.7&quot;</span> key=(null)</code></pre></div>
<p>原来是被父进程搞死了。。。</p>
<h2 id="7-查看gunicorn日志"><a href="#7-查看gunicorn日志" class="headerlink" title="7. 查看gunicorn日志"></a>7. 查看gunicorn日志</h2><p>进入supervisord控制台，通过<code>tail -f </code> 打印 <code>gunicorn</code>进程的输出。</p>
<div class="code-wrapper"><pre><code class="hljs less"><span class="hljs-selector-attr">[CRITICAL]</span> <span class="hljs-selector-tag">WORKER</span> <span class="hljs-selector-tag">TIMEOUT</span> (<span class="hljs-attribute">pid</span>:<span class="hljs-number">15577</span>)
<span class="hljs-selector-attr">[INFO]</span> <span class="hljs-selector-tag">Worker</span> <span class="hljs-selector-tag">exiting</span> (<span class="hljs-attribute">pid</span>: <span class="hljs-number">15577</span>)
<span class="hljs-selector-attr">[INFO]</span> <span class="hljs-selector-tag">Booting</span> <span class="hljs-selector-tag">worker</span> <span class="hljs-selector-tag">with</span> <span class="hljs-selector-tag">pid</span>: <span class="hljs-selector-tag">15646</span></code></pre></div>
<p><code>timeout</code>…原因就是最开始猜测的超时问题。</p>
<p><code>gunicorn</code> 给子进程的执行时间就有30秒，如果超过这个限制就会被父进程kill。可是timeout的超时配置并不生效。。。</p>
<h2 id="8-最终解决方案"><a href="#8-最终解决方案" class="headerlink" title="8.最终解决方案"></a>8.最终解决方案</h2><p><code>Gunicorn</code> 运行命令增加 <code>-k gevent</code> 配置</p>
<p><code>Gunicorn</code> 是 <code>pre-fork</code> 模型，<code>worker</code> 默认是 <code>sync</code> 改为 <code>gevent</code></p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>gunicorn</tag>
        <tag>timeout</tag>
        <tag>redash</tag>
        <tag>超时</tag>
      </tags>
  </entry>
  <entry>
    <title>Redigo</title>
    <url>/redigo/a/</url>
    <content><![CDATA[<p>[<a href="https://github.com/zuoshuwen/redigo]">https://github.com/zuoshuwen/redigo]</a>(github: <a href="https://github.com/zuoshuwen/redigo">https://github.com/zuoshuwen/redigo</a>)</p>
<ol>
<li>翻译</li>
<li>增加定时维护连接池空闲连接功能</li>
</ol>
<p>梳理图：</p>
<p><a href="https://www.processon.com/view/link/61c2bcf81efad45a2b3bca2a">https://www.processon.com/view/link/61c2bcf81efad45a2b3bca2a</a></p>
]]></content>
      <categories>
        <category>Redigo</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title>iOS</title>
    <url>/ios/a/</url>
    <content><![CDATA[<p><a href="http://gk.link/a/10tyZ">极客时间《从0开发一款iOS App》</a></p>
]]></content>
      <categories>
        <category>iOS</category>
      </categories>
      <tags>
        <tag>文章索引</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis文章索引</title>
    <url>/redis/a/</url>
    <content><![CDATA[<p>总结=&gt;背</p>
<h1 id="学习资源"><a href="#学习资源" class="headerlink" title="学习资源"></a>学习资源</h1><ol>
<li><a href="/redis/use/" title="Redis核心技术与实战">Redis核心技术与实战</a></li>
<li><a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzIyOTYxNDI5OA==&action=getalbum&album_id=1699766580538032128&scene=173&subscene=&sessionid=undefined&enterid=0&from_msgid=2247484679&from_itemidx=1&count=3&nolastread=1#wechat_redirect" title="" target="_blank">水滴与银弹</a></li>
<li><a href="/redis/source-code/" title="Redis源码剖析与实战">Redis源码剖析与实战</a></li>
<li><a href="https://mp.weixin.qq.com/s/M3FBetynBYfb8rbxnjJRvg">魔改-Redis性能暴力优化的实践</a></li>
</ol>
<h1 id=""><a href="#" class="headerlink" title="====================================="></a>=====================================</h1><h1 id="学习资料"><a href="#学习资料" class="headerlink" title="学习资料"></a>学习资料</h1><p><a href="https://strikefreedom.top/multiple-threaded-network-model-in-redis">Redis 多线程网络模型全面揭秘</a><br><a href="http://gk.link/a/10keR">极客时间《Redis核心技术与实战》</a><br><a href="https://u.jd.com/6J6Ebnu">《Redis设计与实现》</a><br><a href="https://u.jd.com/6r61kdn">《Redis使用手册》</a><br><a href="https://space.bilibili.com/1324259795/search/video?keyword=redis">硬核课堂</a><br><a href="http://wonderxxf.gitee.io/coderfan/categories/Redis/">奔跑的小石头</a><br><a href="http://zhangtielei.com/">张铁蕾</a></p>
<p><a href="https://hardcore.feishu.cn/docs/doccnp9v7IljXiJ5FpNT1ipLhlR">Redis源码分析(一)</a><br><a href="https://hardcore.feishu.cn/docs/doccnajW6xqatHCoEps4HvXzet6">Redis源码分析(二)</a><br><a href="https://hardcore.feishu.cn/docs/doccnVNnMAff9rYHrXPy3lmelgG">Redis源码分析(三)</a><br><a href="https://hardcore.feishu.cn/docs/doccnvF0IxXFmA9DOZzuAMvP8Kg">Redis源码分析(四)</a></p>
<p><a href="https://redis.io/documentation">redis doc</a></p>
<p><a href="https://segmentfault.com/blog/magebyte">码哥字节</a></p>
<h1 id="全局哈希表"><a href="#全局哈希表" class="headerlink" title="全局哈希表"></a>全局哈希表</h1><p>保存了每个键和值<br><img src="/images/redis/global-hashtable-01.png" height=100 alt="全局哈希表"/></p>
<h1 id="RedisObject"><a href="#RedisObject" class="headerlink" title="RedisObject"></a>RedisObject</h1><p>用来封装各种数据结构的结构，包含信息：元数据（8Byte）、ptr(实际数据指针，8Byte)</p>
<h1 id="数据类型与底层数据结构对应关系"><a href="#数据类型与底层数据结构对应关系" class="headerlink" title="数据类型与底层数据结构对应关系"></a>数据类型与底层数据结构对应关系</h1><p>5 v 6<br><img src="/images/redis/datastruct-01.png" height=100 alt="数据类型与底层数据结构对应关系"/></p>
<h1 id="String"><a href="#String" class="headerlink" title="String"></a>String</h1><p>底层使用 简单动态字符串（Simple Dynamic String，SDS。占用64Byte大小。<br><img src="/images/redis/string-sds-01.png" height=100 alt="SDS"/></p>
<h1 id="Hash"><a href="#Hash" class="headerlink" title="Hash"></a>Hash</h1><h1 id="list"><a href="#list" class="headerlink" title="list"></a>list</h1><h1 id="set"><a href="#set" class="headerlink" title="set"></a>set</h1><h1 id="zset"><a href="#zset" class="headerlink" title="zset"></a>zset</h1><h1 id="队列"><a href="#队列" class="headerlink" title="队列"></a>队列</h1><h1 id="主从"><a href="#主从" class="headerlink" title="主从"></a>主从</h1><h1 id="哨兵"><a href="#哨兵" class="headerlink" title="哨兵"></a>哨兵</h1><h1 id="集群"><a href="#集群" class="headerlink" title="集群"></a>集群</h1><h1 id="RDB"><a href="#RDB" class="headerlink" title="RDB"></a>RDB</h1><h1 id="AOF"><a href="#AOF" class="headerlink" title="AOF"></a>AOF</h1><h2 id="性能因素"><a href="#性能因素" class="headerlink" title="性能因素"></a>性能因素</h2><ul>
<li>CPU</li>
<li>内存</li>
<li>存储持久化</li>
<li>网络通信</li>
</ul>
<h2 id="两大维度，三大主线"><a href="#两大维度，三大主线" class="headerlink" title="两大维度，三大主线"></a>两大维度，三大主线</h2><p><img src="/images/redis/redis-01.png" alt="两大维度，三大主线"></p>
<h2 id="Redis问题画像"><a href="#Redis问题画像" class="headerlink" title="Redis问题画像"></a>Redis问题画像</h2><p><img src="/images/redis/redis-02.png" alt="Redis问题画像"></p>
<h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><h4 id="哈希冲突"><a href="#哈希冲突" class="headerlink" title="哈希冲突"></a>哈希冲突</h4><p><img src="/images/redis/global-hashtable-02.png" alt="哈希冲突"></p>
<h4 id="双hashtable渐进式"><a href="#双hashtable渐进式" class="headerlink" title="双hashtable渐进式"></a>双hashtable渐进式</h4><p><img src="/images/redis/global-hashtable-03.png" alt="双hashtable渐进式"></p>
<h3 id="压缩表"><a href="#压缩表" class="headerlink" title="压缩表"></a>压缩表</h3><p><img src="/images/redis/ziplist-01.png" alt="压缩表"></p>
<h3 id="跳表"><a href="#跳表" class="headerlink" title="跳表"></a>跳表</h3><p><img src="/images/redis/skiplist-01.png" alt="跳表"></p>
<h2 id="时间复杂度"><a href="#时间复杂度" class="headerlink" title="时间复杂度"></a>时间复杂度</h2><p><img src="/images/redis/O-01.png" alt="时间复杂度"></p>
<h2 id="IO模型"><a href="#IO模型" class="headerlink" title="IO模型"></a>IO模型</h2><p><img src="/images/redis/io-epoll-01.png" alt="IO模型"></p>
<h2 id="持久化"><a href="#持久化" class="headerlink" title="持久化"></a>持久化</h2><h3 id="AOF-1"><a href="#AOF-1" class="headerlink" title="AOF"></a>AOF</h3><p><img src="/images/redis/storage-aof-01.png" alt="aof"></p>
<ul>
<li>always：同步写回</li>
<li>everysec：每秒写回</li>
<li>no：操作系统控制写回</li>
</ul>
<p><img src="/images/redis/storage-aof-02.png" alt="对比"></p>
<h4 id="重写机制"><a href="#重写机制" class="headerlink" title="重写机制"></a>重写机制</h4><p>只保存最新的命令，减小AOF大小</p>
<ul>
<li>后台线程bgwriteaof执行</li>
<li>AOF缓存、AOF重写缓冲</li>
</ul>
<h3 id="RDB-1"><a href="#RDB-1" class="headerlink" title="RDB"></a>RDB</h3><p><img src="/images/redis/storage-rdb-01.png" alt="COW"></p>
<h4 id="增量快照"><a href="#增量快照" class="headerlink" title="增量快照"></a>增量快照</h4><h4 id="RDB、AOF混合快照"><a href="#RDB、AOF混合快照" class="headerlink" title="RDB、AOF混合快照"></a>RDB、AOF混合快照</h4><h2 id="主从-1"><a href="#主从-1" class="headerlink" title="主从"></a>主从</h2><p><img src="/images/redis/master-slave-01.png" alt="主从"></p>
<p><img src="/images/redis/master-slave-02.png" alt="同步过程"></p>
<p><img src="/images/redis/master-slave-03.png" alt="主从从"></p>
<p><img src="/images/redis/master-slave-04.png" alt="repl_backlog_buffer"></p>
<p><img src="/images/redis/master-slave-05.png" alt="增量复制"></p>
<h2 id="哨兵-1"><a href="#哨兵-1" class="headerlink" title="哨兵"></a>哨兵</h2><h3 id="主观下线"><a href="#主观下线" class="headerlink" title="主观下线"></a>主观下线</h3><p>哨兵使用PING命令检测他和主、从的网络连接情况，用来判断实例的状态，如果是从库，会直接标记下线，但是从库不会这么简单的判断。</p>
<h3 id="客观下线"><a href="#客观下线" class="headerlink" title="客观下线"></a>客观下线</h3><p><img src="/images/redis/sentinel-01.png" alt="客观下线"></p>
<h3 id="新主库选择"><a href="#新主库选择" class="headerlink" title="新主库选择"></a>新主库选择</h3><h2 id="mmap、零拷贝"><a href="#mmap、零拷贝" class="headerlink" title="mmap、零拷贝"></a>mmap、零拷贝</h2><h2 id="其它问题"><a href="#其它问题" class="headerlink" title="其它问题"></a>其它问题</h2><p>redis续租</p>
<h2 id="clion-远程调试"><a href="#clion-远程调试" class="headerlink" title="clion 远程调试"></a>clion 远程调试</h2><p>linux 安装 redis，只是make就可以，不用make all</p>
<p>clion 配置 sftp、gdb remote debug</p>
<p>linux 执行 gdbserver :1234 ./src/redis-server</p>
<h3 id="总结一下"><a href="#总结一下" class="headerlink" title="总结一下"></a>总结一下</h3><p>主要就是如何用clion远程调试c（gdb debug），然后是clion如何调试redis</p>
<p><img src="/images/redis/shui-di-yu-yin-dan-01.png" alt="redis变慢原因分析"></p>
]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>文章索引</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis配置</title>
    <url>/redis/config/</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>配置</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis源码剖析与实战</title>
    <url>/redis/source-code/</url>
    <content><![CDATA[<h1 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h1><h2 id="动态字符串、SDS"><a href="#动态字符串、SDS" class="headerlink" title="动态字符串、SDS"></a>动态字符串、SDS</h2><h3 id="总结1"><a href="#总结1" class="headerlink" title="总结1"></a>总结1</h3><p>因此这节课，你需要重点关注三个要点，分别是：</p>
<ul>
<li>C 语言中使用 char* 实现字符串的不足，主要是因为使用“\0”表示字符串结束，操作时需遍历字符串，效率不高，并且无法完整表示包含“\0”的数据，因而这就无法满足 Redis 的需求。</li>
<li>Redis 中字符串的设计思想与实现方法。Redis 专门设计了 SDS 数据结构，在字符数组的基础上，增加了字符数组长度和分配空间大小等元数据。这样一来，需要基于字符串长度进行的追加、复制、比较等操作，就可以直接读取元数据，效率也就提升了。而且，SDS 不通过字符串中的“\0”字符判断字符串结束，而是直接将其作为二进制数据处理，可以用来保存图片等二进制数据。</li>
<li>SDS 中是通过设计不同 SDS 类型来表示不同大小的字符串，并使用__attribute__ ((<strong>packed</strong>))这个编程小技巧，来实现紧凑型内存布局，达到节省内存的目的。</li>
</ul>
<p>字符串看起来简单，但通过今天这节课的学习，你可以看到实现字符串有很多需要精巧设计的地方。C 语言字符串的实现方法和 SDS 的联系与区别，也是 Redis 面试时经常会被问到的问题，所以我也希望你能通过今天这节课，掌握好它俩的区别。</p>
<h3 id="总结2"><a href="#总结2" class="headerlink" title="总结2"></a>总结2</h3><p>char* 的不足：</p>
<ul>
<li>操作效率低：获取长度需遍历，O(N)复杂度</li>
<li>二进制不安全：无法存储包含 \0 的数据</li>
</ul>
<p>SDS 的优势：</p>
<ul>
<li>操作效率高：获取长度无需遍历，O(1)复杂度</li>
<li>二进制安全：因单独记录长度字段，所以可存储包含 \0 的数据</li>
<li>兼容 C 字符串函数，可直接使用字符串 API</li>
</ul>
<p>另外 Redis 在操作 SDS 时，为了避免频繁操作字符串时，每次「申请、释放」内存的开销，还做了这些优化：</p>
<ul>
<li>内存预分配：SDS 扩容，会多申请一些内存（小于 1MB 翻倍扩容，大于 1MB 按 1MB 扩容）</li>
<li>多余内存不释放：SDS 缩容，不释放多余的内存，下次使用可直接复用这些内存</li>
</ul>
<p>这种策略，是以多占一些内存的方式，换取「追加」操作的速度。</p>
<p>这个内存预分配策略，详细逻辑可以看 sds.c 的 sdsMakeRoomFor 函数。</p>
<p>课后题：SDS 字符串在 Redis 内部模块实现中也被广泛使用，你能在 Redis server 和客户端的实现中，找到使用 SDS 字符串的地方么？</p>
<ol>
<li>Redis 中所有 key 的类型就是 SDS（详见 db.c 的 dbAdd 函数）</li>
<li>Redis Server 在读取 Client 发来的请求时，会先读到一个缓冲区中，这个缓冲区也是 SDS（详见 server.h 中 struct client 的 querybuf 字段）</li>
<li>写操作追加到 AOF 时，也会先写到 AOF 缓冲区，这个缓冲区也是 SDS （详见 server.h 中 struct client 的 aof_buf 字段）</li>
</ol>
<h2 id="Hash"><a href="#Hash" class="headerlink" title="Hash"></a>Hash</h2><h3 id="总结1-1"><a href="#总结1-1" class="headerlink" title="总结1"></a>总结1</h3><p>实现一个高性能的 Hash 表不仅是 Redis 的需求，也是很多计算机系统开发过程中的重要目标。而要想实现一个性能优异的 Hash 表，就需要重点解决哈希冲突和 rehash 开销这两个问题。</p>
<p>今天这节课，我带你学习了 Redis 中 Hash 表的结构设计、链式哈希方法的实现，以及渐进式 rehash 方法的设计实现。Redis 中 Hash 表的结构设计很特别，它的每个哈希项都包含了一个指针，用于实现链式哈希。同时，Redis 在全局哈希表中还包含了两个 Hash 表，这种设计思路也是为了在实现 rehash 时，帮助数据从一个表迁移到另一个表。</p>
<p>此外，Redis 实现的渐进式 rehash 是一个用于 Hash 表扩容的通用方法，非常值得我们学习。这个设计方法的关键是每次仅迁移有限个数的 bucket，避免一次性迁移给所有 bucket 带来的性能影响。当你掌握了渐进式 rehash 这个设计思想和实现方法，你就可以把它应用到自己的 Hash 表实现场景中。</p>
<h3 id="总结2-1"><a href="#总结2-1" class="headerlink" title="总结2"></a>总结2</h3><ol>
<li><p>Redis 中的 dict 数据结构，采用「链式哈希」的方式存储，当哈希冲突严重时，会开辟一个新的哈希表，翻倍扩容，并采用「渐进式 rehash」的方式迁移数据</p>
</li>
<li><p>所谓「渐进式 rehash」是指，把很大块迁移数据的开销，平摊到多次小的操作中，目的是降低主线程的性能影响</p>
</li>
<li><p>Redis 中凡是需要 O(1) 时间获取 k-v 数据的场景，都使用了 dict 这个数据结构，也就是说 dict 是 Redis 中重中之重的「底层数据结构」</p>
</li>
<li><p>dict 封装好了友好的「增删改查」API，并在适当时机「自动扩容、缩容」，这给上层数据类型（Hash/Set/Sorted Set）、全局哈希表的实现提供了非常大的便利</p>
</li>
<li><p>例如，Redis 中每个 DB 存放数据的「全局哈希表、过期key」都用到了 dict：</p>
<div class="code-wrapper"><pre><code class="hljs c"><span class="hljs-comment">// server.h</span>
<span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">redisDb</span> &#123;</span>
   dict *dict; <span class="hljs-comment">// 全局哈希表，数据键值对存在这</span>
   dict *expires; <span class="hljs-comment">// 过期 key + 过期时间 存在这</span>
   ...
&#125;</code></pre></div></li>
<li><p>「全局哈希表」在触发渐进式 rehash 的情况有 2 个：</p>
</li>
</ol>
<ul>
<li>增删改查哈希表时：每次迁移 1 个哈希桶（文章提到的 dict.c 中的 _dictRehashStep 函数）</li>
<li>定时 rehash：如果 dict 一直没有操作，无法渐进式迁移数据，那主线程会默认每间隔 100ms 执行一次迁移操作。这里一次会以 100 个桶为基本单位迁移数据，并限制如果一次操作耗时超时 1ms 就结束本次任务，待下次再次触发迁移（文章没提到这个，详见 dict.c 的 dictRehashMilliseconds 函数）</li>
</ul>
<p>（注意：定时 rehash 只会迁移全局哈希表中的数据，不会定时迁移 Hash/Set/Sorted Set 下的哈希表的数据，这些哈希表只会在操作数据时做实时的渐进式 rehash）</p>
<ol start="7">
<li>dict 在负载因子超过 1 时（used: bucket size &gt;= 1），会触发 rehash。但如果 Redis 正在 RDB 或 AOF rewrite，为避免父进程大量写时复制，会暂时关闭触发 rehash。但这里有个例外，如果负载因子超过了 5（哈希冲突已非常严重），依旧会强制做 rehash（重点）</li>
<li>dict 在 rehash 期间，查询旧哈希表找不到结果，还需要在新哈希表查询一次</li>
</ol>
<p>课后题：Hash 函数会影响 Hash 表的查询效率及哈希冲突情况，那么，你能从 Redis 的源码中，找到 Hash 表使用的是哪一种 Hash 函数吗？</p>
<p>找到 dict.c 的 dictFind 函数，可以看到查询一个 key 在哈希表的位置时，调用了 dictHashKey 计算 key 的哈希值：</p>
<div class="code-wrapper"><pre><code class="hljs c"><span class="hljs-function">dictEntry *<span class="hljs-title">dictFind</span><span class="hljs-params">(dict *d, <span class="hljs-keyword">const</span> <span class="hljs-keyword">void</span> *key)</span> </span>&#123;
   <span class="hljs-comment">// 计算 key 的哈希值</span>
   h = dictHashKey(d, key);
   ...
&#125;</code></pre></div>

<p>继续跟代码可以看到 dictHashKey 调用了 struct dict 下 dictType 的 hashFunction 函数：</p>
<div class="code-wrapper"><pre><code class="hljs c"><span class="hljs-comment">// dict.h</span>
dictHashKey(d, key) (d)-&gt;type-&gt;hashFunction(key)</code></pre></div>

<p>而这个 hashFunction 是在初始化一个 dict 时，才会指定使用哪个哈希函数的。</p>
<p>当 Redis Server 在启动时会创建「全局哈希表」：</p>
<div class="code-wrapper"><pre><code class="hljs c"><span class="hljs-comment">// 初始化 db 下的全局哈希表</span>
<span class="hljs-keyword">for</span> (j = <span class="hljs-number">0</span>; j &lt; server.dbnum; j++) &#123;
   <span class="hljs-comment">// dbDictType 中指定了哈希函数</span>
   server.db[j].dict = dictCreate(&amp;dbDictType,<span class="hljs-literal">NULL</span>);
...
&#125;</code></pre></div>

<p>这个 dbDictType struct 指定了具体的哈希函数，跟代码进去能看到，使用了 SipHash 算法，具体实现逻辑在 siphash.c。</p>
<p>（SipHash 哈希算法是在 Redis 4.0 才开始使用的，3.0-4.0 使用的是 MurmurHash2 哈希算法，3.0 之前是 DJBX33A 哈希算法）</p>
<h2 id="RedisObject"><a href="#RedisObject" class="headerlink" title="RedisObject"></a>RedisObject</h2><h3 id="总结1-2"><a href="#总结1-2" class="headerlink" title="总结1"></a>总结1</h3><p>降低内存开销，对于 Redis 这样的内存数据库来说非常重要。今天这节课，我们了解了 Redis 用于优化内存使用效率的两种方法：内存优化的数据结构设计和节省内存的共享数据访问。</p>
<p>那么，对于实现数据结构来说，如果想要节省内存，Redis 就给我们提供了两个优秀的设计思想：一个是使用连续的内存空间，避免内存碎片开销；二个是针对不同长度的数据，采用不同大小的元数据，以避免使用统一大小的元数据，造成内存空间的浪费。</p>
<p>另外在数据访问方面，你也要知道，使用共享对象其实可以避免重复创建冗余的数据，从而也可以有效地节省内存空间。不过，共享对象主要适用于只读场景，如果一个字符串被反复地修改，就无法被多个请求共享访问了。所以这一点，你在应用时也需要注意一下。</p>
<h3 id="总结2-2"><a href="#总结2-2" class="headerlink" title="总结2"></a>总结2</h3><ol>
<li>要想理解 Redis 数据类型的设计，必须要先了解 redisObject。</li>
</ol>
<p>Redis 的 key 是 String 类型，但 value 可以是很多类型（String/List/Hash/Set/ZSet等），所以 Redis 要想存储多种数据类型，就要设计一个通用的对象进行封装，这个对象就是 redisObject。</p>
<div class="code-wrapper"><pre><code class="hljs c"><span class="hljs-comment">// server.h</span>
<span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">redisObject</span> &#123;</span>
   <span class="hljs-keyword">unsigned</span> type:<span class="hljs-number">4</span>;
   <span class="hljs-keyword">unsigned</span> encoding:<span class="hljs-number">4</span>;
   <span class="hljs-keyword">unsigned</span> lru:LRU_BITS;
   <span class="hljs-keyword">int</span> refcount;
   <span class="hljs-keyword">void</span> *ptr;
&#125; robj;</code></pre></div>

<p>其中，最重要的 2 个字段：</p>
<ul>
<li>type：面向用户的数据类型（String/List/Hash/Set/ZSet等）</li>
<li>encoding：每一种数据类型，可以对应不同的底层数据结构来实现（SDS/ziplist/intset/hashtable/skiplist等）</li>
</ul>
<p>例如 String，可以用 embstr（嵌入式字符串，redisObject 和 SDS 一起分配内存），也可以用 rawstr（redisObject 和 SDS 分开存储）实现。</p>
<p>又或者，当用户写入的是一个「数字」时，底层会转成 long 来存储，节省内存。</p>
<p>同理，Hash/Set/ZSet 在数据量少时，采用 ziplist 存储，否则就转为 hashtable 来存。</p>
<p>所以，redisObject 的作用在于：</p>
<ul>
<li>为多种数据类型提供统一的表示方式</li>
<li>同一种数据类型，底层可以对应不同实现，节省内存</li>
<li>支持对象共享和引用计数，共享对象存储一份，可多次使用，节省内存</li>
</ul>
<p>redisObject 更像是连接「上层数据类型」和「底层数据结构」之间的桥梁。</p>
<ol start="2">
<li>关于 String 类型的实现，底层对应 3 种数据结构：</li>
</ol>
<ul>
<li>embstr：小于 44 字节，嵌入式存储，redisObject 和 SDS 一起分配内存，只分配 1 次内存</li>
<li>rawstr：大于 44 字节，redisObject 和 SDS 分开存储，需分配 2 次内存</li>
<li>long：整数存储（小于 10000，使用共享对象池存储，但有个前提：Redis 没有设置淘汰策略，详见 object.c 的 tryObjectEncoding 函数）</li>
</ul>
<ol start="3">
<li>ziplist 的特点：</li>
</ol>
<ul>
<li>连续内存存储：每个元素紧凑排列，内存利用率高</li>
<li>变长编码：存储数据时，采用变长编码（满足数据长度的前提下，尽可能少分配内存）</li>
<li>寻找元素需遍历：存放太多元素，性能会下降（适合少量数据存储）</li>
<li>级联更新：更新、删除元素，会引发级联更新（因为内存连续，前面数据膨胀/删除了，后面要跟着一起动）</li>
</ul>
<p>List、Hash、Set、ZSet 底层都用到了 ziplist。</p>
<ol start="4">
<li>intset 的特点：</li>
</ol>
<ul>
<li>Set 存储如果都是数字，采用 intset 存储</li>
<li>变长编码：数字范围不同，intset 会选择 int16/int32/int64 编码（intset.c 的 _intsetValueEncoding 函数）</li>
<li>有序：intset 在存储时是有序的，这意味着查找一个元素，可使用「二分查找」（intset.c 的 intsetSearch 函数）</li>
<li>编码升级/降级：添加、更新、删除元素，数据范围发生变化，会引发编码长度升级或降级</li>
</ul>
<p>课后题：SDS 判断是否使用嵌入式字符串的条件是 44 字节，你知道为什么是 44 字节吗？</p>
<p>嵌入式字符串会把 redisObject 和 SDS 一起分配内存，那在存储时结构是这样的：</p>
<ul>
<li>redisObject：16 个字节</li>
<li>SDS：sdshdr8（3 个字节）+ SDS 字符数组（N 字节 + \0 结束符 1 个字节）</li>
</ul>
<p>Redis 规定嵌入式字符串最大以 64 字节存储，所以 N = 64 - 16(redisObject) - 3(sdshr8) - 1(\0)， N = 44 字节。</p>
<h2 id="ZSet"><a href="#ZSet" class="headerlink" title="ZSet"></a>ZSet</h2><h3 id="总结1-3"><a href="#总结1-3" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我给你介绍了 Sorted Set 数据类型的底层实现。Sorted Set 为了能同时支持按照权重的范围查询，以及针对元素权重的单点查询，在底层数据结构上设计了组合使用跳表和哈希表的方法。</p>
<p>跳表是一个多层的有序链表，在跳表中进行查询操作时，查询代码可以从最高层开始查询。层数越高，结点数越少，同时高层结点的跨度会比较大。因此，在高层查询结点时，查询一个结点可能就已经查到了链表的中间位置了。</p>
<p>这样一来，跳表就会先查高层，如果高层直接查到了等于待查元素的结点，那么就可以直接返回。如果查到第一个大于待查元素的结点后，就转向下一层查询。下层上的结点数多于上层，所以这样可以在更多的结点中进一步查找待查元素是否存在。</p>
<p>跳表的这种设计方法就可以节省查询开销，同时，跳表设计采用随机的方法来确定每个结点的层数，这样就可以避免新增结点时，引起结点连锁更新问题。</p>
<p>此外，Sorted Set 中还将元素保存在了哈希表中，作为哈希表的 key，同时将 value 指向元素在跳表中的权重。使用了哈希表后，Sorted Set 可以通过哈希计算直接查找到某个元素及其权重值，相较于通过跳表查找单个元素，使用哈希表就有效提升了查询效率。</p>
<p>总之，组合使用两种索引结构来对数据进行管理，比如 Sorted Set 中组合使用跳表和哈希表，这是一个很好的设计思路，希望你也能应用在日常的系统开发中。</p>
<h3 id="总结2-3"><a href="#总结2-3" class="headerlink" title="总结2"></a>总结2</h3><ol>
<li>ZSet 当数据比较少时，采用 ziplist 存储，每个 member/score 元素紧凑排列，节省内存</li>
<li>当数据超过阈值（zset-max-ziplist-entries、zset-max-ziplist-value）后，转为 hashtable + skiplist 存储，降低查询的时间复杂度</li>
<li>hashtable 存储 member-&gt;score 的关系，所以 ZSCORE 的时间复杂度为 O(1)</li>
<li>skiplist 是一个「有序链表 + 多层索引」的结构，把查询元素的复杂度降到了 O(logN)，服务于 ZRANGE/ZREVRANGE 这类命令</li>
<li>skiplist 的多层索引，采用「随机」的方式来构建，也就是说每次添加一个元素进来，要不要对这个元素建立「多层索引」？建立「几层索引」？都要通过「随机数」的方式来决定</li>
<li>每次随机一个 0-1 之间的数，如果这个数小于 0.25（25% 概率），那就给这个元素加一层指针，持续随机直到大于 0.25 结束，最终确定这个元素的层数（层数越高，概率越低，且限制最多 64 层，详见 t_zset.c 的 zslRandomLevel 函数）</li>
<li>这个预设「概率」决定了一个跳表的内存占用和查询复杂度：概率设置越低，层数越少，元素指针越少，内存占用也就越少，但查询复杂会变高，反之亦然。这也是 skiplist 的一大特点，可通过控制概率，进而控制内存和查询效率</li>
<li>skiplist 新插入一个节点，只需修改这一层前后节点的指针，不影响其它节点的层数，降低了操作复杂度（相比平衡二叉树的再平衡，skiplist 插入性能更优）</li>
</ol>
<p>关于 Redis 的 ZSet 为什么用 skiplist 而不用平衡二叉树实现的问题，原因是：</p>
<ul>
<li>skiplist 更省内存：25% 概率的随机层数，可通过公式计算出 skiplist 平均每个节点的指针数是 1.33 个，平衡二叉树每个节点指针是 2 个（左右子树）</li>
<li>skiplist 遍历更友好：skiplist 找到大于目标元素后，向后遍历链表即可，平衡树需要通过中序遍历方式来完成，实现也略复杂</li>
<li>skiplist 更易实现和维护：扩展 skiplist 只需要改少量代码即可完成，平衡树维护起来较复杂</li>
</ul>
<p>课后题：在使用跳表和哈希表相结合的双索引机制时，在获得高效范围查询和单点查询的同时，你能想到有哪些不足之处么？</p>
<p>这种发挥「多个数据结构」的优势，来完成某个功能的场景，最大的特点就是「空间换时间」，所以内存占用多是它的不足。</p>
<p>不过也没办法，想要高效率查询，就得牺牲内存，鱼和熊掌不可兼得。</p>
<p>不过 skiplist 在实现时，Redis 作者应该也考虑到这个问题了，就是上面提到的这个「随机概率」，Redis 后期维护可以通过调整这个概率，进而达到「控制」查询效率和内存平衡的结果。当然，这个预设值是固定写死的，不可配置，应该是 Redis 作者经过测试和权衡后的设定，我们这里只需要知晓原理就好。</p>
<h2 id="ZipList、QuickList、ListPack"><a href="#ZipList、QuickList、ListPack" class="headerlink" title="ZipList、QuickList、ListPack"></a>ZipList、QuickList、ListPack</h2><h3 id="总结1-4"><a href="#总结1-4" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我从 ziplist 的设计不足出发，依次给你介绍了 quicklist 和 listpack 的设计思想。</p>
<p>你要知道，ziplist 的不足主要在于一旦 ziplist 中元素个数多了，它的查找效率就会降低。而且如果在 ziplist 里新增或修改数据，ziplist 占用的内存空间还需要重新分配；更糟糕的是，ziplist 新增某个元素或修改某个元素时，可能会导致后续元素的 prevlen 占用空间都发生变化，从而引起连锁更新问题，导致每个元素的空间都要重新分配，这就会导致 ziplist 的访问性能下降。</p>
<p>所以，为了应对 ziplist 的问题，Redis 先是在 3.0 版本中设计实现了 quicklist。quicklist 结构在 ziplist 基础上，使用链表将 ziplist 串联起来，链表的每个元素就是一个 ziplist。这种设计减少了数据插入时内存空间的重新分配，以及内存数据的拷贝。同时，quicklist 限制了每个节点上 ziplist 的大小，一旦一个 ziplist 过大，就会采用新增 quicklist 节点的方法。</p>
<p>不过，又因为 quicklist 使用 quicklistNode 结构指向每个 ziplist，无疑增加了内存开销。为了减少内存开销，并进一步避免 ziplist 连锁更新问题，Redis 在 5.0 版本中，就设计实现了 listpack 结构。listpack 结构沿用了 ziplist 紧凑型的内存布局，把每个元素都紧挨着放置。</p>
<p>listpack 中每个列表项不再包含前一项的长度了，因此当某个列表项中的数据发生变化，导致列表项长度变化时，其他列表项的长度是不会受影响的，因而这就避免了 ziplist 面临的连锁更新问题。</p>
<p>总而言之，Redis 在内存紧凑型列表的设计与实现上，从 ziplist 到 quicklist，再到 listpack，你可以看到 Redis 在内存空间开销和访问性能之间的设计取舍，这一系列的设计变化，是非常值得你学习的。</p>
<h3 id="总结2-4"><a href="#总结2-4" class="headerlink" title="总结2"></a>总结2</h3><ol>
<li>ziplist 设计的初衷就是「节省内存」，在存储数据时，把内存利用率发挥到了极致：</li>
</ol>
<ul>
<li>数字按「整型」编码存储，比直接当字符串存内存占用少</li>
<li>数据「长度」字段，会根据内容的大小选择最小的长度编码</li>
<li>甚至对于极小的数据，干脆把内容直接放到了「长度」字段中（前几个位表示长度，后几个位存数据）</li>
</ul>
<ol start="2">
<li>但 ziplist 的劣势也很明显：</li>
</ol>
<ul>
<li>寻找元素只能挨个遍历，存储过长数据，查询性能很低</li>
<li>每个元素中保存了「上一个」元素的长度（为了方便反向遍历），这会导致上一个元素内容发生修改，长度超过了原来的编码长度，下一个元素的内容也要跟着变，重新分配内存，进而就有可能再次引起下一级的变化，一级级更新下去，频繁申请内存</li>
</ul>
<ol start="3">
<li>想要缓解 ziplist 的问题，比较简单直接的方案就是，多个数据项，不再用一个 ziplist 来存，而是分拆到多个 ziplist 中，每个 ziplist 用指针串起来，这样修改其中一个数据项，即便发生级联更新，也只会影响这一个 ziplist，其它 ziplist 不受影响，这种方案就是 quicklist：</li>
</ol>
<p>qucklist: ziplist1(也叫quicklistNode) &lt;-&gt; ziplist2 &lt;-&gt; ziplist3 &lt;-&gt; …</p>
<ol start="4">
<li>List 数据类型底层实现，就是用的 quicklist，因为它是一个链表，所以 LPUSH/LPOP/RPUSH/RPOP 的复杂度是 O(1)</li>
<li>List 中每个 ziplist 节点可以存的元素个数/总大小，可以通过 list-max-ziplist-size 配置：</li>
</ol>
<ul>
<li>正数：ziplist 最多包含几个数据项</li>
<li>负数：取值 -1 ~ -5，表示每个 ziplist 存储最大的字节数，默认 -2，每个ziplist 8KB</li>
</ul>
<p>ziplist 超过上述任一配置，添加新元素就会新建 ziplist 插入到链表中。</p>
<ol start="6">
<li>List 因为更多是两头操作，为了节省内存，还可以把中间的 ziplist「压缩」，具体可看 list-compress-depth 配置项，默认配置不压缩</li>
<li>要想彻底解决 ziplist 级联更新问题，本质上要修改 ziplist 的存储结构，也就是不要让每个元素保存「上一个」元素的长度即可，所以才有了 listpack</li>
<li>listpack 每个元素项不再保存上一个元素的长度，而是优化元素内字段的顺序，来保证既可以从前也可以向后遍历</li>
<li>listpack 是为了替代 ziplist 为设计的，但因为 List/Hash/Set/ZSet 都严重依赖 ziplist，所以这个替换之路很漫长，目前只有 Stream 数据类型用到了 listpack</li>
</ol>
<h2 id="Radix-Tree"><a href="#Radix-Tree" class="headerlink" title="Radix Tree"></a>Radix Tree</h2><h3 id="总结1-5"><a href="#总结1-5" class="headerlink" title="总结1"></a>总结1</h3><p>今天这节课上，我带你学习了 Redis Stream 数据类型的底层实现结构。现在你已经知道，Stream 最主要的作用就是可以用来保存消息数据。</p>
<p>每条消息都会有一个时间戳和序号组成的消息 ID，以及键值对组成的消息内容。而因为不同消息 ID 中的时间戳，通常会共享部分相同的前缀，如果采用诸如哈希表的结构来保存消息，每个消息 ID 都单独保存，容易造成空间浪费。因此，Stream 为了节省内存空间，采用了 Radix Tree 来保存消息 ID，同时使用 listpack 来保存消息本身的内容。</p>
<p>在 Radix Tree 的设计实现中，它的整体结构和节点数据结构是理解 Radix Tree 的重要基础，所以，你要重点关注 Radix Tree 的非压缩节点和压缩节点类型，以及源码中的实际数据结构 raxNode。</p>
<p>另外，为了方便你更好地掌握非压缩节点和压缩节点，我再给你总结下它们的相同之处和区别，你也可以来整体回顾下。</p>
<p>它们的相同之处在于：</p>
<ul>
<li>都有保存元数据的节点头 HDR；</li>
<li>都会包含指向子节点的指针，以及子节点所代表的字符串。</li>
<li>从根节点到当前节点路径上的字符串如果是 Radix Tree 的一个 key，它们都会包含指向 key 对应 value 的指针。</li>
</ul>
<p>不同之处在于：</p>
<ul>
<li>非压缩节点指向的子节点，每个子节点代表一个字符，非压缩节点可以指向多个子节点；</li>
<li>压缩节点指向的子节点，代表的是一个合并字符串，压缩节点只能指向一个子节点。</li>
</ul>
<p>而除了学习 raxNode，我还给你介绍了下 Radix Tree 中几个基本操作函数的作用，并展示了 Stream 类型是如何把消息 ID 和消息内容，分别保存在 Radix Tree 和 listpack 中的。</p>
<p>这里你要注意的是，因为 Radix Tree 在保存具有公共前缀的数据时，能有效节省内存开销。同时，Radix Tree 本身也是有序的树型索引，可以支持单点和范围查询。所以，Redis 把消息 ID 保存在 Radix Tree 中，既可以节省内存空间，也能高效支持消息 ID 的查询。而 listpack 本身是紧凑列表，在保存大量消息内容的同时，也能有效节省内存。</p>
<p>所以我希望，你能通过 Stream 对 Radix Tree 和 listpack 的使用，举一反三，把它们用在相应的消息存取或是大量字符串存取的场景中。</p>
<h3 id="总结2-5"><a href="#总结2-5" class="headerlink" title="总结2"></a>总结2</h3><p>作为有序索引，Radix Tree 也能提供范围查询，和我们日常使用的 B+ 树，以及第5讲中介绍的跳表相比，你觉得 Radix Tree 有什么优势和不足么？</p>
<ol>
<li>Radix Tree 优势</li>
</ol>
<ul>
<li>本质上是前缀树，所以存储有「公共前缀」的数据时，比 B+ 树、跳表节省内存</li>
<li>没有公共前缀的数据项，压缩存储，value 用 listpack 存储，也可以节省内存</li>
<li>查询复杂度是 O(K)，只与「目标长度」有关，与总数据量无关</li>
<li>这种数据结构也经常用在搜索引擎提示、文字自动补全等场景</li>
</ul>
<p>Stream 在存消息时，推荐使用默认自动生成的「时间戳+序号」作为消息 ID，不建议自己指定消息 ID，这样才能发挥 Radix Tree 公共前缀的优势。</p>
<ol start="2">
<li>Radix Tree 不足</li>
</ol>
<ul>
<li>如果数据集公共前缀较少，会导致内存占用多</li>
<li>增删节点需要处理其它节点的「分裂、合并」，跳表只需调整前后指针即可</li>
<li>B+ 树、跳表范围查询友好，直接遍历链表即可，Radix Tree 需遍历树结构</li>
<li>实现难度高比 B+ 树、跳表复杂</li>
</ul>
<p>每种数据结构都是在面对不同问题场景下，才被设计出来的，结合各自场景中的数据特点，使用优势最大的数据结构才是正解。</p>
<h1 id="事件驱动"><a href="#事件驱动" class="headerlink" title="事件驱动"></a>事件驱动</h1><h2 id="Redis-Server"><a href="#Redis-Server" class="headerlink" title="Redis Server"></a>Redis Server</h2><h3 id="总结1-6"><a href="#总结1-6" class="headerlink" title="总结1"></a>总结1</h3><p>今天这节课，我们通过 server.c 文件中 main 函数的设计和实现思路，了解了 Redis server 启动后的五个主要阶段。在这五个阶段中，运行参数解析、server 初始化和执行事件驱动框架则是 Redis sever 启动过程中的三个关键阶段。所以相应的，我们需要重点关注以下三个要点。</p>
<p>第一，main 函数是使用 initServerConfig 给 server 运行参数设置默认值，然后会解析命令行参数，并通过 loadServerConfig 读取配置文件参数值，将命令行参数追加至配置项字符串。最后，Redis 会调用 loadServerConfigFromString 函数，来完成配置文件参数和命令行参数的设置。</p>
<p>第二，在 Redis server 完成参数设置后，initServer 函数会被调用，用来初始化 server 资源管理的主要结构，同时会初始化数据库启动状态，以及完成 server 监听 IP 和端口的设置。</p>
<p>第三，一旦 server 可以接收外部客户端的请求后，main 函数会把程序的主体控制权，交给事件驱动框架的入口函数，也就 aeMain 函数。aeMain 函数会一直循环执行，处理收到的客户端请求。到此为止，server.c 中的 main 函数功能就已经全部完成了，程序控制权也交给了事件驱动循环框架，Redis 也就可以正常处理客户端请求了。</p>
<p>实际上，Redis server 的启动过程从基本的初始化操作，到命令行和配置文件的参数解析设置，再到初始化 server 各种数据结构，以及最后的执行事件驱动框架，这是一个典型的网络服务器执行过程，你在开发网络服务器时，就可以作为参考。</p>
<p>而且，掌握了启动过程中的初始化操作，还可以帮你解答一些使用中的疑惑。比如，Redis 启动时是先读取 RDB 文件，还是先读取 AOF 文件。如果你了解了 Redis server 的启动过程，就可以从 loadDataFromDisk 函数中看到，Redis server 会先读取 AOF；而如果没有 AOF，则再读取 RDB。</p>
<p>所以，掌握 Redis server 启动过程，有助于你更好地了解 Redis 运行细节，这样当你遇到问题时，就知道还可以从启动过程中去溯源 server 的各种初始状态，从而助力你更好地解决问题。</p>
<h3 id="总结2-6"><a href="#总结2-6" class="headerlink" title="总结2"></a>总结2</h3><p>Redis 启动流程，主要的工作有：</p>
<ol>
<li>初始化前置操作（设置时区、随机种子）</li>
<li>初始化 Server 的各种默认配置（server.c 的 initServerConfig 函数），默认配置见 server.h 中的 CONFIG_DEFAULT_XXX，比较典型的配置有：</li>
</ol>
<ul>
<li>默认端口</li>
<li>定时任务频率</li>
<li>数据库数量</li>
<li>AOF 刷盘策略</li>
<li>淘汰策略</li>
<li>数据结构转换阈值</li>
<li>主从复制参数</li>
</ul>
<ol start="3">
<li>加载配置启动参数，覆盖默认配置（config.c 的 loadServerConfig 函数）：</li>
</ol>
<ul>
<li>解析命令行参数</li>
<li>解析配置文件</li>
</ul>
<ol start="3">
<li>初始化 Server（server.c 的 initServer 函数），例如会初始化：</li>
</ol>
<ul>
<li>共享对象池</li>
<li>客户端链表</li>
<li>从库链表</li>
<li>监听端口</li>
<li>全局哈希表</li>
<li>LRU 池</li>
<li>注册定时任务函数</li>
<li>注册监听请求函数</li>
</ul>
<ol start="4">
<li>启动事件循环（ae.c 的 aeMain 函数）</li>
</ol>
<ul>
<li>处理请求</li>
<li>处理定时任务</li>
</ul>
<p>这里补充一下，初始化 Server 完成后，Redis 还会启动 3 类后台线程（server.c 的 InitServerLast 函数），协助主线程工作（异步释放 fd、AOF 每秒刷盘、lazyfree）。</p>
<p>课后题：Redis 源码的 main 函数在调用 initServer 函数之前，会执行如下的代码片段，你知道这个代码片段的作用是什么吗？</p>
<div class="code-wrapper"><pre><code class="hljs c"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">main</span><span class="hljs-params">(<span class="hljs-keyword">int</span> argc, <span class="hljs-keyword">char</span> **argv)</span> </span>&#123;
   ...
   server.supervised = redisIsSupervised(server.supervised_mode);
   <span class="hljs-keyword">int</span> background = server.daemonize &amp;&amp; !server.supervised;
   <span class="hljs-keyword">if</span> (background) daemonize();
   ...
&#125;</code></pre></div>

<p>Redis 可以配置以守护进程的方式启动（配置文件 daemonize = yes），也可以把 Redis 托管给 upstart 或 systemd 来启动 / 停止（supervised = upstart|systemd|auto）。</p>
<h2 id="IO多路复用"><a href="#IO多路复用" class="headerlink" title="IO多路复用"></a>IO多路复用</h2><h3 id="总结1-7"><a href="#总结1-7" class="headerlink" title="总结1"></a>总结1</h3><p>今天这节课，我给你介绍了 Redis 网络通信依赖的操作系统底层机制，也就是 IO 多路复用机制。</p>
<p>由于 Redis 是单线程程序，如果使用基本的 Socket 编程模型的话，只能对一个监听套接字或一个已连接套接字进行监听。而当 Redis 实例面临很多并发的客户端时，这种处理方式的效率就会很低。</p>
<p>所以，和基本的 Socket 通信相比，使用 IO 多路复用机制，就可以一次性获得就绪的多个套接字，从而避免了逐个检测套接字的开销。</p>
<p>这节课，我是以最常用的 Linux 操作系统为例，给你具体介绍了 Linux 系统提供的三种 IO 多路复用机制，分别是 select、poll 和 epoll。这三种机制在能监听的描述符数量和查找就绪描述符的方法上是不一样的，你可以重点参考下图，来掌握它们的不同之处。这些差异，其实也决定了 epoll 相比于 select 和 poll 来说，效率更高，也应用更广泛。<br><img src="/images/redis/io-epoll-02.png" alt="img.png"></p>
<p>最后我想说的是，虽然这节课我没有给你介绍 Redis 的源码，但是学习 IO 多路复用的机制和使用流程，其实就是掌握 Redis 事件驱动框架的基础。Redis 的ae_select.c和ae_epoll.c文件，就分别使用了 select 和 epoll 这两种机制，实现 IO 多路复用。而在接下来的第 10、11 两节课上，我还会给分别你介绍，Redis 事件驱动框架是如何基于 epoll 进行封装开发和运行的，以及 Redis 事件驱动框架的事件类型和处理方法。这样一来，你就能对 Redis 事件驱动框架的底层支撑、框架运行和事件类型与处理，有个全面的掌握了。</p>
<h3 id="总结2-7"><a href="#总结2-7" class="headerlink" title="总结2"></a>总结2</h3><ol>
<li>单线程服务器模型，面临的最大的问题就是，一个线程如何处理多个客户端请求？解决这种问题的办法就是「IO 多路复用」。它本质上是应用层不用维护多个客户端的连接状态，而是把它们「托管」给了操作系统，操作系统维护这些连接的状态变化，之后应用层只管问操作系统，哪些 socket 有数据可读/可写就好了，大大简化了应用层的复杂度</li>
<li>IO 多路复用机制要想高效使用，一般还需要把 socket 设置成「非阻塞」模式，即 socket 没有数据可读/可写时，应用层去 read/write socket 也不会阻塞住（内核会返回指定错误，应用层可继续重试），这样应用层就可以去处理其它业务逻辑，不会阻塞影响性能</li>
<li>为什么 Redis 要使用「单线程」处理客户端请求？本质上是因为，Redis 操作的是内存，操作内存数据是极快的，所以 Redis 的瓶颈不在 CPU，优化的重点就在网络 IO 上，高效的 IO 多路复用机制，正好可以满足这种需求，模型简单，性能也极高</li>
<li>但成也萧何败也萧何，因为 Redis 处理请求是「单线程」，所以如果有任意请求在 Server 端发生耗时（例如操作 bigkey，或一次请求数据过多），就会导致后面的请求发生「排队」，业务端就会感知到延迟增大，性能下降</li>
<li>基于此，Redis 又做了很多优化：一些耗时的操作，不再放在主线程处理，而是丢到后台线程慢慢执行。例如，异步关闭 fd，异步释放内存、后台 AOF 刷盘这些操作。所以 Redis Server 其实是「多线程」的，只不过最核心的处理请求逻辑是单线程的，这点一定要区分开</li>
</ol>
<p>课后题：在 Redis 事件驱动框架代码中，分别使用了 Linux 系统上的 select 和 epoll 两种机制，你知道为什么 Redis 没有使用 poll 这一机制吗？</p>
<p>首先要明确一点，select 并不是只有 Linux 才支持的，Windows 平台也支持。</p>
<p>而 Redis 针对不同操作系统，会选择不同的 IO 多路复用机制来封装事件驱动框架，具体代码见 ae.c。</p>
<div class="code-wrapper"><pre><code class="hljs c"><span class="hljs-comment">// ae.c</span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">ifdef</span> HAVE_EVPORT</span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&quot;ae_evport.c&quot;</span> <span class="hljs-comment">// Solaris</span></span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">else</span></span>
    <span class="hljs-meta">#<span class="hljs-meta-keyword">ifdef</span> HAVE_EPOLL</span>
    <span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&quot;ae_epoll.c&quot;</span> <span class="hljs-comment">// Linux</span></span>
    <span class="hljs-meta">#<span class="hljs-meta-keyword">else</span></span>
        <span class="hljs-meta">#<span class="hljs-meta-keyword">ifdef</span> HAVE_KQUEUE</span>
        <span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&quot;ae_kqueue.c&quot;</span> <span class="hljs-comment">// MacOS</span></span>
        <span class="hljs-meta">#<span class="hljs-meta-keyword">else</span></span>
        <span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&quot;ae_select.c&quot;</span> <span class="hljs-comment">// Windows</span></span>
        <span class="hljs-meta">#<span class="hljs-meta-keyword">endif</span></span>
    <span class="hljs-meta">#<span class="hljs-meta-keyword">endif</span></span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">endif</span></span></code></pre></div>

<p>仔细看上面的代码逻辑，先判断了 Solaris/Linux/MacOS 系统，选择对应的多路复用模型，最后剩下的系统都用 select 模型。</p>
<p>所以我理解，select 并不是为 Linux 服务的，而是在 Windows 下使用的。</p>
<p>因为 epoll 性能优于 select 和 poll，所以 Linux 平台下，Redis 直接会选择 epoll。而 Windows 不支持 epoll 和 poll，所以会用 select 模型。</p>
<h2 id="进程模型"><a href="#进程模型" class="headerlink" title="进程模型"></a>进程模型</h2><h3 id="总结1-8"><a href="#总结1-8" class="headerlink" title="总结1"></a>总结1</h3><p>Redis 一直被称为单线程架构，按照我们通常的理解，单个线程只能处理单个客户端的请求，但是在实际使用时，我们会看到 Redis 能同时和成百上千个客户端进行交互，这就是因为 Redis 基于 Reactor 模型，实现了高性能的网络框架，通过事件驱动框架，Redis 可以使用一个循环来不断捕获、分发和处理客户端产生的网络连接、数据读写事件。</p>
<p>为了方便你从代码层面掌握 Redis 事件驱动框架的实现，我总结了一个表格，其中列出了 Redis 事件驱动框架的主要函数和功能、它们所属的 C 文件，以及这些函数本身是在 Redis 代码结构中的哪里被调用。你可以使用这张表格，来巩固今天这节课学习的事件驱动框架。</p>
<p><img src="/images/redis/process-model-01.png" alt="img.png"></p>
<p>最后，我也再强调下，这节课我们主要关注的是，事件驱动框架的基本运行流程，并以客户端连接事件为例，将框架主循环、事件捕获分发和事件注册的关键步骤串起来，给你做了介绍。Redis 事件驱动框架监听处理的事件，还包括客户端请求、服务器端写数据以及周期性操作等，这也是我下一节课要和你一起学习的主要内容。</p>
<h3 id="总结2-8"><a href="#总结2-8" class="headerlink" title="总结2"></a>总结2</h3><ol>
<li><p>为了高效处理网络 IO 的「连接事件」、「读事件」、「写事件」，演化出了 Reactor 模型</p>
</li>
<li><p>Reactor 模型主要有 reactor、acceptor、handler 三类角色：</p>
</li>
</ol>
<ul>
<li>reactor：分配事件</li>
<li>acceptor：接收连接请求</li>
<li>handler：处理业务逻辑</li>
</ul>
<ol start="3">
<li>Reactor 模型又分为 3 类：</li>
</ol>
<ul>
<li>单 Reactor 单线程：accept -&gt; read -&gt; 处理业务逻辑 -&gt; write 都在一个线程</li>
<li>单 Reactor 多线程：accept/read/write 在一个线程，处理业务逻辑在另一个线程</li>
<li>多 Reactor 多线程 / 进程：accept 在一个线程/进程，read/处理业务逻辑/write 在另一个线程/进程</li>
</ul>
<ol start="4">
<li>Redis 6.0 以下版本，属于单 Reactor 单线程模型，监听请求、读取数据、处理请求、写回数据都在一个线程中执行，这样会有 3 个问题：</li>
</ol>
<ul>
<li>单线程无法利用多核</li>
<li>处理请求发生耗时，会阻塞整个线程，影响整体性能</li>
<li>并发请求过高，读取/写回数据存在瓶颈</li>
</ul>
<ol start="5">
<li>针对问题 3，Redis 6.0 进行了优化，引入了 IO 多线程，把读写请求数据的逻辑，用多线程处理，提升并发性能，但处理请求的逻辑依旧是单线程处理</li>
</ol>
<p>课后题：除了 Redis，你还了解什么软件系统使用了 Reactor 模型吗？</p>
<p>Netty、Memcached 采用多 Reactor 多线程模型。</p>
<p>Nginx 采用多 Reactor 多进程模型，不过与标准的多 Reactor 多进程模型有些许差异。Nginx 的主进程只用来初始化 socket，不会 accept 连接，而是由子进程 accept 连接，之后这个连接的所有处理都在子进程中完成。</p>
<h2 id="事件"><a href="#事件" class="headerlink" title="事件"></a>事件</h2><h3 id="总结1-9"><a href="#总结1-9" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我给你介绍了 Redis 事件驱动框架中的两类事件：IO 事件和时间事件。</p>
<p>对于 IO 事件来说，它可以进一步分成可读、可写和屏障事件。因为可读、可写事件在 Redis 和客户端通信处理请求过程中使用广泛，所以今天我们重点学习了这两种 IO 事件。当 Redis server 创建 Socket 后，就会注册可读事件，并使用 acceptTCPHandler 回调函数处理客户端的连接请求。</p>
<p>当 server 和客户端完成连接建立后，server 会在已连接套接字上监听可读事件，并使用 readQueryFromClient 函数处理客户端读写请求。这里，你需要再注意下，无论客户端发送的请求是读或写操作，对于 server 来说，都是要读取客户端的请求并解析处理。所以，server 在客户端的已连接套接字上注册的是可读事件。</p>
<p>而当实例需要向客户端写回数据时，实例会在事件驱动框架中注册可写事件，并使用 sendReplyToClient 作为回调函数，将缓冲区中数据写回客户端。我总结了一张表格，以便你再回顾下 IO 事件和相应套接字、回调函数的对应关系。</p>
<p><img src="/images/redis/event-model-01.png" alt="img.png"></p>
<p>然后，对于时间事件来说，它主要是用于在事件驱动框架中注册一些周期性执行的任务，以便 Redis server 进行后台处理。时间事件的回调函数是 serverCron 函数，你可以做进一步阅读了解其中的具体任务。</p>
<p>好了，从第 9 讲开始，我用了 3 节课，向你介绍 Redis 事件驱动框架的运行机制，本质上来说，事件驱动框架是基于操作系统提供的 IO 多路复用机制进行了封装，并加上了时间事件的处理。这是一个非常经典的事件框架实现，我希望你可以学习并掌握好它，然后用在你自己的系统开发中。</p>
<h3 id="总结2-9"><a href="#总结2-9" class="headerlink" title="总结2"></a>总结2</h3><ol>
<li>Redis 事件循环主要处理两类事件：文件事件、时间事件</li>
</ol>
<ul>
<li>文件事件包括：client 发起新连接、client 向 server 写数据、server 向 client 响应数据</li>
<li>时间事件：Redis 的各种定时任务（主线程中执行）</li>
</ul>
<ol start="2">
<li>Redis 在启动时，会创建 aeEventLoop，初始化 epoll 对象，监听端口，之后会注册文件事件、时间事件：</li>
</ol>
<ul>
<li>文件事件：把 listen socket fd 注册到 epoll 中，回调函数是 acceptTcpHandler（新连接事件）</li>
<li>时间事件：把 serverCron 函数注册到 aeEventLoop 中，并指定执行频率</li>
</ul>
<ol start="3">
<li>Redis Server 启动后，会启动一个死循环，持续处理事件（ae.c 的 aeProcessEvents 函数）</li>
<li>有文件事件（网络 IO)，则优先处理。例如，client 到 server 的新连接，会调用 acceptTcpHandler 函数，之后会注册读事件 readQueryFromClient 函数，client 发给 server 的数据，都会在这个函数处理，这个函数会解析 client 的数据，找到对应的 cmd 函数执行</li>
<li>cmd 逻辑执行完成后，server 需要写回数据给 client，会先把响应数据写到对应 client 的 内存 buffer 中，在下一次处理 IO 事件之前，Redis 会把每个 client 的 buffer 数据写到 client 的 socket 中，给 client 响应</li>
<li>如果响应给 client 的数据过多，则会分多次发送，待发送的数据会暂存到 buffer，然后会向 epoll 注册回调函数 sendReplyToClient，待 socket 可写时，继续调用回调函数向 client 写回剩余数据</li>
<li>在这个死循环中处理每次事件时，都会先检查一下，时间事件是否需要执行，因为之前已经注册好了时间事件的回调函数 + 执行频率，所以在执行 aeApiPoll 时，timeout 就是定时任务的周期，这样即使没有 IO 事件，epoll_wait 也可以正常返回，此时就可以执行一次定时任务 serverCron 函数，这样就可以在一个线程中就完成 IO 事件 + 定时任务的处理</li>
</ol>
<p>课后题：Redis 在调用 aeApiCreate、aeApiAddEvent 这些函数时，是根据什么条件来决定，具体调用哪个文件中的 IO 多路复用函数的？</p>
<p>在 ae.c 中，根据不同平台，首先定义好了要导入的封装好的 IO 多路复用函数，每个平台对应的文件中都定义了 aeApiCreate、aeApiAddEvent 这类函数，在执行时就会执行对应平台的函数逻辑。</p>
<div class="code-wrapper"><pre><code class="hljs c"><span class="hljs-comment">// ae.c</span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">ifdef</span> HAVE_EVPORT</span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&quot;ae_evport.c&quot;</span> <span class="hljs-comment">// Solaris</span></span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">else</span></span>
    <span class="hljs-meta">#<span class="hljs-meta-keyword">ifdef</span> HAVE_EPOLL</span>
    <span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&quot;ae_epoll.c&quot;</span> <span class="hljs-comment">// Linux</span></span>
    <span class="hljs-meta">#<span class="hljs-meta-keyword">else</span></span>
        <span class="hljs-meta">#<span class="hljs-meta-keyword">ifdef</span> HAVE_KQUEUE</span>
        <span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&quot;ae_kqueue.c&quot;</span> <span class="hljs-comment">// MacOS</span></span>
        <span class="hljs-meta">#<span class="hljs-meta-keyword">else</span></span>
        <span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&quot;ae_select.c&quot;</span> <span class="hljs-comment">// Windows</span></span>
        <span class="hljs-meta">#<span class="hljs-meta-keyword">endif</span></span>
    <span class="hljs-meta">#<span class="hljs-meta-keyword">endif</span></span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">endif</span></span></code></pre></div>


<h2 id="多进程"><a href="#多进程" class="headerlink" title="多进程"></a>多进程</h2><h3 id="总结1-10"><a href="#总结1-10" class="headerlink" title="总结1"></a>总结1</h3><p>今天这节课，我给你介绍了 Redis 的执行模型，并且也从源码的角度出发，通过分析代码，带你了解了 Redis 进程创建、以子进程方式创建的守护进程、以及后台线程和它们负责的工作任务。同时，这也解答了你在面试中可能经常会被问到的问题：Redis 是单线程程序吗？</p>
<p>事实上，Redis server 启动后，它的主要工作包括接收客户端请求、解析请求和进行数据读写等操作，是由单线程来执行的，这也是我们常说 Redis 是单线程程序的原因。</p>
<p>但是，学完这节课你应该也知道，Redis 还启动了 3 个线程来执行文件关闭、AOF 同步写和惰性删除等操作，从这个角度来说，Redis 又不能算单线程程序，它还是有多线程的。而且，在下节课，我会给你介绍 Redis 6.0 中多 IO 线程的实现，从多 IO 线程角度看，Redis 也无法称为是单线程程序了。</p>
<p>另外学完了这节课之后，你还需要重点注意下，fork 函数使用和生产者 - 消费者模型这两个关键知识点。</p>
<p>首先是 fork 函数的使用。fork 函数可以在一个进程运行时，再创建一个子进程。当 Redis 被配置为以守护进程方式运行时，Redis 的 main 函数就是调用 fork 函数，创建子进程，让子进程以守护进程形式执行，并让一开始启动执行的父进程退出。因为，子进程会从父进程那继承代码，所以 main 函数中的执行逻辑就交给了子进程继续执行。</p>
<p>其次是生产者 - 消费者模型。Redis 在 bio.c 和 bio.h 文件中创建了后台线程，并实现了后台任务的执行。你要重点关注一下这里使用的生产者 - 消费者执行模型，这也是 bio.c 实现后台任务执行的核心设计思想。而且，当你需要实现异步的任务执行时，生产者 - 消费者模型就是一个很好的解决方案，你可以从 Redis 源码中掌握这个方案的实现思路。</p>
<h3 id="总结2-10"><a href="#总结2-10" class="headerlink" title="总结2"></a>总结2</h3><ol>
<li>很多人认为 Redis 是单线程，这个描述是不准确的。准确来说 Redis 只有在处理「客户端请求」时，是单线程的。但整个 Redis Server 并不是单线程的，还有后台线程在辅助处理一些工作</li>
<li>Redis 选择单线程处理请求，是因为 Redis 操作的是「内存」，加上设计了「高效」的数据结构，所以操作速度极快，利用 IO 多路复用机制，单线程依旧可以有非常高的性能</li>
<li>但如果一个请求发生耗时，单线程的缺点就暴露出来了，后面的请求都要「排队」等待，所以 Redis 在启动时会启动一些「后台线程」来辅助工作，目的是把耗时的操作，放到后台处理，避免主线程操作耗时影响整体性能</li>
<li>例如关闭 fd、AOF 刷盘、释放 key 的内存，这些耗时操作，都可以放到后台线程中处理，对主逻辑没有任何影响</li>
<li>后台线程处理这些任务，就相当于一个消费者，生产者（主线程）把耗时任务丢到队列中（链表），消费者不停轮询这个队列，拿出任务就去执行对应的方法即可：</li>
</ol>
<ul>
<li>BIO_CLOSE_FILE：close(fd)</li>
<li>BIO_AOF_FSYNC：fsync(fd)</li>
<li>BIO_LAZY_FREE：free(obj) / free(dict) / free(skiplist)</li>
</ul>
<p>课后题：Redis 后台任务使用 bio_job 结构体来描述，该结构体用了三个指针变量来表示任务参数，如果我们创建的任务，所需要的参数大于 3 个，你有什么应对方法来传参么？</p>
<p>最直接的方法就是，把参数换成数组类型，这样就可以传递任意数量参数了。因为这里 Redis 的后台任务都比较简单，最多 3 个参数就足够满足需求，所以 job 直接写死了 3 个参数变量，这样做的好处是维护起来简单直接。</p>
<h2 id="多IO线程"><a href="#多IO线程" class="headerlink" title="多IO线程"></a>多IO线程</h2><h3 id="总结1-11"><a href="#总结1-11" class="headerlink" title="总结1"></a>总结1</h3><p>今天这节课，我给你介绍了 Redis 6.0 中新设计实现的多 IO 线程机制。这个机制的设计主要是为了使用多个 IO 线程，来并发处理客户端读取数据、解析命令和写回数据。使用了多线程后，Redis 就可以充分利用服务器的多核特性，从而提高 IO 效率。</p>
<p>总结来说，Redis 6.0 先是在初始化过程中，根据用户设置的 IO 线程数量，创建对应数量的 IO 线程。</p>
<p>当 Redis server 初始化完成后正常运行时，它会在 readQueryFromClient 函数中通过调用 postponeClientRead 函数来决定是否推迟客户端读操作。同时，Redis server 会在 addReply 函数中通过调用 prepareClientToWrite 函数，来决定是否推迟客户端写操作。而待读写的客户端会被分别加入到 clients_pending_read 和 clients_pending_write 两个列表中。</p>
<p>这样，每当 Redis server 要进入事件循环流程前，都会在 beforeSleep 函数中分别调用 handleClientsWithPendingReadsUsingThreads 函数和 handleClientsWithPendingWritesUsingThreads 函数，将待读写客户端以轮询方式分配给 IO 线程，加入到 IO 线程的待处理客户端列表 io_threads_list 中。</p>
<p>而 IO 线程一旦运行后，本身会一直检测 io_threads_list 中的客户端，如果有待读写客户端，IO 线程就会调用 readQueryFromClient 或 writeToClient 函数来进行处理。</p>
<p>最后，我也想再提醒你一下，多 IO 线程本身并不会执行命令，它们只是利用多核并行地读取数据和解析命令，或是将 server 数据写回（下节课我还会结合分布式锁的原子性保证，来给你介绍这一部分的源码实现。）。所以，Redis 执行命令的线程还是主 IO 线程。这一点对于你理解多 IO 线程机制很重要，可以避免你误解 Redis 有多线程同时执行命令。</p>
<p>这样一来，我们原来针对 Redis 单个主 IO 线程做的优化仍然有效，比如避免 bigkey、避免阻塞操作等。</p>
<h3 id="总结2-11"><a href="#总结2-11" class="headerlink" title="总结2"></a>总结2</h3><ol>
<li>Redis 6.0 之前，处理客户端请求是单线程，这种模型的缺点是，只能用到「单核」CPU。如果并发量很高，那么在读写客户端数据时，容易引发性能瓶颈，所以 Redis 6.0 引入了多 IO 线程解决这个问题</li>
<li>配置文件开启 io-threads N 后，Redis Server 启动时，会启动 N - 1 个 IO 线程（主线程也算一个 IO 线程），这些 IO 线程执行的逻辑是 networking.c 的 IOThreadMain 函数。但默认只开启多线程「写」client socket，如果要开启多线程「读」，还需配置 io-threads-do-reads = yes</li>
<li>Redis 在读取客户端请求时，判断如果开启了 IO 多线程，则把这个 client 放到 clients_pending_read 链表中（postponeClientRead 函数），之后主线程在处理每次事件循环之前，把链表数据轮询放到 IO 线程的链表（io_threads_list）中</li>
<li>同样地，在写回响应时，是把 client 放到 clients_pending_write 中（prepareClientToWrite 函数），执行事件循环之前把数据轮询放到 IO 线程的链表（io_threads_list）中</li>
<li>主线程把 client 分发到 IO 线程时，自己也会读写客户端 socket（主线程也要分担一部分读写操作），之后「等待」所有 IO 线程完成读写，再由主线程「串行」执行后续逻辑</li>
<li>每个 IO 线程，不停地从 io_threads_list 链表中取出 client，并根据指定类型读、写 client socket</li>
<li>IO 线程在处理读、写 client 时有些许差异，如果 write_client_pedding &lt; io_threads * 2，则直接由「主线程」负责写，不再交给 IO 线程处理，从而节省 CPU 消耗</li>
<li>Redis 官方建议，服务器最少 4 核 CPU 才建议开启 IO 多线程，4 核 CPU 建议开 2-3 个 IO 线程，8 核 CPU 开 6 个 IO 线程，超过 8 个线程性能提升不大</li>
<li>Redis 官方表示，开启多 IO 线程后，性能可提升 1 倍。当然，如果 Redis 性能足够用，没必要开 IO 线程</li>
</ol>
<p>课后题：为什么 startThreadedIO / stopThreadedIO 要执行加解锁？</p>
<p>既然涉及到加锁操作，必然是为了「互斥」从而控制某些逻辑。可以在代码中检索这个锁变量，看存在哪些逻辑对 io_threads_mutex 操作了加解锁。</p>
<p>跟踪代码可以看到，在 networking.c 的 IOThreadMain 函数，也对这个变量进行了加解锁操作，那就说明 startThreadedIO / stopThreadedIO 函数，可以控制 IOThreadMain 里逻辑的执行，IOThreadMain 代码如下。</p>
<div class="code-wrapper"><pre><code class="hljs c"><span class="hljs-function"><span class="hljs-keyword">void</span> *<span class="hljs-title">IOThreadMain</span><span class="hljs-params">(<span class="hljs-keyword">void</span> *myid)</span> </span>&#123;
    ...
    <span class="hljs-keyword">while</span>(<span class="hljs-number">1</span>) &#123;
    ...
    <span class="hljs-comment">/* Give the main thread a chance to stop this thread. */</span>
    <span class="hljs-keyword">if</span> (io_threads_pending[id] == <span class="hljs-number">0</span>) &#123;
    pthread_mutex_lock(&amp;io_threads_mutex[id]);
    pthread_mutex_unlock(&amp;io_threads_mutex[id]);
    <span class="hljs-keyword">continue</span>;
    &#125;
    <span class="hljs-comment">// 读写 client socket</span>
    <span class="hljs-comment">// ...</span>
&#125;</code></pre></div>

<p>这个函数正是 IO 多线程的主逻辑。</p>
<p>从注释可以看到，这是为了给主线程停止 IO 线程的的机会。也就是说，这里的目的是为了让主线程可以控制 IO 线程的开启 / 暂停。</p>
<p>因为每次 IO 线程在执行时必须先拿到锁，才能执行后面的逻辑，如果主线程执行了 stopThreadedIO，就会先拿到锁，那么 IOThreadMain 函数在执行时就会因为拿不到锁阻塞「等待」，这就达到了 stop IO 线程的目的。</p>
<p>同样地，调用 startThreadedIO 函数后，会释放锁，IO 线程就可以拿到锁，继续「恢复」执行。</p>
<h2 id="分布式的原子性"><a href="#分布式的原子性" class="headerlink" title="分布式的原子性"></a>分布式的原子性</h2><h3 id="总结1-12"><a href="#总结1-12" class="headerlink" title="总结1"></a>总结1</h3><p>今天这节课我主要结合分布式锁的原子性保证需求，带你学习了 Redis 处理一条命令的整个过程。其中，你需要重点关注分布式锁实现的方法。</p>
<p>我们知道，加锁和解锁操作分别可以使用 SET 命令和 Lua 脚本与 EVAL 命令来完成。那么，分布式锁的原子性保证，就主要依赖 SET 和 EVAL 命令在 Redis server 中执行时的原子性保证了。</p>
<p>紧接着，我还带你具体剖析了下 Redis 中命令处理的整个过程。我把这个过程分成了四个阶段，分别是命令读取、命令解析、命令执行和结果返回。所以，你还需要了解这四个阶段中所执行函数的主要流程。</p>
<p>这四个阶段在 Redis 6.0 版本前都是由主 IO 线程来执行完成的。虽然 Redis 使用了 IO 多路复用机制，但是该机制只是一次性获取多个就绪的 socket 描述符，对应了多个发送命令请求的客户端。而 Redis 在主 IO 线程中，还是逐一来处理每个客户端上的命令的，所以命令执行的原子性依然可以得到保证。</p>
<p>而当使用了 Redis 6.0 版本后，命令处理过程中的读取、解析和结果写回，就由多个 IO 线程来处理了。不过你也不用担心，多个 IO 线程只是完成解析第一个读到的命令，命令的实际执行还是由主 IO 线程处理。当多个 IO 线程在并发写回结果时，命令就已经执行完了，不存在多 IO 线程冲突的问题。所以，使用了多 IO 线程后，命令执行的原子性仍然可以得到保证。</p>
<p>好，最后，我也想再说下我对多 IO 线程的看法。从今天课程介绍的内容中，你可以看到，多 IO 线程实际并不会加快命令的执行，而是只会将读取解析命令并行化执行，以及写回结果并行化执行，并且读取解析命令还是针对收到的第一条命令。实际上，这一设计考虑还是由于网络 IO 需要加速处理。那么，如果命令执行本身成为 Redis 运行时瓶颈了，你其实可以考虑使用 Redis 切片集群来提升处理效率。</p>
<h3 id="总结2-12"><a href="#总结2-12" class="headerlink" title="总结2"></a>总结2</h3><ol>
<li>无论是 IO 多路复用，还是 Redis 6.0 的多 IO 线程，Redis 执行具体命令的主逻辑依旧是「单线程」的</li>
<li>执行命令是单线程，本质上就保证了每个命令必定是「串行」执行的，前面请求处理完成，后面请求才能开始处理</li>
<li>所以 Redis 在实现分布式锁时，内部不需要考虑加锁问题，直接在主线程中判断 key 是否存在即可，实现起来非常简单</li>
</ol>
<p>课后题：如果将命令处理过程中的命令执行也交给多 IO 线程执行，除了对原子性会有影响，还会有什么好处和坏处？</p>
<p>好处：</p>
<ul>
<li>每个请求分配给不同的线程处理，一个请求处理慢，并不影响其它请求</li>
<li>请求操作的 key 越分散，性能会变高（并行处理比串行处理性能高）</li>
<li>可充分利用多核 CPU 资源</li>
</ul>
<p>坏处：</p>
<ul>
<li>操作同一个 key 需加锁，加锁会影响性能，如果是热点 key，性能下降明显</li>
<li>多线程上下文切换存在性能损耗</li>
<li>多线程开发和调试不友好</li>
</ul>
<h2 id="LRU"><a href="#LRU" class="headerlink" title="LRU"></a>LRU</h2><h3 id="总结1-13"><a href="#总结1-13" class="headerlink" title="总结1"></a>总结1</h3><p>好了，今天这节课就到这里，我们来总结下。</p>
<p>今天这节课我给你介绍了 Redis 中，是如何实现 LRU 算法来进行缓存数据替换的。其中，我们根据 LRU 算法的基本原理，可以发现如果严格按照原理来实现 LRU 算法，那么开发的系统就需要用额外的内存空间来保存 LRU 链表，而且系统运行时也会受到 LRU 链表操作的开销影响。</p>
<p>而对于 Redis 来说，内存资源和性能都很重要，所以 Redis 实现了近似 LRU 算法。而为了实现近似 LRU 算法，Redis 首先是设置了全局 LRU 时钟，并在键值对创建时获取全局 LRU 时钟值作为访问时间戳，以及在每次访问时获取全局 LRU 时钟值，更新访问时间戳。</p>
<p>然后，当 Redis 每处理一个命令时，都会调用 freeMemoryIfNeeded 函数来判断是否需要释放内存。如果已使用内存超出了 maxmemory，那么，近似 LRU 算法就会随机选择一些键值对，组成待淘汰候选集合，并根据它们的访问时间戳，选出最旧的数据，将其淘汰。</p>
<p>实际上，通过学习这节课的内容，你可以体会到一个算法的基本原理和算法的实际执行，在系统开发中会有一定的折中选择，主要就是因为我们需要综合考虑所开发的系统，在资源和性能方面的要求，以避免严格按照算法实现带来的资源和性能开销。因此，这一点就是你在进行计算机系统开发时，要秉承的一个原则。</p>
<h3 id="总结2-13"><a href="#总结2-13" class="headerlink" title="总结2"></a>总结2</h3><ol>
<li>实现一个严格的 LRU 算法，需要额外的内存构建 LRU 链表，同时维护链表也存在性能开销，Redis 对于内存资源和性能要求极高，所以没有采用严格 LRU 算法，而是采用「近似」LRU 算法实现数据淘汰策略</li>
<li>触发数据淘汰的时机，是每次处理「请求」时判断的。也就是说，执行一个命令之前，首先要判断实例内存是否达到 maxmemory，是的话则先执行数据淘汰，再执行具体的命令</li>
<li>淘汰数据时，会「持续」判断 Redis 内存是否下降到了 maxmemory 以下，不满足的话会继续淘汰数据，直到内存下降到 maxmemory 之下才会停止</li>
<li>可见，如果发生大量淘汰的情况，那么处理客户端请求就会发生「延迟」，影响性能</li>
<li>Redis 计算实例内存时，不会把「主从复制」的缓冲区计算在内，也就是说不管一个实例后面挂了多少个从库，主库不会把主从复制所需的「缓冲区」内存，计算到实例内存中，即这部分内存增加，不会对数据淘汰产生影响</li>
<li>但如果 Redis 内存已达到 maxmemory，要谨慎执行 MONITOR 命令，因为 Redis Server 会向执行 MONITOR 的 client 缓冲区填充数据，这会导致缓冲区内存增长，进而引发数据淘汰</li>
</ol>
<p>课后题：为什么键值对的 LRU 时钟值，不是直接通过调用 getLRUClock 函数来获取？</p>
<p>本质上是为了性能。</p>
<p>Redis 这种对性能要求极高的数据库，在系统调用上的优化也做到了极致。</p>
<p>获取机器时钟本质上也是一个「系统调用」，对于 Redis 这种动不动每秒上万的 QPS，如果每次都触发一次系统调用，这么频繁的操作也是一笔不小的开销。</p>
<p>所以，Redis 用一个定时任务（serverCron 函数），以固定频率触发系统调用获取机器时钟，然后把机器时钟挂到 server 的全局变量下，这相当于维护了一个「本地缓存」，当需要获取时钟时，直接从全局变量获取即可，节省了大量的系统调用开销。</p>
<h2 id="LFU"><a href="#LFU" class="headerlink" title="LFU"></a>LFU</h2><h3 id="总结1-14"><a href="#总结1-14" class="headerlink" title="总结1"></a>总结1</h3><p>这节课我主要是给你介绍了 Redis 使用的 LFU 缓存淘汰策略。LFU 算法会根据键值对的访问频率来淘汰数据，而和使用访问次数淘汰数据不同，使用访问频率，不仅需要统计访问次数，而且还要考虑所记录的访问距离当前时间的时长。</p>
<p>所以，正是基于这样的设计考虑，Redis 源码在实现 LFU 算法时，在键值对的 redisObject 结构体中的 lru 变量里，会同时记录访问次数和访问时间戳。当键值对被再次访问时，lru 变量中的访问次数，会先根据上一次访问距离当前的时长，执行衰减操作，然后才会执行增加操作。</p>
<p>不过，键值对的访问次数只能用 lru 变量中有限的 8 bits 来记录，最大值就是 255。这样一来，如果每访问一次键值对，访问次数就加 1 的话，那么访问次数很容易就达到最大值了，这就无法区分不同的访问频率了。</p>
<p>为了区分不同的访问频率，LFU 算法在实现时是采用了按概率增加访问次数的方法，也就是说，已有访问次数越大的键值对，它的访问次数就越难再增加。</p>
<p>另外你也要知道，对于 LFU 算法的执行流程来说，它和 LRU 算法的基本执行流程是相同的，这包括入口函数、待释放内存空间计算、更新待淘汰候选键值对集合，以及选择实际被淘汰数据这几个关键步骤。不同的是，LFU 算法在待淘汰键值对集合中，是按照键值对的访问频率大小来排序和选择淘汰数据的，这也符合 LFU 算法本身的要求。</p>
<p>而且，正因为 LFU 算法会根据访问频率来淘汰数据，以及访问频率会随时间推移而衰减，所以，LFU 算法相比其他算法来说，更容易把低频访问的冷数据尽早淘汰掉，这也是它的适用场景。</p>
<p>最后，从 LFU 算法的实现代码来看，当我们自己实现按访问频率进行操作的软件模块时，我觉得 Redis 采用的这两种设计方法：访问次数按时间衰减和访问次数按概率增加，其实是一个不错的参考范例。你在自己的实现场景中，就可以借鉴使用。</p>
<h3 id="总结2-14"><a href="#总结2-14" class="headerlink" title="总结2"></a>总结2</h3><ol>
<li>LFU 是在 Redis 4.0 新增的淘汰策略，它涉及的巧妙之处在于，其复用了 redisObject 结构的 lru 字段，把这个字段「一分为二」，保存最后访问时间和访问次数</li>
<li>key 的访问次数不能只增不减，它需要根据时间间隔来做衰减，才能达到 LFU 的目的</li>
<li>每次在访问一个 key 时，会「懒惰」更新这个 key 的访问次数：先衰减访问次数，再更新访问次数</li>
<li>衰减访问次数，会根据时间间隔计算，间隔时间越久，衰减越厉害</li>
<li>因为 redisObject lru 字段宽度限制，这个访问次数是有上限的（8 bit 最大值 255），所以递增访问次数时，会根据「当前」访问次数和「概率」的方式做递增，访问次数越大，递增因子越大，递增概率越低</li>
<li>Redis 实现的 LFU 算法也是「近似」LFU，是在性能和内存方面平衡的结果</li>
</ol>
<p>课后题：LFU 算法在初始化键值对的访问次数时，会将访问次数设置为 LFU_INIT_VAL，默认值是 5 次。如果 LFU_INIT_VAL 设置为 1，会发生什么情况？</p>
<p>如果开启了 LFU，那在写入一个新 key 时，需要初始化访问时间、访问次数（createObject 函数），如果访问次数初始值太小，那这些新 key 的访问次数，很有可能在短时间内就被「衰减」为 0，那就会面临马上被淘汰的风险。</p>
<p>新 key 初始访问次数 LFU_INIT_VAL = 5，就是为了避免一个 key 在创建后，不会面临被立即淘汰的情况发生。</p>
<h2 id="Lazy-Free"><a href="#Lazy-Free" class="headerlink" title="Lazy Free"></a>Lazy Free</h2><h3 id="总结1-15"><a href="#总结1-15" class="headerlink" title="总结1"></a>总结1</h3><p>今天这节课，我给你介绍了 Redis 缓存在淘汰数据时，执行的数据删除流程。因为在 Redis 4.0 版本之后提供了惰性删除的功能，所以 Redis 缓存淘汰数据的时候，就会根据是否启用惰性删除，来决定是执行同步删除还是异步的惰性删除。</p>
<p>而你要知道，无论是同步删除还是异步的惰性删除，它们都会先把被淘汰的键值对从哈希表中移除。然后，同步删除就会紧接着调用 dictFreeKey、dictFreeVal 和 zfree 三个函数来分别释放 key、value 和键值对哈希项的内存空间。而异步的惰性删除，则是把空间释放任务交给了后台线程来完成。</p>
<p>注意，虽然惰性删除是由后台线程异步完成的，但是后台线程启动后会监听惰性删除的任务队列，一旦有了惰性删除任务，后台线程就会执行并释放内存空间。所以，从淘汰数据释放内存空间的角度来说，惰性删除并不会影响缓存淘汰时的空间释放要求。</p>
<p>不过在最后，我也想提醒你一下，就是后台线程需要通过同步机制获取任务，这个过程会引入一些额外的时间开销，会导致内存释放不像同步删除那样非常及时。实际上，这也是 Redis 在被淘汰数据是小集合（元素不超过 64 个）时，仍然使用主线程进行内存释放的设计考虑因素。</p>
<h3 id="总结2-15"><a href="#总结2-15" class="headerlink" title="总结2"></a>总结2</h3><ol>
<li>lazy-free 是 4.0 新增的功能，默认是关闭的，需要手动开启</li>
<li>开启 lazy-free 时，有多个「子选项」可以控制，分别对应不同场景下，是否开启异步释放内存：</li>
</ol>
<ul>
<li>lazyfree-lazy-expire：key 在过期删除时尝试异步释放内存</li>
<li>lazyfree-lazy-eviction：内存达到 maxmemory 并设置了淘汰策略时尝试异步释放内存</li>
<li>lazyfree-lazy-server-del：执行 RENAME/MOVE 等命令或需要覆盖一个 key 时，Redis 内部删除旧 key 尝试异步释放内存</li>
<li>replica-lazy-flush：主从全量同步，从库清空数据库时异步释放内存</li>
</ul>
<ol start="3">
<li>即使开启了 lazy-free，但如果执行的是 DEL 命令，则还是会同步释放 key 内存，只有使用 UNLINK 命令才「可能」异步释放内存</li>
<li>Redis 6.0 版本新增了一个新的选项 lazyfree-lazy-user-del，打开后执行 DEL 就与 UNLINK 效果一样了</li>
<li>最关键的一点，开启 lazy-free 后，除 replica-lazy-flush 之外，其它选项都只是「可能」异步释放 key 的内存，并不是说每次释放 key 内存都是丢到后台线程的</li>
<li>开启 lazy-free 后，Redis 在释放一个 key 内存时，首先会评估「代价」，如果代价很小，那么就直接在「主线程」操作了，「没必要」放到后台线程中执行（不同线程传递数据也会有性能消耗）</li>
<li>什么情况才会真正异步释放内存？这和 key 的类型、编码方式、元素数量都有关系（详见 lazyfreeGetFreeEffort 函数）：</li>
</ol>
<ul>
<li>当 Hash/Set 底层采用哈希表存储（非 ziplist/int 编码存储）时，并且元素数量超过 64 个</li>
<li>当 ZSet 底层采用跳表存储（非 ziplist 编码存储）时，并且元素数量超过 64 个</li>
<li>当 List 链表节点数量超过 64 个（注意，不是元素数量，而是链表节点的数量，List 底层实现是一个链表，链表每个节点是一个 ziplist，一个 ziplist 可能有多个元素数据）</li>
</ul>
<p>只有满足以上条件，在释放 key 内存时，才会真正放到「后台线程」中执行，其它情况一律还是在主线程操作。</p>
<p>也就是说 String（不管内存占用多大）、List（少量元素）、Set（int 编码存储）、Hash/ZSet（ziplist 编码存储）这些情况下的 key，在释放内存时，依旧在「主线程」中操作。</p>
<ol start="8">
<li>可见，即使打开了 lazy-free，String 类型的 bigkey，在删除时依旧有「阻塞」主线程的风险。所以，即便 Redis 提供了 lazy-free，还是不建议在 Redis 存储 bigkey</li>
</ol>
<p>9、Redis 在释放内存「评估」代价时，不是看 key 的内存大小，而是关注释放内存时的「工作量」有多大。从上面分析可以看出，如果 key 内存是连续的，释放内存的代价就比较低，则依旧放在「主线程」处理。如果 key 内存不连续（包含大量指针），这个代价就比较高，这才会放在「后台线程」中执行</p>
<p>课后题：freeMemoryIfNeeded 函数在使用后台线程，删除被淘汰数据的过程中，主线程是否仍然可以处理外部请求？</p>
<p>肯定是可以继续处理请求的。</p>
<p>主线程决定淘汰这个 key 之后，会先把这个 key 从「全局哈希表」中剔除，然后评估释放内存的代价，如果符合条件，则丢到「后台线程」中执行「释放内存」操作。</p>
<p>之后就可以继续处理客户端请求，尽管后台线程还未完成释放内存，但因为 key 已被全局哈希表剔除，所以主线程已查询不到这个 key 了，对客户端来说无影响。</p>
<h2 id="RDB"><a href="#RDB" class="headerlink" title="RDB"></a>RDB</h2><h3 id="总结1-16"><a href="#总结1-16" class="headerlink" title="总结1"></a>总结1</h3><p>今天这节课，我给你介绍了 Redis 内存快照文件 RDB 的生成。你要知道，创建 RDB 文件的三个入口函数分别是 rdbSave、rdbSaveBackground、rdbSaveToSlavesSockets，它们在 Redis 源码中被调用的地方，也就是触发 RDB 文件生成的时机。</p>
<p>另外，你也要重点关注 RDB 文件的基本组成，并且也要结合 rdbSaveRio 函数的执行流程，来掌握 RDB 文件头、文件数据部分和文件尾这三个部分的生成。我总结了以下两点，方便你对 RDB 文件结构和内容有个整体把握：</p>
<ul>
<li>RDB 文件使用多种操作码来标识 Redis 不同的属性信息，以及使用类型码来标识不同 value 类型；</li>
<li>RDB 文件内容是自包含的，也就是说，无论是属性信息还是键值对，RDB 文件都会按照类型、长度、实际数据的格式来记录，这样方便程序对 RDB 文件的解析。</li>
</ul>
<p>最后，我也想再说一下，RDB 文件包含了 Redis 数据库某一时刻的所有键值对，以及这些键值对的类型、大小、过期时间等信息。当你了解了 RDB 文件的格式和生成方法后，其实你就可以根据需求，开发解析 RDB 文件的程序或是加载 RDB 文件的程序了。</p>
<p>比如，你可以在 RDB 文件中查找内存空间消耗大的键值对，也就是在优化 Redis 性能时通常需要查找的 bigkey；你也可以分析不同类型键值对的数量、空间占用等分布情况，来了解业务数据的特点；你还可以自行加载 RDB 文件，用于测试或故障排查。</p>
<p>当然，这里我也再给你一个小提示，就是在你实际开发 RDB 文件分析工具之前，可以看下redis-rdb-tools这个工具，它能够帮助你分析 RDB 文件中的内容。而如果它还不能满足你的定制化需求，你就可以用上这节课学习的内容，来开发自己的 RDB 分析工具了。</p>
<h3 id="总结2-16"><a href="#总结2-16" class="headerlink" title="总结2"></a>总结2</h3><ol>
<li>RDB 文件是 Redis 的数据快照，以「二进制」格式存储，相比 AOF 文件更小，写盘和加载时间更短</li>
<li>RDB 在执行 SAVE / BGSAVE 命令、定时 BGSAVE、主从复制时产生</li>
<li>RDB 文件包含文件头、数据部分、文件尾</li>
<li>文件头主要包括 Redis 的魔数、RDB 版本、Redis 版本、RDB 创建时间、键值对占用的内存大小等信息</li>
<li>文件数据部分包括整个 Redis 数据库中存储的所有键值对信息</li>
</ol>
<ul>
<li>数据库信息：db 编号、db 中 key 的数量、过期 key 的数量、键值数据</li>
<li>键值数据：过期标识、时间戳（绝对时间）、键值对类型、key 长度、key、value 长度、value</li>
</ul>
<ol start="6">
<li>文件尾保存了 RDB 的结束标记、文件校验值</li>
<li>RDB 存储的数据，为了压缩体积，还做了很多优化:</li>
</ol>
<ul>
<li>变长编码存储键值对数据</li>
<li>用操作码标识不同的内容</li>
<li>可整数编码的内容使用整数类型紧凑编码</li>
</ul>
<p>课后题：在 serverCron 函数中，rdbSaveBackground 函数一共会被调用执行几次？这又分别对应了什么场景？</p>
<p>在 serverCron 函数中 rdbSaveBackground 会被调用 2 次。</p>
<p>一次是满足配置的定时 RDB 条件后（save <seconds> &lt;changes），触发子进程生成 RDB。</p>
<p>另一次是客户端执行了 BGSAVE 命令，Redis 会先设置 server.rdb_bgsave_scheduled = 1，之后 serverCron 函数判断这个变量为 1，也会触发子进程生成 RDB。</p>
<h2 id="AOF-上"><a href="#AOF-上" class="headerlink" title="AOF 上"></a>AOF 上</h2><h3 id="总结1-17"><a href="#总结1-17" class="headerlink" title="总结1"></a>总结1</h3><p>今天这节课我给你介绍了 Redis AOF 重写机制的实现，你需要重点关注以下两个要点：</p>
<ul>
<li>AOF 重写的触发时机。这既包括了我们主动执行 bgrewriteaof 命令，也包括了 Redis server 根据 AOF 文件大小而自动触发的重写。此外，在主从复制的过程中，从节点也会启动 AOF 重写，形成一份完整的 AOF 日志，以便后续进行恢复。当然你也要知道，当要触发 AOF 重写时，Redis server 是不能运行 RDB 子进程和 AOF 重写子进程的。</li>
<li>AOF 重写的基本执行过程。AOF 重写和 RDB 创建的过程类似，它也是创建了一个子进程来完成重写工作。这是因为 AOF 重写操作，实际上需要遍历 Redis server 上的所有数据库，把每个键值对以插入操作的形式写入日志文件，而日志文件又要进行写盘操作。所以，Redis 源码使用子进程来实现 AOF 重写，这就避免了阻塞主线程，也减少了对 Redis 整体性能的影响。</li>
</ul>
<p>不过，你需要注意的是，虽然 AOF 重写和 RDB 创建都用了子进程，但是它们也有不同的地方，AOF 重写过程中父进程收到的写操作，也需要尽量写入 AOF 重写日志，在这里，Redis 源码是使用了管道机制来实现父进程和 AOF 重写子进程间的通信的。在下一讲中，我就会重点给你介绍，Redis 是如何使用管道完成父子进程的通信，以及它们通过管道又传递了哪些数据或信息。</p>
<h3 id="总结2-17"><a href="#总结2-17" class="headerlink" title="总结2"></a>总结2</h3><ol>
<li>AOF 记录的是每个命令的「操作历史」，随着时间增长，AOF 文件会越来越大，所以需要 AOF 重写来「瘦身」，减小文件体积</li>
<li>AOF 重写时，会扫描整个实例中的数据，把数据以「命令 + 键值对」的格式，写到 AOF 文件中</li>
<li>触发 AOF 重写的时机有 4 个：</li>
</ol>
<ul>
<li>执行 bgrewriteaof 命令</li>
<li>手动打开 AOF 开关（config set appendonly yes）</li>
<li>从库加载完主库 RDB 后（AOF 被启动的前提下）</li>
<li>定时触发：AOF 文件大小比例超出阈值、AOF 文件大小绝对值超出阈值（AOF 被启动的前提下）</li>
</ul>
<p>这 4 个时机，都不能有 RDB 子进程，否则 AOF 重写会延迟执行。</p>
<ol start="4">
<li>AOF 重写期间会禁用 rehash，不让父进程调整哈希表大小，目的是父进程「写时复制」拷贝大量内存页面</li>
</ol>
<p>课后题：为什么 Redis 源码中在有 RDB 子进程运行时，不会启动 AOF 重写子进程？</p>
<p>无论是生成 RDB 还是 AOF 重写，都需要创建子进程，然后把实例中的所有数据写到磁盘上，这个过程中涉及到两块：</p>
<ul>
<li>CPU：写盘之前需要先迭代实例中的所有数据，在这期间会耗费比较多的 CPU 资源，两者同时进行，CPU 资源消耗大</li>
<li>磁盘：同样地，RDB 和 AOF 重写，都是把内存数据落盘，在这期间 Redis 会持续写磁盘，如果同时进行，磁盘 IO 压力也会较大</li>
</ul>
<p>整体来说都是为了资源考虑，所以不会让它们同时进行。</p>
<h2 id="AOF-下"><a href="#AOF-下" class="headerlink" title="AOF 下"></a>AOF 下</h2><h3 id="总结1-18"><a href="#总结1-18" class="headerlink" title="总结1"></a>总结1</h3><p>今天这节课，我主要给你介绍了在 AOF 重写过程中，主进程和重写子进程间的管道通信。这里，你需要重点关注管道机制的使用，以及主进程和重写子进程使用管道通信的过程。</p>
<p>在这个过程中，AOF 重写子进程和主进程是使用了一个操作命令传输管道和两个 ACK 信息发送管道。操作命令传输管道是用于主进程写入收到的新操作命令，以及用于重写子进程读取操作命令，而 ACK 信息发送管道是在重写结束时，重写子进程和主进程用来相互确认重写过程的结束。最后，重写子进程会进一步将收到的操作命令记录到重写日志文件中。</p>
<p>这样一来，AOF 重写过程中主进程收到的新写操作，就不会被遗漏了。因为一方面，这些新写操作会被记录在正常的 AOF 日志中，另一方面，主进程会将新写操作缓存在 aof_rewrite_buf_blocks 数据块列表中，并通过管道发送给重写子进程。这样，就能尽可能地保证重写日志具有最新、最完整的写操作了。</p>
<p>最后，我也再提醒你一下，今天这节课我们学习的管道其实属于匿名管道，是用在父子进程间进行通信的。如果你在实际开发中，要在非父子进程的两个进程间进行通信，那么你就需要用到命名管道了。而命名管道会以一个文件的形式保存在文件系统中，并会有相应的路径和文件名。这样，非父子进程的两个进程通过命名管道的路径和文件名，就可以打开管道进行通信了。</p>
<h3 id="总结2-18"><a href="#总结2-18" class="headerlink" title="总结2"></a>总结2</h3><ol>
<li>AOF 重写是在子进程中执行，但在此期间父进程还会接收写操作，为了保证新的 AOF 文件数据更完整，所以父进程需要把在这期间的写操作缓存下来，然后发给子进程，让子进程追加到 AOF 文件中</li>
<li>因为需要父子进程传输数据，所以需要用到操作系统提供的进程间通信机制，这里 Redis 用的是「管道」，管道只能是一个进程写，另一个进程读，特点是单向传输</li>
<li>AOF 重写时，父子进程用了 3 个管道，分别传输不同类别的数据：</li>
</ol>
<ul>
<li>父进程传输数据给子进程的管道：发送 AOF 重写期间新的写操作</li>
<li>子进程完成重写后通知父进程的管道：让父进程停止发送新的写操作</li>
<li>父进程确认收到子进程通知的管道：父进程通知子进程已收到通知</li>
</ul>
<ol start="4">
<li>AOF 重写的完整流程是：父进程 fork 出子进程，子进程迭代实例所有数据，写到一个临时 AOF 文件，在写文件期间，父进程收到新的写操作，会先缓存到 buf 中，之后父进程把 buf 中的数据，通过管道发给子进程，子进程写完 AOF 文件后，会从管道中读取这些命令，再追加到 AOF 文件中，最后 rename 这个临时 AOF 文件为新文件，替换旧的 AOF 文件，重写结束</li>
</ol>
<p>课后题：Redis 中其它使用管道的地方还有哪些？</p>
<p>在源码中搜索 pipe 函数，能看到 server.child_info_pipe 和 server.module_blocked_pipe 也使用了管道。</p>
<p>其中 child_info_pipe 管道如下：</p>
<div class="code-wrapper"><pre><code class="hljs c"><span class="hljs-comment">/* Pipe and data structures for child -&gt; parent info sharing. */</span>
<span class="hljs-keyword">int</span> child_info_pipe[<span class="hljs-number">2</span>]; <span class="hljs-comment">/* Pipe used to write the child_info_data. */</span>
<span class="hljs-class"><span class="hljs-keyword">struct</span> &#123;</span>
    <span class="hljs-keyword">int</span> process_type; <span class="hljs-comment">/* AOF or RDB child? */</span>
    <span class="hljs-keyword">size_t</span> cow_size; <span class="hljs-comment">/* Copy on write size. */</span>
    <span class="hljs-keyword">unsigned</span> <span class="hljs-keyword">long</span> <span class="hljs-keyword">long</span> magic; <span class="hljs-comment">/* Magic value to make sure data is valid. */</span>
&#125; child_info_data;</code></pre></div>


<p>从注释能看出，子进程在生成 RDB 或 AOF 重写完成后，子进程通知父进程在这期间，父进程「写时复制」了多少内存，父进程把这个数据记录到 server 的 stat_rdb_cow_bytes / stat_aof_cow_bytes 下（childinfo.c 的 receiveChildInfo 函数），以便客户端可以查询到最后一次 RDB 和 AOF 重写期间写时复制时，新申请的内存大小。</p>
<p>而 module_blocked_pipe 管道主要服务于 Redis module。</p>
<div class="code-wrapper"><pre><code class="hljs c"><span class="hljs-comment">/* Pipe used to awake the event loop if a client blocked on a module command needs to be processed. */</span>
<span class="hljs-keyword">int</span> module_blocked_pipe[<span class="hljs-number">2</span>];</code></pre></div>

<p>看注释是指，如果被 module 命令阻塞的客户端需要处理，则会唤醒事件循环开始处理。</p>
<h2 id="主从复制"><a href="#主从复制" class="headerlink" title="主从复制"></a>主从复制</h2><h3 id="总结1-19"><a href="#总结1-19" class="headerlink" title="总结1"></a>总结1</h3><p>主从复制是 Redis、MySQL 等数据库或存储系统，用来实现高可用性的方法。要实现主从复制，则需要应对整个过程中 Redis 在不同状态下的各种处理逻辑，因此，如何正确实现主从复制，并且不遗漏可能的状态，是我们在实际开发中需要面对的问题。</p>
<p>这节课我们学习了 Redis 主从复制的设计思想与实现方法。Redis 采用了状态机驱动的方法，为从库实例设置状态变量。在整个复制过程中，代码逻辑会根据从库状态机的变迁，处理不同状态下的情况。</p>
<p>为了便于你掌握主从复制的实现，我将整个过程分解成四个阶段：初始化、建立连接、主从握手、复制类型判断与执行。在每个阶段中，从库的状态会不断变化，完成和主库建立网络连接、交换配置信息、发送同步命令，并根据主库对同步请求的返回结果，执行全量同步或增量同步。</p>
<p>状态机驱动的设计方法是一种通用的设计方法，在涉及网络通信的场景中应用广泛。Redis 对主从复制的实现为我们提供了良好的参考示例，当你需要自行设计和实现网络功能时，就可以把状态机驱动的方法使用起来。</p>
<h3 id="总结2-19"><a href="#总结2-19" class="headerlink" title="总结2"></a>总结2</h3><ol>
<li>Redis 主从复制分为 4 个阶段：</li>
</ol>
<ul>
<li>初始化</li>
<li>建立连接</li>
<li>主从握手</li>
<li>数据传输（全量/增量复制）</li>
</ul>
<ol start="2">
<li>主从复制流程由于是是「从库」发起的，所以重点要看从库的执行流程</li>
<li>从库发起复制的方式有 3 个：</li>
</ol>
<ul>
<li>执行 slaveof / replicaof 命令</li>
<li>配置文件配置了主库的 ip port</li>
<li>启动实例时指定了主库的 ip port</li>
</ul>
<ol start="4">
<li>建议从 slaveof / replicaof 命令跟源码进去，来看整个主从复制的流程（入口在 replication.c 的 replicaofCommand 函数）</li>
<li>从库执行这个命令后，会先在 server 结构体上，记录主库的 ip port，然后把 server.repl_state 从 REPL_STATE_NONE 改为 REPL_STATE_CONNECT，「复制状态机」启动</li>
<li>随后从库会在定时任务（server.c 的 serverCron 函数）中会检测 server.repl_state 的状态，然后向主库发起复制请求（replication.c 的 replicationCron 函数），进入复制流程（replication.c 的 connectWithMaster 函数）</li>
<li>从库会与主库建立连接（REPL_STATE_CONNECTING），注册读事件（syncWithMaster 函数），之后主从进入握手认证阶段，从库会告知主库自己的 ip port 等信息，在这期间会流转多个状态（server.h 中定义的复制状态）：</li>
</ol>
<div class="code-wrapper"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> REPL_STATE_RECEIVE_PONG 3 <span class="hljs-comment">/* Wait for PING reply */</span></span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> REPL_STATE_SEND_AUTH 4 <span class="hljs-comment">/* Send AUTH to master */</span></span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> REPL_STATE_RECEIVE_AUTH 5 <span class="hljs-comment">/* Wait for AUTH reply */</span></span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> REPL_STATE_SEND_PORT 6 <span class="hljs-comment">/* Send REPLCONF listening-port */</span></span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> REPL_STATE_RECEIVE_PORT 7 <span class="hljs-comment">/* Wait for REPLCONF reply */</span></span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> REPL_STATE_SEND_IP 8 <span class="hljs-comment">/* Send REPLCONF ip-address */</span></span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> REPL_STATE_RECEIVE_IP 9 <span class="hljs-comment">/* Wait for REPLCONF reply */</span></span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> REPL_STATE_SEND_CAPA 10 <span class="hljs-comment">/* Send REPLCONF capa */</span></span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> REPL_STATE_RECEIVE_CAPA 11 <span class="hljs-comment">/* Wait for REPLCONF reply */</span></span></code></pre></div>

<ol start="8">
<li>完成握手后，从库向主库发送 PSYNC 命令和自己的 offset，首先尝试「增量同步」，如果 offset = -1，主库返回 FULLRESYNC 表示「全量同步」数据，否则返回 CONTINUE 增量同步</li>
<li>如果是全量同步，主库会先生成 RDB，从库等待，主库完成 RDB 后发给从库，从库接收 RDB，然后清空实例数据，加载 RDB，之后读取主库发来的「增量」数据</li>
<li>如果是增量同步，从库只需接收主库传来的增量数据即可</li>
</ol>
<p>课后题：当一个实例是主库时，为什么不需要使用状态机来实现主库在主从复制时的流程流转？</p>
<p>因为复制数据的发起方是从库，从库要求复制数据会经历多个阶段（发起连接、握手认证、请求数据），而主库只需要「被动」接收从库的请求，根据需要「响应数据」即可完成整个流程，所以主库不需要状态机流转。</p>
<h2 id="哨兵"><a href="#哨兵" class="headerlink" title="哨兵"></a>哨兵</h2><h3 id="总结1-20"><a href="#总结1-20" class="headerlink" title="总结1"></a>总结1</h3><p>今天这节课，我给你介绍了哨兵实例的初始化过程。哨兵实例和 Redis 实例使用的是相同的入口 main 函数，但是由于哨兵实例在运行时使用的配置项、运行时信息、支持的可执行命令、事件处理和 Redis 实例又有所区别。</p>
<p>所以，main 函数会先通过 checkForSentinelMode 函数来判断当前运行是否为哨兵实例，并相应地设置全局配置项 server.sentinel_mode，这个配置项就会在源码其他地方被用于标识哨兵实例是否运行。</p>
<p>这样，当启动的是哨兵实例时，main 函数会调用 initSentinelConfig、initSentinel 函数来完成哨兵实例的初始化，然后，main 函数会调用 sentinelIsRunning 函数，来向被监听的主节点发送事件信息，从而开始监听主节点。</p>
<p>最后，我也想再提醒你一下，从今天这节课的内容中，我们可以看到哨兵实例在运行后，开始使用 Pub/Sub 订阅频道模式的通信方法，这种通信方法通常适用于多对多的通信场景中。</p>
<p>因为哨兵实例除了和主节点通信外，还需要和其他哨兵实例、客户端进行通信，而采用 Pub/Sub 通信方法，可以高效地完成这些通信过程。我在接下来的课程中还会给你介绍 Pub/Sub 通信方法在哨兵运行过程中的使用，也希望你在学完这部分课程内容之后，能够掌握这种通信方法的实现。</p>
<h3 id="总结2-20"><a href="#总结2-20" class="headerlink" title="总结2"></a>总结2</h3><ol>
<li>哨兵和 Redis 实例是一套代码，只不过哨兵会根据启动参数（redis-sentinel 或 redis-server –sentinel），设置当前实例为哨兵模式（server.sentinel_mode = 1），然后初始化哨兵相关数据</li>
<li>哨兵模式的实例，只能执行一部分命令（ping、sentinel、subscribe、unsubscribe、psubscribe、punsubscribe、publish、info、role、client、shutdown、auth），其中 sentinel、publish、info、role 都是针对哨兵专门实现的</li>
<li>之后哨兵会初始化各种属性，例如哨兵实例 ID、用于故障切换的当前纪元、监听的主节点、正在执行的脚本数量、与其他哨兵实例发送的 IP 和端口号等信息</li>
<li>启动哨兵后，会检查配置文件是否可写（不可写直接退出，哨兵需把监控的实例信息写入配置文件）、是否配置了哨兵 ID（没配置随机生成一个）</li>
<li>最后哨兵会在监控的 master 实例的 PubSub（+monitor 频道）发布一条消息，表示哨兵开始监控 Redis 实例</li>
<li>哨兵后续会通过 PubSub 的方式，与主从库、其它哨兵实例进行通信</li>
</ol>
<p>课后题：哨兵实例本身是有配置文件 sentinel.conf 的，那么在哨兵实例的初始化过程中，解析这个配置文件的函数在哪？</p>
<p>Redis 启动时，会在 main 函数中调用 loadServerConfig 加载配置文件，loadServerConfig 函数会读取配置文件中的内容，然后调用 loadServerConfigFromString 函数解析具体的配置项。</p>
<p>loadServerConfigFromString 函数中，其中有一个分支，对哨兵模式进行了判断，如果是哨兵模式，则调用 sentinelHandleConfiguration 函数解析哨兵配置项。</p>
<p>所以，函数调用链为 main -&gt; loadServerConfig（读出配置文件内容） -&gt; loadServerConfigFromString（解析配置项） -&gt; sentinelHandleConfiguration（解析哨兵配置项）。</p>
<h2 id="哨兵选举-上"><a href="#哨兵选举-上" class="headerlink" title="哨兵选举 上"></a>哨兵选举 上</h2><h3 id="总结1-21"><a href="#总结1-21" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我主要是给你介绍了哨兵工作过程中的一个重要环节，也就是哨兵 Leader 的选举。这个选举过程是参考了分布式系统中常用的分布式共识协议 Raft 协议来实现的。所以，你需要先了解 Raft 协议的基本流程，包括 Leader、Follower、Candidate 三种节点类型，Follower 成为 Candidate 的条件和具体操作，以及 Leader 投票的规则。</p>
<p>那么，对于哨兵 Leader 选举来说，它参考了 Raft 协议，但你需要注意的是，哨兵在正常运行时并不像 Raft 协议那样区分了三种节点类型，而是所有哨兵都是对等的。而当哨兵发现主节点故障，要执行故障切换时，会按照 Raft 协议中 Leader 选举的规则，进行投票选出 Leader。这是哨兵 Leader 选举和 Raft 协议的区别与联系。</p>
<p>此外，我还介绍了哨兵的时间事件处理函数 sentinelTimer，这个函数会对哨兵监听的每个主节点，周期性调用 sentinelHandleRedisInstance 函数，来检查主节点在线状态。当主节点客观下线了，哨兵会启动 Leader 选举并执行故障切换。这节课我们是先了解了 sentinelHandleRedisInstance 函数的整体执行流程，这样，你也能掌握哨兵的整体工作过程。同时，针对哨兵和主节点重建连接、发送命令和检查主观下线的三个函数，你也要有所了解，它们也是哨兵工作中的三个重要步骤。</p>
<p>那么，在下节课，我将带你了解哨兵 Leader 选举的具体过程以及故障切换的执行。</p>
<h3 id="总结2-21"><a href="#总结2-21" class="headerlink" title="总结2"></a>总结2</h3><ol>
<li>Redis 为了实现故障自动切换，引入了一个外部「观察者」检测实例的状态，这个观察者就是「哨兵」</li>
<li>但一个哨兵检测实例，有可能因为网络原因导致「误判」，所以需要「多个」哨兵共同判定</li>
<li>多个哨兵共同判定出实例故障后（主观下线、客观下线），会进入故障切换流程，切换时需要「选举」出一个哨兵「领导者」进行操作</li>
<li>这个选举的过程，就是「分布式共识」，即多个哨兵通过「投票」选举出一个都认可的实例当领导者，由这个领导者发起切换，这个选举使用的算法是 Raft 算法</li>
<li>严格来说，Raft 算法的核心流程是这样的：</li>
</ol>
<ul>
<li>集群正常情况下，Leader 会持续给 Follower 发心跳消息，维护 Leader 地位</li>
<li>如果 Follower 一段时间内收不到 Leader 心跳消息，则变为 Candidate 发起选举</li>
<li>Candidate 先给自己投一票，然后向其它节点发送投票请求</li>
<li>Candidate 收到超过半数确认票，则提升为新的 Leader，新 Leader 给其它 Follower 发心跳消息，维护新的 Leader 地位</li>
<li>Candidate 投票期间，收到了 Leader 心跳消息，则自动变为 Follower</li>
<li>投票结束后，没有超过半数确认票的实例，选举失败，会再次发起选举</li>
</ul>
<ol start="6">
<li>但哨兵的选举没有按照严格按照 Raft 实现，因为多个哨兵之间是「对等」关系，没有 Leader 和 Follower 角色，只有当 Redis 实例发生故障时，哨兵才选举领导者进行切换，选举 Leader 的过程是按照 Raft 算法步骤 3-6 实现的</li>
</ol>
<p>课后题：哨兵实例执行的周期性函数 sentinelTimer 的最后，修改 server.hz 的目的是什么？</p>
<p>server.hz 表示执行定时任务函数 serverCron 的频率，哨兵在最后修改 server.hz 增加一个随机值，是为了避免多个哨兵以「相同频率」执行，引发每个哨兵同时发起选举，进而导致没有一个哨兵能拿到多数投票，领导者选举失败的问题。适当打散执行频率，可以有效降低选举失败的概率。</p>
<h2 id="哨兵选举-下"><a href="#哨兵选举-下" class="headerlink" title="哨兵选举 下"></a>哨兵选举 下</h2><h3 id="总结1-22"><a href="#总结1-22" class="headerlink" title="总结1"></a>总结1</h3><p>好了，今天这节课的内容就到这里，我们来小结下。</p>
<p>今天这节课，我在上节课的基础上，重点给你介绍了哨兵工作过程中的客观下线判断，以及 Leader 选举。因为这个过程涉及哨兵之间的交互询问，所以并不容易掌握，你需要好好关注以下我提到的重点内容。</p>
<p>首先，客观下线的判断涉及三个标记的判断，分别是主节点 flags 中的 SRI_S_DOWN 和 SRI_O_DOWN，以及哨兵实例 flags 中的 SRI_MASTER_DOWN，我画了下面这张表，展示了这三个标记的设置函数和条件，你可以再整体回顾下。</p>
<p><img src="/images/redis/sentinel-02.png" alt="img.png"></p>
<p>而一旦哨兵判断主节点客观下线了，那么哨兵就会调用 sentinelAskMasterStateToOtherSentinels 函数进行哨兵 Leader 选举。这里，你需要注意的是，向其他哨兵询问主节点主观下线状态，以及向其他哨兵发起 Leader 投票，都是通过 sentinel is-master-down-by-addr 命令实现的，而 Redis 源码是用了同一个函数 sentinelAskMasterStateToOtherSentinels 来发送该命令，所以你在阅读源码时，要注意区分 sentinelAskMasterStateToOtherSentinels 发送的命令是查询主节点主观下线状态还是进行投票。</p>
<p>最后，哨兵 Leader 选举的投票是在 sentinelVoteLeader 函数中完成的，为了符合 Raft 协议的规定，sentinelVoteLeader 函数在执行时主要是要比较哨兵的纪元，以及 master 记录的 Leader 纪元，这样才能满足 Raft 协议对 Follower 在一轮投票中只能投一票的要求。</p>
<p>好了，到今天这节课，我们就了解了哨兵 Leader 选举的过程，你可以看到，虽然哨兵选举的最后执行逻辑就是在一个函数中，但是哨兵选举的触发逻辑是包含在了哨兵的整个工作过程中的，所以我们也需要掌握这个过程中的其他操作，比如主观下线判断、客观下线判断等。</p>
<h3 id="总结2-22"><a href="#总结2-22" class="headerlink" title="总结2"></a>总结2</h3><ol>
<li>一个哨兵检测判定主库故障，这个过程是「主观下线」，另外这个哨兵还会向其它哨兵询问（发送 sentinel is-master-down-by-addr 命令），多个哨兵都检测主库故障，数量达到配置的 quorum 值，则判定为「客观下线」</li>
<li>首先判定为客观下线的哨兵，会发起选举，让其它哨兵给自己投票成为「领导者」，成为领导者的条件是，拿到超过「半数」的确认票 + 超过预设的 quorum 阈值的赞成票</li>
<li>投票过程中会比较哨兵和主库的「纪元」（主库纪元 &lt; 发起投票哨兵的纪元 + 发起投票哨兵的纪元 &gt; 其它哨兵的纪元），保证一轮投票中一个哨兵只能投一次票</li>
</ol>
<p>课后题：哨兵在 sentinelTimer 函数中调用 sentinelHandleDictOfRedisInstances 函数，对每个主节点都执行 sentinelHandleRedisInstance 函数，并且还会对主节点的所有从节点也执行 sentinelHandleRedisInstance 函数，那么，哨兵会不会判断从节点的主观下线和客观下线？</p>
<p>sentinelHandleRedisInstance 函数逻辑如下：</p>
<div class="code-wrapper"><pre><code class="hljs c"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">sentinelHandleRedisInstance</span><span class="hljs-params">(sentinelRedisInstance *ri)</span> </span>&#123;
    ...

    <span class="hljs-comment">/* Every kind of instance */</span>
    <span class="hljs-comment">// 判断主观下线</span>
    sentinelCheckSubjectivelyDown(ri);

    ...

    <span class="hljs-comment">/* Only masters */</span>
    <span class="hljs-keyword">if</span> (ri-&gt;flags &amp; SRI_MASTER) &#123;
        <span class="hljs-comment">// 判断客观下线</span>
        sentinelCheckObjectivelyDown(ri);
        <span class="hljs-keyword">if</span> (sentinelStartFailoverIfNeeded(ri))
            sentinelAskMasterStateToOtherSentinels(ri,SENTINEL_ASK_FORCED);
        sentinelFailoverStateMachine(ri);
        sentinelAskMasterStateToOtherSentinels(ri,SENTINEL_NO_FLAGS);
    &#125;
&#125;</code></pre></div>

<p>可以看到，无论主库还是从库，哨兵都判断了「主观下线」，但只有主库才判断「客观下线」和「故障切换」。</p>
<h2 id="pub-sub"><a href="#pub-sub" class="headerlink" title="pub/sub"></a>pub/sub</h2><h3 id="总结1-23"><a href="#总结1-23" class="headerlink" title="总结1"></a>总结1</h3><p>今天这节课，我们了解了 Redis 实现的发布订阅通信方法。这个方法是提供了频道的方式，让要通信的双方按照频道来完成消息交互。而不同频道的不同名称，就代表了哨兵工作过程中的不同状态。当客户端需要了解哨兵的工作进度或是主节点的状态判断时，就可以通过订阅哨兵发布消息的频道来完成。</p>
<p>当然，对于一个哨兵来说，它一定会订阅的频道是它所监听的主节点的”<strong>sentinel</strong>:hello”频道。通过这个频道，监听同一主节点的不同哨兵就能通过频道上的 hello 消息，来交互彼此的访问信息了，比如哨兵的 IP、端口号等。</p>
<p>此外，在这节课，我还给你介绍了一个 C 语言函数可变参数的使用小技巧，当你开发发布订阅功能时，都需要生成发布的消息，而可变参数就可以用来生成长度不定的消息。希望你能把这个小技巧应用起来。</p>
<h3 id="总结2-23"><a href="#总结2-23" class="headerlink" title="总结2"></a>总结2</h3><ol>
<li>哨兵是通过 master 的 PubSub 发现其它哨兵的：每个哨兵向 master 的 PubSub（<strong>sentinel</strong>:hello 频道）发布消息，同时也会订阅这个频道，这样每个哨兵就能拿到其它哨兵的 IP、端口等信息</li>
<li>每个哨兵有了其它哨兵的信息后，在判定 Redis 实例状态时，就可以互相通信、交换信息，共同判定实例是否真的故障</li>
<li>哨兵判定 Redis 实例故障、发起切换时，都会向 master 的 PubSub 的频道发布消息</li>
<li>客户端可以订阅 master 的 PubSub，感知到哨兵工作到了哪个状态节点，从而作出自己的反应</li>
<li>PubSub 的实现，其实就是 Redis 在内存中维护了一个「发布-订阅」映射表，订阅者执行 SUBSCRIBE 命令，Redis 会把订阅者加入到指定频道的「链表」下。发布者执行 PUBLISH，Redis 就找到这个映射表中这个频道的所有「订阅者」，把消息「实时转发」给这些订阅者</li>
</ol>
<p>课后题：在哨兵实例上执行 publish 命令，这条命令是不是就是由 pubsub.c 文件中的 publishCommand 函数来处理的?</p>
<p>以哨兵模式启动的 Redis 实例，会使用新「命令表」。</p>
<p>在 server.c 的 main 函数中可以看到，哨兵模式启动后，会调用 initSentinel 函数。</p>
<div class="code-wrapper"><pre><code class="hljs c"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">initSentinel</span><span class="hljs-params">(<span class="hljs-keyword">void</span>)</span> </span>&#123;
    ...

    <span class="hljs-comment">// 只添加 sentinelcmds 下的命令</span>
    <span class="hljs-keyword">for</span> (j = <span class="hljs-number">0</span>; j &lt; <span class="hljs-keyword">sizeof</span>(sentinelcmds)/<span class="hljs-keyword">sizeof</span>(sentinelcmds[<span class="hljs-number">0</span>]); j++) &#123;
        <span class="hljs-keyword">int</span> retval;
        <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">redisCommand</span> *<span class="hljs-title">cmd</span> =</span> sentinelcmds+j;

        retval = dictAdd(server.commands, sdsnew(cmd-&gt;name), cmd);
        serverAssert(retval == DICT_OK);
    &#125;
    ...
&#125;</code></pre></div>

<p>可以看到只把 sentinelcmds 命令表添加到了 server.commands 中。sentinelcmds 如下：</p>
<div class="code-wrapper"><pre><code class="hljs c"><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">redisCommand</span> <span class="hljs-title">sentinelcmds</span>[] =</span> &#123;
    ...
    &#123;<span class="hljs-string">&quot;subscribe&quot;</span>,subscribeCommand,<span class="hljs-number">-2</span>,<span class="hljs-string">&quot;&quot;</span>,<span class="hljs-number">0</span>,<span class="hljs-literal">NULL</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>&#125;,
    &#123;<span class="hljs-string">&quot;publish&quot;</span>,sentinelPublishCommand,<span class="hljs-number">3</span>,<span class="hljs-string">&quot;&quot;</span>,<span class="hljs-number">0</span>,<span class="hljs-literal">NULL</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>&#125;,
    &#123;<span class="hljs-string">&quot;info&quot;</span>,sentinelInfoCommand,<span class="hljs-number">-1</span>,<span class="hljs-string">&quot;&quot;</span>,<span class="hljs-number">0</span>,<span class="hljs-literal">NULL</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>&#125;,
    ...
&#125;;</code></pre></div>

<p>可以看到哨兵的 PUBLISH 命令是由 sentinelPublishCommand 单独实现的，并非普通实例的 publishCommand。</p>
<h2 id="redis-性能测试"><a href="#redis-性能测试" class="headerlink" title="redis 性能测试"></a>redis 性能测试</h2><h3 id="总结1-24"><a href="#总结1-24" class="headerlink" title="总结1"></a>总结1</h3><p>今天这节课我给你介绍了 redis-benchmark 工具的使用。redis-benchmark 是常用的 Redis 性能测试工具，它可以通过设置并发客户端、总操作数、value 大小、key 的随机性、批量发送等配置项，来给 Redis server 施加不同的压力。</p>
<p>redis-benchmark 工具本身提供了一些常见命令的测试，比如 SET、GET、LPUSH，等等。这些命令的测试是 redis-benchmark 在它的实现文件中固定写好的。你可以在 redis-benchmark.c 文件中的 main 函数里面，找到这些命令。而如果我们想要测试不在固定测试命令集中的其他命令，我们可以在 redis-benchmark 命令的最后，设置其他的 Redis 命令，从而可以测试其他命令的性能结果。</p>
<p>最后，我也给你介绍了 redis-benchmark 的基本实现。它其实是启动多个客户端向 Redis server 发送命令操作。这个过程中，redis-benchmark 使用了事件驱动框架。每当启动一个测试客户端，这个客户端会在事件驱动框架中创建写事件和读事件。写事件对应了测试客户端向 Redis server 发送操作命令，而读事件对应了测试客户端从 Redis server 读取响应结果。</p>
<p>从这里，你可以看到，Redis 实现的事件驱动框架不仅用在 server 的运行过程中，而且还用在了性能测试工具实现的客户端中。</p>
<h3 id="总结2-24"><a href="#总结2-24" class="headerlink" title="总结2"></a>总结2</h3><ol>
<li>redis-benchmark 是 Redis 官方提供的性能测试工具，一般都用这个工具测试其性能</li>
<li>测试性能结果，与客户端并发数、value 大小、是否用 pipeline 都有关系</li>
<li>除此之外，性能结果还受系统环境的影响，例如 CPU 负载、网络带宽、客户端和服务端是否在同一机器、实例是否部署在虚拟机、Redis 绑核情况都会影响性能结果</li>
<li>提升 Redis 性能的几点优化：</li>
</ol>
<ul>
<li>控制客户端并发数</li>
<li>value 小于 10KB</li>
<li>推荐使用 pipeline</li>
<li>隔离部署</li>
<li>保证 CPU、网络带宽负载正常</li>
<li>不部署在虚拟机</li>
<li>进程绑核</li>
<li>CPU 绑定网卡队列</li>
<li>Redis 内存碎片</li>
<li>不使用 Swap</li>
</ul>
<h2 id="RDB、AOF文件损坏"><a href="#RDB、AOF文件损坏" class="headerlink" title="RDB、AOF文件损坏"></a>RDB、AOF文件损坏</h2><h3 id="总结1-25"><a href="#总结1-25" class="headerlink" title="总结1"></a>总结1</h3><p>今天这节课，我带你了解了检测 AOF 文件和 RDB 文件正确性和完整性的两个命令，redis-check-aof 和 redis-check-rdb，以及它们各自的实现过程。</p>
<p>对于 redis-check-aof 命令来说，它是根据 AOF 文件中记录的操作命令格式，逐一读取命令，并根据命令参数个数、参数字符串长度等信息，进行命令正确性和完整性的判断。</p>
<p>对于 redis-check-rdb 命令来说，它的实现逻辑较为简单，也就是按照 RDB 文件的组织格式，依次读取 RDB 文件头、数据部分和文件尾，并在读取过程中判断内容是否正确，并进行报错。</p>
<p>事实上，Redis server 在运行时，遇到故障而导致 AOF 文件或 RDB 文件没有记录完整，这种情况有时是不可避免的。当了解了 redis-check-aof 命令的实现后，我们就知道它可以提供出现错误或不完整命令的文件位置，并且，它本身提供了修复功能，可以从出现错误的文件位置处截断后续的文件内容。不过，如果我们不想通过截断来修复 AOF 文件的话，也可以尝试人工修补。</p>
<p>而在了解了 redis-check-rdb 命令的实现后，我们知道它可以发现 RDB 文件的问题所在。不过，redis-check-rdb 命令目前并没有提供修复功能。所以如果我们需要修复的话，就只能通过人工自己来修复了。</p>
<h3 id="总结2-25"><a href="#总结2-25" class="headerlink" title="总结2"></a>总结2</h3><ol>
<li>RDB 和 AOF 文件在写盘故障时，可能发生损坏不完整的情况，那使用其恢复数据就会出现问题，所以 Redis 提供了 2 个命令来检测文件是否有错误</li>
<li>要想检测出文件错误，那说明 RDB 和 AOF 必定是按照某种固定格式写入的，检测是否完整只需要按照其格式规则，发现不符即认为文件不完整</li>
<li>redis-check-rdb 命令检测 RDB，因为 RDB 有明确的文件头、数据部分、文件尾，读取文件发现不完整即报错</li>
<li>redis-check-aof 命令检测 AOF，AOF 按照 RESP 协议写入，按照这个协议可以读取每个命令参数个数、参数字符串长度，如果不符合协议格式，则说明不完整。但这个命令提供了 –fix 命令，可以修复 AOF 文件，实现原理是：把不完整的命令和后续部分，直接从 AOF 中删除</li>
</ol>
<p>课后题：redis_check_aof_main 函数是检测 AOF 文件的入口函数，但是它还会调用检测 RDB 文件的入口函数 redis_check_rdb_main，它的作用是什么？</p>
<p>Redis 在 4.0 版本支持了「混合持久化」，即在 AOF rewrite 期间，先以 RDB 格式写入到 AOF 文件中，再把后续命令追加到 AOF 中，这样 AOF rewrite 后的文件既包括了 RDB 格式，又包含 AOF 格式（目的是为了让 AOF 体积更小），所以 redis_check_rdb_main 在检测 AOF 文件时，RDB 和 AOF 文件格式都需要检测。</p>
<h2 id="Gossip"><a href="#Gossip" class="headerlink" title="Gossip"></a>Gossip</h2><h3 id="总结1-26"><a href="#总结1-26" class="headerlink" title="总结1"></a>总结1</h3><p>今天这节课，我给你介绍了 Redis Cluster 使用的 Gossip 协议的设计和实现。Gossip 协议实现的关键有两个，一个是要通过 Ping-Pong 消息发送节点自身的信息，以及节点已知的其他节点的信息。针对这一点，Redis 是设计了 clusterMsg 结构的消息，其中消息头包含了发送消息节点自身的信息，比如名称、IP、端口号、slots 分布等。</p>
<p>而 clusterMsg 结构中的消息体，是设计使用了 clusterMsgDataGossip 类型的数组，这个数组的每一个元素对应了发送消息节点已知的一个节点的信息。这样一来，发送消息节点通过 Ping 消息可以把自己的信息和已知的其他节点信息传播出去。</p>
<p>同样的，收到 Ping 消息的节点，也会使用同样结构的 Pong 消息将自己的信息和它已知的其他节点信息返回给发送节点。这样一来，就能实现 Gossip 协议的要求。</p>
<p>Gossip 协议实现的另一个关键就是要随机选择节点发送，这一点，Redis Cluster 在源码中就比较容易实现了。其实，就是 clusterCron 函数先通过随机选择五个节点，然后，再在其中挑选和当前节点最长时间没有发送 Pong 消息的节点，作为目标节点，这样一来，也满足了 Gossip 协议的要求。</p>
<p>通过今天这节课的学习，我希望你能了解 Redis Cluster 设计的消息结构、周期发送 Ping 和 Pong 消息的整体执行逻辑。这些都是你可以用在自行开发 Gossip 协议时的经典参考设计。</p>
<h3 id="总结2-26"><a href="#总结2-26" class="headerlink" title="总结2"></a>总结2</h3><ol>
<li>多个节点组成一个分布式系统，它们之间需要交换数据，可以采用中心化的方式（依赖第三方系统，例如ZK），也可以采用非中心化（分布式协议，例如 Gossip）的方式</li>
<li>Redis Cluster 采用非中心化的方式 Gossip 协议，实现多个节点之间信息交换</li>
<li>集群中的每个实例，会按照固定频率，从集群中「随机」挑选部分实例，发送 PING 消息（自身实例状态、已知部分实例信息、slots 分布），用来交换彼此状态信息</li>
<li>收到 PING 的实例，会响应 PONG 消息，PONG 消息和 PING 消息格式一样，包含了自身实例状态、已知部分实例信息、slots 分布</li>
<li>这样经过几次交换后，集群中每个实例都能拿到其它实例的状态信息</li>
<li>即使有节点状态发生变化（新实例加入、节点故障、数据迁移），也可以通过 Gossip 协议的 PING-PONG 消息完成整个集群状态在每个实例上的同步</li>
</ol>
<p>课后题：为什么 clusterSendPing 函数计算 wanted 值时，是用的集群节点个数的十分之一？</p>
<p>这个和 Redis Cluster 判定实例「故障」逻辑有关了。</p>
<p>Redis Cluster 实例在周期性向其它实例交换信息时，会先随机选出 5 个实例，然后从中找出最久没通信过的实例，发送 PING 消息。</p>
<p>但这里有个问题，随机选出的这 5 个实例，有可能并不是整个「集群」中最久没通信过的，为了避免拿不到这些实例的状态，导致集群误以为这些实例已过期，所以制定了一个策略：如果和实例最近通信时间超过了 cluster-node-timeout / 2，那会立即向这个实例发送 PING 消息。</p>
<p>每次 PING 都会收到 PONG 响应，一来一回 2 次心跳包，来回都带有部分实例的状态信息，那在 cluster-node-timeout 时间内会收到 4 次心跳包。</p>
<p>又因为 Redis Cluster 计算故障转移超时时间是 cluster-node-timeout * 2，那这段时间内就能收到 8 个 PING + PONG 心跳包，每个心跳包中实例个数设置为集群的 1/10，那在故障转移期间就能收到集群 80%（8 * 1/10）节点发来的故障状态信息了，满足集群大部分节点发来的节点故障情况。</p>
<h2 id="MOVED、ASK"><a href="#MOVED、ASK" class="headerlink" title="MOVED、ASK"></a>MOVED、ASK</h2><h3 id="总结1-27"><a href="#总结1-27" class="headerlink" title="总结1"></a>总结1</h3><p>今天这节课，我给你介绍了集群节点对客户端命令的处理过程。和单个 Redis server 处理命令的过程相似，集群节点也会经历命令读取、解析、执行和返回结果四个阶段，并且集群节点也使用了和单 Redis server 相同的入口处理函数。</p>
<p>不过你要知道的是，Redis Cluster 会因为负载均衡或节点故障等原因而执行数据迁移，而这就会导致客户端访问的 key 并不在接收到命令的集群节点上。因此，集群节点在命令执行函数 processCommand 中，针对集群模式，就增加了额外的处理逻辑。这主要是包括调用 getNodeByQuery 函数查询访问的 key 实际所属的节点，以及根据查询结果调用 clusterRedirectClient 函数执行请求重定向。</p>
<p>事实上，对于分布式集群来说，Redis Cluster 设计实现的请求重定向机制是一个不错的参考示例。其中，MOVED 和 ASK 两种重定向情况，就充分考虑了数据正在迁移的场景，这种设计值得我们学习。而且，getNodeByQuery 函数在查询 key 所属的 slot 和节点时，也充分考虑了 Redis 的事务操作，在对命令访问 key 进行查询时，巧妙地使用了同一个数据结构 multiState，来封装事务涉及的多条命令和常规的单条命令，增加了代码的复用程度，这一点也非常值得学习。</p>
<p>当然，在这节课里我们也多次提到了数据迁移，那么在下节课，我就会给你介绍 Redis Cluster 中数据迁移的具体实现。</p>
<h3 id="总结2-27"><a href="#总结2-27" class="headerlink" title="总结2"></a>总结2</h3><p>1、cluster 模式的 Redis，在执行命令阶段，需要判断 key 是否属于本实例，不属于会给客户端返回请求重定向的信息</p>
<p>2、判断 key 是否属于本实例，会先计算 key 所属的 slot，再根据 slot 定位属于哪个实例</p>
<p>3、找不到 key 所属的实例，或者操作的多个 key 不在同一个 slot，则会给客户端返回错误；key 正在做数据迁出，并且访问的这个 key 不在本实例中，会给客户端返回 ASK，让客户端去目标节点再次查询一次（临时重定向）；key 所属的 slot 不是本实例，而是其它节点，会给客户端返回 MOVED，告知客户端 key 不在本实例，以后都去目标节点查询（永久重定向）</p>
<p>课后题：processCommand 函数在调用完 getNodeByQuery 函数后，实际调用 clusterRedirectClient 函数进行请求重定向前，会根据当前命令是否是 EXEC，分别调用 discardTransaction 和 flagTransaction 两个函数。这 2 个函数的目的是什么?</p>
<p>看代码逻辑，只有当 n == NULL || n != server.cluster-&gt;myself 时，才会调用这 2 个方法。</p>
<p>其中，如果当前执行的是 EXEC 命令，则调用 discardTransaction。这个函数表示放弃整个事务，它会清空这个 client 之前缓存的命令队列，放弃事务中 watch 的 key，重置 client 的事务标记。</p>
<p>如果当前命令不是 EXEC，而是一个普通命令，则调用 flagTransaction。这个函数会给当前 client 打上一个标记 CLIENT_DIRTY_EXEC，如果后面执行了 EXEC，就会判断这个标记，随即也会放弃执行事务，给客户端返回错误。</p>
<p>也就是说，当集群不可用、key 找不到对应的 slot、key 不在本实例中、操作的 keys 不在同一个 slot、key 正在迁移中，发生这几种情况时，都会放弃整个事务的执行。</p>
<h2 id="Cluster数据迁移会阻塞？"><a href="#Cluster数据迁移会阻塞？" class="headerlink" title="Cluster数据迁移会阻塞？"></a>Cluster数据迁移会阻塞？</h2><h3 id="总结1-28"><a href="#总结1-28" class="headerlink" title="总结1"></a>总结1</h3><p>在今天的课程中，我给你介绍了 Redis Cluster 数据迁移过程的代码实现，你要掌握以下两个要点。</p>
<p>首先是记录集群状态的数据结构 clusterState。这个结构中是使用了 migrating_slots_to 和 importing_slots_from 两个数组，来记录数据迁出迁入情况，使用了 slots 数组记录每个 slot 所属的节点，以及使用 slots_to_keys 字典树记录 slots 中的 keys。你需要掌握这几个数据结构的含义，因为在你阅读集群源码时，这几个结构是会频繁使用到的。</p>
<p>然后是数据迁移过程的五大步骤。分别是：</p>
<ul>
<li>标记迁入、迁出节点；</li>
<li>获取待迁出的 keys；</li>
<li>源节点实际迁移数据；</li>
<li>目的节点处理迁移数据；</li>
<li>标记迁移结果。</li>
</ul>
<p>这五个步骤对应了 CLUSTER 命令的不同选项、MIGRATE 命令以及 RESTORE 命令，所以，它们的实现逻辑就主要对应在 clusterCommand、migrateCommand 和 restoreCommand 函数中。如果你想了解数据迁移的更多细节，你可以从这几个函数入手进一步学习。</p>
<p>最后，我也想再提醒你两个关键点。</p>
<p>一是，Redis Cluster 在执行数据迁移时，会调用 syncWrite 和 syncReadLine 函数，向目的节点同步发送迁移数据，以及同步读取回复结果。而这个同步写和同步读的过程，会阻塞源节点正常处理请求。所以，你在迁移数据时要控制迁移的 key 数量和 key 大小，避免一次性迁移过多的 key 或是过大的 key，而导致 Redis 阻塞。</p>
<p>二是，我们在实际应用中，会用到 redis-cli 工具，或者是 Ruby 开发的 Redis Cluster 集群运维工具 redis-trib，来执行数据迁移。这些工具最终也会调用这节课中，我们介绍的命令来完成数据的实际迁移。所以，学习今天课程的内容，对于你在实际应用中，从代码层面排查 redis-cli、redis-trib 这些工具的问题也是有所帮助的。</p>
]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>源码</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis核心技术与实战</title>
    <url>/redis/use/</url>
    <content><![CDATA[<h2 id="数据结构之慢操作"><a href="#数据结构之慢操作" class="headerlink" title="数据结构之慢操作"></a>数据结构之慢操作</h2><h3 id="总结1"><a href="#总结1" class="headerlink" title="总结1"></a>总结1</h3><p>一，作者讲了什么？</p>
<ol>
<li>Redis的底层数据结构</li>
</ol>
<p>二，作者是怎么把这事给讲明白的？</p>
<ol>
<li>讲了Redis的数据结构：数据的保存形式与底层数据结构</li>
<li>由数据结构的异同点，引出数据操作的快慢原因</li>
</ol>
<p>三，为了讲明白，作者讲了哪些要点？有哪些亮点？</p>
<ol>
<li>亮点1：string，list，set，hast,sortset都只是数据的保存形式，底层的数据结构是：简单动态字符串，双向链表，压缩列表，哈希表，跳表，整数数组</li>
<li>亮点2：Redis使用了一个哈希表保存所有的键值对</li>
<li>要点1：五种数据形式的底层实现<br>a，string：简单动态字符串<br>b，list：双向链表，压缩列表<br>c，hash：压缩列表，哈希表<br>d，Sorted Set：压缩列表，跳表<br>e，set：哈希表，整数数组</li>
<li>要点2：List ,hash，set ,sorted set被统称为集合类型，一个键对应了一个集合的数据</li>
<li>要点3：集合类型的键和值之间的结构组织<br>a：Redis使用一个哈希表保存所有键值对，一个哈希表实则是一个数组，数组的每个元素称为哈希桶。<br>b：哈希桶中的元素保存的不是值的本身，而是指向具体值的指针</li>
<li>要点4：哈希冲突解决<br>a：Redis的hash表是全局的，所以当写入大量的key时，将会带来哈希冲突，已经rehash可能带来的操作阻塞<br>b：Redis解决hash冲突的方式，是链式哈希：同一个哈希桶中的多个元素用一个链表来保存<br>c：当哈希冲突链过长时，Redis会对hash表进行rehash操作。rehash就是增加现有的hash桶数量，分散entry元素。</li>
<li>要点5：rehash机制<br>a：为了使rehash操作更高效，Redis默认使用了两个全局哈希表：哈希表1和哈希表2，起始时hash2没有分配空间<br>b：随着数据增多，Redis执行分三步执行rehash;<br> 1，给hash2分配更大的内存空间，如是hash1的两倍<br> 2，把hash1中的数据重新映射并拷贝到哈希表2中<br> 3，释放hash1的空间</li>
<li>要点6：渐进式rehash<br>a：由于步骤2重新映射非常耗时，会阻塞redis<br>b：讲集中迁移数据，改成每处理一个请求时，就从hash1中的第一个索引位置，顺带将这个索引位置上的所有entries拷贝到hash2中。</li>
<li>要点7 ：压缩列表，跳表的特点<br>a：压缩列表类似于一个数组，不同的是:压缩列表在表头有三个字段zlbytes,zltail和zllen分别表示长度，列表尾的偏移量和列表中的entry的个数，压缩列表尾部还有一个zlend，表示列表结束<br>所以压缩列表定位第一个和最后一个是O(1),但其他就是O(n)<br>b：跳表：是在链表的基础上增加了多级索引，通过索引的几次跳转，实现数据快速定位</li>
</ol>
<p>四，对于作者所讲，我有哪些发散性思考？</p>
<p>五，在将来的哪些场景中，我能够用到它？</p>
<p>六，评论区收获</p>
<ol>
<li>数组和压缩列表可以提升内存利用率，因为他们的数据结构紧凑</li>
<li>数组对CPU高速缓存支持友好，当数据元素超过阈值时，会转为hash和跳表，保证查询效率时，集合数据元素较少情况下，默认采用内存紧凑排列的方式存储，同时利用CPU高速缓存不会降低访问速度。当数据元素超过设定阈值后，避免查询时间复杂度太高，转为哈希和跳表数据结构存储，保证查询效率。</li>
<li>内存利用率，数组和压缩列表都是非常紧凑的数据结构，它比链表占用的内存要更少。Redis是内存数据库，大量数据存到内存中，此时需要做尽可能的优化，提高内存的利用率。</li>
<li>数组对CPU高速缓存支持更友好，所以Redis在设计时，集合数据元素较少情况下，默认采用内存紧凑排列的方式存储，同时利用CPU高速缓存不会降低访问速度。当数据元素超过设定阈值后，避免查询时间复杂度太高，转为哈希和跳表数据结构存储，保证查询效率。</li>
</ol>
<h2 id="单线程为什么快"><a href="#单线程为什么快" class="headerlink" title="单线程为什么快"></a>单线程为什么快</h2><h3 id="总结1-1"><a href="#总结1-1" class="headerlink" title="总结1"></a>总结1</h3><p>现在，我们知道了，Redis 单线程是指它对网络 IO 和数据读写的操作采用了一个线程，而采用单线程的一个核心原因是避免多线程开发的并发控制问题。单线程的 Redis 也能获得高性能，跟多路复用的 IO 模型密切相关，因为这避免了 accept() 和 send()/recv() 潜在的网络 IO 操作阻塞点。</p>
<h3 id="总结2"><a href="#总结2" class="headerlink" title="总结2"></a>总结2</h3><p>1，作者讲了什么？<br>redis实现单线程实现高性能IO的设计机制<br>2，作者是怎么把这事给讲明白的？<br>作者首先从简单的网络通信socket讲起，引出了非阻塞socket，由此谈到了著名的I/O多路复用，Linux内核的select/epoll机制<br>3，为了讲明白，作者讲了哪些要点?有哪些亮点？<br>（1）首先声明“redis单线程”这个概念的具体含义<br>（2）引入具体业务场景：redis的数据读取，事件处理机制模型<br>（3）解析单线程相对多线程带来的优势，已及多线程所特有的问题<br>（4）基于redis单线程的，设计机制，引出了网络socket的问题</p>
<h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>在“Redis 基本 IO 模型”图中，你觉得还有哪些潜在的性能瓶颈吗？</p>
<h3 id="解答"><a href="#解答" class="headerlink" title="解答"></a>解答</h3><p>Redis单线程处理IO请求性能瓶颈主要包括2个方面：</p>
<ol>
<li>任意一个请求在server中一旦发生耗时，都会影响整个server的性能，也就是说后面的请求都要等前面这个耗时请求处理完成，自己才能被处理到。耗时的操作包括以下几种：<br>a. 操作bigkey：写入一个bigkey在分配内存时需要消耗更多的时间，同样，删除bigkey释放内存同样会产生耗时；<br>b. 使用复杂度过高的命令：例如SORT/SUNION/ZUNIONSTORE，或者O(N)命令，但是N很大，例如lrange key 0 -1一次查询全量数据；<br>c. 大量key集中过期：Redis的过期机制也是在主线程中执行的，大量key集中过期会导致处理一个请求时，耗时都在删除过期key，耗时变长；<br>d. 淘汰策略：淘汰策略也是在主线程执行的，当内存超过Redis内存上限后，每次写入都需要淘汰一些key，也会造成耗时变长；<br>e. AOF刷盘开启always机制：每次写入都需要把这个操作刷到磁盘，写磁盘的速度远比写内存慢，会拖慢Redis的性能；<br>f. 主从全量同步生成RDB：虽然采用fork子进程生成数据快照，但fork这一瞬间也是会阻塞整个线程的，实例越大，阻塞时间越久；</li>
<li>并发量非常大时，单线程读写客户端IO数据存在性能瓶颈，虽然采用IO多路复用机制，但是读写客户端数据依旧是同步IO，只能单线程依次读取客户端的数据，无法利用到CPU多核。</li>
</ol>
<p>针对问题1，一方面需要业务人员去规避，一方面Redis在4.0推出了lazy-free机制，把bigkey释放内存的耗时操作放在了异步线程中执行，降低对主线程的影响。</p>
<p>针对问题2，Redis在6.0推出了多线程，可以在高并发场景下利用CPU多核多线程读写客户端数据，进一步提升server性能，当然，只是针对客户端的读写是并行的，每个命令的真正操作依旧是单线程的。</p>
<h2 id="AOF日志，宕机了，如何避免数据丢失"><a href="#AOF日志，宕机了，如何避免数据丢失" class="headerlink" title="AOF日志，宕机了，如何避免数据丢失"></a>AOF日志，宕机了，如何避免数据丢失</h2><h3 id="总结1-2"><a href="#总结1-2" class="headerlink" title="总结1"></a>总结1</h3><p>这个方法看似“简单”，但也是充分考虑了对 Redis 性能的影响。总结来说，它提供了 AOF 日志的三种写回策略，分别是 Always、Everysec 和 No，这三种策略在可靠性上是从高到低，而在性能上则是从低到高。</p>
<p>此外，为了避免日志文件过大，Redis 还提供了 AOF 重写机制，直接根据数据库里数据的最新状态，生成这些数据的插入命令，作为新日志。这个过程通过后台线程完成，避免了对主线程的阻塞。</p>
<p>其中，三种写回策略体现了系统设计中的一个重要原则 ，即 trade-off，或者称为“取舍”，指的就是在性能和可靠性保证之间做取舍。我认为，这是做系统设计和开发的一个关键哲学，我也非常希望，你能充分地理解这个原则，并在日常开发中加以应用。</p>
<p>不过，你可能也注意到了，落盘时机和重写机制都是在“记日志”这一过程中发挥作用的。例如，落盘时机的选择可以避免记日志时阻塞主线程，重写可以避免日志文件过大。但是，在“用日志”的过程中，也就是使用 AOF 进行故障恢复时，我们仍然需要把所有的操作记录都运行一遍。再加上 Redis 的单线程设计，这些命令操作只能一条一条按顺序执行，这个“重放”的过程就会很慢了。</p>
<h3 id="总结2-1"><a href="#总结2-1" class="headerlink" title="总结2"></a>总结2</h3><p>1，作者讲了什么？<br>本章讲了Redis两种持久化机制之一：AOF机制原理<br>aof日志记录了redis所有增删改的操作，保存在磁盘上，当redis宕机，需要恢复内存中的数据时，可以通过读取aop日志恢复数据，从而避免因redis异常导致的数据丢失</p>
<p>2，作者是怎么把这事给讲明白的？<br>（1）作者先讲述redis宕机会导致内存数据丢失，需要有一种机制在redis重启后恢复数据。<br>（2）介绍了AOF通过记录每一个对redis数据进行增删改的操作日志，可以实现这种功能<br>（2）介绍了AOF的运行机制，数据保存机制，以及由此带来的优点和缺点<br>3，为了讲明白，作者讲了哪些要点，有哪些亮点？<br>（1）亮点：记录操作的时机分为：“写前日志和写后日志”，这个是我之前所不知道的<br>（2）要点1：AOF是写后日志，这样带来的好处是，记录的所有操作命令都是正确的，不需要额外的语法检查，确保redis重启时能够正确的读取回复数据<br>（3）要点2：AOF日志写入磁盘是比较影响性能的，为了平衡性能与数据安全，开发了三种机制：①：立即写入②：按秒写入③：系统写入<br>（4）要点3：AOF日志会变得巨大，所以Redis提供了日志重整的机制，通过读取内存中的数据重新产生一份数据写入日志<br>4，对于作者所讲，我有哪些发散性的思考？<br>作者说系统设计“取舍”二字非常重要，这是我之前未曾意识到的。作者讲了fork子进程机制，是Linux系统的一个能力，在刘超的课中讲过，这鼓舞了我继续学习的信心<br>5，将来有哪些场景，我可以应用上它？<br>目前还没有机会直接操作生产的redis配置，但现在要学习，争取将来可以直接操作</p>
<h3 id="问题1"><a href="#问题1" class="headerlink" title="问题1"></a>问题1</h3><ol>
<li>AOF 日志重写的时候，是由 bgrewriteaof 子进程来完成的，不用主线程参与，我们今天说的非阻塞也是指子进程的执行不阻塞主线程。但是，你觉得，这个重写过程有没有其他潜在的阻塞风险呢？如果有的话，会在哪里阻塞？</li>
</ol>
<h3 id="解答1"><a href="#解答1" class="headerlink" title="解答1"></a>解答1</h3><p>Redis采用fork子进程重写AOF文件时，潜在的阻塞风险包括：fork子进程 和 AOF重写过程中父进程产生写入的场景，下面依次介绍。</p>
<p>a、fork子进程，fork这个瞬间一定是会阻塞主线程的（注意，fork时并不会一次性拷贝所有内存数据给子进程，老师文章写的是拷贝所有内存数据给子进程，我个人认为是有歧义的），fork采用操作系统提供的写实复制(Copy On Write)机制，就是为了避免一次性拷贝大量内存数据给子进程造成的长时间阻塞问题，但fork子进程需要拷贝进程必要的数据结构，其中有一项就是拷贝内存页表（虚拟内存和物理内存的映射索引表），这个拷贝过程会消耗大量CPU资源，拷贝完成之前整个进程是会阻塞的，阻塞时间取决于整个实例的内存大小，实例越大，内存页表越大，fork阻塞时间越久。拷贝内存页表完成后，子进程与父进程指向相同的内存地址空间，也就是说此时虽然产生了子进程，但是并没有申请与父进程相同的内存大小。那什么时候父子进程才会真正内存分离呢？“写实复制”顾名思义，就是在写发生时，才真正拷贝内存真正的数据，这个过程中，父进程也可能会产生阻塞的风险，就是下面介绍的场景。</p>
<p>b、fork出的子进程指向与父进程相同的内存地址空间，此时子进程就可以执行AOF重写，把内存中的所有数据写入到AOF文件中。但是此时父进程依旧是会有流量写入的，如果父进程操作的是一个已经存在的key，那么这个时候父进程就会真正拷贝这个key对应的内存数据，申请新的内存空间，这样逐渐地，父子进程内存数据开始分离，父子进程逐渐拥有各自独立的内存空间。因为内存分配是以页为单位进行分配的，默认4k，如果父进程此时操作的是一个bigkey，重新申请大块内存耗时会变长，可能会产阻塞风险。另外，如果操作系统开启了内存大页机制(Huge Page，页面大小2M)，那么父进程申请内存时阻塞的概率将会大大提高，所以在Redis机器上需要关闭Huge Page机制。Redis每次fork生成RDB或AOF重写完成后，都可以在Redis log中看到父进程重新申请了多大的内存空间。</p>
<h3 id="问题2"><a href="#问题2" class="headerlink" title="问题2"></a>问题2</h3><ol start="2">
<li>AOF 重写也有一个重写日志，为什么它不共享使用 AOF 本身的日志呢？</li>
</ol>
<h3 id="解答2"><a href="#解答2" class="headerlink" title="解答2"></a>解答2</h3><p>AOF重写不复用AOF本身的日志，一个原因是父子进程写同一个文件必然会产生竞争问题，控制竞争就意味着会影响父进程的性能。二是如果AOF重写过程中失败了，那么原本的AOF文件相当于被污染了，无法做恢复使用。所以Redis AOF重写一个新文件，重写失败的话，直接删除这个文件就好了，不会对原先的AOF文件产生影响。等重写完成之后，直接替换旧文件即可。</p>
<p>这里要谢谢Kaito同学指出的文章中的歧义：fork子进程时，子进程是会拷贝父进程的页表，即虚实映射关系，而不会拷贝物理内存。子进程复制了父进程页表，也能共享访问父进程的内存数据了，此时，类似于有了父进程的所有内存数据。我的描述不太严谨了，非常感谢指出！</p>
<p>Kaito同学还提到了Huge page。这个特性大家在使用Redis也要注意。Huge page对提升TLB命中率比较友好，因为在相同的内存容量下，使用huge page可以减少页表项，TLB就可以缓存更多的页表项，能减少TLB miss的开销。</p>
<p>但是，这个机制对于Redis这种喜欢用fork的系统来说，的确不太友好，尤其是在Redis的写入请求比较多的情况下。因为fork后，父进程修改数据采用写时复制，复制的粒度为一个内存页。如果只是修改一个256B的数据，父进程需要读原来的内存页，然后再映射到新的物理地址写入。一读一写会造成读写放大。如果内存页越大（例如2MB的大页），那么读写放大也就越严重，对Redis性能造成影响。</p>
<p>Huge page在实际使用Redis时是建议关掉的。</p>
<h2 id="内存快照：宕机后，Redis如何实现快速恢复？"><a href="#内存快照：宕机后，Redis如何实现快速恢复？" class="headerlink" title="内存快照：宕机后，Redis如何实现快速恢复？"></a>内存快照：宕机后，Redis如何实现快速恢复？</h2><h3 id="总结1-3"><a href="#总结1-3" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我们学习了 Redis 用于避免数据丢失的内存快照方法。这个方法的优势在于，可以快速恢复数据库，也就是只需要把 RDB 文件直接读入内存，这就避免了 AOF 需要顺序、逐一重新执行操作命令带来的低效性能问题。</p>
<p>不过，内存快照也有它的局限性。它拍的是一张内存的“大合影”，不可避免地会耗时耗力。虽然，Redis 设计了 bgsave 和写时复制方式，尽可能减少了内存快照对正常读写的影响，但是，频繁快照仍然是不太能接受的。而混合使用 RDB 和 AOF，正好可以取两者之长，避两者之短，以较小的性能开销保证数据可靠性和性能。</p>
<p>最后，关于 AOF 和 RDB 的选择问题，我想再给你提三点建议：</p>
<ul>
<li>数据不能丢失时，内存快照和 AOF 的混合使用是一个很好的选择；</li>
<li>如果允许分钟级别的数据丢失，可以只使用 RDB；</li>
<li>如果只用 AOF，优先使用 everysec 的配置选项，因为它在可靠性和性能之间取了一个平衡。</li>
</ul>
<h3 id="总结2-2"><a href="#总结2-2" class="headerlink" title="总结2"></a>总结2</h3><p>1，作者讲了什么？<br>作者在本章讲了redis两种持久化方式中的RDB方式<br>2，作者是怎么把这事给讲明白的？<br>为了让大家明白RDB的快照的概念，作者举了拍照片，照合影的例子<br>3，为了讲明白，作者讲了哪些要点，有哪些亮点？<br>（1）亮点1：作者解释快照使用了拍合影的例子，让我很好的理解快照的概念，以及内存数据大小对快照产生的影响<br>（2）要点1：RDB快照，将此时内存中的所有的数据写入磁盘<br>（3）要点2：生成快照有两种方式：sava和bgsava，save是主进程执行，生成时会阻塞redis，只能执行查找。bgsave是由主进程fork出子进程执行，<br>（4）要点3：子进程在被fork处理时，与主进程共享同一份内存，但在生成快照时采取COW机制，确保不会阻塞主进程的数据读写<br>（5）要点4：RDB的执行频率很重要，这会影响到数据的完整性和Redis的性能稳定性。所以4.0后有了aof和rdb混合的数据持久化机制<br>4，对于作者所讲，我有哪些发散性思考？<br>作者开篇提到的两个问题：快照什么数据，快照有何影响，具体的场景，才能讨论出具体的技术方案，我个人认为，脱离场景谈方案是在自嗨</p>
<p>5，将来有哪些场景，我能够使用到它？<br>我们项目的redis持久化使用的方式就是aof和rdb混合，前一段时间，做过集群升级扩容。把每台8c,30G内存,5主5从，升级改造成为8c,15G内存,15主15从。这样搞主要是因为之前的集群内存占用太高，导致数据持久化失败<br>6，读者评论的收获：<br>定这个专栏，真是觉得捡到宝了，大神@Kaito写的评论实在漂亮，每次都要读好几遍，读完都有赏心悦目的愉悦感，期望自己有一天也可像他那样出色</p>
<h3 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h3><p>我曾碰到过这么一个场景：<br>我们使用一个 2 核 CPU、4GB 内存、500GB 磁盘的云主机运行 Redis，Redis 数据库的数据量大小差不多是 2GB，我们使用了 RDB 做持久化保证。当时 Redis 的运行负载以修改操作为主，写读比例差不多在 8:2 左右，也就是说，如果有 100 个请求，80 个请求执行的是修改操作。你觉得，在这个场景下，用 RDB 做持久化有什么风险吗？你能帮着一起分析分析吗？</p>
<h3 id="解答-1"><a href="#解答-1" class="headerlink" title="解答"></a>解答</h3><p>2核CPU、4GB内存、500G磁盘，Redis实例占用2GB，写读比例为8:2，此时做RDB持久化，产生的风险主要在于 CPU资源 和 内存资源 这2方面：</p>
<p>a、内存资源风险：Redis fork子进程做RDB持久化，由于写的比例为80%，那么在持久化过程中，“写实复制”会重新分配整个实例80%的内存副本，大约需要重新分配1.6GB内存空间，这样整个系统的内存使用接近饱和，如果此时父进程又有大量新key写入，很快机器内存就会被吃光，如果机器开启了Swap机制，那么Redis会有一部分数据被换到磁盘上，当Redis访问这部分在磁盘上的数据时，性能会急剧下降，已经达不到高性能的标准（可以理解为武功被废）。如果机器没有开启Swap，会直接触发OOM，父子进程会面临被系统kill掉的风险。</p>
<p>b、CPU资源风险：虽然子进程在做RDB持久化，但生成RDB快照过程会消耗大量的CPU资源，虽然Redis处理处理请求是单线程的，但Redis Server还有其他线程在后台工作，例如AOF每秒刷盘、异步关闭文件描述符这些操作。由于机器只有2核CPU，这也就意味着父进程占用了超过一半的CPU资源，此时子进程做RDB持久化，可能会产生CPU竞争，导致的结果就是父进程处理请求延迟增大，子进程生成RDB快照的时间也会变长，整个Redis Server性能下降。</p>
<p>c、另外，可以再延伸一下，老师的问题没有提到Redis进程是否绑定了CPU，如果绑定了CPU，那么子进程会继承父进程的CPU亲和性属性，子进程必然会与父进程争夺同一个CPU资源，整个Redis Server的性能必然会受到影响！所以如果Redis需要开启定时RDB和AOF重写，进程一定不要绑定CPU。</p>
<h2 id="数据复制-主从同步"><a href="#数据复制-主从同步" class="headerlink" title="数据复制-主从同步"></a>数据复制-主从同步</h2><h3 id="总结1-4"><a href="#总结1-4" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我们一起学习了 Redis 的主从库同步的基本原理，总结来说，有三种模式：全量复制、基于长连接的命令传播，以及增量复制。</p>
<p>全量复制虽然耗时，但是对于从库来说，如果是第一次同步，全量复制是无法避免的，所以，我给你一个小建议：一个 Redis 实例的数据库不要太大，一个实例大小在几 GB 级别比较合适，这样可以减少 RDB 文件生成、传输和重新加载的开销。另外，为了避免多个从库同时和主库进行全量复制，给主库过大的同步压力，我们也可以采用“主 - 从 - 从”这一级联模式，来缓解主库的压力。</p>
<p>长连接复制是主从库正常运行后的常规同步阶段。在这个阶段中，主从库之间通过命令传播实现同步。不过，这期间如果遇到了网络断连，增量复制就派上用场了。我特别建议你留意一下 repl_backlog_size 这个配置参数。如果它配置得过小，在增量复制阶段，可能会导致从库的复制进度赶不上主库，进而导致从库重新进行全量复制。所以，通过调大这个参数，可以减少从库在网络断连时全量复制的风险。</p>
<p>不过，主从库模式使用读写分离虽然避免了同时写多个实例带来的数据不一致问题，但是还面临主库故障的潜在风险。主库故障了从库该怎么办，数据还能保持一致吗，Redis 还能正常提供服务吗？在接下来的两节课里，我会和你具体聊聊主库故障后，保证服务可靠性的解决方案。</p>
<h3 id="总结2-3"><a href="#总结2-3" class="headerlink" title="总结2"></a>总结2</h3><p>一，作者讲了什么？<br>Redis的主从库数据同步机制的诞生背景和运行机制</p>
<p>二，作者是怎么把这事给讲明白的？<br>1， 作者首先介绍了主从库诞生需求背景：（写到这让我想起许式伟在架构课中提到的：拆解架构的两个核心：需求和规格）<br>为了实现Redis的高可用性，需要有多个redis实例，并且要保证多个实例数据一致（CAP定理：一致性，可用性，分区容错性）<br>2，介绍Redis的主从库间的工作机制：读写分离，主库负责接收读写请求，从库负责接收读请求，为保证从库可以正确的响应读请求，主库需要向从库同步数据<br>3，详细介绍了主从同步的机制：同步时间，同步内容，异常处理，失败补偿</p>
<p>三，作者为了讲明白，讲了哪些要点？有哪些亮点？<br>1，亮点1：Redis采用读写分离的好处：避免了加锁，实例间协商是否完成修改等复杂操作<br>1，亮点2：全量同步的发生时机：首次上线 和 从库的环形缓冲区位置标识被覆盖<br>2，亮点3：增量同步保障机制依赖于一个特殊的数据结构：环形缓冲区<br>3，要点1：首次同步分为三个阶段，①：建立连接，②：同步RDB文件，③：同步增量数据<br>4，要点2：全量同步需要主机fork子进程，产生全量RDB文件，并发送，为了减轻主机的压力，从机之间也可用互相同步<br>5，要点3：增量同步可以缓解主机全量同步的压力，它需要特殊机制保障：replication buffer，环形缓冲区，master_repl_offset，slave_repl_offset<br>6，要点4：从机的同步位置标识，在环形缓冲区被覆盖后，会触发新的一轮全量同步，所repl_backlog_buffer的大小是redis重要的调优参数<br>7，要点5：主从同步有三种机制：全量同步，基于长链接的命令传播（在写这个笔记时把它忽略了），增量同步</p>
<p>四，对于作者所讲，我有哪些发散性思考？<br>1，作者在介绍数据备份和数据同步时，都提到了单个redis的实例不宜过大<br>2，同步机制不止是redis需要，kafka，mysql中也需要，这个需要去看看他们是怎么设计的<br>3，作者介绍的redis数据一致性保障机制是很有趣，对于异常的处理机制值得学习</p>
<p>五，在未来的哪些场景里，我能够使用它？<br>1，以后面试，redis的数据备份和数同步可以不怂了<br>2，分布式系统的三定律有了联系对象</p>
<p>六，评论区的收获<br>从@Kaito 大神 那里了解到，<br>1，repl_backlog_buffer，是随着主机一起诞生的<br>2，主机和所有的clent端（包括从机）都会建立一个对应的buffer<br>3，replication buffer是与每个clent端一一对应<br>4，redis的所有写命令除了用于长链接广播，还都会写入repl_backlog_buffer</p>
<h3 id="问题-2"><a href="#问题-2" class="headerlink" title="问题"></a>问题</h3><p>按照惯例，我给你提一个小问题。这节课，我提到，主从库间的数据复制同步使用的是 RDB 文件，前面我们学习过，AOF 记录的操作命令更全，相比于 RDB 丢失的数据更少。那么，为什么主从库间的复制不使用 AOF 呢？</p>
<h3 id="解答-2"><a href="#解答-2" class="headerlink" title="解答"></a>解答</h3><p>主从全量同步使用RDB而不使用AOF的原因：</p>
<p>1、RDB文件内容是经过压缩的二进制数据（不同数据类型数据做了针对性优化），文件很小。而AOF文件记录的是每一次写操作的命令，写操作越多文件会变得很大，其中还包括很多对同一个key的多次冗余操作。在主从全量数据同步时，传输RDB文件可以尽量降低对主库机器网络带宽的消耗，从库在加载RDB文件时，一是文件小，读取整个文件的速度会很快，二是因为RDB文件存储的都是二进制数据，从库直接按照RDB协议解析还原数据即可，速度会非常快，而AOF需要依次重放每个写命令，这个过程会经历冗长的处理逻辑，恢复速度相比RDB会慢得多，所以使用RDB进行主从全量同步的成本最低。</p>
<p>2、假设要使用AOF做全量同步，意味着必须打开AOF功能，打开AOF就要选择文件刷盘的策略，选择不当会严重影响Redis性能。而RDB只有在需要定时备份和主从全量同步数据时才会触发生成一次快照。而在很多丢失数据不敏感的业务场景，其实是不需要开启AOF的。</p>
<p>另外，需要指出老师文章的错误：“当主从库断连后，主库会把断连期间收到的写操作命令，写入 replication buffer，同时也会把这些操作命令也写入 repl_backlog_buffer 这个缓冲区。”</p>
<p>1、主从库连接都断开了，哪里来replication buffer呢？</p>
<p>2、应该不是“主从库断连后”主库才把写操作写入repl_backlog_buffer，只要有从库存在，这个repl_backlog_buffer就会存在。主库的所有写命令除了传播给从库之外，都会在这个repl_backlog_buffer中记录一份，缓存起来，只有预先缓存了这些命令，当从库断连后，从库重新发送psync $master_runid $offset，主库才能通过$offset在repl_backlog_buffer中找到从库断开的位置，只发送$offset之后的增量数据给从库即可。</p>
<p>有同学对repl_backlog_buffer和replication buffer理解比较混淆，我大概解释一下：</p>
<p>1、repl_backlog_buffer：就是上面我解释到的，它是为了从库断开之后，如何找到主从差异数据而设计的环形缓冲区，从而避免全量同步带来的性能开销。如果从库断开时间太久，repl_backlog_buffer环形缓冲区被主库的写命令覆盖了，那么从库连上主库后只能乖乖地进行一次全量同步，所以repl_backlog_buffer配置尽量大一些，可以降低主从断开后全量同步的概率。而在repl_backlog_buffer中找主从差异的数据后，如何发给从库呢？这就用到了replication buffer。</p>
<p>2、replication buffer：Redis和客户端通信也好，和从库通信也好，Redis都需要给分配一个 内存buffer进行数据交互，客户端是一个client，从库也是一个client，我们每个client连上Redis后，Redis都会分配一个client buffer，所有数据交互都是通过这个buffer进行的：Redis先把数据写到这个buffer中，然后再把buffer中的数据发到client socket中再通过网络发送出去，这样就完成了数据交互。所以主从在增量同步时，从库作为一个client，也会分配一个buffer，只不过这个buffer专门用来传播用户的写命令到从库，保证主从数据一致，我们通常把它叫做replication buffer。</p>
<p>3、再延伸一下，既然有这个内存buffer存在，那么这个buffer有没有限制呢？如果主从在传播命令时，因为某些原因从库处理得非常慢，那么主库上的这个buffer就会持续增长，消耗大量的内存资源，甚至OOM。所以Redis提供了client-output-buffer-limit参数限制这个buffer的大小，如果超过限制，主库会强制断开这个client的连接，也就是说从库处理慢导致主库内存buffer的积压达到限制后，主库会强制断开从库的连接，此时主从复制会中断，中断后如果从库再次发起复制请求，那么此时可能会导致恶性循环，引发复制风暴，这种情况需要格外注意。</p>
<h2 id="哨兵机制：主库挂了，如何不间断服务"><a href="#哨兵机制：主库挂了，如何不间断服务" class="headerlink" title="哨兵机制：主库挂了，如何不间断服务"></a>哨兵机制：主库挂了，如何不间断服务</h2><h3 id="总结1-5"><a href="#总结1-5" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我们一起学习了哨兵机制，它是实现 Redis 不间断服务的重要保证。具体来说，主从集群的数据同步，是数据可靠的基础保证；而在主库发生故障时，自动的主从切换是服务不间断的关键支撑。</p>
<p>Redis 的哨兵机制自动完成了以下三大功能，从而实现了主从库的自动切换，可以降低 Redis 集群的运维开销：</p>
<ul>
<li>监控主库运行状态，并判断主库是否客观下线；</li>
<li>在主库客观下线后，选取新主库；</li>
<li>选出新主库后，通知从库和客户端。</li>
</ul>
<p>为了降低误判率，在实际应用时，哨兵机制通常采用多实例的方式进行部署，多个哨兵实例通过“少数服从多数”的原则，来判断主库是否客观下线。一般来说，我们可以部署三个哨兵，如果有两个哨兵认定主库“主观下线”，就可以开始切换过程。当然，如果你希望进一步提升判断准确率，也可以再适当增加哨兵个数，比如说使用五个哨兵。<br>但是，使用多个哨兵实例来降低误判率，其实相当于组成了一个哨兵集群，我们会因此面临着一些新的挑战，例如：</p>
<ul>
<li>哨兵集群中有实例挂了，怎么办，会影响主库状态判断和选主吗？</li>
<li>哨兵集群多数实例达成共识，判断出主库“客观下线”后，由哪个实例来执行主从切换呢？</li>
</ul>
<p>要搞懂这些问题，就不得不提哨兵集群了，下节课，我们来具体聊聊哨兵集群的机制和问题。</p>
<h3 id="总结2-4"><a href="#总结2-4" class="headerlink" title="总结2"></a>总结2</h3><p>一，作者讲了什么？<br>Redis故障转移：主从切换机制哨兵</p>
<p>二，作者是怎么把这事给讲明白的？<br>1，提出主从切换的三个问题：a，主机状态确认 b，新主库选举 c，新主库通知<br>2，讲解了哨兵的本质是一个特殊的redis进程（实例），有三个职责：监控，选主，通知</p>
<p>三，为了讲明白，作者讲了哪些要点，有哪些亮点？<br>1，亮点1：哨兵的本质：是一个redis实例，要做三件事：监控主库，选举新主库，通知客户端和从机（这让我对哨兵理解清晰了很多）<br>2，要点1：哨兵是通过心跳检测，监控主库状态，主库下线被分为：主观下线和客观下线、<br>3，要点2：哨兵监控是可能误判的，所以哨兵一般是集群部署，采取投票的形式减少误判<br>4，要点3：选定新主库规则是先筛选在打分，得分高的会被选为新主库，<br>5，要点4：筛选规则：从库当前的网络连接状况，以及之前的网络连接状况，筛选中断次数标准可以配置<br>6，要点5：打分规则：从库的优先级，数据同步状况，Id号大小，可以分为三轮，只要有一轮出现得分高的，就能选出</p>
<p>四，对作者所讲，我有哪些发散性思考？<br>选举机制，在分布式的场景中经常出现。我在刚开始学习这一类知识的时候，经常会想：那些大神是怎么会想到这种解决方案的？<br>后来读了一些西方社会运行机制的书，我有所释然。得到一些感悟：大神思考的技术问题解决方案，和他所生活的社会环境有着莫大的关系</p>
<p>五，将来在哪些场景，我能够使用到它？</p>
<p>六，留言区的收获<br>1，数据同步状况的判断：（感谢@Monday 同学的提问）<br>a：判断哪个从库的数据同步最接近主库，不是拿从库与主库比较，而是从库之间互相比较，谁大谁就是最接近的<br>b：这样做的原因有二：主库已下线无法获取主库信息，环形缓冲区的位置偏移量是单调递增的（主库的被称为：master_repl_offset，从库的被称为：slave_repl_offset，其实两者本质是相同的，叫不同的名字只是为了区分）<br>2，哨兵的使用：（感谢 @Kaito 大神简洁明了，无私的分享）<br>a：主库下线，可读不可写，写失败的时间=哨兵切换主从的时间+客户端感知新主库时间<br>b：主库下线无感知，需要客户端与哨兵配合改造：<br>1：哨兵主动通知：哨兵需要将最新的主库地址写入自己的pubsub中，客户端需要订阅这个pubsub，当这个pubsub有数据时，客户端就能感知到<br>2：客户端主动获取：客户端不将主从库写死，而是从哨兵集群中获取，从而始终获取最新的主从地址<br>c：集群分片模式的Redis集群，可以不使用哨兵机制（我们项目组就是这样的）</p>
<h3 id="问题-3"><a href="#问题-3" class="headerlink" title="问题"></a>问题</h3><p>按照惯例，我给你提个小问题。这节课，我提到，通过哨兵机制，可以实现主从库的自动切换，这是实现服务不间断的关键支撑，同时，我也提到了主从库切换是需要一定时间的。所以，请你考虑下，在这个切换过程中，客户端能否正常地进行请求操作呢？如果想要应用程序不感知服务的中断，还需要哨兵或需要客户端再做些什么吗？</p>
<h3 id="解答-3"><a href="#解答-3" class="headerlink" title="解答"></a>解答</h3><p>哨兵在操作主从切换的过程中，客户端能否正常地进行请求操作？</p>
<p>如果客户端使用了读写分离，那么读请求可以在从库上正常执行，不会受到影响。但是由于此时主库已经挂了，而且哨兵还没有选出新的主库，所以在这期间写请求会失败，失败持续的时间 = 哨兵切换主从的时间 + 客户端感知到新主库 的时间。</p>
<p>如果不想让业务感知到异常，客户端只能把写失败的请求先缓存起来或写入消息队列中间件中，等哨兵切换完主从后，再把这些写请求发给新的主库，但这种场景只适合对写入请求返回值不敏感的业务，而且还需要业务层做适配，另外主从切换时间过长，也会导致客户端或消息队列中间件缓存写请求过多，切换完成之后重放这些请求的时间变长。</p>
<p>哨兵检测主库多久没有响应就提升从库为新的主库，这个时间是可以配置的（down-after-milliseconds参数）。配置的时间越短，哨兵越敏感，哨兵集群认为主库在短时间内连不上就会发起主从切换，这种配置很可能因为网络拥塞但主库正常而发生不必要的切换，当然，当主库真正故障时，因为切换得及时，对业务的影响最小。如果配置的时间比较长，哨兵越保守，这种情况可以减少哨兵误判的概率，但是主库故障发生时，业务写失败的时间也会比较久，缓存写请求数据量越多。</p>
<p>应用程序不感知服务的中断，还需要哨兵和客户端做些什么？当哨兵完成主从切换后，客户端需要及时感知到主库发生了变更，然后把缓存的写请求写入到新库中，保证后续写请求不会再受到影响，具体做法如下：</p>
<p>哨兵提升一个从库为新主库后，哨兵会把新主库的地址写入自己实例的pubsub（switch-master）中。客户端需要订阅这个pubsub，当这个pubsub有数据时，客户端就能感知到主库发生变更，同时可以拿到最新的主库地址，然后把写请求写到这个新主库即可，这种机制属于哨兵主动通知客户端。</p>
<p>如果客户端因为某些原因错过了哨兵的通知，或者哨兵通知后客户端处理失败了，安全起见，客户端也需要支持主动去获取最新主从的地址进行访问。</p>
<p>所以，客户端需要访问主从库时，不能直接写死主从库的地址了，而是需要从哨兵集群中获取最新的地址（sentinel get-master-addr-by-name命令），这样当实例异常时，哨兵切换后或者客户端断开重连，都可以从哨兵集群中拿到最新的实例地址。</p>
<p>一般Redis的SDK都提供了通过哨兵拿到实例地址，再访问实例的方式，我们直接使用即可，不需要自己实现这些逻辑。当然，对于只有主从实例的情况，客户端需要和哨兵配合使用，而在分片集群模式下，这些逻辑都可以做在proxy层，这样客户端也不需要关心这些逻辑了，Codis就是这么做的。</p>
<p>另外再简单回答下哨兵相关的问题：</p>
<p>1、哨兵集群中有实例挂了，怎么办，会影响主库状态判断和选主吗？</p>
<p>这个属于分布式系统领域的问题了，指的是在分布式系统中，如果存在故障节点，整个集群是否还可以提供服务？而且提供的服务是正确的？</p>
<p>这是一个分布式系统容错问题，这方面最著名的就是分布式领域中的“拜占庭将军”问题了，“拜占庭将军问题”不仅解决了容错问题，还可以解决错误节点的问题，虽然比较复杂，但还是值得研究的，有兴趣的同学可以去了解下。</p>
<p>简单说结论：存在故障节点时，只要集群中大多数节点状态正常，集群依旧可以对外提供服务。具体推导过程细节很多，大家去查前面的资料了解就好。</p>
<p>2、哨兵集群多数实例达成共识，判断出主库“客观下线”后，由哪个实例来执行主从切换呢？</p>
<p>哨兵集群判断出主库“主观下线”后，会选出一个“哨兵领导者”，之后整个过程由它来完成主从切换。</p>
<p>但是如何选出“哨兵领导者”？这个问题也是一个分布式系统中的问题，就是我们经常听说的共识算法，指的是集群中多个节点如何就一个问题达成共识。共识算法有很多种，例如Paxos、Raft，这里哨兵集群采用的类似于Raft的共识算法。</p>
<p>简单来说就是每个哨兵设置一个随机超时时间，超时后每个哨兵会请求其他哨兵为自己投票，其他哨兵节点对收到的第一个请求进行投票确认，一轮投票下来后，首先达到多数选票的哨兵节点成为“哨兵领导者”，如果没有达到多数选票的哨兵节点，那么会重新选举，直到能够成功选出“哨兵领导者”。</p>
<h2 id="哨兵集群：哨兵挂了，如何服务"><a href="#哨兵集群：哨兵挂了，如何服务" class="headerlink" title="哨兵集群：哨兵挂了，如何服务"></a>哨兵集群：哨兵挂了，如何服务</h2><h3 id="总结1-6"><a href="#总结1-6" class="headerlink" title="总结1"></a>总结1</h3><p>通常，我们在解决一个系统问题的时候，会引入一个新机制，或者设计一层新功能，就像我们在这两节课学习的内容：为了实现主从切换，我们引入了哨兵；为了避免单个哨兵故障后无法进行主从切换，以及为了减少误判率，又引入了哨兵集群；哨兵集群又需要有一些机制来支撑它的正常运行。</p>
<p>这节课上，我就向你介绍了支持哨兵集群的这些关键机制，包括：</p>
<ul>
<li>基于 pub/sub 机制的哨兵集群组成过程；</li>
<li>基于 INFO 命令的从库列表，这可以帮助哨兵和从库建立连接；</li>
<li>基于哨兵自身的 pub/sub 功能，这实现了客户端和哨兵之间的事件通知。</li>
</ul>
<p>对于主从切换，当然不是哪个哨兵想执行就可以执行的，否则就乱套了。所以，这就需要哨兵集群在判断了主库“客观下线”后，经过投票仲裁，选举一个 Leader 出来，由它负责实际的主从切换，即由它来完成新主库的选择以及通知从库与客户端。</p>
<p>最后，我想再给你分享一个经验：要保证所有哨兵实例的配置是一致的，尤其是主观下线的判断值 down-after-milliseconds。我们曾经就踩过一个“坑”。当时，在我们的项目中，因为这个值在不同的哨兵实例上配置不一致，导致哨兵集群一直没有对有故障的主库形成共识，也就没有及时切换主库，最终的结果就是集群服务不稳定。所以，你一定不要忽略这条看似简单的经验。</p>
<h3 id="总结2-5"><a href="#总结2-5" class="headerlink" title="总结2"></a>总结2</h3><p>一，作者讲了什么？<br>哨兵集群的工作机制</p>
<p>二，作者是怎么把这事给讲明白的？<br>1，哨兵之间互通机制：基于pub/sub机制，在主库中有一个”<strong>sentinel</strong>:hello”的频道，哨兵之间互相发现通信<br>2，哨兵与主从库互通机制：哨兵向主库发送INFO指令，可以获取所有从库的信息，实现对主库，从库的监控<br>3，哨兵判定主库异常机制：哨兵集群中任意一个实例都可以发起主库异常“投票仲裁”流程</p>
<p>三，为了讲明白，作者都讲了哪些要点？有哪些亮点？<br>1，亮点1：哨兵之间的互动是通过发布订阅机制完成的，利用自身的特性来实现。这让我联想到kafka对于日息位置偏移量的管理<br>2，要点1：哨兵之间通信不是哨兵之间之间联系，而是通过订阅主库的同一频道来获取彼此的信息<br>3，要点2：哨兵是通过INFO指令，从主库获取从库信息，并与每个从库建立连接，监控所有主从库状态<br>4，要点3：哨兵是一个特殊的redis实例，所以客户端可以订阅哨兵的指定频道获得redis主从库的信息<br>5，要点4：哨兵集群执行主从切换机制：谁发现，谁就发起投票流程，谁获得多数票，谁就是哨兵Leader，由Leader负责主从库切换<br>6，要点5：哨兵集群Leader选举成功与否，依赖于网络通信状况，网络拥塞会导致选举失败，重新进行新一轮选举</p>
<p>四，对于作者所讲，我有哪些发散性思考？</p>
<p>五，在未来的哪些场景里，我可以使用它？</p>
<p>六，留言区的收获：（感谢 @ 小喵喵 的提问）<br>1，哨兵投票机制：<br>a：哨兵实例只有在自己判定主库下线时，才会给自己投票，而其他的哨兵实例会把票投给第一个来要票的请求，其后的都拒绝<br>b：如果出现多个哨兵同时发现主库下线并给自己投票，导致投票选举失败，就会触发新一轮投票，直至成功</p>
<p>2，哨兵Leader切换主从库的机制：（感谢 @Kaito ，@Darren 大神的解答）<br>        哨兵成为Leader的必要条件：a：获得半数以上的票数，b：得到的票数要达到配置的quorum阀值<br>        主从切换只能由Leader执行，而成为Leader有两个必要的条件，所以当哨兵集群中实例异常过多时，会导致主从库无法切换</p>
<h3 id="问题-4"><a href="#问题-4" class="headerlink" title="问题"></a>问题</h3><p>假设有一个 Redis 集群，是“一主四从”，同时配置了包含 5 个哨兵实例的集群，quorum 值设为 2。在运行过程中，如果有 3 个哨兵实例都发生故障了，此时，Redis 主库如果有故障，还能正确地判断主库“客观下线”吗？如果可以的话，还能进行主从库自动切换吗？此外，哨兵实例是不是越多越好呢，如果同时调大 down-after-milliseconds 值，对减少误判是不是也有好处呢？</p>
<h3 id="解答-4"><a href="#解答-4" class="headerlink" title="解答"></a>解答</h3><p>Redis 1主4从，5个哨兵，哨兵配置quorum为2，如果3个哨兵故障，当主库宕机时，哨兵能否判断主库“客观下线”？能否自动切换？</p>
<p>经过实际测试，我的结论如下：</p>
<p>1、哨兵集群可以判定主库“主观下线”。由于quorum=2，所以当一个哨兵判断主库“主观下线”后，询问另外一个哨兵后也会得到同样的结果，2个哨兵都判定“主观下线”，达到了quorum的值，因此，哨兵集群可以判定主库为“客观下线”。</p>
<p>2、但哨兵不能完成主从切换。哨兵标记主库“客观下线后”，在选举“哨兵领导者”时，一个哨兵必须拿到超过多数的选票(5/2+1=3票)。但目前只有2个哨兵活着，无论怎么投票，一个哨兵最多只能拿到2票，永远无法达到多数选票的结果。</p>
<p>但是投票选举过程的细节并不是大家认为的：每个哨兵各自1票，这个情况是不一定的。下面具体说一下：</p>
<p>场景a：哨兵A先判定主库“主观下线”，然后马上询问哨兵B（注意，此时哨兵B只是被动接受询问，并没有去询问哨兵A，也就是它还没有进入判定“客观下线”的流程），哨兵B回复主库已“主观下线”，达到quorum=2后哨兵A此时可以判定主库“客观下线”。此时，哨兵A马上可以向其他哨兵发起成为“哨兵领导者”的投票，哨兵B收到投票请求后，由于自己还没有询问哨兵A进入判定“客观下线”的流程，所以哨兵B是可以给哨兵A投票确认的，这样哨兵A就已经拿到2票了。等稍后哨兵B也判定“主观下线”后想成为领导者时，因为它已经给别人投过票了，所以这一轮自己就不能再成为领导者了。</p>
<p>场景b：哨兵A和哨兵B同时判定主库“主观下线”，然后同时询问对方后都得到可以“客观下线”的结论，此时它们各自给自己投上1票后，然后向其他哨兵发起投票请求，但是因为各自都给自己投过票了，因此各自都拒绝了对方的投票请求，这样2个哨兵各自持有1票。</p>
<p>场景a是1个哨兵拿到2票，场景b是2个哨兵各自有1票，这2种情况都不满足大多数选票(3票)的结果，因此无法完成主从切换。</p>
<p>经过测试发现，场景b发生的概率非常小，只有2个哨兵同时进入判定“主观下线”的流程时才可以发生。我测试几次后发现，都是复现的场景a。</p>
<p>哨兵实例是不是越多越好？</p>
<p>并不是，我们也看到了，哨兵在判定“主观下线”和选举“哨兵领导者”时，都需要和其他节点进行通信，交换信息，哨兵实例越多，通信的次数也就越多，而且部署多个哨兵时，会分布在不同机器上，节点越多带来的机器故障风险也会越大，这些问题都会影响到哨兵的通信和选举，出问题时也就意味着选举时间会变长，切换主从的时间变久。</p>
<p>调大down-after-milliseconds值，对减少误判是不是有好处？</p>
<p>是有好处的，适当调大down-after-milliseconds值，当哨兵与主库之间网络存在短时波动时，可以降低误判的概率。但是调大down-after-milliseconds值也意味着主从切换的时间会变长，对业务的影响时间越久，我们需要根据实际场景进行权衡，设置合理的阈值。</p>
<h2 id="切片集群：是增加内存还是增加实例"><a href="#切片集群：是增加内存还是增加实例" class="headerlink" title="切片集群：是增加内存还是增加实例"></a>切片集群：是增加内存还是增加实例</h2><h3 id="总结1-7"><a href="#总结1-7" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我们学习了切片集群在保存大量数据方面的优势，以及基于哈希槽的数据分布机制和客户端定位键值对的方法。</p>
<p>在应对数据量扩容时，虽然增加内存这种纵向扩展的方法简单直接，但是会造成数据库的内存过大，导致性能变慢。Redis 切片集群提供了横向扩展的模式，也就是使用多个实例，并给每个实例配置一定数量的哈希槽，数据可以通过键的哈希值映射到哈希槽，再通过哈希槽分散保存到不同的实例上。这样做的好处是扩展性好，不管有多少数据，切片集群都能应对。</p>
<p>另外，集群的实例增减，或者是为了实现负载均衡而进行的数据重新分布，会导致哈希槽和实例的映射关系发生变化，客户端发送请求时，会收到命令执行报错信息。了解了 MOVED 和 ASK 命令，你就不会为这类报错而头疼了。</p>
<p>我刚刚说过，在 Redis 3.0 之前，Redis 官方并没有提供切片集群方案，但是，其实当时业界已经有了一些切片集群的方案，例如基于客户端分区的 ShardedJedis，基于代理的 Codis、Twemproxy 等。这些方案的应用早于 Redis Cluster 方案，在支撑的集群实例规模、集群稳定性、客户端友好性方面也都有着各自的优势，我会在后面的课程中，专门和你聊聊这些方案的实现机制，以及实践经验。这样一来，当你再碰到业务发展带来的数据量巨大的难题时，就可以根据这些方案的特点，选择合适的方案实现切片集群，以应对业务需求了。</p>
<h3 id="总结2-6"><a href="#总结2-6" class="headerlink" title="总结2"></a>总结2</h3><p>1，作者讲了什么？<br>切片集群</p>
<p>2，作者是怎么把事给讲明白的？<br>从一个案例入手，讲到单实例内存过大在数据备份时会导致Redis性能下降，<br>引出redis分片集群来解决大数据量，高性能的设计<br>提出两个关键问题：数据分片与实例间如何建立对应关系，2，客户端如何知晓去哪个实例中获取数据</p>
<p>3，为了讲明白，作者讲了哪些要点？有哪些亮点？<br>1，亮点1：这一课我更加清晰的明白了之前别人聊Redis扩容中的纵向扩容和横向扩容的真实含义和区别<br>2，要点1：数据分片和实例的对应关系建立：按照CRC16算法计算一个key的16bit的值，在将这值对16384取模<br>3，要点2：一个切片集群的槽位是固定的16384个，可手动分配每个实例的槽位，但必须将槽位全部分完<br>4，要点3：客户端如何确定要访问那个实例获取数据：1从任意个实例获取并缓存在自己本地，2，重定向机制<br>5，要点4：重定向机制：客户端访问的实例没有数据，被访问实例响应move命令，告诉客户端指向新的实例地址<br>6，要点5：ASK命令：1，表明数据正在迁移 2，告知客户端数据所在的实例<br>7，要点6：ASK命令和MOVE命令的区别：<br>move命令是在数据迁移完毕后被响应，客户端会更新本地缓存。<br>ASK命令是在数据迁移中被响应，不会让客户端更新缓存</p>
<p>4，对作者所讲，我有哪些发散性思考？<br>对于CRC16算法，应该可以用到我们系统当中，对所有手机的设备号进行计算取模，用于分表存储数据<br>在系统设计时，可以通过分层或增加一层来提升系统设计的弹性</p>
<p>5，在将来的那些场景中，我能够使用它？</p>
<p>6，留言区的收获（来自 @Kaito 大神）<br>1，Redis Cluster不采用直接把key映射到实例，而采用哈希槽的方式原因：可用使Redis集群设计：简洁，高效，有弹性<br>不使用的劣势<br>①：集群中的key无法预估，直接存key对应实例的映射关系，需占用的内存空间不可控<br>②：Cluster是去中心化设计，所有实例都需保存完整的映射关系，<br>采用直接的映射，会导致节点间信息交换成本高昂<br>③：key与实例直接映射，在集群扩缩容时，需要数据迁移，所有的key都需要重新映射<br>使用的好处<br>①：在中间增加一层哈希槽，可以将数据与节点解耦，使数据分配均匀<br>key通过hsah计算在取模，可以把数据打的更散，<br>只需要关心映射到了哪个哈希槽，通过哈希槽映射表找到对应的实例<br>②：增加哈希槽可以使得映射表比较小，有利于客户端和服务端保存，节点间信息交换<br>③：集群扩缩容，数据均衡时，操作单位是哈希槽，可以简化操作难度</p>
<p>2，Redis集群方案的两个关键问题：<br>    ①：请求路由<br>    ②：数据迁移</p>
<h3 id="问题-5"><a href="#问题-5" class="headerlink" title="问题"></a>问题</h3><p>Redis Cluster 方案通过哈希槽的方式把键值对分配到不同的实例上，这个过程需要对键值对的 key 做 CRC 计算，然后再和哈希槽做映射，这样做有什么好处吗？如果用一个表直接把键值对和实例的对应关系记录下来（例如键值对 1 在实例 2 上，键值对 2 在实例 1 上），这样就不用计算 key 和哈希槽的对应关系了，只用查表就行了，Redis 为什么不这么做呢？</p>
<h3 id="解答-5"><a href="#解答-5" class="headerlink" title="解答"></a>解答</h3><p>Redis Cluster不采用把key直接映射到实例的方式，而采用哈希槽的方式原因：</p>
<p>1、整个集群存储key的数量是无法预估的，key的数量非常多时，直接记录每个key对应的实例映射关系，这个映射表会非常庞大，这个映射表无论是存储在服务端还是客户端都占用了非常大的内存空间。</p>
<p>2、Redis Cluster采用无中心化的模式（无proxy，客户端与服务端直连），客户端在某个节点访问一个key，如果这个key不在这个节点上，这个节点需要有纠正客户端路由到正确节点的能力（MOVED响应），这就需要节点之间互相交换路由表，每个节点拥有整个集群完整的路由关系。如果存储的都是key与实例的对应关系，节点之间交换信息也会变得非常庞大，消耗过多的网络资源，而且就算交换完成，相当于每个节点都需要额外存储其他节点的路由表，内存占用过大造成资源浪费。</p>
<p>3、当集群在扩容、缩容、数据均衡时，节点之间会发生数据迁移，迁移时需要修改每个key的映射关系，维护成本高。</p>
<p>4、而在中间增加一层哈希槽，可以把数据和节点解耦，key通过Hash计算，只需要关心映射到了哪个哈希槽，然后再通过哈希槽和节点的映射表找到节点，相当于消耗了很少的CPU资源，不但让数据分布更均匀，还可以让这个映射表变得很小，利于客户端和服务端保存，节点之间交换信息时也变得轻量。</p>
<p>5、当集群在扩容、缩容、数据均衡时，节点之间的操作例如数据迁移，都以哈希槽为基本单位进行操作，简化了节点扩容、缩容的难度，便于集群的维护和管理。</p>
<p>另外，我想补充一下Redis集群相关的知识，以及我的理解：</p>
<p>Redis使用集群方案就是为了解决单个节点数据量大、写入量大产生的性能瓶颈的问题。多个节点组成一个集群，可以提高集群的性能和可靠性，但随之而来的就是集群的管理问题，最核心问题有2个：请求路由、数据迁移（扩容/缩容/数据平衡）。</p>
<p>1、请求路由：一般都是采用哈希槽的映射关系表找到指定节点，然后在这个节点上操作的方案。</p>
<p>Redis Cluster在每个节点记录完整的映射关系(便于纠正客户端的错误路由请求)，同时也发给客户端让客户端缓存一份，便于客户端直接找到指定节点，客户端与服务端配合完成数据的路由，这需要业务在使用Redis Cluster时，必须升级为集群版的SDK才支持客户端和服务端的协议交互。</p>
<p>其他Redis集群化方案例如Twemproxy、Codis都是中心化模式（增加Proxy层），客户端通过Proxy对整个集群进行操作，Proxy后面可以挂N多个Redis实例，Proxy层维护了路由的转发逻辑。操作Proxy就像是操作一个普通Redis一样，客户端也不需要更换SDK，而Redis Cluster是把这些路由逻辑做在了SDK中。当然，增加一层Proxy也会带来一定的性能损耗。</p>
<p>2、数据迁移：当集群节点不足以支撑业务需求时，就需要扩容节点，扩容就意味着节点之间的数据需要做迁移，而迁移过程中是否会影响到业务，这也是判定一个集群方案是否成熟的标准。</p>
<p>Twemproxy不支持在线扩容，它只解决了请求路由的问题，扩容时需要停机做数据重新分配。而Redis Cluster和Codis都做到了在线扩容（不影响业务或对业务的影响非常小），重点就是在数据迁移过程中，客户端对于正在迁移的key进行操作时，集群如何处理？还要保证响应正确的结果？</p>
<p>Redis Cluster和Codis都需要服务端和客户端/Proxy层互相配合，迁移过程中，服务端针对正在迁移的key，需要让客户端或Proxy去新节点访问（重定向），这个过程就是为了保证业务在访问这些key时依旧不受影响，而且可以得到正确的结果。由于重定向的存在，所以这个期间的访问延迟会变大。等迁移完成之后，Redis Cluster每个节点会更新路由映射表，同时也会让客户端感知到，更新客户端缓存。Codis会在Proxy层更新路由表，客户端在整个过程中无感知。</p>
<p>除了访问正确的节点之外，数据迁移过程中还需要解决异常情况（迁移超时、迁移失败）、性能问题（如何让数据迁移更快、bigkey如何处理），这个过程中的细节也很多。</p>
<p>Redis Cluster的数据迁移是同步的，迁移一个key会同时阻塞源节点和目标节点，迁移过程中会有性能问题。而Codis提供了异步迁移数据的方案，迁移速度更快，对性能影响最小，当然，实现方案也比较复杂。</p>
<h2 id="string为什么不好用了"><a href="#string为什么不好用了" class="headerlink" title="string为什么不好用了"></a>string为什么不好用了</h2><h3 id="总结1-8"><a href="#总结1-8" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我们打破了对 String 的认知误区，以前，我们认为 String 是“万金油”，什么场合都适用，但是，在保存的键值对本身占用的内存空间不大时（例如这节课里提到的的图片 ID 和图片存储对象 ID），String 类型的元数据开销就占据主导了，这里面包括了 RedisObject 结构、SDS 结构、dictEntry 结构的内存开销。</p>
<p>针对这种情况，我们可以使用压缩列表保存数据。当然，使用 Hash 这种集合类型保存单值键值对的数据时，我们需要将单值数据拆分成两部分，分别作为 Hash 集合的键和值，就像刚才案例中用二级编码来表示图片 ID，希望你能把这个方法用到自己的场景中。</p>
<p>最后，我还想再给你提供一个小方法：如果你想知道键值对采用不同类型保存时的内存开销，可以在这个网址里输入你的键值对长度和使用的数据类型，这样就能知道实际消耗的内存大小了。建议你把这个小工具用起来，它可以帮助你充分地节省内存。</p>
<h3 id="总结2-7"><a href="#总结2-7" class="headerlink" title="总结2"></a>总结2</h3><p>一，作者讲了什么？<br>Redis的String类型数据结构，及其底层实现<br>二，作者是怎么把这事给说明白的？<br>1，通过一个图片存储的案例，讲通过合理利用Redis的数据结构，降低资源消耗</p>
<p>三，为了讲明白，作者讲了哪些要点？有哪些亮点？<br>1，亮点1：String类型的数据占用内存，分别是被谁占用了<br>2，亮点2：可以巧妙的利用Redis的底层数据结构特性，降低资源消耗<br>3，要点1： Simple Dynamic String结构体（<br>buf：字节数组，为了表示字节结束，会在结尾增加“\0”<br>len： 占4个字节，表示buf的已用长度<br>alloc：占4个字节，表示buf实际分配的长度，一般大于len）</p>
<p>4，要点2： RedisObject 结构体（<br>元数据：8字节（用于记录最后一次访问时间，被引用次数。。。）<br>指针：8字节，指向具体数据类型的实际数据所在 ）</p>
<p>5，要点3：dicEntry 结构体（<br>key：8个字节指针，指向key<br>value：8个字节指针，指向value<br>next：指向下一个dicEntry）<br>6，要点4：ziplist(压缩列表)（<br>zlbytes：在表头，表示列表长度<br>zltail：在表头，表示列尾偏移量<br>zllen：在表头，表示列表中<br>entry：保存数据对象模型<br>zlend：在表尾，表示列表结束）<br>entry：（<br>prev_len：表示一个entry的长度，有两种取值方式：1字节或5字节。<br>1字节表示一个entry小于254字节，255是zlend的默认值，所以不使用。<br>len：表示自身长度，4字节<br>encodeing：表示编码方式，1字节<br>content：保存实际数据）</p>
<p>5，要点4：String类型的内存空间消耗<br>①，保存Long类型时，指针直接保存整数数据值，可以节省空间开销（被称为：int编码）<br>②，保存字符串，且不大于44字节时，RedisObject的元数据，指针和SDS是连续的，可以避免内存碎片（被称为：embstr编码）<br>③，当保存的字符串大于44字节时，SDS的数据量变多，Redis会给SDS分配独立的空间，并用指针指向SDS结构（被称为：raw编码）<br>④，Redis使用一个全局哈希表保存所以键值对，哈希表的每一项都是一个dicEntry，每个dicEntry占用32字节空间<br>⑤，dicEntry自身24字节，但会占用32字节空间，是因为Redis使用了内存分配库jemalloc。<br>jemalloc在分配内存时，会根据申请的字节数N，找一个比N大，但最接近N的2的幂次数作为分配空间，这样可以减少频繁分配内存的次数</p>
<p>4，要点5：使用什么数据结构可以节省内存？<br>①， 压缩列表，是一种非常节省内存的数据结构，因为他使用连续的内存空间保存数据，不需要额外的指针进行连接<br>②，Redis基于压缩列表实现List，Hash，Sorted Set集合类型，最大的好处是节省了dicEntry开销</p>
<p>5，要点6：如何使用集合类型保存键值对？<br>①，Hash类型设置了用压缩列表保存数据时的两个阀值，一旦超过就会将压缩列表转为哈希表，且不可回退<br>②，hash-max-ziplist-entries：表示用压缩列表保存哈希集合中的最大元素个数<br>③，hash-max-ziplist-value：表示用压缩列表保存时，哈希集合中单个元素的最大长度</p>
<p>四，对于作者所讲，我有哪些发散性思考？<br>看了老师讲解，做了笔记，又看了黄建宏写的《Redis 设计与实现》<br>有这样的讲解：<br>当哈希对象可以同时满足以下两个条件时， 哈希对象使用 ziplist 编码：</p>
<ol>
<li>哈希对象保存的所有键值对的键和值的字符串长度都小于 64 字节；</li>
<li>哈希对象保存的键值对数量小于 512 个；</li>
</ol>
<p>五，在将来的哪些场景中，我能够使用它？<br>这次学习Redis数据结构特性有了更多了解，在以后可以更加有信心根据业务需要，选取特定的数据结构</p>
<h3 id="问题-6"><a href="#问题-6" class="headerlink" title="问题"></a>问题</h3><p>除了 String 类型和 Hash 类型，你觉得，还有其他合适的类型可以应用在这节课所说的保存图片的例子吗？</p>
<h3 id="解答-6"><a href="#解答-6" class="headerlink" title="解答"></a>解答</h3><p>保存图片的例子，除了用String和Hash存储之外，还可以用Sorted Set存储（勉强）。</p>
<p>Sorted Set与Hash类似，当元素数量少于zset-max-ziplist-entries，并且每个元素内存占用小于zset-max-ziplist-value时，默认也采用ziplist结构存储。我们可以把zset-max-ziplist-entries参数设置为1000，这样Sorted Set默认就会使用ziplist存储了，member和score也会紧凑排列存储，可以节省内存空间。</p>
<p>使用zadd 1101000 3302000080 060命令存储图片ID和对象ID的映射关系，查询时使用zscore 1101000 060获取结果。</p>
<p>但是Sorted Set使用ziplist存储时的缺点是，这个ziplist是需要按照score排序的（为了方便zrange和zrevrange命令的使用），所以在插入一个元素时，需要先根据score找到对应的位置，然后把member和score插入进去，这也意味着Sorted Set插入元素的性能没有Hash高（这也是前面说勉强能用Sorte Set存储的原因）。而Hash在插入元素时，只需要将新的元素插入到ziplist的尾部即可，不需要定位到指定位置。</p>
<p>不管是使用Hash还是Sorted Set，当采用ziplist方式存储时，虽然可以节省内存空间，但是在查询指定元素时，都要遍历整个ziplist，找到指定的元素。所以使用ziplist方式存储时，虽然可以利用CPU高速缓存，但也不适合存储过多的数据（hash-max-ziplist-entries和zset-max-ziplist-entries不宜设置过大），否则查询性能就会下降比较厉害。整体来说，这样的方案就是时间换空间，我们需要权衡使用。</p>
<p>当使用ziplist存储时，我们尽量存储int数据，ziplist在设计时每个entry都进行了优化，针对要存储的数据，会尽量选择占用内存小的方式存储（整数比字符串在存储时占用内存更小），这也有利于我们节省Redis的内存。还有，因为ziplist是每个元素紧凑排列，而且每个元素存储了上一个元素的长度，所以当修改其中一个元素超过一定大小时，会引发多个元素的级联调整（前面一个元素发生大的变动，后面的元素都要重新排列位置，重新分配内存），这也会引发性能问题，需要注意。</p>
<p>另外，使用Hash和Sorted Set存储时，虽然节省了内存空间，但是设置过期变得困难（无法控制每个元素的过期，只能整个key设置过期，或者业务层单独维护每个元素过期删除的逻辑，但比较复杂）。而使用String虽然占用内存多，但是每个key都可以单独设置过期时间，还可以设置maxmemory和淘汰策略，以这种方式控制整个实例的内存上限。</p>
<p>所以在选用Hash和Sorted Set存储时，意味着把Redis当做数据库使用，这样就需要务必保证Redis的可靠性（做好备份、主从副本），防止实例宕机引发数据丢失的风险。而采用String存储时，可以把Redis当做缓存使用，每个key设置过期时间，同时设置maxmemory和淘汰策略，控制整个实例的内存上限，这种方案需要在数据库层（例如MySQL）也存储一份映射关系，当Redis中的缓存过期或被淘汰时，需要从数据库中重新查询重建缓存，同时需要保证数据库和缓存的一致性，这些逻辑也需要编写业务代码实现。</p>
<p>总之，各有利弊，我们需要根据实际场景进行选择。</p>
<h2 id="一亿keys要统计，用哪种集合"><a href="#一亿keys要统计，用哪种集合" class="headerlink" title="一亿keys要统计，用哪种集合"></a>一亿keys要统计，用哪种集合</h2><h3 id="总结1-9"><a href="#总结1-9" class="headerlink" title="总结1"></a>总结1</h3><p><img src="/images/redis/datastruct-02.png" alt="img.png"><br>可以看到，Set 和 Sorted Set 都支持多种聚合统计，不过，对于差集计算来说，只有 Set 支持。Bitmap 也能做多个 Bitmap 间的聚合计算，包括与、或和异或操作。</p>
<p>当需要进行排序统计时，List 中的元素虽然有序，但是一旦有新元素插入，原来的元素在 List 中的位置就会移动，那么，按位置读取的排序结果可能就不准确了。而 Sorted Set 本身是按照集合元素的权重排序，可以准确地按序获取结果，所以建议你优先使用它。</p>
<p>如果我们记录的数据只有 0 和 1 两个值的状态，Bitmap 会是一个很好的选择，这主要归功于 Bitmap 对于一个数据只用 1 个 bit 记录，可以节省内存。</p>
<p>对于基数统计来说，如果集合元素量达到亿级别而且不需要精确统计时，我建议你使用 HyperLogLog。</p>
<h3 id="总结2-8"><a href="#总结2-8" class="headerlink" title="总结2"></a>总结2</h3><p>1，作者讲了什么？<br>1，Redis有那些数据结构适合做统计</p>
<p>2，作者是怎么把这事给讲明白的？<br>1，列举了常见的数据统计需求。从实际需求出发，推荐适合的数据类型，讲解了怎么用，并解答这种数据结构为什么可以<br>2，将数据统计需求，分了四类，分类分别讲解</p>
<p>3，为了讲明白，作者讲了哪些要点，有哪些亮点？<br>1，亮点1：BITMAP的特性和使用场景，方式<br>2，亮点2：HyperLogLog的特性和使用场景，方式<br>3，要点1：日常的统计需求可以分为四类：聚合，排序，二值状态，基数，选用适合的数据类型可以实现即快速又节省内存<br>4，要点2：聚合统计，可以选用Set类型完成，但Set的差，并，交集操作复杂度高，在数据量大的时候会阻塞主进程<br>5，要点3：排序统计，可以选用List和Sorted Set<br>6，要点4：二值状态统计：Bitmap本身是用String类型作为底层数据结构实现，String类型会保存为二进制字节数组，所以可以看作是一个bit数组<br>7，要点5：基数统计：HyperLogLog ,计算基数所需空间总是固定的，而且很小。但要注意，HyperLogLog是统计规则是基于概率完成的，不是非常准确</p>
<p>4，对于作者所讲，我有那些发散性思考？<br>1，对于统计用户的打卡情况，我们项目组也做了这个需求，但遗憾的是我们没有采用bitmap这种方案，而是使用了 sortSet<br>2，HyperLogLog可以考虑使用到，我们项目中的统计视频播放次数，现在这块，我们的方案是，每天产生一个key，单调递增。在通过定时任务，将缓存中的结果，每天一条数据记录，存入数据库</p>
<p>5，在将来的那些场景中，我能够使用它？</p>
<p>6，留言区的收获</p>
<p>1，主从库模式使用Set数据类型聚合命令(来自 @kaito 大神)<br>①：使用SUNIONSTORE，SDIFFSTORE，SINTERSTOR做并集，差集，交集时，这三个命令都会在Redis中生成一个新key,而从库默认是readOnly。所以这些命令只能在主库上使用<br>②：SUNION，SDIFF,SINTER，这些命令可以计算出结果，不产生新的key可以在从库使用</p>
<h3 id="问题-7"><a href="#问题-7" class="headerlink" title="问题"></a>问题</h3><p>这节课，我们学习了 4 种典型的统计模式，以及各种集合类型的支持情况和优缺点，我想请你聊一聊，你还遇到过其他的统计场景吗？用的是怎样的集合类型呢？</p>
<h3 id="解答-7"><a href="#解答-7" class="headerlink" title="解答"></a>解答</h3><p>使用Sorted Set可以实现统计一段时间内的在线用户数：用户上线时使用zadd online_users $timestamp $user_id把用户添加到Sorted Set中，使用zcount online_users $start_timestamp $end_timestamp就可以得出指定时间段内的在线用户数。</p>
<p>如果key是以天划分的，还可以执行zinterstore online_users_tmp 2 online_users_{date1} online_users_{date2} aggregate max，把结果存储到online_users_tmp中，然后通过zrange online_users_tmp 0 -1 withscores就可以得到这2天都在线过的用户，并且score就是这些用户最近一次的上线时间。</p>
<p>还有一个有意思的方式，使用Set记录数据，再使用zunionstore命令求并集。例如sadd user1 apple orange banana、sadd user2 apple banana peach记录2个用户喜欢的水果，使用zunionstore fruits_union 2 user1 user2把结果存储到fruits_union这个key中，zrange fruits_union 0 -1 withscores可以得出每种水果被喜欢的次数。</p>
<p>使用HyperLogLog计算UV时，补充一点，还可以使用pfcount page1:uv page2:uv page3:uv或pfmerge page_union:uv page1:uv page2:uv page3:uv得出3个页面的UV总和。</p>
<p>另外，需要指出老师文章描述不严谨的地方：“Set数据类型，使用SUNIONSTORE、SDIFFSTORE、SINTERSTORE做并集、差集、交集时，选择一个从库进行聚合计算”。这3个命令都会在Redis中生成一个新key，而从库默认是readonly不可写的，所以这些命令只能在主库使用。想在从库上操作，可以使用SUNION、SDIFF、SINTER，这些命令可以计算出结果，但不会生成新key。</p>
<p>最后需要提醒一下：</p>
<p>1、如果是在集群模式使用多个key聚合计算的命令，一定要注意，因为这些key可能分布在不同的实例上，多个实例之间是无法做聚合运算的，这样操作可能会直接报错或者得到的结果是错误的！</p>
<p>2、当数据量非常大时，使用这些统计命令，因为复杂度较高，可能会有阻塞Redis的风险，建议把这些统计数据与在线业务数据拆分开，实例单独部署，防止在做统计操作时影响到在线业务。</p>
<h2 id="GEO"><a href="#GEO" class="headerlink" title="GEO"></a>GEO</h2><h3 id="总结1-10"><a href="#总结1-10" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我们学习了 Redis 的扩展数据类型 GEO。GEO 可以记录经纬度形式的地理位置信息，被广泛地应用在 LBS 服务中。GEO 本身并没有设计新的底层数据结构，而是直接使用了 Sorted Set 集合类型。</p>
<p>GEO 类型使用 GeoHash 编码方法实现了经纬度到 Sorted Set 中元素权重分数的转换，这其中的两个关键机制就是对二维地图做区间划分，以及对区间进行编码。一组经纬度落在某个区间后，就用区间的编码值来表示，并把编码值作为 Sorted Set 元素的权重分数。这样一来，我们就可以把经纬度保存到 Sorted Set 中，利用 Sorted Set 提供的“按权重进行有序范围查找”的特性，实现 LBS 服务中频繁使用的“搜索附近”的需求。</p>
<p>GEO 属于 Redis 提供的扩展数据类型。扩展数据类型有两种实现途径：一种是基于现有的数据类型，通过数据编码或是实现新的操作的方式，来实现扩展数据类型，例如基于 Sorted Set 和 GeoHash 编码实现 GEO，以及基于 String 和位操作实现 Bitmap；另一种就是开发自定义的数据类型，具体的操作是增加新数据类型的定义，实现创建和释放函数，实现新数据类型支持的命令操作，建议你尝试着把今天学到的内容灵活地应用到你的工作场景中。</p>
<h3 id="总结2-9"><a href="#总结2-9" class="headerlink" title="总结2"></a>总结2</h3><p>1，作者讲了什么？<br>Redis的三种扩展数据类型之一：GEO，一种可以实现LBS服务的数据结构</p>
<p>2，作者是怎么把这事给讲明白的？<br>1，提出一个真问题：打车软件是怎么基于位置提供服务的<br>2，通过GEO原理讲解，说明GEO为什么可以</p>
<p>3，作者为了把这事给讲清楚，讲了那些要点？有哪些亮点？<br>1，亮点1：GEO的原理，这个是我之前所不知道的，学完后对GEO有了一些认知<br>2，亮点2：Redis居然支持自定义数据存储结构，这打开了我的眼界<br>3，要点1：GEO的底层实现，是sortSet，元素是车辆信息，权重是车辆经纬度转换过来的float值<br>4，要点2：GEOHash编码，基本原理“二分区间，区间编码”（二分法的应用，将一个值编码成N位的二进制值）<br>5，要点3：GEO使用GEOHash编码后，将经纬度，按照纬奇经偶位分别填充组合，得到一个车辆的经纬度编码值<br>6，要点4：GEOHash编码实现的效果是将一个空间分割成为一个个方块，可以实现LBS服务（但编码值相近，不一定位置相近）</p>
<p>4，对于作者所讲，我有哪些发散性思考？<br>①：这一篇讲了通过Redis的GEO数据类型可以实现LBS服务，让我体验到了算法的巧妙应用带来的巨大便利（这应是科技让生活更美好的实例）。<br>②：不过，我觉得最大的惊喜在于作者介绍了如何自定义一种新的数据类型，虽然我尚未掌握开发新数据类型的能力。<br>③：通过作者的讲解，拓宽了我了见识，这让我体验到了购买专栏的价值（如果都是搜索引擎能解决的事，何必买专栏）。<br>④：作者细致的讲解开发过程，也让我对Redis的数据结构，RedisObjecti有了进一步认识（面向对象等）</p>
<p>5，在未来的那些场景中，我能够使用它？<br>redis采用的GEOHash算法，貌似可以协助我们处理分省的一些业务</p>
<h3 id="问题-8"><a href="#问题-8" class="headerlink" title="问题"></a>问题</h3><p>我想请你来聊一聊，你在日常的实践过程中，还用过 Redis 的其他数据类型吗？</p>
<h3 id="解答-8"><a href="#解答-8" class="headerlink" title="解答"></a>解答</h3><p>Redis也可以使用List数据类型当做队列使用，一个客户端使用rpush生产数据到Redis中，另一个客户端使用lpop取出数据进行消费，非常方便。但要注意的是，使用List当做队列，缺点是没有ack机制和不支持多个消费者。没有ack机制会导致从Redis中取出的数据后，如果客户端处理失败了，取出的这个数据相当于丢失了，无法重新消费。所以使用List用作队列适合于对于丢失数据不敏感的业务场景，但它的优点是，因为都是内存操作，所以非常快和轻量。</p>
<p>而Redis提供的PubSub，可以支持多个消费者进行消费，生产者发布一条消息，多个消费者同时订阅消费。但是它的缺点是，如果任意一个消费者挂了，等恢复过来后，在这期间的生产者的数据就丢失了。PubSub只把数据发给在线的消费者，消费者一旦下线，就会丢弃数据。另一个缺点是，PubSub中的数据不支持数据持久化，当Redis宕机恢复后，其他类型的数据都可以从RDB和AOF中恢复回来，但PubSub不行，它就是简单的基于内存的多播机制。</p>
<p>之后Redis 5.0推出了Stream数据结构，它借鉴了Kafka的设计思想，弥补了List和PubSub的不足。Stream类型数据可以持久化、支持ack机制、支持多个消费者、支持回溯消费，基本上实现了队列中间件大部分功能，比List和PubSub更可靠。</p>
<p>另一个经常使用的是基于Redis实现的布隆过滤器，其底层实现利用的是String数据结构和位运算，可以解决业务层缓存穿透的问题，而且内存占用非常小，操作非常高效。</p>
<h2 id="时间序列数据"><a href="#时间序列数据" class="headerlink" title="时间序列数据"></a>时间序列数据</h2><h3 id="总结1-11"><a href="#总结1-11" class="headerlink" title="总结1"></a>总结1</h3><p>在这节课，我们一起学习了如何用 Redis 保存时间序列数据。时间序列数据的写入特点是要能快速写入，而查询的特点有三个：</p>
<ul>
<li>点查询，根据一个时间戳，查询相应时间的数据；</li>
<li>范围查询，查询起始和截止时间戳范围内的数据；</li>
<li>聚合计算，针对起始和截止时间戳范围内的所有数据进行计算，例如求最大 / 最小值，求均值等。</li>
</ul>
<p>关于快速写入的要求，Redis 的高性能写特性足以应对了；而针对多样化的查询需求，Redis 提供了两种方案。</p>
<p>第一种方案是，组合使用 Redis 内置的 Hash 和 Sorted Set 类型，把数据同时保存在 Hash 集合和 Sorted Set 集合中。这种方案既可以利用 Hash 类型实现对单键的快速查询，还能利用 Sorted Set 实现对范围查询的高效支持，一下子满足了时间序列数据的两大查询需求。</p>
<p>不过，第一种方案也有两个不足：一个是，在执行聚合计算时，我们需要把数据读取到客户端再进行聚合，当有大量数据要聚合时，数据传输开销大；另一个是，所有的数据会在两个数据类型中各保存一份，内存开销不小。不过，我们可以通过设置适当的数据过期时间，释放内存，减小内存压力。</p>
<p>我们学习的第二种实现方案是使用 RedisTimeSeries 模块。这是专门为存取时间序列数据而设计的扩展模块。和第一种方案相比，RedisTimeSeries 能支持直接在 Redis 实例上进行多种数据聚合计算，避免了大量数据在实例和客户端间传输。不过，RedisTimeSeries 的底层数据结构使用了链表，它的范围查询的复杂度是 O(N) 级别的，同时，它的 TS.GET 查询只能返回最新的数据，没有办法像第一种方案的 Hash 类型一样，可以返回任一时间点的数据。</p>
<p>所以，组合使用 Hash 和 Sorted Set，或者使用 RedisTimeSeries，在支持时间序列数据存取上各有优劣势。我给你的建议是：</p>
<ul>
<li>如果你的部署环境中网络带宽高、Redis 实例内存大，可以优先考虑第一种方案；</li>
<li>如果你的部署环境中网络、内存资源有限，而且数据量大，聚合计算频繁，需要按数据集合属性查询，可以优先考虑第二种方案。</li>
</ul>
<h3 id="总结2-10"><a href="#总结2-10" class="headerlink" title="总结2"></a>总结2</h3><p>1，作者讲了什么？<br>根据时间序列数据的特点，选择合适的存储方案</p>
<p>2，作者是怎么把这事给讲明白的？<br>结合具体场景，探讨解决方案<br>1，介绍需求背景，用户行为，设备监控数据分析<br>2，介绍数据特点，时间线连续，没有逻辑关系，数据量大<br>3，介绍操作场景，插入多且快，常单点查询，分组统计聚合</p>
<p>3，作者为了把这事给讲清楚，讲了那些要点？有哪些亮点？<br>1，亮点1：先讲清楚需求背景，从实际问题出发，推演出存储时间序列数据适合使用sort set 和hash解决点查询和范围查询的需求<br>2，要点1：同时写入sort set和hash 两种数据类型的存储，需要使用原子操作，可以借助MULTI和 EXEC命令<br>3，要点2：大数据量的聚合统计，会非常消耗网络带宽，所以可以使用RedisTimeSeries模块处理</p>
<p>4，对于作者所讲，我有哪些发散性思考？</p>
<p>5，在未来的那些场景中，我能够使用它？</p>
<p>6，留言区的收获</p>
<h3 id="问题-9"><a href="#问题-9" class="headerlink" title="问题"></a>问题</h3><p>在这节课上，我提到，我们可以使用 Sorted Set 保存时间序列数据，把时间戳作为 score，把实际的数据作为 member，你觉得这样保存数据有没有潜在的风险？另外，如果你是 Redis 的开发维护者，你会把聚合计算也设计为 Sorted Set 的一个内在功能吗？</p>
<h3 id="解答-9"><a href="#解答-9" class="headerlink" title="解答"></a>解答</h3><p>使用Sorted Set保存时序数据，把时间戳作为score，把实际的数据作为member，有什么潜在的风险？</p>
<p>我目前能想到的风险是，如果对某一个对象的时序数据记录很频繁的话，那么这个key很容易变成一个bigkey，在key过期释放内存时可能引发阻塞风险。所以不能把这个对象的所有时序数据存储在一个key上，而是需要拆分存储，例如可以按天/周/月拆分（根据具体查询需求来定）。当然，拆分key的缺点是，在查询时，可能需要客户端查询多个key后再做聚合才能得到结果。</p>
<p>如果你是Redis的开发维护者，你会把聚合计算也设计为Sorted Set的内在功能吗？</p>
<p>不会。因为聚合计算是CPU密集型任务，Redis在处理请求时是单线程的，也就是它在做聚合计算时无法利用到多核CPU来提升计算速度，如果计算量太大，这也会导致Redis的响应延迟变长，影响Redis的性能。Redis的定位就是高性能的内存数据库，要求访问速度极快。所以对于时序数据的存储和聚合计算，我觉得更好的方式是交给时序数据库去做，时序数据库会针对这些存储和计算的场景做针对性优化。</p>
<p>另外，在使用MULTI和EXEC命令时，建议客户端使用pipeline，当使用pipeline时，客户端会把命令一次性批量发送给服务端，然后让服务端执行，这样可以减少客户端和服务端的来回网络IO次数，提升访问性能。</p>
<h2 id="redis消息队列"><a href="#redis消息队列" class="headerlink" title="redis消息队列"></a>redis消息队列</h2><h3 id="总结1-12"><a href="#总结1-12" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我们学习了分布式系统组件使用消息队列时的三大需求：消息保序、重复消息处理和消息可靠性保证，这三大需求可以进一步转换为对消息队列的三大要求：消息数据有序存取，消息数据具有全局唯一编号，以及消息数据在消费完成后被删除。</p>
<p>我画了一张表格，汇总了用 List 和 Streams 实现消息队列的特点和区别。当然，在实践的过程中，你也可以根据新的积累，进一步补充和完善这张表。<br><img src="/images/redis/list-01.png" alt="img.png"></p>
<p>其实，关于 Redis 是否适合做消息队列，业界一直是有争论的。很多人认为，要使用消息队列，就应该采用 Kafka、RabbitMQ 这些专门面向消息队列场景的软件，而 Redis 更加适合做缓存。</p>
<p>根据这些年做 Redis 研发工作的经验，我的看法是：Redis 是一个非常轻量级的键值数据库，部署一个 Redis 实例就是启动一个进程，部署 Redis 集群，也就是部署多个 Redis 实例。而 Kafka、RabbitMQ 部署时，涉及额外的组件，例如 Kafka 的运行就需要再部署 ZooKeeper。相比 Redis 来说，Kafka 和 RabbitMQ 一般被认为是重量级的消息队列。</p>
<p>所以，关于是否用 Redis 做消息队列的问题，不能一概而论，我们需要考虑业务层面的数据体量，以及对性能、可靠性、可扩展性的需求。如果分布式系统中的组件消息通信量不大，那么，Redis 只需要使用有限的内存空间就能满足消息存储的需求，而且，Redis 的高性能特性能支持快速的消息读写，不失为消息队列的一个好的解决方案。</p>
<h3 id="总结2-11"><a href="#总结2-11" class="headerlink" title="总结2"></a>总结2</h3><p>1，作者讲了什么？<br>如何使用redis实现消息队列的需求</p>
<p>2，作者是怎么把这事给说明白的？<br>1，将一个问题拆解为两个具体的小问题：消息队列应具备哪些特性，Redis能否实现这些特性</p>
<p>3，为了讲明白，作者讲了哪些要点？，有哪些亮点？<br>1，亮点1：作者首先将一个相对模糊的问题，拆解成为两个问题更精确的问题<br>2，要点1：消息队列读取需求有三点：消息保存，消息唯一，消息可靠性<br>3，要点2：消息还要确保有序，削峰平谷，消费性能有弹性<br>4，要点3：Redis的list和5.0后的Stream数据结构可以满足<br>5，要点4：消息队列的三大要求：消息数据有序存取，消息数据具有全局唯一编号，消息数据在消费完成后被删除</p>
<p>4，对于作者所讲，我有哪些发散性思考？<br>解决问题的前提是搞清楚问题是什么<br>开篇：“Redis适合做消息队列吗”？对于这样的问题，我本能的就会直接想：“用Redis做消息队列？应该可以吧，很多资料上都这么说的”。<br>这样的回答，证明我并没有思考，只是陈述了我所知道的一点东西。我总是渴求快速有个答案，没有在意答案是否正确，更没有思考该如何回答问题。<br>虽然我总会说要想解决问题，首先要搞清楚问题是什么。这个句话似乎有点白痴，自己遇到的问题，这个问题不就它本身吗？怎么还会需要搞清楚呢？<br>其实不然，我们遇到的往往未必是问题的真身，而只是问题的表面现象或衍生出的问题。其实一个好问题的本身，就是一个好答案，而一个好问题胜过无数好答案。<br>那什么才是真正的解答问题？这需要先回答如何回答这个问题，也就是要先搞清楚要从哪些方面解释问题，而不是铺陈信息。<br>老师开篇对问题的回答方法，就是个非常好的范例<br>他是怎么解答的呢？<br>他并没有立即回答行或不行（这是我们最常有的反应），而是向后退了一步，问这个问题真正的问题是啥呢？消息队列存取消息需要哪些特性？Redis如何实现这些特性？<br>这就将一个相对模糊的问题拆解为两个较清晰的小问题，分别作答，最终得到一篇很好的文章</p>
<p>5，将来在哪些场景里，我能够使用它？</p>
<p>6，留言区收获<br>1，Redis是否可以作为消息队列？如果可以，哪些场景适合使用Redis，而不是消息中间件？<br>答：这个问题应当进一步拆分为：消息队列读写消息有哪些需求和Redis如何实现这些需求。<br>首先消息队列的消息读写有三大需求：消息读写的有序性，消息数据的唯一性，消息消费后数据删除。<br>针对这三大需求，Redis的List和5.0后的Stream数据结构，可以支持。<br>对于List，POP和PUSH命令，还有阻塞式的，备份式的。<br>对于Stream，是Redis5.0后提供新的数据结构，专门用户消息队列，他可以生成全局唯一id，还有能够创建消费者组，多个消费者同时消费<br>Stream类型，使用了应答机制，消费者消费完毕后会给Streams发送XACK命令，否则消息将会保存Streams的内部队列中，使用XPENDING命令可以查看<br>就Redis的相关数据结构而言，是可以作为消息队列的。但也要注意使用它的场景，虽然它性能很高，部署维护也轻量，但缺点是无法严格保证数据的完整性。<br>他适用于消息量并不是非常巨大，数据不是非常重要，从而不必引入其他消息组件的场景，如发短信，站内信</p>
<p>2，如果一个生产者发送给消息队列的消息，需要被多个消费者进行读取和处理，Redis的什么数据类型可以解决这个问题？<br>答：如果要使用Redis实现这个需求，Redis的Streams数据类型可以实现。<br>Streams可以使用XADD向队列中写入消息，XGOURP创建消费者组，XREADGROUP已消费者组形式消费消息，XACK向消息队列确认处理完成，XPENDING查询已消费待确认的消息</p>
<p>3，如果使用Redis作为消息队列，有哪些事项需要注意？<br>答：消息的可靠性，重点需要关注的是如何保证不丢消息</p>
<p>4，在使用消息队列时，如何保证不丢消息？<br>答：消息丢失可能会发生在三个环节：生产者发布消息，消息者消费消息，消息中间件丢失消息<br>生产者丢失消息一般通过重试机制和全局唯一id来解决，<br>消费者消费消息一般通过ack方式问询上报消费进度，<br>消息中间件宕机，一般通过主从备份，分布式集群来解决</p>
<h3 id="问题1-1"><a href="#问题1-1" class="headerlink" title="问题1"></a>问题1</h3><p>按照惯例，我给你提个小问题。如果一个生产者发送给消息队列的消息，需要被多个消费者进行读取和处理（例如，一个消息是一条从业务系统采集的数据，既要被消费者 1 读取进行实时计算，也要被消费者 2 读取并留存到分布式文件系统 HDFS 中，以便后续进行历史查询），你会使用 Redis 的什么数据类型来解决这个问题呢？</p>
<h3 id="解答1-1"><a href="#解答1-1" class="headerlink" title="解答1"></a>解答1</h3><p>如果一个生产者发送给消息队列的消息，需要被多个消费者进行读取和处理，你会使用Redis的什么数据类型来解决这个问题？</p>
<p>这种情况下，只能使用Streams数据类型来解决。使用Streams数据类型，创建多个消费者组，就可以实现同时消费生产者的数据。每个消费者组内可以再挂多个消费者分担读取消息进行消费，消费完成后，各自向Redis发送XACK，标记自己的消费组已经消费到了哪个位置，而且消费组之间互不影响。</p>
<p>另外，老师在介绍使用List用作队列时，为了保证消息可靠性，使用BRPOPLPUSH命令把消息取出的同时，还把消息插入到备份队列中，从而防止消费者故障导致消息丢失。</p>
<p>这种情况下，还需要额外做一些工作，也就是维护这个备份队列：每次执行BRPOPLPUSH命令后，因为都会把消息插入一份到备份队列中，所以当消费者成功消费取出的消息后，最好把备份队列中的消息删除，防止备份队列存储过多无用的数据，导致内存浪费。</p>
<p>这篇文章主要是讲消息队列的使用，借这个机会，也顺便总结一下使用消息队列时的注意点：</p>
<p>在使用消息队列时，重点需要关注的是如何保证不丢消息？</p>
<p>那么下面就来分析一下，哪些情况下，会丢消息，以及如何解决？</p>
<p>1、生产者在发布消息时异常：</p>
<p>a) 网络故障或其他问题导致发布失败（直接返回错误，消息根本没发出去）<br>b) 网络抖动导致发布超时（可能发送数据包成功，但读取响应结果超时了，不知道结果如何）</p>
<p>情况a还好，消息根本没发出去，那么重新发一次就好了。但是情况b没办法知道到底有没有发布成功，所以也只能再发一次。所以这两种情况，生产者都需要重新发布消息，直到成功为止（一般设定一个最大重试次数，超过最大次数依旧失败的需要报警处理）。这就会导致消费者可能会收到重复消息的问题，所以消费者需要保证在收到重复消息时，依旧能保证业务的正确性（设计幂等逻辑），一般需要根据具体业务来做，例如使用消息的唯一ID，或者版本号配合业务逻辑来处理。</p>
<p>2、消费者在处理消息时异常：</p>
<p>也就是消费者把消息拿出来了，但是还没处理完，消费者就挂了。这种情况，需要消费者恢复时，依旧能处理之前没有消费成功的消息。使用List当作队列时，也就是利用老师文章所讲的备份队列来保证，代价是增加了维护这个备份队列的成本。而Streams则是采用ack的方式，消费成功后告知中间件，这种方式处理起来更优雅，成熟的队列中间件例如RabbitMQ、Kafka都是采用这种方式来保证消费者不丢消息的。</p>
<p>3、消息队列中间件丢失消息</p>
<p>上面2个层面都比较好处理，只要客户端和服务端配合好，就能保证生产者和消费者都不丢消息。但是，如果消息队列中间件本身就不可靠，也有可能会丢失消息，毕竟生产者和消费这都依赖它，如果它不可靠，那么生产者和消费者无论怎么做，都无法保证数据不丢失。</p>
<p>a) 在用Redis当作队列或存储数据时，是有可能丢失数据的：一个场景是，如果打开AOF并且是每秒写盘，因为这个写盘过程是异步的，Redis宕机时会丢失1秒的数据。而如果AOF改为同步写盘，那么写入性能会下降。另一个场景是，如果采用主从集群，如果写入量比较大，从库同步存在延迟，此时进行主从切换，也存在丢失数据的可能（从库还未同步完成主库发来的数据就被提成主库）。总的来说，Redis不保证严格的数据完整性和主从切换时的一致性。我们在使用Redis时需要注意。</p>
<p>b) 而采用RabbitMQ和Kafka这些专业的队列中间件时，就没有这个问题了。这些组件一般是部署一个集群，生产者在发布消息时，队列中间件一般会采用写多个节点+预写磁盘的方式保证消息的完整性，即便其中一个节点挂了，也能保证集群的数据不丢失。当然，为了做到这些，方案肯定比Redis设计的要复杂（毕竟是专们针对队列场景设计的）。</p>
<p>综上，Redis可以用作队列，而且性能很高，部署维护也很轻量，但缺点是无法严格保数据的完整性（个人认为这就是业界有争议要不要使用Redis当作队列的地方）。而使用专业的队列中间件，可以严格保证数据的完整性，但缺点是，部署维护成本高，用起来比较重。</p>
<p>所以我们需要根据具体情况进行选择，如果对于丢数据不敏感的业务，例如发短信、发通知的场景，可以采用Redis作队列。如果是金融相关的业务场景，例如交易、支付这类，建议还是使用专业的队列中间件。</p>
<h2 id="异步机制：如何避免单线程模型的阻塞？"><a href="#异步机制：如何避免单线程模型的阻塞？" class="headerlink" title="异步机制：如何避免单线程模型的阻塞？"></a>异步机制：如何避免单线程模型的阻塞？</h2><h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结 1"></a>总结 1</h3><p>这节课，我们学习了 Redis 实例运行时的 4 大类交互对象：客户端、磁盘、主从库实例、切片集群实例。基于这 4 大类交互对象，我们梳理了会导致 Redis 性能受损的 5 大阻塞点，包括集合全量查询和聚合操作、bigkey 删除、清空数据库、AOF 日志同步写，以及从库加载 RDB 文件。</p>
<p>在这 5 大阻塞点中，bigkey 删除、清空数据库、AOF 日志同步写不属于关键路径操作，可以使用异步子线程机制来完成。Redis 在运行时会创建三个子线程，主线程会通过一个任务队列和三个子线程进行交互。子线程会根据任务的具体类型，来执行相应的异步操作。</p>
<p>不过，异步删除操作是 Redis 4.0 以后才有的功能，如果你使用的是 4.0 之前的版本，当你遇到 bigkey 删除时，我给你个小建议：先使用集合类型提供的 SCAN 命令读取数据，然后再进行删除。因为用 SCAN 命令可以每次只读取一部分数据并进行删除，这样可以避免一次性删除大量 key 给主线程带来的阻塞。</p>
<p>例如，对于 Hash 类型的 bigkey 删除，你可以使用 HSCAN 命令，每次从 Hash 集合中获取一部分键值对（例如 200 个），再使用 HDEL 删除这些键值对，这样就可以把删除压力分摊到多次操作中，那么，每次删除操作的耗时就不会太长，也就不会阻塞主线程了。</p>
<p>最后，我想再提一下，集合全量查询和聚合操作、从库加载 RDB 文件是在关键路径上，无法使用异步操作来完成。对于这两个阻塞点，我也给你两个小建议。</p>
<ul>
<li>集合全量查询和聚合操作：可以使用 SCAN 命令，分批读取数据，再在客户端进行聚合计算；</li>
<li>从库加载 RDB 文件：把主库的数据量大小控制在 2~4GB 左右，以保证 RDB 文件能以较快的速度加载。</li>
</ul>
<h3 id="问题1-2"><a href="#问题1-2" class="headerlink" title="问题1"></a>问题1</h3><p>按照惯例，我给你提一个小问题：我们今天学习了关键路径上的操作，你觉得，Redis 的写操作（例如 SET、HSET、SADD 等）是在关键路径上吗？</p>
<h3 id="解答1-2"><a href="#解答1-2" class="headerlink" title="解答1"></a>解答1</h3><p>Redis的写操作（例如SET，HSET，SADD等）是在关键路径上吗？</p>
<p>我觉得这需要客户端根据业务需要来区分：</p>
<p>1、如果客户端依赖操作返回值的不同，进而需要处理不同的业务逻辑，那么HSET和SADD操作算关键路径，而SET操作不算关键路径。因为HSET和SADD操作，如果field或member不存在时，Redis结果会返回1，否则返回0。而SET操作返回的结果都是OK，客户端不需要关心结果有什么不同。</p>
<p>2、如果客户端不关心返回值，只关心数据是否写入成功，那么SET/HSET/SADD不算关键路径，多次执行这些命令都是幂等的，这种情况下可以放到异步线程中执行。</p>
<p>3、但是有种例外情况，如果Redis设置了maxmemory，但是却没有设置淘汰策略，这三个操作也都算关键路径。因为如果Redis内存超过了maxmemory，再写入数据时，Redis返回的结果是OOM error，这种情况下，客户端需要感知有错误发生才行。</p>
<p>另外，我查阅了lazy-free相关的源码，发现有很多细节需要补充下：</p>
<p>1、lazy-free是4.0新增的功能，但是默认是关闭的，需要手动开启。</p>
<p>2、手动开启lazy-free时，有4个选项可以控制，分别对应不同场景下，要不要开启异步释放内存机制：<br>a) lazyfree-lazy-expire：key在过期删除时尝试异步释放内存<br>b) lazyfree-lazy-eviction：内存达到maxmemory并设置了淘汰策略时尝试异步释放内存<br>c) lazyfree-lazy-server-del：执行RENAME/MOVE等命令或需要覆盖一个key时，删除旧key尝试异步释放内存<br>d) replica-lazy-flush：主从全量同步，从库清空数据库时异步释放内存</p>
<p>3、即使开启了lazy-free，如果直接使用DEL命令还是会同步删除key，只有使用UNLINK命令才会可能异步删除key。</p>
<p>4、这也是最关键的一点，上面提到开启lazy-free的场景，除了replica-lazy-flush之外，其他情况都只是<em>可能</em>去异步释放key的内存，并不是每次必定异步释放内存的。</p>
<p>开启lazy-free后，Redis在释放一个key的内存时，首先会评估代价，如果释放内存的代价很小，那么就直接在主线程中操作了，没必要放到异步线程中执行（不同线程传递数据也会有性能消耗）。</p>
<p>什么情况才会真正异步释放内存？这和key的类型、编码方式、元素数量都有关系（详细可参考源码中的lazyfreeGetFreeEffort函数）：</p>
<p>a) 当Hash/Set底层采用哈希表存储（非ziplist/int编码存储）时，并且元素数量超过64个<br>b) 当ZSet底层采用跳表存储（非ziplist编码存储）时，并且元素数量超过64个<br>c) 当List链表节点数量超过64个（注意，不是元素数量，而是链表节点的数量，List的实现是在每个节点包含了若干个元素的数据，这些元素采用ziplist存储）</p>
<p>只有以上这些情况，在删除key释放内存时，才会真正放到异步线程中执行，其他情况一律还是在主线程操作。</p>
<p>也就是说String（不管内存占用多大）、List（少量元素）、Set（int编码存储）、Hash/ZSet（ziplist编码存储）这些情况下的key在释放内存时，依旧在主线程中操作。</p>
<p>可见，即使开启了lazy-free，String类型的bigkey，在删除时依旧有阻塞主线程的风险。所以，即便Redis提供了lazy-free，我建议还是尽量不要在Redis中存储bigkey。</p>
<p>个人理解Redis在设计评估释放内存的代价时，不是看key的内存占用有多少，而是关注释放内存时的工作量有多大。从上面分析基本能看出，如果需要释放的内存是连续的，Redis作者认为释放内存的代价比较低，就放在主线程做。如果释放的内存不连续（大量指针类型的数据），这个代价就比较高，所以才会放在异步线程中去执行。</p>
<p>如果我的理解有偏差，还请老师和大家指出！</p>
<h2 id="为什么CPU结构也会影响Redis的性能？"><a href="#为什么CPU结构也会影响Redis的性能？" class="headerlink" title="为什么CPU结构也会影响Redis的性能？"></a>为什么CPU结构也会影响Redis的性能？</h2><h3 id="总结1-13"><a href="#总结1-13" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我们学习了 CPU 架构对 Redis 性能的影响。首先，我们了解了目前主流的多核 CPU 架构，以及 NUMA 架构。</p>
<p>在多核 CPU 架构下，Redis 如果在不同的核上运行，就需要频繁地进行上下文切换，这个过程会增加 Redis 的执行时间，客户端也会观察到较高的尾延迟了。所以，建议你在 Redis 运行时，把实例和某个核绑定，这样，就能重复利用核上的 L1、L2 缓存，可以降低响应延迟。</p>
<p>为了提升 Redis 的网络性能，我们有时还会把网络中断处理程序和 CPU 核绑定。在这种情况下，如果服务器使用的是 NUMA 架构，Redis 实例一旦被调度到和中断处理程序不在同一个 CPU Socket，就要跨 CPU Socket 访问网络数据，这就会降低 Redis 的性能。所以，我建议你把 Redis 实例和网络中断处理程序绑在同一个 CPU Socket 下的不同核上，这样可以提升 Redis 的运行性能。</p>
<p>虽然绑核可以帮助 Redis 降低请求执行时间，但是，除了主线程，Redis 还有用于 RDB 和 AOF 重写的子进程，以及 4.0 版本之后提供的用于惰性删除的后台线程。当 Redis 实例和一个逻辑核绑定后，这些子进程和后台线程会和主线程竞争 CPU 资源，也会对 Redis 性能造成影响。所以，我给了你两个建议：</p>
<ul>
<li>如果你不想修改 Redis 代码，可以把按一个 Redis 实例一个物理核方式进行绑定，这样，Redis 的主线程、子进程和后台线程可以共享使用一个物理核上的两个逻辑核。</li>
<li>如果你很熟悉 Redis 的源码，就可以在源码中增加绑核操作，把子进程和后台线程绑到不同的核上，这样可以避免对主线程的 CPU 资源竞争。不过，如果你不熟悉 Redis 源码，也不用太担心，Redis 6.0 出来后，可以支持 CPU 核绑定的配置操作了，我将在第 38 讲中向你介绍 Redis 6.0 的最新特性。</li>
</ul>
<p>Redis 的低延迟是我们永恒的追求目标，而多核 CPU 和 NUMA 架构已经成为了目前服务器的主流配置，所以，希望你能掌握绑核优化方案，并把它应用到实践中。</p>
<h3 id="总结2-12"><a href="#总结2-12" class="headerlink" title="总结2"></a>总结2</h3><p>1.作者讲了什么？<br>在多核CPU架构和NUMA架构下，如何对redis进行优化配置<br>2.作者是怎么把这件事将明白的？<br>1，讲解了主流的CPU架构，主要有多核CPU架构和NUMA架构两个架构<br>多核CPU架构： 多个物理核，各物理核使用私有的1、2级缓存，共享3级缓存。物理核可包含2个超线程，称为逻辑核<br>NUMA架构： 一个服务器上多个cpu，称为CPU Socket，每个cpu socker存在多个物理核。每个socket通过总线连接，并且有用私有的内存空间<br>3.为了讲明白，作者讲了哪些要点，哪些亮点？<br>1、亮点：将主流的CPU架构进行剖析，使人更好理解cpu的原理，有助于后续redis性能的优化<br>2、要点：cpu架构：一个cpu一般拥有多个物理核，每个物理核都拥有私有的一级缓存，二级缓存。三级缓存是各物理核共享的缓存空间。而物理核又可以分为多个超线程，称为逻辑核，同一个物理核的逻辑核会共享使用 L1、L2 缓存。<br>3、要点：一级缓存和二级缓存访问延迟不超过10纳秒，但空间很小，只是KB单位。而应用程序访问内存延迟是百纳秒级别，基本上是一二级缓存的10倍<br>4、要点：不同的物理核还会共享一个共同的三级缓存，三级缓存空间比较多，为几到几十MB，当 L1、L2 缓存中没有数据缓存时，可以访问 L3，尽可能避免访问内存。<br>5、要点：多核CPU运行redis实例，会导致context switch，导致增加延迟，可以通过taskset 命令把redis进程绑定到某个cup物理核上。<br>6、要点：NUMA架构运行redis实例，如果网络中断程序和redis实例运行在不同的socket上，就需要跨 CPU Socket 访问内存，这个过程会花费较多时间。<br>7、要点：绑核的风险和解决方案：<br>一个 Redis 实例对应绑一个物理核 ： 将redis服务绑定到一个物理核上，而不是一个逻辑核上，如 taskset -c 0,12 ./redis-server<br>优化 Redis 源码。<br>4.对于作者所讲的，我有哪些发散性思考？<br>给自己提了几个问题：<br>1，在多核CPU架构和NUMA架构，那个对于redis来说性能比较好<br>2，如何设置网络中断处理和redis绑定设置在同个socket上呢？</p>
<p>5.将来在哪些场景里，我能够使用它？</p>
<p>6.留言区收获<br>如果redis实例中内存不足以使用时，会用到swap那会怎么样？（答案来自@kaito 大佬）<br>因为Redis要求性能非常高，如果从Swap中读取数据，此时Redis的性能就会急剧下降，延迟变大。</p>
<h3 id="问题1-3"><a href="#问题1-3" class="headerlink" title="问题1"></a>问题1</h3><p>在一台有 2 个 CPU Socket（每个 Socket 8 个物理核）的服务器上，我们部署了有 8 个实例的 Redis 切片集群（8 个实例都为主节点，没有主备关系），现在有两个方案：</p>
<ol>
<li>在同一个 CPU Socket 上运行 8 个实例，并和 8 个 CPU 核绑定；</li>
<li>在 2 个 CPU Socket 上各运行 4 个实例，并和相应 Socket 上的核绑定。</li>
</ol>
<p>如果不考虑网络数据读取的影响，你会选择哪个方案呢？</p>
<h3 id="解答1-3"><a href="#解答1-3" class="headerlink" title="解答1"></a>解答1</h3><p>这篇文章收获很大！对于CPU结构和如何绑核有了进一步了解。其实在NUMA架构下，不光对于CPU的绑核需要注意，对于内存的使用，也有很多注意点，下面回答课后问题，也会提到NUMA架构下内存方面的注意事项。</p>
<p>在一台有2个CPU Socket（每个Socket 8个物理核）的服务器上，我们部署了有8个实例的Redis切片集群（8个实例都为主节点，没有主备关系），采用哪种方案绑核最佳？</p>
<p>我更倾向于的方案是：在两个CPU Socket上各运行4个实例，并和相应Socket上的核绑定。这么做的原因主要从L3 Cache的命中率、内存利用率、避免使用到Swap这三个方面考虑：</p>
<p>1、由于CPU Socket1和2分别有自己的L3 Cache，如果把所有实例都绑定在同一个CPU Socket上，相当于这些实例共用这一个L3 Cache，另一个CPU Socket的L3 Cache浪费了。这些实例共用一个L3 Cache，会导致Cache中的数据频繁被替换，访问命中率下降，之后只能从内存中读取数据，这会增加访问的延迟。而8个实例分别绑定CPU Socket，可以充分使用2个L3 Cache，提高L3 Cache的命中率，减少从内存读取数据的开销，从而降低延迟。</p>
<p>2、如果这些实例都绑定在一个CPU Socket，由于采用NUMA架构的原因，所有实例会优先使用这一个节点的内存，当这个节点内存不足时，再经过总线去申请另一个CPU Socket下的内存，此时也会增加延迟。而8个实例分别使用2个CPU Socket，各自在访问内存时都是就近访问，延迟最低。</p>
<p>3、如果这些实例都绑定在一个CPU Socket，还有一个比较大的风险是：用到Swap的概率将会大大提高。如果这个CPU Socket对应的内存不够了，也可能不会去另一个节点申请内存（操作系统可以配置内存回收策略和Swap使用倾向：本节点回收内存/其他节点申请内存/内存数据换到Swap的倾向程度），而操作系统可能会把这个节点的一部分内存数据换到Swap上从而释放出内存给进程使用（如果没开启Swap可会导致直接OOM）。因为Redis要求性能非常高，如果从Swap中读取数据，此时Redis的性能就会急剧下降，延迟变大。所以8个实例分别绑定CPU Socket，既可以充分使用2个节点的内存，提高内存使用率，而且触发使用Swap的风险也会降低。</p>
<p>其实我们可以查一下，在NUMA架构下，也经常发生某一个节点内存不够，但其他节点内存充足的情况下，依旧使用到了Swap，进而导致软件性能急剧下降的例子。所以在运维层面，我们也需要关注NUMA架构下的内存使用情况（多个内存节点使用可能不均衡），并合理配置系统参数（内存回收策略/Swap使用倾向），尽量去避免使用到Swap。</p>
<h2 id="波动的响应延迟：如何应对变慢的Redis？（上）"><a href="#波动的响应延迟：如何应对变慢的Redis？（上）" class="headerlink" title="波动的响应延迟：如何应对变慢的Redis？（上）"></a>波动的响应延迟：如何应对变慢的Redis？（上）</h2><h3 id="总结1-14"><a href="#总结1-14" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我首先给你介绍了 Redis 性能变慢带来的重要影响，希望你能充分重视这个问题。我重点介绍了判断 Redis 变慢的方法，一个是看响应延迟，一个是看基线性能。同时，我还给了你两种排查和解决 Redis 变慢这个问题的方法：</p>
<ul>
<li>从慢查询命令开始排查，并且根据业务需求替换慢查询命令；</li>
<li>排查过期 key 的时间设置，并根据实际使用需求，设置不同的过期时间。</li>
</ul>
<p>性能诊断通常是一件困难的事，所以我们一定不能毫无目标地“乱找”。这节课给你介绍的内容，就是排查和解决 Redis 性能变慢的章法，你一定要按照章法逐一排查，这样才可能尽快地找出原因。</p>
<p>当然，要真正把 Redis 用好，除了要了解 Redis 本身的原理，还要了解和 Redis 交互的各底层系统的关键机制，包括操作系统和文件系统。通常情况下，一些难以排查的问题是 Redis 的用法或设置和底层系统的工作机制不协调导致的。下节课，我会着重给你介绍文件系统、操作系统对 Redis 性能的影响，以及相应的排查方法和解决方案。</p>
<h3 id="总结2-13"><a href="#总结2-13" class="headerlink" title="总结2"></a>总结2</h3><p>第十八课：<br>1.作者讲了什么？<br>当redis查询变慢了怎么办，如何排查，如何进行处理？<br>2.作者是怎么把这件事将明白的？<br>1、通过分析redis各组件及硬件，找出问题所在<br>3.为了讲明白，作者讲了哪些要点，哪些亮点？<br>1、亮点：通过redis-cli –intrinsic-latency 120可以得知redis的基准线。后续可以根据基准线的响应速度进行判断是否查询慢，这是我之前所不知道的判断方法<br>2、要点：基于自己对 Redis 本身的工作原理的理解，并且结合和它交互的操作系统、存储以及网络等外部系统关键机制，再借助一些辅助工具来定位原因，并制定行之有效的解决方案<br>3、要点：Redis 自身操作特性的影响</p>
<ol>
<li>慢查询命令：命令操作的复杂度有关<br>排查方法：通过 Redis 日志，或者是 latency monitor 工具，查询变慢的请求<br>解决方法：1.用其他高效命令代替。如不要使用keys查询所有key，可以使用scan进行查询，不会阻塞线程<br>2.当你需要执行排序、交集、并集操作时，可以在客户端完成，而不要用 SORT、SUNION、SINTER 这些命令，以免拖慢 Redis 实例。<br>2.过期 key 操作：redis本身的内存回收机制会造成redis操作阻塞，导致性能变慢（Redis 4.0 后可以用异步线程机制来减少阻塞影响）<br>导致原因：大批量的key同时间内过期，导致删除过期key的机制一直触发，引起redis操作阻塞<br>解决方法：对key设定过期时间时，添加一个删除的时间随机数，能避免key存在同一时间过期<br>4、要点：redis删除过期key的机制，每100毫秒对一些key进行删除。算法如下<br>1.采样 ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP 个数的 key，并将其中过期的 key 全部删除；<br>2.如果超过 25% 的 key 过期了，则重复删除的过程，直到过期 key 的比例降至 25% 以下。</li>
</ol>
<p>4.对于作者所讲的，我有哪些发散性思考？</p>
<p>5.将来在哪些场景里，我能够使用它？</p>
<p>6.留言区收获<br>1.在生产环境中，可以使用scan替代keys命令（答案来自@kaito 大佬）<br>当scan在Redis在做Rehash时，会不会漏key或返回重复的key？<br>1.不漏keys：Redis在SCAN遍历全局哈希表时，采用<em>高位进位法</em>的方式遍历哈希桶（可网上查询图例，一看就明白），当哈希表扩容后，通过这种算法遍历，旧哈希表中的数据映射到新哈希表，依旧会保留原来的先后顺序，这样就可以保证遍历时不会遗漏也不会重复。<br>2.key重复：这个情况主要发生在哈希表缩容。已经遍历过的哈希桶在缩容时，会映射到新哈希表没有遍历到的位置，所以继续遍历就会对同一个key返回多次。处理方法是在客户端直接做重复过滤<br>2.在redis-cluster中，不能使用一次scan在整个集群中获取所有的key，只能通过在每个实例上单独执行scan才可以，再到客户端进行合并</p>
<h3 id="问题1-4"><a href="#问题1-4" class="headerlink" title="问题1"></a>问题1</h3><p>这节课，我提到了 KEYS 命令，因为它的复杂度很高，容易引起 Redis 线程操作阻塞，不适用于生产环境。但是，KEYS 命令本身提供的功能是上层业务应用经常需要的，即返回与输入模式匹配的 keys。</p>
<p>请思考一下，在 Redis 中，还有哪些其他命令可以代替 KEYS 命令，实现同样的功能呢？这些命令的复杂度会导致 Redis 变慢吗？</p>
<h3 id="解答1-4"><a href="#解答1-4" class="headerlink" title="解答1"></a>解答1</h3><p>在 Redis 中，还有哪些其他命令可以代替 KEYS 命令，实现同样的功能呢？这些命令的复杂度会导致 Redis 变慢吗？</p>
<p>如果想要获取整个实例的所有key，建议使用SCAN命令代替。客户端通过执行SCAN $cursor COUNT $count可以得到一批key以及下一个游标$cursor，然后把这个$cursor当作SCAN的参数，再次执行，以此往复，直到返回的$cursor为0时，就把整个实例中的所有key遍历出来了。</p>
<p>关于SCAN讨论最多的问题就是，Redis在做Rehash时，会不会漏key或返回重复的key。</p>
<p>在使用SCAN命令时，不会漏key，但可能会得到重复的key，这主要和Redis的Rehash机制有关。Redis的所有key存在一个全局的哈希表中，如果存入的key慢慢变多，在达到一定阈值后，为了避免哈希冲突导致查询效率降低，这个哈希表会进行扩容。与之对应的，key数量逐渐变少时，这个哈希表会缩容以节省空间。</p>
<p>1、为什么不会漏key？Redis在SCAN遍历全局哈希表时，采用<em>高位进位法</em>的方式遍历哈希桶（可网上查询图例，一看就明白），当哈希表扩容后，通过这种算法遍历，旧哈希表中的数据映射到新哈希表，依旧会保留原来的先后顺序，这样就可以保证遍历时不会遗漏也不会重复。</p>
<p>2、为什么SCAN会得到重复的key？这个情况主要发生在哈希表缩容。已经遍历过的哈希桶在缩容时，会映射到新哈希表没有遍历到的位置，所以继续遍历就会对同一个key返回多次。</p>
<p>SCAN是遍历整个实例的所有key，另外Redis针对Hash/Set/Sorted Set也提供了HSCAN/SSCAN/ZSCAN命令，用于遍历一个key中的所有元素，建议在获取一个bigkey的所有数据时使用，避免发生阻塞风险。</p>
<p>但是使用HSCAN/SSCAN/ZSCAN命令，返回的元素数量与执行SCAN逻辑可能不同。执行SCAN $cursor COUNT $count时一次最多返回count个数的key，数量不会超过count。</p>
<p>但Hash/Set/Sorted Set元素数量比较少时，底层会采用intset/ziplist方式存储，如果以这种方式存储，在执行HSCAN/SSCAN/ZSCAN命令时，会无视count参数，直接把所有元素一次性返回，也就是说，得到的元素数量是会大于count参数的。当底层转为哈希表或跳表存储时，才会真正使用发count参数，最多返回count个元素。</p>
<h2 id="波动的响应延迟：如何应对变慢的Redis？（下）"><a href="#波动的响应延迟：如何应对变慢的Redis？（下）" class="headerlink" title="波动的响应延迟：如何应对变慢的Redis？（下）"></a>波动的响应延迟：如何应对变慢的Redis？（下）</h2><h3 id="总结1-15"><a href="#总结1-15" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我从文件系统和操作系统两个维度，给你介绍了应对 Redis 变慢的方法。</p>
<p>为了方便你应用，我给你梳理了一个包含 9 个检查点的 Checklist，希望你在遇到 Redis 性能变慢时，按照这些步骤逐一检查，高效地解决问题。</p>
<ol>
<li>获取 Redis 实例在当前环境下的基线性能。</li>
<li>是否用了慢查询命令？如果是的话，就使用其他命令替代慢查询命令，或者把聚合计算命令放在客户端做。</li>
<li>是否对过期 key 设置了相同的过期时间？对于批量删除的 key，可以在每个 key 的过期时间上加一个随机数，避免同时删除。</li>
<li>是否存在 bigkey？ 对于 bigkey 的删除操作，如果你的 Redis 是 4.0 及以上的版本，可以直接利用异步线程机制减少主线程阻塞；如果是 Redis 4.0 以前的版本，可以使用 SCAN 命令迭代删除；对于 bigkey 的集合查询和聚合操作，可以使用 SCAN 命令在客户端完成。</li>
<li>Redis AOF 配置级别是什么？业务层面是否的确需要这一可靠性级别？如果我们需要高性能，同时也允许数据丢失，可以将配置项 no-appendfsync-on-rewrite 设置为 yes，避免 AOF 重写和 fsync 竞争磁盘 IO 资源，导致 Redis 延迟增加。当然， 如果既需要高性能又需要高可靠性，最好使用高速固态盘作为 AOF 日志的写入盘。</li>
<li>Redis 实例的内存使用是否过大？发生 swap 了吗？如果是的话，就增加机器内存，或者是使用 Redis 集群，分摊单机 Redis 的键值对数量和内存压力。同时，要避免出现 Redis 和其他内存需求大的应用共享机器的情况。</li>
<li>在 Redis 实例的运行环境中，是否启用了透明大页机制？如果是的话，直接关闭内存大页机制就行了。</li>
<li>是否运行了 Redis 主从集群？如果是的话，把主库实例的数据量大小控制在 2~4GB，以免主从复制时，从库因加载大的 RDB 文件而阻塞。</li>
<li>是否使用了多核 CPU 或 NUMA 架构的机器运行 Redis 实例？使用多核 CPU 时，可以给 Redis 实例绑定物理核；使用 NUMA 架构时，注意把 Redis 实例和网络中断处理程序运行在同一个 CPU Socket 上。</li>
</ol>
<p>实际上，影响系统性能的因素还有很多，这两节课给你讲的都是应对最常见问题的解决方案。</p>
<p>如果你遇到了一些特殊情况，也不要慌，我再给你分享一个小技巧：仔细检查下有没有恼人的“邻居”，具体点说，就是 Redis 所在的机器上有没有一些其他占内存、磁盘 IO 和网络 IO 的程序，比如说数据库程序或者数据采集程序。如果有的话，我建议你将这些程序迁移到其他机器上运行。</p>
<p>为了保证 Redis 高性能，我们需要给 Redis 充足的计算、内存和 IO 资源，给它提供一个“安静”的环境。</p>
<h3 id="总结2-14"><a href="#总结2-14" class="headerlink" title="总结2"></a>总结2</h3><h3 id="问题1-5"><a href="#问题1-5" class="headerlink" title="问题1"></a>问题1</h3><p>这两节课，我向你介绍了系统性定位、排查和解决 Redis 变慢的方法。所以，我想请你聊一聊，你遇到过 Redis 变慢的情况吗？如果有的话，你是怎么解决的呢？</p>
<h3 id="解答1-5"><a href="#解答1-5" class="headerlink" title="解答1"></a>解答1</h3><p>关于如何分析、排查、解决Redis变慢问题，我总结的checklist如下：</p>
<p>1、使用复杂度过高的命令（例如SORT/SUION/ZUNIONSTORE/KEYS），或一次查询全量数据（例如LRANGE key 0 N，但N很大）</p>
<p>分析：a) 查看slowlog是否存在这些命令 b) Redis进程CPU使用率是否飙升（聚合运算命令导致）</p>
<p>解决：a) 不使用复杂度过高的命令，或用其他方式代替实现（放在客户端做） b) 数据尽量分批查询（LRANGE key 0 N，建议N&lt;=100，查询全量数据建议使用HSCAN/SSCAN/ZSCAN）</p>
<p>2、操作bigkey</p>
<p>分析：a) slowlog出现很多SET/DELETE变慢命令（bigkey分配内存和释放内存变慢） b) 使用redis-cli -h $host -p $port –bigkeys扫描出很多bigkey</p>
<p>解决：a) 优化业务，避免存储bigkey b) Redis 4.0+可开启lazy-free机制</p>
<p>3、大量key集中过期</p>
<p>分析：a) 业务使用EXPIREAT/PEXPIREAT命令 b) Redis info中的expired_keys指标短期突增</p>
<p>解决：a) 优化业务，过期增加随机时间，把时间打散，减轻删除过期key的压力 b) 运维层面，监控expired_keys指标，有短期突增及时报警排查</p>
<p>4、Redis内存达到maxmemory</p>
<p>分析：a) 实例内存达到maxmemory，且写入量大，淘汰key压力变大 b) Redis info中的evicted_keys指标短期突增</p>
<p>解决：a) 业务层面，根据情况调整淘汰策略（随机比LRU快） b) 运维层面，监控evicted_keys指标，有短期突增及时报警 c) 集群扩容，多个实例减轻淘汰key的压力</p>
<p>5、大量短连接请求</p>
<p>分析：Redis处理大量短连接请求，TCP三次握手和四次挥手也会增加耗时</p>
<p>解决：使用长连接操作Redis</p>
<p>6、生成RDB和AOF重写fork耗时严重</p>
<p>分析：a) Redis变慢只发生在生成RDB和AOF重写期间 b) 实例占用内存越大，fork拷贝内存页表越久 c) Redis info中latest_fork_usec耗时变长</p>
<p>解决：a) 实例尽量小 b) Redis尽量部署在物理机上 c) 优化备份策略（例如低峰期备份） d) 合理配置repl-backlog和slave client-output-buffer-limit，避免主从全量同步 e) 视情况考虑关闭AOF f) 监控latest_fork_usec耗时是否变长</p>
<p>7、AOF使用awalys机制</p>
<p>分析：磁盘IO负载变高</p>
<p>解决：a) 使用everysec机制 b) 丢失数据不敏感的业务不开启AOF</p>
<p>8、使用Swap</p>
<p>分析：a) 所有请求全部开始变慢 b) slowlog大量慢日志 c) 查看Redis进程是否使用到了Swap</p>
<p>解决：a) 增加机器内存 b) 集群扩容 c) Swap使用时监控报警</p>
<p>9、进程绑定CPU不合理</p>
<p>分析：a) Redis进程只绑定一个CPU逻辑核 b) NUMA架构下，网络中断处理程序和Redis进程没有绑定在同一个Socket下</p>
<p>解决：a) Redis进程绑定多个CPU逻辑核 b) 网络中断处理程序和Redis进程绑定在同一个Socket下</p>
<p>10、开启透明大页机制</p>
<p>分析：生成RDB和AOF重写期间，主线程处理写请求耗时变长（拷贝内存副本耗时变长）</p>
<p>解决：关闭透明大页机制</p>
<p>11、网卡负载过高</p>
<p>分析：a) TCP/IP层延迟变大，丢包重传变多 b) 是否存在流量过大的实例占满带宽</p>
<p>解决：a) 机器网络资源监控，负载过高及时报警 b) 提前规划部署策略，访问量大的实例隔离部署</p>
<p>总之，Redis的性能与CPU、内存、网络、磁盘都息息相关，任何一处发生问题，都会影响到Redis的性能。</p>
<p>主要涉及到的包括业务使用层面和运维层面：业务人员需要了解Redis基本的运行原理，使用合理的命令、规避bigke问题和集中过期问题。运维层面需要DBA提前规划好部署策略，预留足够的资源，同时做好监控，这样当发生问题时，能够及时发现并尽快处理。</p>
<h2 id="删除数据后，为什么内存占用率还是很高？"><a href="#删除数据后，为什么内存占用率还是很高？" class="headerlink" title="删除数据后，为什么内存占用率还是很高？"></a>删除数据后，为什么内存占用率还是很高？</h2><h3 id="总结1-16"><a href="#总结1-16" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我和你一起了解了 Redis 的内存空间效率问题，这里面的一个关键技术点就是要识别和处理内存碎片。简单来说，就是“三个一”：</p>
<ul>
<li>info memory 命令是一个好工具，可以帮助你查看碎片率的情况；</li>
<li>碎片率阈值是一个好经验，可以帮忙你有效地判断是否要进行碎片清理了；</li>
<li>内存碎片自动清理是一个好方法，可以避免因为碎片导致 Redis 的内存实际利用率降低，提升成本收益率。</li>
</ul>
<p>内存碎片并不可怕，我们要做的就是了解它，重视它，并借用高效的方法解决它。</p>
<p>最后，我再给你提供一个小贴士：内存碎片自动清理涉及内存拷贝，这对 Redis 而言，是个潜在的风险。如果你在实践过程中遇到 Redis 性能变慢，记得通过日志看下是否正在进行碎片清理。如果 Redis 的确正在清理碎片，那么，我建议你调小 active-defrag-cycle-max 的值，以减轻对正常请求处理的影响。</p>
<h3 id="总结2-15"><a href="#总结2-15" class="headerlink" title="总结2"></a>总结2</h3><h3 id="问题1-6"><a href="#问题1-6" class="headerlink" title="问题1"></a>问题1</h3><p>按照惯例，我给你提一个小问题。在这节课中，我提到，可以使用 mem_fragmentation_ratio 来判断 Redis 当前的内存碎片率是否严重，我给出的经验阈值都是大于 1 的。那么，我想请你来聊一聊，如果 mem_fragmentation_ratio 小于 1 了，Redis 的内存使用是什么情况呢？会对 Redis 的性能和内存空间利用率造成什么影响呢？</p>
<h3 id="解答1-6"><a href="#解答1-6" class="headerlink" title="解答1"></a>解答1</h3><p>如果 mem_fragmentation_ratio 小于 1 了，Redis 的内存使用是什么情况呢？会对 Redis 的性能和内存空间利用率造成什么影响？</p>
<p>mem_fragmentation_ratio小于1，说明used_memory_rss小于了used_memory，这意味着操作系统分配给Redis进程的物理内存，要小于Redis实际存储数据的内存，也就是说Redis没有足够的物理内存可以使用了，这会导致Redis一部分内存数据会被换到Swap中，之后当Redis访问Swap中的数据时，延迟会变大，性能下降。</p>
<p>通过这篇文章了解到，Redis在进行内存碎片整理时，由于是主线程操作的，所以这块也是一个影响Redis性能的风险点。</p>
<p>其中active-defrag-ignore-bytes和active-defrag-threshold-lower参数主要用于控制达到什么阈值后开始碎片整理，如果配置的碎片大小和碎片率在可接受的范围内，那么Redis不会进行碎片整理，也就不会对Redis产生性能影响。</p>
<p>而达到设定阈值开始碎片整理后，active-defrag-cycle-min和active-defrag-cycle-max参数则用来控制在这期间，Redis主线程资源使用的上下限，这个需要根据碎片整理的时间、Redis的响应延迟进行权衡，合理配置。</p>
<p>我个人认为，应该优先保证Redis性能尽量不受影响，让碎片整理期间的资源消耗控制在稳定的范围内，并尽量缩短碎片整理的时间。</p>
<h2 id="缓冲区：一个可能引发“惨案”的地方"><a href="#缓冲区：一个可能引发“惨案”的地方" class="headerlink" title="缓冲区：一个可能引发“惨案”的地方"></a>缓冲区：一个可能引发“惨案”的地方</h2><h3 id="总结1-17"><a href="#总结1-17" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我们一起学习了 Redis 中使用的缓冲区。使用缓冲区以后，当命令数据的接收方处理速度跟不上发送方的发送速度时，缓冲区可以避免命令数据的丢失。</p>
<p>按照缓冲区的用途，例如是用于客户端通信还是用于主从节点复制，我把缓冲区分成了客户端的输入和输出缓冲区，以及主从集群中主节点上的复制缓冲区和复制积压缓冲区。这样学习的好处是，你可以很清楚 Redis 中到底有哪些地方使用了缓冲区，那么在排查问题的时候，就可以快速找到方向——从客户端和服务器端的通信过程以及主从节点的复制过程中分析原因。</p>
<p>现在，从缓冲区溢出对 Redis 的影响的角度，我再把这四个缓冲区分成两类做个总结。</p>
<ul>
<li>缓冲区溢出导致网络连接关闭：普通客户端、订阅客户端，以及从节点客户端，它们使用的缓冲区，本质上都是 Redis 客户端和服务器端之间，或是主从节点之间为了传输命令数据而维护的。这些缓冲区一旦发生溢出，处理机制都是直接把客户端和服务器端的连接，或是主从节点间的连接关闭。网络连接关闭造成的直接影响，就是业务程序无法读写 Redis，或者是主从节点全量同步失败，需要重新执行。</li>
<li>缓冲区溢出导致命令数据丢失：主节点上的复制积压缓冲区属于环形缓冲区，一旦发生溢出，新写入的命令数据就会覆盖旧的命令数据，导致旧命令数据的丢失，进而导致主从节点重新进行全量复制。</li>
</ul>
<p>从本质上看，缓冲区溢出，无非就是三个原因：命令数据发送过快过大；命令数据处理较慢；缓冲区空间过小。明白了这个，我们就可以有针对性地拿出应对策略了。</p>
<ul>
<li>针对命令数据发送过快过大的问题，对于普通客户端来说可以避免 bigkey，而对于复制缓冲区来说，就是避免过大的 RDB 文件。</li>
<li>针对命令数据处理较慢的问题，解决方案就是减少 Redis 主线程上的阻塞操作，例如使用异步的删除操作。</li>
<li>针对缓冲区空间过小的问题，解决方案就是使用 client-output-buffer-limit 配置项设置合理的输出缓冲区、复制缓冲区和复制积压缓冲区大小。当然，我们不要忘了，输入缓冲区的大小默认是固定的，我们无法通过配置来修改它，除非直接去修改 Redis 源码。</li>
</ul>
<h3 id="总结2-16"><a href="#总结2-16" class="headerlink" title="总结2"></a>总结2</h3><h3 id="问题1-7"><a href="#问题1-7" class="headerlink" title="问题1"></a>问题1</h3><p>在这节课上，我们提到 Redis 采用了 client-server 架构，服务器端会为每个客户端维护输入、输出缓冲区。那么，应用程序和 Redis 实例交互时，应用程序中使用的客户端需要使用缓冲区吗？如果使用的话，对 Redis 的性能和内存使用会有影响吗？</p>
<h3 id="解答1-7"><a href="#解答1-7" class="headerlink" title="解答1"></a>解答1</h3><p>应用程序和Redis实例交互时，应用程序中使用的客户端需要使用缓冲区吗？如果使用的话，对Redis的性能和内存使用有什么影响？</p>
<p>客户端需要使用缓冲区，好处如下。</p>
<p>1、客户端和服务端交互，一般都会制定一个交互协议，客户端给服务端发数据时，都会按照这个协议把数据拼装好，然后写到客户端buffer中，客户端再一次性把buffer数据写到操作系统的网络缓冲区中，最后由操作系统发送给服务端。这样服务端就能从网络缓冲区中读取到一整块数据，然后按照协议解析数据即可。使用buffer发送数据会比一个个发送数据到服务端效率要高很多。</p>
<p>2、客户端还可以使用Pipeline批量发送命令到服务端，以提高访问性能。不使用Pipeline时，客户端是发送一个命令、读取一次结果。而使用Pipeline时，客户端先把一批命令暂存到buffer中，然后一次性把buffer中的命令发送到服务端，服务端处理多个命令后批量返回结果，这样做的好处是可以减少来回网络IO的次数，降低延迟，提高访问性能。当然，Redis服务端的buffer内存也会相应增长，可以控制好Pipeline命令的数量防止buffer超限。</p>
<p>缓冲区其实无处不在，客户端缓冲区、服务端缓冲区、操作系统网络缓冲区等等，凡是进行数据交互的两端，一般都会利用缓冲区来降低两端速度不匹配的影响。没有缓冲区，就好比一个个工人搬运货物到目的地，每个工人不仅成本高，而且运输效率低。而有了缓冲区后，相当于把这些货物先装到一个集装箱里，然后以集装箱为单位，开车运送到目的地，这样既降低了成本，又提高了运输效率。缓冲区相当于把需要运送的零散数据，进行一块块规整化，然后分批运输。</p>
<p>另外，关于Redis服务端为客户端分配的输出缓冲区，我想补充一点：主库上的从库输出缓冲区（slave client-output-buffer）是不计算在Redis使用的总内存中的，也就是说主从同步延迟，数据积压在主库上的从库输出缓冲区中，这个缓冲区内存占用变大，不会超过maxmemory导致淘汰数据。只有普通客户端和订阅客户端的输出缓冲区内存增长，超过maxmemory时，才会淘汰数据。</p>
<h2 id="旁路缓存：Redis是如何工作的？"><a href="#旁路缓存：Redis是如何工作的？" class="headerlink" title="旁路缓存：Redis是如何工作的？"></a>旁路缓存：Redis是如何工作的？</h2><h3 id="总结1-18"><a href="#总结1-18" class="headerlink" title="总结1"></a>总结1</h3><p>今天，我们学习了缓存的两个特征，分别是在分层系统中，数据暂存在快速子系统中有助于加速访问；缓存容量有限，缓存写满时，数据需要被淘汰。而 Redis 天然就具有高性能访问和数据淘汰机制，正好符合缓存的这两个特征的要求，所以非常适合用作缓存。</p>
<p>另外，我们还学习了 Redis 作为旁路缓存的特性，旁路缓存就意味着需要在应用程序中新增缓存逻辑处理的代码。当然，如果是无法修改源码的应用场景，就不能使用 Redis 做缓存了。</p>
<p>Redis 做缓存时，还有两种模式，分别是只读缓存和读写缓存。其中，读写缓存还提供了同步直写和异步写回这两种模式，同步直写模式侧重于保证数据可靠性，而异步写回模式则侧重于提供低延迟访问，我们要根据实际的业务场景需求来进行选择。</p>
<p>这节课，虽然我提到了 Redis 有数据淘汰机制，但是并没有展开讲具体的淘汰策略。那么，Redis 究竟是怎么淘汰数据的呢？我会在下节课给你具体介绍。</p>
<h3 id="总结2-17"><a href="#总结2-17" class="headerlink" title="总结2"></a>总结2</h3><h3 id="问题1-8"><a href="#问题1-8" class="headerlink" title="问题1"></a>问题1</h3><p>按照惯例，我给你提一个小问题。这节课，我提到了 Redis 只读缓存和使用直写策略的读写缓存，这两种缓存都会把数据同步写到后端数据库中，你觉得，它们有什么区别吗？</p>
<h3 id="解答1-8"><a href="#解答1-8" class="headerlink" title="解答1"></a>解答1</h3><p>Redis只读缓存和使用直写策略的读写缓存，这两种缓存都会把数据同步写到后端数据库中，它们的区别在于：</p>
<p>1、使用只读缓存时，是先把修改写到后端数据库中，再把缓存中的数据删除。当下次访问这个数据时，会以后端数据库中的值为准，重新加载到缓存中。这样做的优点是，数据库和缓存可以保证完全一致，并且缓存中永远保留的是经常访问的热点数据。缺点是每次修改操作都会把缓存中的数据删除，之后访问时都会先触发一次缓存缺失，然后从后端数据库加载数据到缓存中，这个过程访问延迟会变大。</p>
<p>2、使用读写缓存时，是同时修改数据库和缓存中的值。这样做的优点是，被修改后的数据永远在缓存中存在，下次访问时，能够直接命中缓存，不用再从后端数据库中查询，这个过程拥有比较好的性能，比较适合先修改又立即访问的业务场景。但缺点是在高并发场景下，如果存在多个操作同时修改同一个值的情况，可能会导致缓存和数据库的不一致。</p>
<p>3、当使用只读缓存时，如果修改数据库失败了，那么缓存中的数据也不会被删除，此时数据库和缓存中的数据依旧保持一致。而使用读写缓存时，如果是先修改缓存，后修改数据库，如果缓存修改成功，而数据库修改失败了，那么此时数据库和缓存数据就不一致了。如果先修改数据库，再修改缓存，也会产生上面所说的并发场景下的不一致。</p>
<p>我个人总结，只读缓存是牺牲了一定的性能，优先保证数据库和缓存的一致性，它更适合对于一致性要求比较要高的业务场景。而如果对于数据库和缓存一致性要求不高，或者不存在并发修改同一个值的情况，那么使用读写缓存就比较合适，它可以保证更好的访问性能。</p>
<h2 id="替换策略：缓存满了怎么办？"><a href="#替换策略：缓存满了怎么办？" class="headerlink" title="替换策略：缓存满了怎么办？"></a>替换策略：缓存满了怎么办？</h2><h3 id="总结1-19"><a href="#总结1-19" class="headerlink" title="总结1"></a>总结1</h3><p>在这节课上，我围绕着“缓存满了该怎么办”这一问题，向你介绍了缓存替换时的数据淘汰策略，以及被淘汰数据的处理方法。</p>
<p>Redis 4.0 版本以后一共提供了 8 种数据淘汰策略，从淘汰数据的候选集范围来看，我们有两种候选范围：一种是所有数据都是候选集，一种是设置了过期时间的数据是候选集。另外，无论是面向哪种候选数据集进行淘汰数据选择，我们都有三种策略，分别是随机选择，根据 LRU 算法选择，以及根据 LFU 算法选择。当然，当面向设置了过期时间的数据集选择淘汰数据时，我们还可以根据数据离过期时间的远近来决定。</p>
<p>一般来说，缓存系统对于选定的被淘汰数据，会根据其是干净数据还是脏数据，选择直接删除还是写回数据库。但是，在 Redis 中，被淘汰数据无论干净与否都会被删除，所以，这是我们在使用 Redis 缓存时要特别注意的：当数据修改成为脏数据时，需要在数据库中也把数据修改过来。</p>
<p>选择哪种缓存策略是值得我们多加琢磨的，它在筛选数据方面是否能筛选出可能被再次访问的数据，直接决定了缓存效率的高与低。</p>
<p>很简单的一个对比，如果我们使用随机策略，刚筛选出来的要被删除的数据可能正好又被访问了，此时应用就只能花费几毫秒从数据库中读取数据了。而如果使用 LRU 策略，被筛选出来的数据往往是经过时间验证了，如果在一段时间内一直没有访问，本身被再次访问的概率也很低了。</p>
<p>所以，我给你的建议是，先根据是否有始终会被频繁访问的数据（例如置顶消息），来选择淘汰数据的候选集，也就是决定是针对所有数据进行淘汰，还是针对设置了过期时间的数据进行淘汰。候选数据集范围选定后，建议优先使用 LRU 算法，也就是，allkeys-lru 或 volatile-lru 策略。</p>
<p>当然，设置缓存容量的大小也很重要，我的建议是：结合实际应用的数据总量、热数据的体量，以及成本预算，把缓存空间大小设置在总数据量的 15% 到 30% 这个区间就可以。</p>
<h3 id="总结2-18"><a href="#总结2-18" class="headerlink" title="总结2"></a>总结2</h3><h3 id="问题1-9"><a href="#问题1-9" class="headerlink" title="问题1"></a>问题1</h3><p>按照惯例，我给你提一个小问题。这节课，我向你介绍了 Redis 缓存在应对脏数据时，需要在数据修改的同时，也把它写回数据库，针对我们上节课介绍的缓存读写模式：只读缓存，以及读写缓存中的两种写回策略，请你思考下，Redis 缓存对应哪一种或哪几种模式？</p>
<h3 id="解答1-9"><a href="#解答1-9" class="headerlink" title="解答1"></a>解答1</h3><p>Redis在用作缓存时，使用只读缓存或读写缓存的哪种模式？</p>
<p>1、只读缓存模式：每次修改直接写入后端数据库，如果Redis缓存不命中，则什么都不用操作，如果Redis缓存命中，则删除缓存中的数据，待下次读取时从后端数据库中加载最新值到缓存中。</p>
<p>2、读写缓存模式+同步直写策略：由于Redis在淘汰数据时，直接在内部删除键值对，外部无法介入处理脏数据写回数据库，所以使用Redis作读写缓存时，只能采用同步直写策略，修改缓存的同时也要写入到后端数据库中，从而保证修改操作不被丢失。但这种方案在并发场景下会导致数据库和缓存的不一致，需要在特定业务场景下或者配合分布式锁使用。</p>
<p>当一个系统引入缓存时，需要面临最大的问题就是，如何保证缓存和后端数据库的一致性问题，最常见的3个解决方案分别是Cache Aside、Read/Write Throught和Write Back缓存更新策略。</p>
<p>1、Cache Aside策略：就是文章所讲的只读缓存模式。读操作命中缓存直接返回，否则从后端数据库加载到缓存再返回。写操作直接更新数据库，然后删除缓存。这种策略的优点是一切以后端数据库为准，可以保证缓存和数据库的一致性。缺点是写操作会让缓存失效，再次读取时需要从数据库中加载。这种策略是我们在开发软件时最常用的，在使用Memcached或Redis时一般都采用这种方案。</p>
<p>2、Read/Write Throught策略：应用层读写只需要操作缓存，不需要关心后端数据库。应用层在操作缓存时，缓存层会自动从数据库中加载或写回到数据库中，这种策略的优点是，对于应用层的使用非常友好，只需要操作缓存即可，缺点是需要缓存层支持和后端数据库的联动。</p>
<p>3、Write Back策略：类似于文章所讲的读写缓存模式+异步写回策略。写操作只写缓存，比较简单。而读操作如果命中缓存则直接返回，否则需要从数据库中加载到缓存中，在加载之前，如果缓存已满，则先把需要淘汰的缓存数据写回到后端数据库中，再把对应的数据放入到缓存中。这种策略的优点是，写操作飞快（只写缓存），缺点是如果数据还未来得及写入后端数据库，系统发生异常会导致缓存和数据库的不一致。这种策略经常使用在操作系统Page Cache中，或者应对大量写操作的数据库引擎中。</p>
<p>除了以上提到的缓存和数据库的更新策略之外，还有一个问题就是操作缓存或数据库发生异常时如何处理？例如缓存操作成功，数据库操作失败，或者反过来，还是有可能会产生不一致的情况。</p>
<p>比较简单的解决方案是，根据业务设计好更新缓存和数据库的先后顺序来降低影响，或者给缓存设置较短的有效期来降低不一致的时间。如果需要严格保证缓存和数据库的一致性，即保证两者操作的原子性，这就涉及到分布式事务问题了，常见的解决方案就是我们经常听到的两阶段提交（2PC）、三阶段提交（3PC）、TCC、消息队列等方式来保证了，方案也会比较复杂，一般用在对于一致性要求较高的业务场景中。</p>
<h2 id="缓存异常（上）：如何解决缓存和数据库的数据不一致问题？"><a href="#缓存异常（上）：如何解决缓存和数据库的数据不一致问题？" class="headerlink" title="缓存异常（上）：如何解决缓存和数据库的数据不一致问题？"></a>缓存异常（上）：如何解决缓存和数据库的数据不一致问题？</h2><h3 id="总结1-20"><a href="#总结1-20" class="headerlink" title="总结1"></a>总结1</h3><p>在这节课，我们学习了在使用 Redis 缓存时，最常遇见的一个问题，也就是缓存和数据库不一致的问题。针对这个问题，我们可以分成读写缓存和只读缓存两种情况进行分析。</p>
<p>对于读写缓存来说，如果我们采用同步写回策略，那么可以保证缓存和数据库中的数据一致。只读缓存的情况比较复杂，我总结了一张表，以便于你更加清晰地了解数据不一致的问题原因、现象和应对方案。</p>
<p><img src="/images/redis/mysql-and-redis-01.png" alt="img.png"></p>
<p>希望你能把我总结的这张表格放入到你的学习笔记中，时不时复习一下。</p>
<p>最后，我还想再多说几句。在大多数业务场景下，我们会把 Redis 作为只读缓存使用。针对只读缓存来说，我们既可以先删除缓存值再更新数据库，也可以先更新数据库再删除缓存。我的建议是，优先使用先更新数据库再删除缓存的方法，原因主要有两个：</p>
<ol>
<li>先删除缓存值再更新数据库，有可能导致请求因缓存缺失而访问数据库，给数据库带来压力；</li>
<li>如果业务应用中读取数据库和写缓存的时间不好估算，那么，延迟双删中的等待时间就不好设置。</li>
</ol>
<p>不过，当使用先更新数据库再删除缓存时，也有个地方需要注意，如果业务层要求必须读取一致的数据，那么，我们就需要在更新数据库时，先在 Redis 缓存客户端暂存并发读请求，等数据库更新完、缓存值删除后，再读取数据，从而保证数据一致性。</p>
<h3 id="总结2-19"><a href="#总结2-19" class="headerlink" title="总结2"></a>总结2</h3><h3 id="问题1-10"><a href="#问题1-10" class="headerlink" title="问题1"></a>问题1</h3><p>按照惯例，我给你提个小问题。这节课，我提到，在只读缓存中进行数据的删改操作时，需要在缓存中删除相应的缓存值。我想请你思考一下，如果在这个过程中，我们不是删除缓存值，而是直接更新缓存的值，你觉得和删除缓存值相比，有什么好处和不足吗？</p>
<h3 id="解答1-10"><a href="#解答1-10" class="headerlink" title="解答1"></a>解答1</h3><p>数据在删改操作时，如果不是删除缓存值，而是直接更新缓存的值，你觉得和删除缓存值相比，有什么好处和不足？</p>
<p>这种情况相当于把Redis当做读写缓存使用，删改操作同时操作数据库和缓存。</p>
<p>1、先更新数据库，再更新缓存：如果更新数据库成功，但缓存更新失败，此时数据库中是最新值，但缓存中是旧值，后续的读请求会直接命中缓存，得到的是旧值。</p>
<p>2、先更新缓存，再更新数据库：如果更新缓存成功，但数据库更新失败，此时缓存中是最新值，数据库中是旧值，后续读请求会直接命中缓存，但得到的是最新值，短期对业务影响不大。但是，一旦缓存过期或者满容后被淘汰，读请求就会从数据库中重新加载旧值到缓存中，之后的读请求会从缓存中得到旧值，对业务产生影响。</p>
<p>同样地，针对这种其中一个操作可能失败的情况，也可以使用重试机制解决，把第二步操作放入到消息队列中，消费者从消息队列取出消息，再更新缓存或数据库，成功后把消息从消息队列删除，否则进行重试，以此达到数据库和缓存的最终一致。</p>
<p>以上是没有并发请求的情况。如果存在并发读写，也会产生不一致，分为以下4种场景。</p>
<p>1、先更新数据库，再更新缓存，写+读并发：线程A先更新数据库，之后线程B读取数据，此时线程B会命中缓存，读取到旧值，之后线程A更新缓存成功，后续的读请求会命中缓存得到最新值。这种场景下，线程A未更新完缓存之前，在这期间的读请求会短暂读到旧值，对业务短暂影响。</p>
<p>2、先更新缓存，再更新数据库，写+读并发：线程A先更新缓存成功，之后线程B读取数据，此时线程B命中缓存，读取到最新值后返回，之后线程A更新数据库成功。这种场景下，虽然线程A还未更新完数据库，数据库会与缓存存在短暂不一致，但在这之前进来的读请求都能直接命中缓存，获取到最新值，所以对业务没影响。</p>
<p>3、先更新数据库，再更新缓存，写+写并发：线程A和线程B同时更新同一条数据，更新数据库的顺序是先A后B，但更新缓存时顺序是先B后A，这会导致数据库和缓存的不一致。</p>
<p>4、先更新缓存，再更新数据库，写+写并发：与场景3类似，线程A和线程B同时更新同一条数据，更新缓存的顺序是先A后B，但是更新数据库的顺序是先B后A，这也会导致数据库和缓存的不一致。</p>
<p>场景1和2对业务影响较小，场景3和4会造成数据库和缓存不一致，影响较大。也就是说，在读写缓存模式下，写+读并发对业务的影响较小，而写+写并发时，会造成数据库和缓存的不一致。</p>
<p>针对场景3和4的解决方案是，对于写请求，需要配合分布式锁使用。写请求进来时，针对同一个资源的修改操作，先加分布式锁，这样同一时间只允许一个线程去更新数据库和缓存，没有拿到锁的线程把操作放入到队列中，延时处理。用这种方式保证多个线程操作同一资源的顺序性，以此保证一致性。</p>
<p>综上，使用读写缓存同时操作数据库和缓存时，因为其中一个操作失败导致不一致的问题，同样可以通过消息队列重试来解决。而在并发的场景下，读+写并发对业务没有影响或者影响较小，而写+写并发时需要配合分布式锁的使用，才能保证缓存和数据库的一致性。</p>
<p>另外，读写缓存模式由于会同时更新数据库和缓存，优点是，缓存中一直会有数据，如果更新操作后会立即再次访问，可以直接命中缓存，能够降低读请求对于数据库的压力（没有了只读缓存的删除缓存导致缓存缺失和再加载的过程）。缺点是，如果更新后的数据，之后很少再被访问到，会导致缓存中保留的不是最热的数据，缓存利用率不高（只读缓存中保留的都是热数据），所以读写缓存比较适合用于读写相当的业务场景。</p>
<h2 id="缓存异常（下）：如何解决缓存雪崩、击穿、穿透难题？"><a href="#缓存异常（下）：如何解决缓存雪崩、击穿、穿透难题？" class="headerlink" title="缓存异常（下）：如何解决缓存雪崩、击穿、穿透难题？"></a>缓存异常（下）：如何解决缓存雪崩、击穿、穿透难题？</h2><h3 id="总结1-21"><a href="#总结1-21" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我们学习了缓存雪崩、击穿和穿透这三类异常问题。从问题成因来看，缓存雪崩和击穿主要是因为数据不在缓存中了，而缓存穿透则是因为数据既不在缓存中，也不在数据库中。所以，缓存雪崩或击穿时，一旦数据库中的数据被再次写入到缓存后，应用又可以在缓存中快速访问数据了，数据库的压力也会相应地降低下来，而缓存穿透发生时，Redis 缓存和数据库会同时持续承受请求压力。</p>
<p>为了方便你掌握，我把这三大问题的原因和应对方案总结到了一张表格，你可以再复习一下。</p>
<p><img src="/images/redis/mysql-and-redis-02.png" alt="img.png"></p>
<p>最后，我想强调一下，服务熔断、服务降级、请求限流这些方法都是属于“有损”方案，在保证数据库和整体系统稳定的同时，会对业务应用带来负面影响。例如使用服务降级时，有部分数据的请求就只能得到错误返回信息，无法正常处理。如果使用了服务熔断，那么，整个缓存系统的服务都被暂停了，影响的业务范围更大。而使用了请求限流机制后，整个业务系统的吞吐率会降低，能并发处理的用户请求会减少，会影响到用户体验。</p>
<p>所以，我给你的建议是，尽量使用预防式方案：</p>
<ul>
<li>针对缓存雪崩，合理地设置数据过期时间，以及搭建高可靠缓存集群；</li>
<li>针对缓存击穿，在缓存访问非常频繁的热点数据时，不要设置过期时间；</li>
<li>针对缓存穿透，提前在入口前端实现恶意请求检测，或者规范数据库的数据删除操作，避免误删除。</li>
</ul>
<h3 id="总结2-20"><a href="#总结2-20" class="headerlink" title="总结2"></a>总结2</h3><h3 id="问题1-11"><a href="#问题1-11" class="headerlink" title="问题1"></a>问题1</h3><p>按照惯例，我给你提个小问题。在讲到缓存雪崩时，我提到，可以采用服务熔断、服务降级、请求限流的方法来应对。请你思考下，这三个机制可以用来应对缓存穿透问题吗？</p>
<h3 id="解答1-11"><a href="#解答1-11" class="headerlink" title="解答1"></a>解答1</h3><p>是否可以采用服务熔断、服务降级、请求限流的方法来应对缓存穿透问题？</p>
<p>我觉得需要区分场景来看。</p>
<p>如果缓存穿透的原因是恶意攻击，攻击者故意访问数据库中不存在的数据。这种情况可以先使用服务熔断、服务降级、请求限流的方式，对缓存和数据库层增加保护，防止大量恶意请求把缓存和数据库压垮。在这期间可以对攻击者进行防护，例如封禁IP等操作。</p>
<p>如果缓存穿透的原因是，业务层误操作把数据从缓存和数据库都删除了，如果误删除的数据很少，不会导致大量请求压到数据库的情况，那么快速恢复误删的数据就好了，不需要使用服务熔断、服务降级、请求限流。如果误操作删除的数据范围比较广，导致大量请求压到数据库层，此时使用服务熔断、服务降级、请求限流的方法来应对是有帮助的，使用这些方法先把缓存和数据库保护起来，然后使用备份库快速恢复数据，在数据恢复期间，这些保护方法可以为数据库恢复提供保障。</p>
<p>还有一种缓存穿透的场景，我们平时会遇到的，和大家分享一下。</p>
<p>对于一个刚上线的新业务模块，如果还没有用户在这个模块内产生业务数据，当用户需要查询这个业务模块自己的数据时，由于缓存和数据库都没有这个用户的数据，此时也会产生缓存穿透，但这种场景不像误删数据和恶意攻击那样，而是属于正常的用户行为。</p>
<p>这种场景采用服务熔断、服务降级、请求限流的方式就没有任何意义了，反而会影响正常用户的访问。这种场景只能使用缓存回种空值、布隆过滤器来解决。</p>
<p>可见，服务熔断、服务降级、请求限流的作用是，当系统内部发生故障或潜在问题时，为了防止系统内部的问题进一步恶化，所以会采用这些方式对系统增加保护，待系统内部故障恢复后，可以依旧继续对外提供服务，这些方法属于服务治理的范畴，在任何可能导致系统故障的场景下，都可以选择性配合使用。</p>
<p>另外，关于文章所讲的由于“Redis缓存实例发生故障宕机”导致缓存雪崩的问题，我觉得一个可以优化的方案是，当Redis实例故障宕机后，业务请求可以直接返回错误，没必要再去请求数据库了，这样就不会导致数据库层压力变大。当然，最好的方式还是Redis部署主从集群+哨兵，主节点宕机后，哨兵可以及时把从节点提升为主，继续提供服务。</p>
<p>关于布隆过滤器的使用，还有几点和大家分享。</p>
<p>1、布隆过滤器会有误判：由于采用固定bit的数组，使用多个哈希函数映射到多个bit上，有可能会导致两个不同的值都映射到相同的一组bit上。虽然有误判，但对于业务没有影响，无非就是还存在一些穿透而已，但整体上已经过滤了大多数无效穿透请求。</p>
<p>2、布隆过滤器误判率和空间使用的计算：误判本质是因为哈希冲突，降低误判的方法是增加哈希函数 + 扩大整个bit数组的长度，但增加哈希函数意味着影响性能，扩大数组长度意味着空间占用变大，所以使用布隆过滤器，需要在误判率和性能、空间作一个平衡，具体的误判率是有一个计算公式可以推导出来的（比较复杂）。但我们在使用开源的布隆过滤器时比较简单，通常会提供2个参数：预估存入的数据量大小、要求的误判率，输入这些参数后，布隆过滤器会有自动计算出最佳的哈希函数数量和数组占用的空间大小，直接使用即可。</p>
<p>3、布隆过滤器可以放在缓存和数据库的最前面：把Redis当作布隆过滤器时（4.0提供了布隆过滤器模块，4.0以下需要引入第三方库），当用户产生业务数据写入缓存和数据库后，同时也写入布隆过滤器，之后当用户访问自己的业务数据时，先检查布隆过滤器，如果过滤器不存在，就不需要查询缓存和数据库了，可以同时降低缓存和数据库的压力。</p>
<p>4、Redis实现的布隆过滤器bigkey问题：Redis布隆过滤器是使用String类型实现的，存储的方式是一个bigkey，建议使用时单独部署一个实例，专门存放布隆过滤器的数据，不要和业务数据混用，否则在集群环境下，数据迁移时会导致Redis阻塞问题。</p>
<h2 id="缓存被污染了，该怎么办？"><a href="#缓存被污染了，该怎么办？" class="headerlink" title="缓存被污染了，该怎么办？"></a>缓存被污染了，该怎么办？</h2><h3 id="总结1-22"><a href="#总结1-22" class="headerlink" title="总结1"></a>总结1</h3><p>今天这节课，我们学习的是“如何解决缓存污染”这个问题。</p>
<p>缓存污染问题指的是留存在缓存中的数据，实际不会被再次访问了，但是又占据了缓存空间。如果这样的数据体量很大，甚至占满了缓存，每次有新数据写入缓存时，还需要把这些数据逐步淘汰出缓存，就会增加缓存操作的时间开销。</p>
<p>因此，要解决缓存污染问题，最关键的技术点就是能识别出这些只访问一次或是访问次数很少的数据，在淘汰数据时，优先把它们筛选出来并淘汰掉。因为 noviction 策略不涉及数据淘汰，所以这节课，我们就从能否有效解决缓存污染这个维度，分析了 Redis 的其他 7 种数据淘汰策略。</p>
<p>volatile-random 和 allkeys-random 是随机选择数据进行淘汰，无法把不再访问的数据筛选出来，可能会造成缓存污染。如果业务层明确知道数据的访问时长，可以给数据设置合理的过期时间，再设置 Redis 缓存使用 volatile-ttl 策略。当缓存写满时，剩余存活时间最短的数据就会被淘汰出缓存，避免滞留在缓存中，造成污染。</p>
<p>当我们使用 LRU 策略时，由于 LRU 策略只考虑数据的访问时效，对于只访问一次的数据来说，LRU 策略无法很快将其筛选出来。而 LFU 策略在 LRU 策略基础上进行了优化，在筛选数据时，首先会筛选并淘汰访问次数少的数据，然后针对访问次数相同的数据，再筛选并淘汰访问时间最久远的数据。</p>
<p>在具体实现上，相对于 LRU 策略，Redis 只是把原来 24bit 大小的 lru 字段，又进一步拆分成了 16bit 的 ldt 和 8bit 的 counter，分别用来表示数据的访问时间戳和访问次数。为了避开 8bit 最大只能记录 255 的限制，LFU 策略设计使用非线性增长的计数器来表示数据的访问次数。</p>
<p>在实际业务应用中，LRU 和 LFU 两个策略都有应用。LRU 和 LFU 两个策略关注的数据访问特征各有侧重，LRU 策略更加关注数据的时效性，而 LFU 策略更加关注数据的访问频次。通常情况下，实际应用的负载具有较好的时间局部性，所以 LRU 策略的应用会更加广泛。但是，在扫描式查询的应用场景中，LFU 策略就可以很好地应对缓存污染问题了，建议你优先使用。</p>
<p>此外，如果业务应用中有短时高频访问的数据，除了 LFU 策略本身会对数据的访问次数进行自动衰减以外，我再给你个小建议：你可以优先使用 volatile-lfu 策略，并根据这些数据的访问时限设置它们的过期时间，以免它们留存在缓存中造成污染。</p>
<h3 id="总结2-21"><a href="#总结2-21" class="headerlink" title="总结2"></a>总结2</h3><h3 id="问题1-12"><a href="#问题1-12" class="headerlink" title="问题1"></a>问题1</h3><p>按照惯例，我给你提个小问题。使用了 LFU 策略后，你觉得缓存还会被污染吗？</p>
<h3 id="解答1-12"><a href="#解答1-12" class="headerlink" title="解答1"></a>解答1</h3><p>使用了 LFU 策略后，缓存还会被污染吗？</p>
<p>我觉得还是有被污染的可能性，被污染的概率取决于LFU的配置，也就是lfu-log-factor和lfu-decay-time参数。</p>
<p>1、根据LRU counter计数规则可以得出，counter递增的概率取决于2个因素：</p>
<p>a) counter值越大，递增概率越低<br>b) lfu-log-factor设置越大，递增概率越低</p>
<p>所以当访问次数counter越来越大时，或者lfu-log-factor参数配置过大时，counter递增的概率都会越来越低，这种情况下可能会导致一些key虽然访问次数较高，但是counter值却递增困难，进而导致这些访问频次较高的key却优先被淘汰掉了。</p>
<p>另外由于counter在递增时，有随机数比较的逻辑，这也会存在一定概率导致访问频次低的key的counter反而大于访问频次高的key的counter情况出现。</p>
<p>2、如果lfu-decay-time配置过大，则counter衰减会变慢，也会导致数据淘汰发生推迟的情况。</p>
<p>3、另外，由于LRU的ldt字段只采用了16位存储，其精度是分钟级别的，在counter衰减时可能会产生同一分钟内，后访问的key比先访问的key的counter值优先衰减，进而先被淘汰掉的情况。</p>
<p>可见，Redis实现的LFU策略，也是近似的LFU算法。Redis在实现时，权衡了内存使用、性能开销、LFU的正确性，通过复用并拆分lru字段的方式，配合算法策略来实现近似的结果，虽然会有一定概率的偏差，但在内存数据库这种场景下，已经做得足够好了。</p>
<h2 id="Pika：如何基于SSD实现大容量Redis？"><a href="#Pika：如何基于SSD实现大容量Redis？" class="headerlink" title="Pika：如何基于SSD实现大容量Redis？"></a>Pika：如何基于SSD实现大容量Redis？</h2><h3 id="总结1-23"><a href="#总结1-23" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我们学习了基于 SSD 给 Redis 单实例进行扩容的技术方案 Pika。跟 Redis 相比，Pika 的好处非常明显：既支持 Redis 操作接口，又能支持保存大容量的数据。如果你原来就在应用 Redis，现在想进行扩容，那么，Pika 无疑是一个很好的选择，无论是代码迁移还是运维管理，Pika 基本不需要额外的工作量。</p>
<p>不过，Pika 毕竟是把数据保存到了 SSD 上，数据访问要读写 SSD，所以，读写性能要弱于 Redis。针对这一点，我给你提供两个降低读写 SSD 对 Pika 的性能影响的小建议：</p>
<ol>
<li>利用 Pika 的多线程模型，增加线程数量，提升 Pika 的并发请求处理能力；</li>
<li>为 Pika 配置高配的 SSD，提升 SSD 自身的访问性能。</li>
</ol>
<p>最后，我想再给你一个小提示。Pika 本身提供了很多工具，可以帮助我们把 Redis 数据迁移到 Pika，或者是把 Redis 请求转发给 Pika。比如说，我们使用 aof_to_pika 命令，并且指定 Redis 的 AOF 文件以及 Pika 的连接信息，就可以把 Redis 数据迁移到 Pika 中了，如下所示：</p>
<div class="code-wrapper"><pre><code class="hljs css"><span class="hljs-selector-tag">aof_to_pika</span> <span class="hljs-selector-tag">-i</span> <span class="hljs-selector-attr">[Redis AOF文件]</span> <span class="hljs-selector-tag">-h</span> <span class="hljs-selector-attr">[Pika IP]</span> <span class="hljs-selector-tag">-p</span> <span class="hljs-selector-attr">[Pika port]</span> <span class="hljs-selector-tag">-a</span> <span class="hljs-selector-attr">[认证信息]</span></code></pre></div>

<p>关于这些工具的信息，你都可以直接在 Pika 的<a href="https://github.com/OpenAtomFoundation/pika/wiki">GitHub</a>上找到。而且，Pika 本身也还在迭代开发中，我也建议你多去看看 GitHub，进一步地了解它。这样，你就可以获得 Pika 的最新进展，也能更好地把它应用到你的业务实践中。</p>
<h3 id="总结2-22"><a href="#总结2-22" class="headerlink" title="总结2"></a>总结2</h3><h3 id="问题1-13"><a href="#问题1-13" class="headerlink" title="问题1"></a>问题1</h3><p>按照惯例，我给你提个小问题。这节课，我向你介绍的是使用 SSD 作为内存容量的扩展，增加 Redis 实例的数据保存量，我想请你来聊一聊，我们可以使用机械硬盘来作为实例容量扩展吗，有什么好处或不足吗？</p>
<h3 id="解答1-13"><a href="#解答1-13" class="headerlink" title="解答1"></a>解答1</h3><p>是否可以使用机械硬盘作为Redis的内存容量的扩展？</p>
<p>我觉得也是可以的。机械硬盘相较于固态硬盘的优点是，成本更低、容量更大、寿命更长。</p>
<p>1、成本：机械硬盘是电磁存储，固态硬盘是半导体电容颗粒组成，相同容量下机械硬盘成本是固态硬盘的1/3。<br>2、容量：相同成本下，机械硬盘可使用的容量更大。<br>3、寿命：固态硬盘的电容颗粒擦写次数有限，超过一定次数后会不可用。相同ops情况下，机械硬盘的寿命要比固态硬盘的寿命更长。</p>
<p>但机械硬盘相较于固态硬盘的缺点也很明显，就是速度慢。</p>
<p>机械硬盘在读写数据时，需要通过转动磁盘和磁头等机械方式完成，而固态硬盘是直接通过电信号保存和控制数据的读写，速度非常快。</p>
<p>如果对于访问延迟要求不高，对容量和成本比较关注的场景，可以把Pika部署在机械硬盘上使用。</p>
<p>另外，关于Pika的使用场景，它并不能代替Redis，而是作为Redis的补充，在需要大容量存储（50G数据量以上）、访问延迟要求不苛刻的业务场景下使用。在使用之前，最好是根据自己的业务情况，先做好调研和性能测试，评估后决定是否使用。</p>
<h2 id="无锁的原子操作：Redis如何应对并发访问？"><a href="#无锁的原子操作：Redis如何应对并发访问？" class="headerlink" title="无锁的原子操作：Redis如何应对并发访问？"></a>无锁的原子操作：Redis如何应对并发访问？</h2><h3 id="总结1-24"><a href="#总结1-24" class="headerlink" title="总结1"></a>总结1</h3><p>在并发访问时，并发的 RMW 操作会导致数据错误，所以需要进行并发控制。所谓并发控制，就是要保证临界区代码的互斥执行。</p>
<p>Redis 提供了两种原子操作的方法来实现并发控制，分别是单命令操作和 Lua 脚本。因为原子操作本身不会对太多的资源限制访问，可以维持较高的系统并发性能。</p>
<p>但是，单命令原子操作的适用范围较小，并不是所有的 RMW 操作都能转变成单命令的原子操作（例如 INCR/DECR 命令只能在读取数据后做原子增减），当我们需要对读取的数据做更多判断，或者是我们对数据的修改不是简单的增减时，单命令操作就不适用了。</p>
<p>而 Redis 的 Lua 脚本可以包含多个操作，这些操作都会以原子性的方式执行，绕开了单命令操作的限制。不过，如果把很多操作都放在 Lua 脚本中原子执行，会导致 Redis 执行脚本的时间增加，同样也会降低 Redis 的并发性能。所以，我给你一个小建议：在编写 Lua 脚本时，你要避免把不需要做并发控制的操作写入脚本中。</p>
<p>当然，加锁也能实现临界区代码的互斥执行，只是如果有多个客户端加锁时，就需要分布式锁的支持了。所以，下节课，我就来和你聊聊分布式锁的实现。</p>
<h3 id="总结2-23"><a href="#总结2-23" class="headerlink" title="总结2"></a>总结2</h3><h3 id="问题1-14"><a href="#问题1-14" class="headerlink" title="问题1"></a>问题1</h3><p>按照惯例，我向你提个小问题，Redis 在执行 Lua 脚本时，是可以保证原子性的，那么，在我举的 Lua 脚本例子（lua.script）中，你觉得是否需要把读取客户端 ip 的访问次数，也就是 GET(ip)，以及判断访问次数是否超过 20 的判断逻辑，也加到 Lua 脚本中吗？</p>
<h3 id="解答1-14"><a href="#解答1-14" class="headerlink" title="解答1"></a>解答1</h3><p>是否需要把读取客户端 ip 的访问次数 GET(ip)，以及判断访问次数是否超过 20 的判断逻辑，也加到 Lua 脚本中？</p>
<p>我觉得不需要，理由主要有2个。</p>
<p>1、这2个逻辑都是读操作，不会对资源临界区产生修改，所以不需要做并发控制。</p>
<p>2、减少 lua 脚本中的命令，可以降低Redis执行脚本的时间，避免阻塞 Redis。</p>
<p>另外使用lua脚本时，还有一些注意点：</p>
<p>1、lua 脚本尽量只编写通用的逻辑代码，避免直接写死变量。变量通过外部调用方传递进来，这样 lua 脚本的可复用度更高。</p>
<p>2、建议先使用SCRIPT LOAD命令把 lua 脚本加载到 Redis 中，然后得到一个脚本唯一摘要值，再通过EVALSHA命令 + 脚本摘要值来执行脚本，这样可以避免每次发送脚本内容到 Redis，减少网络开销。</p>
<h2 id="如何使用Redis实现分布式锁？"><a href="#如何使用Redis实现分布式锁？" class="headerlink" title="如何使用Redis实现分布式锁？"></a>如何使用Redis实现分布式锁？</h2><h3 id="总结1-25"><a href="#总结1-25" class="headerlink" title="总结1"></a>总结1</h3><p>分布式锁是由共享存储系统维护的变量，多个客户端可以向共享存储系统发送命令进行加锁或释放锁操作。Redis 作为一个共享存储系统，可以用来实现分布式锁。</p>
<p>在基于单个 Redis 实例实现分布式锁时，对于加锁操作，我们需要满足三个条件。</p>
<ol>
<li>加锁包括了读取锁变量、检查锁变量值和设置锁变量值三个操作，但需要以原子操作的方式完成，所以，我们使用 SET 命令带上 NX 选项来实现加锁；</li>
<li>锁变量需要设置过期时间，以免客户端拿到锁后发生异常，导致锁一直无法释放，所以，我们在 SET 命令执行时加上 EX/PX 选项，设置其过期时间；</li>
<li>锁变量的值需要能区分来自不同客户端的加锁操作，以免在释放锁时，出现误释放操作，所以，我们使用 SET 命令设置锁变量值时，每个客户端设置的值是一个唯一值，用于标识客户端。</li>
</ol>
<p>和加锁类似，释放锁也包含了读取锁变量值、判断锁变量值和删除锁变量三个操作，不过，我们无法使用单个命令来实现，所以，我们可以采用 Lua 脚本执行释放锁操作，通过 Redis 原子性地执行 Lua 脚本，来保证释放锁操作的原子性。</p>
<p>不过，基于单个 Redis 实例实现分布式锁时，会面临实例异常或崩溃的情况，这会导致实例无法提供锁操作，正因为此，Redis 也提供了 Redlock 算法，用来实现基于多个实例的分布式锁。这样一来，锁变量由多个实例维护，即使有实例发生了故障，锁变量仍然是存在的，客户端还是可以完成锁操作。Redlock 算法是实现高可靠分布式锁的一种有效解决方案，你可以在实际应用中把它用起来。</p>
<h3 id="总结2-24"><a href="#总结2-24" class="headerlink" title="总结2"></a>总结2</h3><h3 id="问题1-15"><a href="#问题1-15" class="headerlink" title="问题1"></a>问题1</h3><p>按照惯例，我给你提个小问题。这节课，我提到，我们可以使用 SET 命令带上 NX 和 EX/PX 选项进行加锁操作，那么，我想请你再思考一下，我们是否可以用下面的方式来实现加锁操作呢？</p>
<div class="code-wrapper"><pre><code class="hljs awk"><span class="hljs-regexp">//</span> 加锁
SETNX lock_key unique_value
EXPIRE lock_key <span class="hljs-number">10</span>S
<span class="hljs-regexp">//</span> 业务逻辑
DO THINGS</code></pre></div>

<h3 id="解答1-15"><a href="#解答1-15" class="headerlink" title="解答1"></a>解答1</h3><p>是否可以使用 SETNX + EXPIRE 来完成加锁操作？</p>
<p>不可以这么使用。使用 2 个命令无法保证操作的原子性，在异常情况下，加锁结果会不符合预期。异常情况主要分为以下几种情况：</p>
<p>1、SETNX 执行成功，执行 EXPIRE 时由于网络问题设置过期失败</p>
<p>2、SETNX 执行成功，此时 Redis 实例宕机，EXPIRE 没有机会执行</p>
<p>3、SETNX 执行成功，客户端异常崩溃，EXPIRE 没有机会执行</p>
<p>如果发生以上情况，并且客户端在释放锁时发生异常，没有正常释放锁，那么这把锁就会一直无法释放，其他线程都无法再获得锁。</p>
<p>下面说一下关于 Redis 分布式锁可靠性的问题。</p>
<p>使用单个 Redis 节点（只有一个master）使用分布锁，如果实例宕机，那么无法进行锁操作了。那么采用主从集群模式部署是否可以保证锁的可靠性？</p>
<p>答案是也很难保证。如果在 master 上加锁成功，此时 master 宕机，由于主从复制是异步的，加锁操作的命令还未同步到 slave，此时主从切换，新 master 节点依旧会丢失该锁，对业务来说相当于锁失效了。</p>
<p>所以 Redis 作者才提出基于多个 Redis 节点（master节点）的 Redlock 算法，但这个算法涉及的细节很多，作者在提出这个算法时，业界的分布式系统专家还与 Redis 作者发生过一场争论，来评估这个算法的可靠性，争论的细节都是关于异常情况可能导致 Redlock 失效的场景，例如加锁过程中客户端发生了阻塞、机器时钟发生跳跃等等。</p>
<p>感兴趣的可以看下这篇文章，详细介绍了争论的细节，以及 Redis 分布式锁在各种异常情况是否安全的分析，收益会非常大：<a href="http://zhangtielei.com/posts/blog-redlock-reasoning.html%E3%80%82">http://zhangtielei.com/posts/blog-redlock-reasoning.html。</a></p>
<p>简单总结，基于 Redis 使用分布锁的注意点：</p>
<p>1、使用 SET $lock_key $unique_val EX $second NX 命令保证加锁原子性，并为锁设置过期时间</p>
<p>2、锁的过期时间要提前评估好，要大于操作共享资源的时间</p>
<p>3、每个线程加锁时设置随机值，释放锁时判断是否和加锁设置的值一致，防止自己的锁被别人释放</p>
<p>4、释放锁时使用 Lua 脚本，保证操作的原子性</p>
<p>5、基于多个节点的 Redlock，加锁时超过半数节点操作成功，并且获取锁的耗时没有超过锁的有效时间才算加锁成功</p>
<p>6、Redlock 释放锁时，要对所有节点释放（即使某个节点加锁失败了），因为加锁时可能发生服务端加锁成功，由于网络问题，给客户端回复网络包失败的情况，所以需要把所有节点可能存的锁都释放掉</p>
<p>7、使用 Redlock 时要避免机器时钟发生跳跃，需要运维来保证，对运维有一定要求，否则可能会导致 Redlock 失效。例如共 3 个节点，线程 A 操作 2 个节点加锁成功，但其中 1 个节点机器时钟发生跳跃，锁提前过期，线程 B 正好在另外 2 个节点也加锁成功，此时 Redlock 相当于失效了（Redis 作者和分布式系统专家争论的重要点就在这）</p>
<p>8、如果为了效率，使用基于单个 Redis 节点的分布式锁即可，此方案缺点是允许锁偶尔失效，优点是简单效率高</p>
<p>9、如果是为了正确性，业务对于结果要求非常严格，建议使用 Redlock，但缺点是使用比较重，部署成本高</p>
<h2 id="事务机制：Redis能实现ACID属性吗？"><a href="#事务机制：Redis能实现ACID属性吗？" class="headerlink" title="事务机制：Redis能实现ACID属性吗？"></a>事务机制：Redis能实现ACID属性吗？</h2><h3 id="总结1-26"><a href="#总结1-26" class="headerlink" title="总结1"></a>总结1</h3><p>在这节课上，我们学习了 Redis 中的事务实现。Redis 通过 MULTI、EXEC、DISCARD 和 WATCH 四个命令来支持事务机制，这 4 个命令的作用，我总结在下面的表中，你可以再看下。</p>
<p><img src="/images/redis/acid-01.png" alt="img.png"></p>
<p>事务的 ACID 属性是我们使用事务进行正确操作的基本要求。通过这节课的分析，我们了解到了，Redis 的事务机制可以保证一致性和隔离性，但是无法保证持久性。不过，因为 Redis 本身是内存数据库，持久性并不是一个必须的属性，我们更加关注的还是原子性、一致性和隔离性这三个属性。</p>
<p>原子性的情况比较复杂，只有当事务中使用的命令语法有误时，原子性得不到保证，在其它情况下，事务都可以原子性执行。</p>
<p>所以，我给你一个小建议：严格按照 Redis 的命令规范进行程序开发，并且通过 code review 确保命令的正确性。这样一来，Redis 的事务机制就能被应用在实践中，保证多操作的正确执行。</p>
<h3 id="总结2-25"><a href="#总结2-25" class="headerlink" title="总结2"></a>总结2</h3><p>1、作者讲了什么？<br>作者通过本文讨论，Redis 是否可以保证 ACID 的事务功能。事务是对数据进行一系列操作。<br>2、作者是怎么把事情说明白的？<br>作者先讨论 事务ACID 属性的要求：然后作者说明了 Redis 的 API ：MULTI 和 EXEC 是如何完成事务的；完成说明后，作者开始针对事务的每个特性，讨论 Redis 是否已经完成达成。<br>2.1 原子性。原子性的保证分三种情况<br>2.1.1 队列中有命令存在错误，队列清空；（可保证原子）<br>2.1.2 队列中命令到执行的时候才被发现有错误，不会滚，执行多少算多少；（不保证原子）<br>2.1.3 EXEC 时， Redis 实例发生故障。这个涉及到日志，AOF 的 redis-check-aof 可以发现没执行完成的操作，进而清除；（可以保证原子）<br>2.2 一致性。作者分三种情况说明，并且确认都可以提供一致性。<br>2.3 隔离性。WATCH 机制提供事务隔离性。<br>2.4 持久性。Redis 任何时候都无法提供持久性保障。</p>
<p>3、为了讲明白，作者讲了哪些要点？哪些是亮点？<br>在 Redis 的事务上，作者通过 三种情况 ，分别说明了 Redis 是否满足 ACID 特性，这个划分方法是一个亮点；</p>
<p>4、对于作者所讲，我有哪些发散性思考？<br>Redis 始终坚持是一个高性能的内存数据库，并没有因为事务的重要性而放弃这一个宗旨，故在内存中实现了隔离性，一致性，有条件原子性，不实现持久性。这个也可以放映出 Redis 的定位和一般数据库 MySQL 是不一样的；</p>
<p>5、在未来哪些场景，我可以使用它？<br>在高并发，竞争环境下，需要保证数据正确时，可以考虑 Redis 的事务性实现。</p>
<h3 id="问题1-16"><a href="#问题1-16" class="headerlink" title="问题1"></a>问题1</h3><p>按照惯例，我给你提个小问题，在执行事务时，如果 Redis 实例发生故障，而 Redis 使用了 RDB 机制，那么，事务的原子性还能得到保证吗？</p>
<h3 id="解答1-16"><a href="#解答1-16" class="headerlink" title="解答1"></a>解答1</h3><p>在执行事务时，如果 Redis 实例发生故障，而 Redis 使用的 RDB 机制，事务的原子性还能否得到保证？</p>
<p>我觉得是可以保证原子性的。</p>
<p>如果一个事务只执行了一半，然后 Redis 实例故障宕机了，由于 RDB 不会在事务执行时执行，所以 RDB 文件中不会记录只执行了一部分的结果数据。之后用 RDB 恢复实例数据，恢复的还是事务之前的数据。但 RDB 本身是快照持久化，所以会存在数据丢失，丢失的是距离上一次 RDB 之间的所有更改操作。</p>
<p>关于 Redis 事务的使用，有几个细节我觉得有必要补充下，关于 Pipeline 和 WATCH 命令的使用。</p>
<p>1、在使用事务时，建议配合 Pipeline 使用。</p>
<p>a) 如果不使用 Pipeline，客户端是先发一个 MULTI 命令到服务端，客户端收到 OK，然后客户端再发送一个个操作命令，客户端依次收到 QUEUED，最后客户端发送 EXEC 执行整个事务（文章例子就是这样演示的），这样消息每次都是一来一回，效率比较低，而且在这多次操作之间，别的客户端可能就把原本准备修改的值给修改了，所以无法保证隔离性。</p>
<p>b) 而使用 Pipeline 是一次性把所有命令打包好全部发送到服务端，服务端全部处理完成后返回。这么做好的好处，一是减少了来回网络 IO 次数，提高操作性能。二是一次性发送所有命令到服务端，服务端在处理过程中，是不会被别的请求打断的（Redis单线程特性，此时别的请求进不来），这本身就保证了隔离性。我们平时使用的 Redis SDK 在使用开启事务时，一般都会默认开启 Pipeline 的，可以留意观察一下。</p>
<p>2、关于 WATCH 命令的使用场景。</p>
<p>a) 在上面 1-a 场景中，也就是使用了事务命令，但没有配合 Pipeline 使用，如果想要保证隔离性，需要使用 WATCH 命令保证，也就是文章中讲 WATCH 的例子。但如果是 1-b 场景，使用了 Pipeline 一次发送所有命令到服务端，那么就不需要使用 WATCH 了，因为服务端本身就保证了隔离性。</p>
<p>b) 如果事务 + Pipeline 就可以保证隔离性，那 WATCH 还有没有使用的必要？答案是有的。对于一个资源操作为读取、修改、写回这种场景，如果需要保证事物的原子性，此时就需要用到 WATCH 了。例如想要修改某个资源，但需要事先读取它的值，再基于这个值进行计算后写回，如果在这期间担心这个资源被其他客户端修改了，那么可以先 WATCH 这个资源，再读取、修改、写回，如果写回成功，说明其他客户端在这期间没有修改这个资源。如果其他客户端修改了这个资源，那么这个事务操作会返回失败，不会执行，从而保证了原子性。</p>
<p>细节比较多，如果不太好理解，最好亲自动手试一下。</p>
<h2 id="Redis主从同步与故障切换，有哪些坑？"><a href="#Redis主从同步与故障切换，有哪些坑？" class="headerlink" title="Redis主从同步与故障切换，有哪些坑？"></a>Redis主从同步与故障切换，有哪些坑？</h2><h3 id="总结1-27"><a href="#总结1-27" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我们学习了 Redis 主从库同步时可能出现的 3 个坑，分别是主从数据不一致、读取到过期数据和不合理配置项导致服务挂掉。</p>
<p>为了方便你掌握，我把这些坑的成因和解决方法汇总在下面的这张表中，你可以再回顾下。</p>
<p><img src="/images/redis/master-slave-01.png" alt="img.png"></p>
<p>最后，关于主从库数据不一致的问题，我还想再给你提一个小建议：Redis 中的 slave-serve-stale-data 配置项设置了从库能否处理数据读写命令，你可以把它设置为 no。这样一来，从库只能服务 INFO、SLAVEOF 命令，这就可以避免在从库中读到不一致的数据了。</p>
<p>不过，你要注意下这个配置项和 slave-read-only 的区别，slave-read-only 是设置从库能否处理写命令，slave-read-only 设置为 yes 时，从库只能处理读请求，无法处理写请求，你可不要搞混了。</p>
<h3 id="总结2-26"><a href="#总结2-26" class="headerlink" title="总结2"></a>总结2</h3><h3 id="问题1-17"><a href="#问题1-17" class="headerlink" title="问题1"></a>问题1</h3><p>按照惯例，我给你提个小问题，我们把 slave-read-only 设置为 no，让从库也能直接删除数据，以此来避免读到过期数据，你觉得，这是一个好方法吗？</p>
<h3 id="解答1-17"><a href="#解答1-17" class="headerlink" title="解答1"></a>解答1</h3><p>把 slave-read-only 设置为 no，让从库也能直接删除数据，以此来避免读到过期数据，这种方案是否可行？</p>
<p>我个人觉得这个问题有些歧义，因为尽管把 slave-read-only 设置为 no，其实 slave 也不会主动过期删除从 master 同步过来的数据的。</p>
<p>我猜老师想问的应该是：假设让 slave 也可以自动删除过期数据，是否可以保证主从库的一致性？</p>
<p>其实这样也无法保证，例如以下场景：</p>
<p>1、主从同步存在网络延迟。例如 master 先执行 SET key 1 10，这个 key 同步到了 slave，此时 key 在主从库都是 10s 后过期，之后这个 key 还剩 1s 过期时，master 又执行了 expire key 60，重设这个 key 的过期时间。但 expire 命令向 slave 同步时，发生了网络延迟并且超过了 1s，如果 slave 可以自动删除过期 key，那么这个 key 正好达到过期时间，就会被 slave 删除了，之后 slave 再收到 expire 命令时，执行会失败。最后的结果是这个 key 在 slave 上丢失了，主从库发生了不一致。</p>
<p>2、主从机器时钟不一致。同样 master 执行 SET key 1 10，然后把这个 key 同步到 slave，但是此时 slave 机器时钟如果发生跳跃，优先把这个 key 过期删除了，也会发生上面说的不一致问题。</p>
<p>所以 Redis 为了保证主从同步的一致性，不会让 slave 自动删除过期 key，而只在 master 删除过期 key，之后 master 会向 slave 发送一个 DEL，slave 再把这个 key 删除掉，这种方式可以解决主从网络延迟和机器时钟不一致带来的影响。</p>
<p>再解释一下 slave-read-only 的作用，它主要用来控制 slave 是否可写，但是否主动删除过期 key，根据 Redis 版本不同，执行逻辑也不同。</p>
<p>1、如果版本低于 Redis 4.0，slave-read-only 设置为 no，此时 slave 允许写入数据，但如果 key 设置了过期时间，那么这个 key 过期后，虽然在 slave 上查询不到了，但并不会在内存中删除，这些过期 key 会一直占着 Redis 内存无法释放。</p>
<p>2、Redis 4.0 版本解决了上述问题，在 slave 写入带过期时间的 key，slave 会记下这些 key，并且在后台定时检测这些 key 是否已过期，过期后从内存中删除。</p>
<p>但是请注意，这 2 种情况，slave 都不会主动删除由 <em>master 同步过来带有过期时间的 key</em>。也就是 master 带有过期时间的 key，什么时候删除由 master 自己维护，slave 不会介入。如果 slave 设置了 slave-read-only = no，而且是 4.0+ 版本，slave 也只维护直接向自己写入 的带有过期的 key，过期时只删除这些 key。</p>
<p>另外，我还能想到的主从同步的 2 个问题:</p>
<p>1、主从库设置的 maxmemory 不同，如果 slave 比 master 小，那么 slave 内存就会优先达到 maxmemroy，然后开始淘汰数据，此时主从库也会产生不一致。</p>
<p>2、如果主从同步的 client-output-buffer-limit 设置过小，并且 master 数据量很大，主从全量同步时可能会导致 buffer 溢出，溢出后主从全量同步就会失败。如果主从集群配置了哨兵，那么哨兵会让 slave 继续向 master 发起全量同步请求，然后 buffer 又溢出同步失败，如此反复，会形成复制风暴，这会浪费 master 大量的 CPU、内存、带宽资源，也会让 master 产生阻塞的风险。</p>
<p>感谢Kaito同学的回复和详细分析！很赞！</p>
<p>我也解释下，到时出这道题的一个考虑出发点。</p>
<p>这道题我其实是想问大家，假设从库也能直接删除过期数据的话，是不是一个好方法。其实，是想提醒下同学们，主从复制中的增删改都需要在主库执行，即使从库能做删除，也不要在从库删除。否则会造成数据不一致。例如，假设主从库上都能做写操作的话，主从库上有a:stock的键，客户端A给主库发送一个SET命令，修改a:stock的值，客户端B给从库发送了一个SET命令，也修改a:stock的值，此时，相同键的值就不一样了。所以，让从库可以做写操作会造成主从数据不一致。</p>
<h2 id="脑裂：一次奇怪的数据丢失"><a href="#脑裂：一次奇怪的数据丢失" class="headerlink" title="脑裂：一次奇怪的数据丢失"></a>脑裂：一次奇怪的数据丢失</h2><h3 id="总结1-28"><a href="#总结1-28" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我们学习了主从切换时可能遇到的脑裂问题。脑裂是指在主从集群中，同时有两个主库都能接收写请求。在 Redis 的主从切换过程中，如果发生了脑裂，客户端数据就会写入到原主库，如果原主库被降为从库，这些新写入的数据就丢失了。</p>
<p>脑裂发生的原因主要是原主库发生了假故障，我们来总结下假故障的两个原因。</p>
<p>和主库部署在同一台服务器上的其他程序临时占用了大量资源（例如 CPU 资源），导致主库资源使用受限，短时间内无法响应心跳。其它程序不再使用资源时，主库又恢复正常。<br>主库自身遇到了阻塞的情况，例如，处理 bigkey 或是发生内存 swap（你可以复习下第 19 讲中总结的导致实例阻塞的原因），短时间内无法响应心跳，等主库阻塞解除后，又恢复正常的请求处理了。</p>
<p>为了应对脑裂，你可以在主从集群部署时，通过合理地配置参数 min-slaves-to-write 和 min-slaves-max-lag，来预防脑裂的发生。</p>
<p>在实际应用中，可能会因为网络暂时拥塞导致从库暂时和主库的 ACK 消息超时。在这种情况下，并不是主库假故障，我们也不用禁止主库接收请求。</p>
<p>所以，我给你的建议是，假设从库有 K 个，可以将 min-slaves-to-write 设置为 K/2+1（如果 K 等于 1，就设为 1），将 min-slaves-max-lag 设置为十几秒（例如 10～20s），在这个配置下，如果有一半以上的从库和主库进行的 ACK 消息延迟超过十几秒，我们就禁止主库接收客户端写请求。</p>
<p>这样一来，我们可以避免脑裂带来数据丢失的情况，而且，也不会因为只有少数几个从库因为网络阻塞连不上主库，就禁止主库接收请求，增加了系统的鲁棒性。</p>
<h3 id="总结2-27"><a href="#总结2-27" class="headerlink" title="总结2"></a>总结2</h3><h3 id="问题1-18"><a href="#问题1-18" class="headerlink" title="问题1"></a>问题1</h3><p>按照惯例，我给你提个小问题，假设我们将 min-slaves-to-write 设置为 1，min-slaves-max-lag 设置为 15s，哨兵的 down-after-milliseconds 设置为 10s，哨兵主从切换需要 5s。主库因为某些原因卡住了 12s，此时，还会发生脑裂吗？主从切换完成后，数据会丢失吗？</p>
<h3 id="解答1-18"><a href="#解答1-18" class="headerlink" title="解答1"></a>解答1</h3><p>假设我们将 min-slaves-to-write 设置为 1，min-slaves-max-lag 设置为 15s，哨兵的 down-after-milliseconds 设置为 10s，哨兵主从切换需要 5s。主库因为某些原因卡住了 12s，此时，还会发生脑裂吗？主从切换完成后，数据会丢失吗？</p>
<p>主库卡住 12s，达到了哨兵设定的切换阈值，所以哨兵会触发主从切换。但哨兵切换的时间是 5s，也就是说哨兵还未切换完成，主库就会从阻塞状态中恢复回来，而且也没有触发 min-slaves-max-lag 阈值，所以主库在哨兵切换剩下的 3s 内，依旧可以接收客户端的写操作，如果这些写操作还未同步到从库，哨兵就把从库提升为主库了，那么此时也会出现脑裂的情况，之后旧主库降级为从库，重新同步新主库的数据，新主库也会发生数据丢失。</p>
<p>由此也可以看出，即使 Redis 配置了 min-slaves-to-write 和 min-slaves-max-lag，当脑裂发生时，还是无法严格保证数据不丢失，它只能是尽量减少数据的丢失。</p>
<p>其实在这种情况下，新主库之所以会发生数据丢失，是因为旧主库从阻塞中恢复过来后，收到的写请求还没同步到从库，从库就被哨兵提升为主库了。如果哨兵在提升从库为新主库前，主库及时把数据同步到从库了，那么从库提升为主库后，也不会发生数据丢失。但这种临界点的情况还是有发生的可能性，因为 Redis 本身不保证主从同步的强一致。</p>
<p>还有一种发生脑裂的情况，就是网络分区：主库和客户端、哨兵和从库被分割成了 2 个网络，主库和客户端处在一个网络中，从库和哨兵在另一个网络中，此时哨兵也会发起主从切换，出现 2 个主库的情况，而且客户端依旧可以向旧主库写入数据。等网络恢复后，主库降级为从库，新主库丢失了这期间写操作的数据。</p>
<p>脑裂产生问题的本质原因是，Redis 主从集群内部没有通过共识算法，来维护多个节点数据的强一致性。它不像 Zookeeper 那样，每次写请求必须大多数节点写成功后才认为成功。当脑裂发生时，Zookeeper 主节点被孤立，此时无法写入大多数节点，写请求会直接返回失败，因此它可以保证集群数据的一致性。</p>
<p>另外关于 min-slaves-to-write，有一点也需要注意：如果只有 1 个从库，当把 min-slaves-to-write 设置为 1 时，在运维时需要小心一些，当日常对从库做维护时，例如更换从库的实例，需要先添加新的从库，再移除旧的从库才可以，或者使用 config set 修改 min-slaves-to-write 为 0 再做操作，否则会导致主库拒绝写，影响到业务。</p>
<h2 id="Codis-VS-Redis-Cluster：我该选择哪一个集群方案？"><a href="#Codis-VS-Redis-Cluster：我该选择哪一个集群方案？" class="headerlink" title="Codis VS Redis Cluster：我该选择哪一个集群方案？"></a>Codis VS Redis Cluster：我该选择哪一个集群方案？</h2><h3 id="总结1-29"><a href="#总结1-29" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我们学习了 Redis 切片集群的 Codis 方案。Codis 集群包含 codis server、codis proxy、Zookeeper、codis dashboard 和 codis fe 这四大类组件。我们再来回顾下它们的主要功能。</p>
<ul>
<li>codis proxy 和 codis server 负责处理数据读写请求，其中，codis proxy 和客户端连接，接收请求，并转发请求给 codis server，而 codis server 负责具体处理请求。</li>
<li>codis dashboard 和 codis fe 负责集群管理，其中，codis dashboard 执行管理操作，而 codis fe 提供 Web 管理界面。</li>
<li>Zookeeper 集群负责保存集群的所有元数据信息，包括路由表、proxy 实例信息等。这里，有个地方需要你注意，除了使用 Zookeeper，Codis 还可以使用 etcd 或本地文件系统保存元数据信息。</li>
</ul>
<p>关于 Codis 和 Redis Cluster 的选型考虑，我从稳定性成熟度、客户端兼容性、Redis 新特性使用以及数据迁移性能四个方面给你提供了建议，希望能帮助到你。</p>
<p>最后，我再给你提供一个 Codis 使用上的小建议：当你有多条业务线要使用 Codis 时，可以启动多个 codis dashboard，每个 dashboard 管理一部分 codis server，同时，再用一个 dashboard 对应负责一个业务线的集群管理，这样，就可以做到用一个 Codis 集群实现多条业务线的隔离管理了。</p>
<h3 id="总结2-28"><a href="#总结2-28" class="headerlink" title="总结2"></a>总结2</h3><h3 id="问题1-19"><a href="#问题1-19" class="headerlink" title="问题1"></a>问题1</h3><p>按照惯例，我会给你提个小问题。假设 Codis 集群中保存的 80% 的键值对都是 Hash 类型，每个 Hash 集合的元素数量在 10 万～20 万个，每个集合元素的大小是 2KB。你觉得，迁移一个这样的 Hash 集合数据，会对 Codis 的性能造成影响吗？</p>
<h3 id="解答1-19"><a href="#解答1-19" class="headerlink" title="解答1"></a>解答1</h3><p>假设 Codis 集群中保存的 80% 的键值对都是 Hash 类型，每个 Hash 集合的元素数量在 10 万 ～ 20 万个，每个集合元素的大小是 2KB。迁移一个这样的 Hash 集合数据，是否会对 Codis 的性能造成影响？</p>
<p>不会有性能影响。</p>
<p>Codis 在迁移数据时，设计的方案可以保证迁移性能不受影响。</p>
<p>1、异步迁移：源节点把迁移的数据发送给目标节点后就返回，之后接着处理客户端请求，这个阶段不会长时间阻塞源节点。目标节点加载迁移的数据成功后，向源节点发送 ACK 命令，告知其迁移成功。</p>
<p>2、源节点异步释放 key：源节点收到目标节点 ACK 后，在源实例删除这个 key，释放 key 内存的操作，会放到后台线程中执行，不会阻塞源实例。（没错，Codis 比 Redis 更早地支持了 lazy-free，只不过只用在了数据迁移中）。</p>
<p>3、小对象序列化传输：小对象依旧采用序列化方式迁移，节省网络流量。</p>
<p>4、bigkey 分批迁移：bigkey 拆分成一条条命令，打包分批迁移（利用了 Pipeline 的优势），提升迁移速度。</p>
<p>5、一次迁移多个 key：一次发送多个 key 进行迁移，提升迁移效率。</p>
<p>6、迁移流量控制：迁移时会控制缓冲区大小，避免占满网络带宽。</p>
<p>7、bigkey 迁移原子性保证（兼容迁移失败情况）：迁移前先发一个 DEL 命令到目标节点（重试可保证幂等性），然后把 bigkey 拆分成一条条命令，并设置一个临时过期时间（防止迁移失败在目标节点遗留垃圾数据），迁移成功后在目标节点设置真实的过期时间。</p>
<p>Codis 在数据迁移方面要比 Redis Cluster 做得更优秀，而且 Codis 还带了一个非常友好的运维界面，方便 DBA 执行增删节点、主从切换、数据迁移等操作。</p>
<p>我当时在对 Codis 开发新的组件时，被 Codis 的优秀设计深深折服。当然，它的缺点也很明显，组件比较多，部署略复杂。另外，因为是基于 Redis 3.2.8 做的二次开发，所以升级 Redis Server 比较困难，新特性也就自然无法使用。</p>
<p>现在 Codis 已经不再维护，但是作为国人开发的 Redis 集群解决方案，其设计思想还是非常值得学习的。也推荐 Go 开发者，读一读 Codis 源码，质量非常高，对于 Go 语言的进阶也会有很大收获！</p>
<h2 id="Redis支撑秒杀场景的关键技术和实践都有哪些？"><a href="#Redis支撑秒杀场景的关键技术和实践都有哪些？" class="headerlink" title="Redis支撑秒杀场景的关键技术和实践都有哪些？"></a>Redis支撑秒杀场景的关键技术和实践都有哪些？</h2><h3 id="总结1-30"><a href="#总结1-30" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我们学习了 Redis 在秒杀场景中的具体应用。秒杀场景有 2 个负载特征，分别是瞬时高并发请求和读多写少。Redis 良好的高并发处理能力，以及高效的键值对读写特性，正好可以满足秒杀场景的需求。</p>
<p>在秒杀场景中，我们可以通过前端 CDN 和浏览器缓存拦截大量秒杀前的请求。在实际秒杀活动进行时，库存查验和库存扣减是承受巨大并发请求压力的两个操作，同时，这两个操作的执行需要保证原子性。Redis 的原子操作、分布式锁这两个功能特性可以有效地来支撑秒杀场景的需求。</p>
<p>当然，对于秒杀场景来说，只用 Redis 是不够的。秒杀系统是一个系统性工程，Redis 实现了对库存查验和扣减这个环节的支撑，除此之外，还有 4 个环节需要我们处理好。</p>
<ol>
<li>前端静态页面的设计。秒杀页面上能静态化处理的页面元素，我们都要尽量静态化，这样可以充分利用 CDN 或浏览器缓存服务秒杀开始前的请求。</li>
<li>请求拦截和流控。在秒杀系统的接入层，对恶意请求进行拦截，避免对系统的恶意攻击，例如使用黑名单禁止恶意 IP 进行访问。如果 Redis 实例的访问压力过大，为了避免实例崩溃，我们也需要在接入层进行限流，控制进入秒杀系统的请求数量。</li>
<li>库存信息过期时间处理。Redis 中保存的库存信息其实是数据库的缓存，为了避免缓存击穿问题，我们不要给库存信息设置过期时间。</li>
<li>数据库订单异常处理。如果数据库没能成功处理订单，可以增加订单重试功能，保证订单最终能被成功处理。</li>
</ol>
<p>最后，我也再给你一个小建议：秒杀活动带来的请求流量巨大，我们需要把秒杀商品的库存信息用单独的实例保存，而不要和日常业务系统的数据保存在同一个实例上，这样可以避免干扰业务系统的正常运行。</p>
<h3 id="总结2-29"><a href="#总结2-29" class="headerlink" title="总结2"></a>总结2</h3><h3 id="问题1-20"><a href="#问题1-20" class="headerlink" title="问题1"></a>问题1</h3><p>按照惯例，我给你提个小问题，假设一个商品的库存量是 800，我们使用一个包含了 4 个实例的切片集群来服务秒杀请求。我们让每个实例各自维护库存量 200，然后，客户端的秒杀请求可以分发到不同的实例上进行处理，你觉得这是一个好方法吗？</p>
<h3 id="解答1-20"><a href="#解答1-20" class="headerlink" title="解答1"></a>解答1</h3><p>使用多个实例的切片集群来分担秒杀请求，是否是一个好方法？</p>
<p>使用切片集群分担秒杀请求，可以降低每个实例的请求压力，前提是秒杀请求可以平均打到每个实例上，否则会出现秒杀请求倾斜的情况，反而会增加某个实例的压力，而且会导致商品没有全部卖出的情况。</p>
<p>但用切片集群分别存储库存信息，缺点是如果需要向用户展示剩余库存，要分别查询多个切片，最后聚合结果后返回给客户端。这种情况下，建议不展示剩余库存信息，直接针对秒杀请求返回是否秒杀成功即可。</p>
<p>秒杀系统最重要的是，把大部分请求拦截在最前面，只让很少请求能够真正进入到后端系统，降低后端服务的压力，常见的方案包括：页面静态化（推送到CDN）、网关恶意请求拦截、请求分段放行、缓存校验和扣减库存、消息队列处理订单。</p>
<p>另外，为了不影响其他业务系统，秒杀系统最好和业务系统隔离，主要包括应用隔离、部署隔离、数据存储隔离。</p>
<h2 id="数据分布优化：如何应对数据倾斜？"><a href="#数据分布优化：如何应对数据倾斜？" class="headerlink" title="数据分布优化：如何应对数据倾斜？"></a>数据分布优化：如何应对数据倾斜？</h2><h3 id="总结1-31"><a href="#总结1-31" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我向你介绍了数据倾斜的两种情况：数据量倾斜和数据访问倾斜。</p>
<p>造成数据量倾斜的原因主要有三个：</p>
<ol>
<li>数据中有 bigkey，导致某个实例的数据量增加；</li>
<li>Slot 手工分配不均，导致某个或某些实例上有大量数据；</li>
<li>使用了 Hash Tag，导致数据集中到某些实例上。</li>
</ol>
<p>而数据访问倾斜的主要原因就是有热点数据存在，导致大量访问请求集中到了热点数据所在的实例上。</p>
<p>为了应对数据倾斜问题，我给你介绍了四个方法，也分别对应了造成数据倾斜的四个原因。我把它们总结在下表中，你可以看下。</p>
<p><img src="/images/redis/q-a-01.png" alt="img.png"></p>
<p>当然，如果已经发生了数据倾斜，我们可以通过数据迁移来缓解数据倾斜的影响。Redis Cluster 和 Codis 集群都提供了查看 Slot 分配和手工迁移 Slot 的命令，你可以把它们应用起来。</p>
<p>最后，关于集群的实例资源配置，我再给你一个小建议：在构建切片集群时，尽量使用大小配置相同的实例（例如实例内存配置保持相同），这样可以避免因实例资源不均衡而在不同实例上分配不同数量的 Slot。</p>
<h3 id="总结2-30"><a href="#总结2-30" class="headerlink" title="总结2"></a>总结2</h3><h3 id="问题1-21"><a href="#问题1-21" class="headerlink" title="问题1"></a>问题1</h3><p>按照惯例，我给你提个小问题，在有数据访问倾斜时，如果热点数据突然过期了，而 Redis 中的数据是缓存，数据的最终值保存在后端数据库，此时会发生什么问题？</p>
<h3 id="解答1-21"><a href="#解答1-21" class="headerlink" title="解答1"></a>解答1</h3><p>在有数据访问倾斜时，如果热点数据突然过期了，而 Redis 中的数据是缓存，数据的最终值保存在后端数据库，此时会发生什么问题？</p>
<p>此时会发生缓存击穿，热点请求会直接打到后端数据库上，数据库的压力剧增，可能会压垮数据库。</p>
<p>Redis 的很多性能问题，例如导致 Redis 阻塞的场景：bigkey、集中过期、大实例 RDB 等等，这些场景都与数据倾斜类似，都是因为数据集中、处理逻辑集中导致的耗时变长。其解决思路也类似，都是把集中变分散，例如 bigkey 拆分为小 key、单个大实例拆分为切片集群等。</p>
<p>从软件架构演进过程来看，从单机到分布式，再到后来出现的消息队列、负载均衡等技术，也都是为了将请求压力分散开，避免数据集中、请求集中的问题，这样既可以让系统承载更大的请求量，同时还保证了系统的稳定性。</p>
<h2 id="通信开销：限制Redis-Cluster规模的关键因素"><a href="#通信开销：限制Redis-Cluster规模的关键因素" class="headerlink" title="通信开销：限制Redis Cluster规模的关键因素"></a>通信开销：限制Redis Cluster规模的关键因素</h2><h3 id="总结1-32"><a href="#总结1-32" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我向你介绍了 Redis Cluster 实例间以 Gossip 协议进行通信的机制。Redis Cluster 运行时，各实例间需要通过 PING、PONG 消息进行信息交换，这些心跳消息包含了当前实例和部分其它实例的状态信息，以及 Slot 分配信息。这种通信机制有助于 Redis Cluster 中的所有实例都拥有完整的集群状态信息。</p>
<p>但是，随着集群规模的增加，实例间的通信量也会增加。如果我们盲目地对 Redis Cluster 进行扩容，就可能会遇到集群性能变慢的情况。这是因为，集群中大规模的实例间心跳消息会挤占集群处理正常请求的带宽。而且，有些实例可能因为网络拥塞导致无法及时收到 PONG 消息，每个实例在运行时会周期性地（每秒 10 次）检测是否有这种情况发生，一旦发生，就会立即给这些 PONG 消息超时的实例发送心跳消息。集群规模越大，网络拥塞的概率就越高，相应的，PONG 消息超时的发生概率就越高，这就会导致集群中有大量的心跳消息，影响集群服务正常请求。</p>
<p>最后，我也给你一个小建议，虽然我们可以通过调整 cluster-node-timeout 配置项减少心跳消息的占用带宽情况，但是，在实际应用中，如果不是特别需要大容量集群，我建议你把 Redis Cluster 的规模控制在 400~500 个实例。</p>
<p>假设单个实例每秒能支撑 8 万请求操作（8 万 QPS），每个主实例配置 1 个从实例，那么，400~ 500 个实例可支持 1600 万~2000 万 QPS（200/250 个主实例 *8 万 QPS=1600/2000 万 QPS），这个吞吐量性能可以满足不少业务应用的需求。</p>
<h3 id="总结2-31"><a href="#总结2-31" class="headerlink" title="总结2"></a>总结2</h3><h3 id="问题1-22"><a href="#问题1-22" class="headerlink" title="问题1"></a>问题1</h3><p>按照惯例，我给你提个小问题，如果我们采用跟 Codis 保存 Slot 分配信息相类似的方法，把集群实例状态信息和 Slot 分配信息保存在第三方的存储系统上（例如 Zookeeper），这种方法会对集群规模产生什么影响吗？</p>
<h3 id="解答1-22"><a href="#解答1-22" class="headerlink" title="解答1"></a>解答1</h3><p>如果采用类似 Codis 保存 Slot 信息的方法，把集群实例状态信息和 Slot 分配信息保存在第三方的存储系统上（例如Zookeeper），这种方法会对集群规模产生什么影响？</p>
<p>由于 Redis Cluster 每个实例需要保存集群完整的路由信息，所以每增加一个实例，都需要多一次与其他实例的通信开销，如果有 N 个实例，集群就要存储 N 份完整的路由信息。而如果像 Codis 那样，把 Slot 信息存储在第三方存储上，那么无论集群实例有多少，这些信息在第三方存储上只会存储一份，也就是说，集群内的通信开销，不会随着实例的增加而增长。当集群需要用到这些信息时，直接从第三方存储上获取即可。</p>
<p>Redis Cluster 把所有功能都集成在了 Redis 实例上，包括路由表的交换、实例健康检查、故障自动切换等等，这么做的好处是，部署和使用非常简单，只需要部署实例，然后让多个实例组成切片集群即可提供服务。但缺点也很明显，每个实例负责的工作比较重，如果看源码实现，也不太容易理解，而且如果其中一个功能出现 bug，只能升级整个 Redis Server 来解决。</p>
<p>而 Codis 把这些功能拆分成多个组件，每个组件负责的工作都非常纯粹，codis-proxy 负责转发请求，codis-dashboard 负责路由表的分发、数据迁移控制，codis-server 负责数据存储和数据迁移，哨兵负责故障自动切换，codis-fe 负责提供友好的运维界面，每个组件都可以单独升级，这些组件相互配合，完成整个集群的对外服务。但其缺点是组件比较多，部署和维护比较复杂。</p>
<p>在实际的业务场景下，我觉得应该尽量避免非常大的分片集群，太大的分片集群一方面存在通信开销大的问题，另一方面也会导致集群变得越来越难以维护。而且当集群出问题时，对业务的影响也比较集中。建议针对不同的业务线、业务模块，单独部署不同的分片集群，这样方便运维和管理的同时，出现问题也只会影响某一个业务模块。</p>
<h2 id="Redis-6-0的新特性：多线程、客户端缓存与安全"><a href="#Redis-6-0的新特性：多线程、客户端缓存与安全" class="headerlink" title="Redis 6.0的新特性：多线程、客户端缓存与安全"></a>Redis 6.0的新特性：多线程、客户端缓存与安全</h2><h3 id="总结1-33"><a href="#总结1-33" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我向你介绍了 Redis 6.0 的新特性，我把这些新特性总结在了一张表里，你可以再回顾巩固下。</p>
<p><img src="/images/redis/redis6-01.png" alt="img.png"></p>
<p>最后，我也再给你一个小建议：因为 Redis 6.0 是刚刚推出的，新的功能特性还需要在实际应用中进行部署和验证，所以，如果你想试用 Redis 6.0，可以尝试先在非核心业务上使用 Redis 6.0，一方面可以验证新特性带来的性能或功能优势，另一方面，也可以避免因为新特性不稳定而导致核心业务受到影响。</p>
<h3 id="总结2-32"><a href="#总结2-32" class="headerlink" title="总结2"></a>总结2</h3><h3 id="问题1-23"><a href="#问题1-23" class="headerlink" title="问题1"></a>问题1</h3><p>你觉得，Redis 6.0 的哪个或哪些新特性会对你有帮助呢？</p>
<h3 id="解答1-23"><a href="#解答1-23" class="headerlink" title="解答1"></a>解答1</h3><p>Redis 6.0 的哪些新特性帮助最大？</p>
<p>我觉得 Redis 6.0 提供的多 IO 线程和客户端缓存这两大特性，对于我们使用 Redis 帮助最大。</p>
<p>多 IO 线程可以让 Redis 在并发量非常大时，让其性能再上一个台阶，性能提升近 1 倍，对于单机 Redis 性能要求更高的业务场景，非常有帮助。</p>
<p>而客户端缓存可以让 Redis 的数据缓存在客户端，相当于每个应用进程多了一个本地缓存，Redis 数据没有变化时，业务直接在应用进程内就能拿到数据，这不仅节省了网络带宽，降低了 Redis 的请求压力，还充分利用了业务应用的资源，对应用性能的提升也非常大。</p>
<h2 id="Redis的下一步：基于NVM内存的实践"><a href="#Redis的下一步：基于NVM内存的实践" class="headerlink" title="Redis的下一步：基于NVM内存的实践"></a>Redis的下一步：基于NVM内存的实践</h2><h3 id="总结1-34"><a href="#总结1-34" class="headerlink" title="总结1"></a>总结1</h3><p>这节课我向你介绍了 NVM 的三大特点：性能高、容量大、数据可以持久化保存。软件系统可以像访问传统 DRAM 内存一样，访问 NVM 内存。目前，Intel 已经推出了 NVM 内存产品 Optane AEP。</p>
<p>这款 NVM 内存产品给软件提供了两种使用模式，分别是 Memory 模式和 App Direct 模式。在 Memory 模式时，Redis 可以利用 NVM 容量大的特点，实现大容量实例，保存更多数据。在使用 App Direct 模式时，Redis 可以直接在持久化内存上进行数据读写，在这种情况下，Redis 不用再使用 RDB 或 AOF 文件了，数据在机器掉电后也不会丢失。而且，实例可以直接使用持久化内存上的数据进行恢复，恢复速度特别快。</p>
<p>NVM 内存是近年来存储设备领域中一个非常大的变化，它既能持久化保存数据，还能像内存一样快速访问，这必然会给当前基于 DRAM 和硬盘的系统软件优化带来新的机遇。现在，很多互联网大厂已经开始使用 NVM 内存了，希望你能够关注这个重要趋势，为未来的发展做好准备。</p>
<h3 id="总结2-33"><a href="#总结2-33" class="headerlink" title="总结2"></a>总结2</h3><h3 id="问题1-24"><a href="#问题1-24" class="headerlink" title="问题1"></a>问题1</h3><p>按照惯例，我给你提个小问题，你觉得有了持久化内存后，还需要 Redis 主从集群吗?</p>
<h3 id="解答1-24"><a href="#解答1-24" class="headerlink" title="解答1"></a>解答1</h3><p>有了持久化内存，是否还需要 Redis 主从集群？</p>
<p>肯定还是需要主从集群的。持久化内存只能解决存储容量和数据恢复问题，关注点在于单个实例。</p>
<p>而 Redis 主从集群，既可以提升集群的访问性能，还能提高集群的可靠性。</p>
<p>例如部署多个从节点，采用读写分离的方式，可以分担单个实例的请求压力，提升集群的访问性能。而且当主节点故障时，可以提升从节点为新的主节点，降低故障对应用的影响。</p>
<p>两者属于不同维度的东西，互不影响。</p>
<h2 id="Redis有哪些好用的运维工具？"><a href="#Redis有哪些好用的运维工具？" class="headerlink" title="Redis有哪些好用的运维工具？"></a>Redis有哪些好用的运维工具？</h2><h3 id="总结1-35"><a href="#总结1-35" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我给你介绍了几种 Redis 的运维工具。</p>
<p>我们先了解了 Redis 的 INFO 命令，这个命令是监控工具的基础，监控工具都会基于 INFO 命令提供的信息进行二次加工。我们还学习了 3 种用来监控 Redis 实时运行状态的运维工具，分别是 Redis-exporter、redis-stat 和 Redis Live。</p>
<p>关于数据迁移，我们既可以使用 Redis-shake 工具，也可以通过 RDB 文件或是 AOF 文件进行迁移。</p>
<p>在运维 Redis 时，刚刚讲到的多款开源工具，已经可以满足我们的不少需求了。但是，有时候，不同业务线对 Redis 运维的需求可能并不一样，直接使用现成的开源工具可能无法满足全部需求，在这种情况下，建议你基于开源工具进行二次开发或是自研，从而更好地满足业务使用需求。</p>
<h3 id="总结2-34"><a href="#总结2-34" class="headerlink" title="总结2"></a>总结2</h3><h3 id="问题1-25"><a href="#问题1-25" class="headerlink" title="问题1"></a>问题1</h3><p>按照惯例，我给你提个小问题：你在实际应用中还使用过什么好的运维工具吗？</p>
<h3 id="解答1-25"><a href="#解答1-25" class="headerlink" title="解答1"></a>解答1</h3><p>老师这节课讲的工具很实用。</p>
<p>平时我们遇到的 Redis 变慢问题，有时觉得很难定位原因，其实是因为我们没有做好完善的监控。</p>
<p>Redis INFO 信息看似简单，但是这些信息记录着 Redis 运行时的各种状态数据，如果我们把这些数据采集到并监控到位，80% 的异常情况能在第一时间发现。</p>
<p>机器的 CPU、内存、网络、磁盘，都影响着 Redis 的性能。</p>
<p>监控时我们最好重点关注以下指标：</p>
<p>1、客户端相关：当前连接数、总连接数、输入缓冲大小、OPS</p>
<p>2、CPU相关：主进程 CPU 使用率、子进程 CPU 使用率</p>
<p>3、内存相关：当前内存、峰值内存、内存碎片率</p>
<p>4、网络相关：输入、输出网络流量</p>
<p>5、持久化相关：最后一次 RDB 时间、RDB fork 耗时、最后一次 AOF rewrite 时间、AOF rewrite 耗时</p>
<p>6、key 相关：过期 key 数量、淘汰 key 数量、key 命中率</p>
<p>7、复制相关：主从节点复制偏移量、主库复制缓冲区</p>
<p>能够查询这些指标的当前状态是最基本的，更好的方案是，能够计算出这些指标的波动情况，然后生成动态的图表展示出来，这样当某一刻指标突增时，监控能帮我们快速捕捉到，降低问题定位的难度。</p>
<p>目前业界比较主流的监控系统，都会使用 Prometheus 来做，插件也很丰富，监控报警也方便集成，推荐用起来。</p>
<h2 id="Redis有哪些好用的运维工具？-1"><a href="#Redis有哪些好用的运维工具？-1" class="headerlink" title="Redis有哪些好用的运维工具？"></a>Redis有哪些好用的运维工具？</h2><h3 id="总结1-36"><a href="#总结1-36" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我围绕 Redis 应用时的高性能访问和节省内存空间这两个目标，分别在键值对使用、命令使用和数据保存三方面向你介绍了 11 个规范。</p>
<p>我按照强制、推荐、建议这三个类别，把这些规范分了下类，如下表所示：</p>
<p><img src="/images/redis/tips-01.png" alt="img.png"></p>
<p>我来解释一下这 3 个类别的规范。</p>
<ul>
<li>强制类别的规范：这表示，如果不按照规范内容来执行，就会给 Redis 的应用带来极大的负面影响，例如性能受损。</li>
<li>推荐类别的规范：这个规范的内容能有效提升性能、节省内存空间，或者是增加开发和运维的便捷性，你可以直接应用到实践中。</li>
<li>建议类别的规范：这类规范内容和实际业务应用相关，我只是从我的经历或经验给你一个建议，你需要结合自己的业务场景参考使用。</li>
</ul>
<h3 id="总结2-35"><a href="#总结2-35" class="headerlink" title="总结2"></a>总结2</h3><h3 id="问题1-26"><a href="#问题1-26" class="headerlink" title="问题1"></a>问题1</h3><p>按照惯例，我给你提个小问题，你在日常应用 Redis 时，有遵循过什么好的使用规范吗？</p>
<h3 id="解答1-26"><a href="#解答1-26" class="headerlink" title="解答1"></a>解答1</h3><p>我总结的 Redis 使用规范分为两大方面，主要包括业务层面和运维层面。</p>
<p>业务层面主要面向的业务开发人员：</p>
<p>1、key 的长度尽量短，节省内存空间<br>2、避免 bigkey，防止阻塞主线程<br>3、4.0+版本建议开启 lazy-free<br>4、把 Redis 当作缓存使用，设置过期时间<br>5、不使用复杂度过高的命令，例如SORT、SINTER、SINTERSTORE、ZUNIONSTORE、ZINTERSTORE<br>6、查询数据尽量不一次性查询全量，写入大量数据建议分多批写入<br>7、批量操作建议 MGET/MSET 替代 GET/SET，HMGET/HMSET 替代 HGET/HSET<br>8、禁止使用 KEYS/FLUSHALL/FLUSHDB 命令<br>9、避免集中过期 key<br>10、根据业务场景选择合适的淘汰策略<br>11、使用连接池操作 Redis，并设置合理的参数，避免短连接<br>12、只使用 db0，减少 SELECT 命令的消耗<br>13、读请求量很大时，建议读写分离，写请求量很大，建议使用切片集群</p>
<p>运维层面主要面向的是 DBA 运维人员：</p>
<p>1、按业务线部署实例，避免多个业务线混合部署，出问题影响其他业务<br>2、保证机器有足够的 CPU、内存、带宽、磁盘资源<br>3、建议部署主从集群，并分布在不同机器上，slave 设置为 readonly<br>4、主从节点所部署的机器各自独立，尽量避免交叉部署，对从节点做维护时，不会影响到主节点<br>5、推荐部署哨兵集群实现故障自动切换，哨兵节点分布在不同机器上<br>6、提前做好容量规划，防止主从全量同步时，实例使用内存突增导致内存不足<br>7、做好机器 CPU、内存、带宽、磁盘监控，资源不足时及时报警，任意资源不足都会影响 Redis 性能<br>8、实例设置最大连接数，防止过多客户端连接导致实例负载过高，影响性能<br>9、单个实例内存建议控制在 10G 以下，大实例在主从全量同步、备份时有阻塞风险<br>10、设置合理的 slowlog 阈值，并对其进行监控，slowlog 过多需及时报警<br>11、设置合理的 repl-backlog，降低主从全量同步的概率<br>12、设置合理的 slave client-output-buffer-limit，避免主从复制中断情况发生<br>13、推荐在从节点上备份，不影响主节点性能<br>14、不开启 AOF 或开启 AOF 配置为每秒刷盘，避免磁盘 IO 拖慢 Redis 性能<br>15、调整 maxmemory 时，注意主从节点的调整顺序，顺序错误会导致主从数据不一致<br>16、对实例部署监控，采集 INFO 信息时采用长连接，避免频繁的短连接<br>17、做好实例运行时监控，重点关注 expired_keys、evicted_keys、latest_fork_usec，这些指标短时突增可能会有阻塞风险<br>18、扫描线上实例时，记得设置休眠时间，避免过高 OPS 产生性能抖动</p>
<h2 id="Redis有哪些好用的运维工具？-2"><a href="#Redis有哪些好用的运维工具？-2" class="headerlink" title="Redis有哪些好用的运维工具？"></a>Redis有哪些好用的运维工具？</h2><h3 id="总结1-37"><a href="#总结1-37" class="headerlink" title="总结1"></a>总结1</h3><p>今天这节课，我们学习了微博的 Redis 实践，从中总结了许多经验。总结来说，微博对 Redis 的技术需求可以概括为 3 点，分别是高性能、大容量和易扩展。</p>
<p>为了满足这些需求，除了对 Redis 进行优化，微博也在自研扩展系统，包括基于 RocksDB 的容量扩展机制，以及服务化的 RedisService 集群。</p>
<p>最后，我还想再跟你分享一下我自己的两个感受。</p>
<p>第一个是关于微博做的 RedisService 集群，这个优化方向是大厂平台部门同学的主要工作方向。</p>
<p>业务纵切、平台横切是当前构建大规模系统的基本思路。所谓业务纵切，是指把不同的业务数据单独部署，这样可以避免相互之间的干扰。而平台横切是指，当不同业务线对运行平台具有相同需求时，可以统一起来，通过构建平台级集群服务来进行支撑。Redis 就是典型的多个业务线都需要的基础性服务，所以将其以集群方式服务化，有助于提升业务的整体效率。</p>
<p>第二个是代码实践在我们成长为 Redis 高手过程中的重要作用。</p>
<p>我发现，对 Redis 的二次改造或开发，是大厂的一个必经之路，这和大厂业务多、需求广有密切关系。</p>
<p>微博做的定制化数据结构、RedRock 和 RedisService 都是非常典型的例子。所以，如果我们想要成为 Redis 高手，成为大厂中的一员，那么，先原理后代码，边学习边实践，就是一个不错的方法。原理用来指导代码阅读的聚焦点，而动手实践至关重要，需要我们同时开展部署操作实践和阅读代码实践。纸上得来终觉浅，绝知此事要躬行，希望你不仅重视学习原理，还要真正地用原理来指导实践，提升自己的实战能力。</p>
<h3 id="总结2-36"><a href="#总结2-36" class="headerlink" title="总结2"></a>总结2</h3><h3 id="问题1-27"><a href="#问题1-27" class="headerlink" title="问题1"></a>问题1</h3><p>按照惯例，我给你提个小问题，你在实际应用 Redis 时，有没有一些经典的优化改进或二次开发经验？</p>
<h3 id="解答1-27"><a href="#解答1-27" class="headerlink" title="解答1"></a>解答1</h3><p>在实际应用 Redis 时，你有哪些优化和二次开发的经验？</p>
<p>分享一下我们对 Redis 的二次开发经验。</p>
<p>由于我们采用的 Redis 集群方案是 Codis，我们主要对 Codis 下的 Redis Server 进行了二次开发。</p>
<p>我们在做服务跨机房容灾和多活时，需要在两个机房各自部署 Codis/Redis 实例，并且两个机房的实例数据需要实时同步，以支持任意机房故障时，可随时切换应用流量到另一个机房继续提供服务。</p>
<p>但由于两个机房之间的网络是通过专线连通的，而专线的质量和稳定性是不如同机房内的，如果使用原生 的 Redis 主从复制方案，当专线长时间故障再恢复时，原生 Redis 主从复制会进行全量的数据同步。全量同步不仅对 master 节点有阻塞风险，同时也会对机房之间的专线的带宽产生巨大的压力，还会影响应用的机房流量切换。</p>
<p>所以我们对 Codis 下的 Redis 做了二次开发，对其增加了类似于 MySQL 的 binlog 模块，把实时的写命令通过异步线程写入到 binlog 文件中，然后开发了数据同步中间件去读取 Redis 的 binlog，向另一个机房实时同步数据，并且支持增量同步、断点续传，这样就可以兼容专线任意时间的故障，故障恢复后我们的同步中间件会从断点处继续增量同步 Redis 数据到另一个机房，避免了全量复制的风险。</p>
<p>同时，我们还对 Codis 进行了二次开发，在集成数据同步中间件时，兼容了 Codis 的日常运维和故障容错，例如集群内节点主从切换、故障转移、数据迁移等操作，保证了机房之间数据同步的最终一致性。</p>
<p>最后，我想说的是，对 Redis 进行改造，优点是可以更加适配自己的业务场景，但缺点是维护和升级成本较高，改造 Redis 相当于自己开辟了一个新的分支，公司内部需要投入人力去持续维护，需要平衡投入产出比。如果没有特别复杂的需求，一般使用官方版本即可，好处是可以第一时间使用最新版本的特性。</p>
]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>使用</tag>
      </tags>
  </entry>
</search>
