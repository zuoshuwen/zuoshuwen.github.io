

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/avatar.png">
  <link rel="icon" href="/img/avatar.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="后端技术、笔记、教程">
  <meta name="author" content="sown">
  <meta name="keywords" content="go,golang,技术,后端,php,linux,redis,kubernetes,k8s,nginx,docker,网络,算法,">
  <meta name="description" content="数据结构之慢操作总结1一，作者讲了什么？  Redis的底层数据结构  二，作者是怎么把这事给讲明白的？  讲了Redis的数据结构：数据的保存形式与底层数据结构 由数据结构的异同点，引出数据操作的快慢原因  三，为了讲明白，作者讲了哪些要点？有哪些亮点？  亮点1：string，list，set，hast,sortset都只是数据的保存形式，底层的数据结构是：简单动态字符串，双向链表，压缩列表，">
<meta property="og:type" content="article">
<meta property="og:title" content="Redis核心技术与实战">
<meta property="og:url" content="https://ilifes.com/redis/use/index.html">
<meta property="og:site_name" content="Sown">
<meta property="og:description" content="数据结构之慢操作总结1一，作者讲了什么？  Redis的底层数据结构  二，作者是怎么把这事给讲明白的？  讲了Redis的数据结构：数据的保存形式与底层数据结构 由数据结构的异同点，引出数据操作的快慢原因  三，为了讲明白，作者讲了哪些要点？有哪些亮点？  亮点1：string，list，set，hast,sortset都只是数据的保存形式，底层的数据结构是：简单动态字符串，双向链表，压缩列表，">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://ilifes.com/images/redis/datastruct-02.png">
<meta property="og:image" content="https://ilifes.com/images/redis/list-01.png">
<meta property="og:image" content="https://ilifes.com/images/redis/mysql-and-redis-01.png">
<meta property="og:image" content="https://ilifes.com/images/redis/mysql-and-redis-02.png">
<meta property="og:image" content="https://ilifes.com/images/redis/acid-01.png">
<meta property="og:image" content="https://ilifes.com/images/redis/master-slave-01.png">
<meta property="og:image" content="https://ilifes.com/images/redis/q-a-01.png">
<meta property="og:image" content="https://ilifes.com/images/redis/redis6-01.png">
<meta property="og:image" content="https://ilifes.com/images/redis/tips-01.png">
<meta property="article:published_time" content="2021-06-16T00:00:00.000Z">
<meta property="article:modified_time" content="2021-10-14T15:55:39.913Z">
<meta property="article:author" content="sown">
<meta property="article:tag" content="使用">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://ilifes.com/images/redis/datastruct-02.png">
  
  <title>Redis核心技术与实战 - Sown</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10.6.0/styles/github-gist.min.css" />
    
  

  
    <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" />
  


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"ilifes.com","root":"/","version":"1.8.12","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"copy_btn":true,"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":false,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"baidu":"97f60cea7055dca81a77d34bd50655bf","google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":"ButetqzXxYeinA3YL6tt2SI5-gzGzoHsz","app_key":"IQfQbzCDGqirp6rGE7bmsnzS","server_url":"https://butetqzx.lc-cn-n1-shared.com","path":"window.location.pathname"}},"search_path":"/local-search.xml"};
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 5.4.0"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Sown</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" target="_self" href="javascript:;" role="button"
                 data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                <i class="iconfont icon-books"></i>
                程序设计
              </a>
              <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                
                  
                  
                  
                  <a class="dropdown-item" href="/datastruct-algorithm/a/">
                    <i class="iconfont icon-notebook"></i>
                    数据结构与算法
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/design-pattern/a/">
                    <i class="iconfont icon-notebook"></i>
                    设计模式
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/program/a/">
                    <i class="iconfont icon-notebook"></i>
                    方案
                  </a>
                
              </div>
            </li>
          
        
          
          
          
          
            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" target="_self" href="javascript:;" role="button"
                 data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                <i class="iconfont icon-books"></i>
                编程
              </a>
              <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                
                  
                  
                  
                  <a class="dropdown-item" href="/netprogram/a/">
                    <i class="iconfont icon-notebook"></i>
                    网络编程
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/golang/a/">
                    <i class="iconfont icon-notebook"></i>
                    Go
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/ios/a/">
                    <i class="iconfont icon-notebook"></i>
                    iOS
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/html5/a/">
                    <i class="iconfont icon-notebook"></i>
                    H5
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/applet/a/">
                    <i class="iconfont icon-notebook"></i>
                    小程序
                  </a>
                
              </div>
            </li>
          
        
          
          
          
          
            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" target="_self" href="javascript:;" role="button"
                 data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                <i class="iconfont icon-books"></i>
                架构
              </a>
              <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                
                  
                  
                  
                  <a class="dropdown-item" href="/distributed/a/">
                    <i class="iconfont icon-notebook"></i>
                    分布式
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/microservices/a/">
                    <i class="iconfont icon-notebook"></i>
                    微服务
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/example/a/">
                    <i class="iconfont icon-notebook"></i>
                    方案设计
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/microservices/a/">
                    <i class="iconfont icon-notebook"></i>
                    架构模式
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/ddd/a/">
                    <i class="iconfont icon-notebook"></i>
                    领域驱动设计
                  </a>
                
              </div>
            </li>
          
        
          
          
          
          
            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" target="_self" href="javascript:;" role="button"
                 data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                <i class="iconfont icon-books"></i>
                开源学习
              </a>
              <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                
                  
                  
                  
                  <a class="dropdown-item" href="/redis/a/">
                    <i class="iconfont icon-notebook"></i>
                    Redis
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/mysql/a/">
                    <i class="iconfont icon-notebook"></i>
                    MySQL
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/etcd/a/">
                    <i class="iconfont icon-notebook"></i>
                    Etcd
                  </a>
                
              </div>
            </li>
          
        
          
          
          
          
            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" target="_self" href="javascript:;" role="button"
                 data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                <i class="iconfont icon-books"></i>
                数据
              </a>
              <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                
                  
                  
                  
                  <a class="dropdown-item" href="/datadev/a/">
                    <i class="iconfont icon-notebook"></i>
                    数据开发
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/datanal/a/">
                    <i class="iconfont icon-notebook"></i>
                    数据分析
                  </a>
                
              </div>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner" id="banner" parallax=true
         style="background: url('/images/default.jpg') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="page-header text-center fade-in-up">
            <span class="h2" id="subtitle" title="Redis核心技术与实战">
              
            </span>

            
              <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2021-06-16 08:00" pubdate>
        2021年6月16日 早上
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      79k 字
    </span>
  

  
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      248 分钟
    </span>
  

  
  
    
      <!-- LeanCloud 统计文章PV -->
      <span id="leancloud-page-views-container" class="post-meta" style="display: none">
        <i class="iconfont icon-eye" aria-hidden="true"></i>
        <span id="leancloud-page-views"></span> 次
      </span>
    
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">Redis核心技术与实战</h1>
            
            <div class="markdown-body">
              <h2 id="数据结构之慢操作"><a href="#数据结构之慢操作" class="headerlink" title="数据结构之慢操作"></a>数据结构之慢操作</h2><h3 id="总结1"><a href="#总结1" class="headerlink" title="总结1"></a>总结1</h3><p>一，作者讲了什么？</p>
<ol>
<li>Redis的底层数据结构</li>
</ol>
<p>二，作者是怎么把这事给讲明白的？</p>
<ol>
<li>讲了Redis的数据结构：数据的保存形式与底层数据结构</li>
<li>由数据结构的异同点，引出数据操作的快慢原因</li>
</ol>
<p>三，为了讲明白，作者讲了哪些要点？有哪些亮点？</p>
<ol>
<li>亮点1：string，list，set，hast,sortset都只是数据的保存形式，底层的数据结构是：简单动态字符串，双向链表，压缩列表，哈希表，跳表，整数数组</li>
<li>亮点2：Redis使用了一个哈希表保存所有的键值对</li>
<li>要点1：五种数据形式的底层实现<br>a，string：简单动态字符串<br>b，list：双向链表，压缩列表<br>c，hash：压缩列表，哈希表<br>d，Sorted Set：压缩列表，跳表<br>e，set：哈希表，整数数组</li>
<li>要点2：List ,hash，set ,sorted set被统称为集合类型，一个键对应了一个集合的数据</li>
<li>要点3：集合类型的键和值之间的结构组织<br>a：Redis使用一个哈希表保存所有键值对，一个哈希表实则是一个数组，数组的每个元素称为哈希桶。<br>b：哈希桶中的元素保存的不是值的本身，而是指向具体值的指针</li>
<li>要点4：哈希冲突解决<br>a：Redis的hash表是全局的，所以当写入大量的key时，将会带来哈希冲突，已经rehash可能带来的操作阻塞<br>b：Redis解决hash冲突的方式，是链式哈希：同一个哈希桶中的多个元素用一个链表来保存<br>c：当哈希冲突链过长时，Redis会对hash表进行rehash操作。rehash就是增加现有的hash桶数量，分散entry元素。</li>
<li>要点5：rehash机制<br>a：为了使rehash操作更高效，Redis默认使用了两个全局哈希表：哈希表1和哈希表2，起始时hash2没有分配空间<br>b：随着数据增多，Redis执行分三步执行rehash;<br> 1，给hash2分配更大的内存空间，如是hash1的两倍<br> 2，把hash1中的数据重新映射并拷贝到哈希表2中<br> 3，释放hash1的空间</li>
<li>要点6：渐进式rehash<br>a：由于步骤2重新映射非常耗时，会阻塞redis<br>b：讲集中迁移数据，改成每处理一个请求时，就从hash1中的第一个索引位置，顺带将这个索引位置上的所有entries拷贝到hash2中。</li>
<li>要点7 ：压缩列表，跳表的特点<br>a：压缩列表类似于一个数组，不同的是:压缩列表在表头有三个字段zlbytes,zltail和zllen分别表示长度，列表尾的偏移量和列表中的entry的个数，压缩列表尾部还有一个zlend，表示列表结束<br>所以压缩列表定位第一个和最后一个是O(1),但其他就是O(n)<br>b：跳表：是在链表的基础上增加了多级索引，通过索引的几次跳转，实现数据快速定位</li>
</ol>
<p>四，对于作者所讲，我有哪些发散性思考？</p>
<p>五，在将来的哪些场景中，我能够用到它？</p>
<p>六，评论区收获</p>
<ol>
<li>数组和压缩列表可以提升内存利用率，因为他们的数据结构紧凑</li>
<li>数组对CPU高速缓存支持友好，当数据元素超过阈值时，会转为hash和跳表，保证查询效率时，集合数据元素较少情况下，默认采用内存紧凑排列的方式存储，同时利用CPU高速缓存不会降低访问速度。当数据元素超过设定阈值后，避免查询时间复杂度太高，转为哈希和跳表数据结构存储，保证查询效率。</li>
<li>内存利用率，数组和压缩列表都是非常紧凑的数据结构，它比链表占用的内存要更少。Redis是内存数据库，大量数据存到内存中，此时需要做尽可能的优化，提高内存的利用率。</li>
<li>数组对CPU高速缓存支持更友好，所以Redis在设计时，集合数据元素较少情况下，默认采用内存紧凑排列的方式存储，同时利用CPU高速缓存不会降低访问速度。当数据元素超过设定阈值后，避免查询时间复杂度太高，转为哈希和跳表数据结构存储，保证查询效率。</li>
</ol>
<h2 id="单线程为什么快"><a href="#单线程为什么快" class="headerlink" title="单线程为什么快"></a>单线程为什么快</h2><h3 id="总结1-1"><a href="#总结1-1" class="headerlink" title="总结1"></a>总结1</h3><p>现在，我们知道了，Redis 单线程是指它对网络 IO 和数据读写的操作采用了一个线程，而采用单线程的一个核心原因是避免多线程开发的并发控制问题。单线程的 Redis 也能获得高性能，跟多路复用的 IO 模型密切相关，因为这避免了 accept() 和 send()/recv() 潜在的网络 IO 操作阻塞点。</p>
<h3 id="总结2"><a href="#总结2" class="headerlink" title="总结2"></a>总结2</h3><p>1，作者讲了什么？<br>redis实现单线程实现高性能IO的设计机制<br>2，作者是怎么把这事给讲明白的？<br>作者首先从简单的网络通信socket讲起，引出了非阻塞socket，由此谈到了著名的I/O多路复用，Linux内核的select/epoll机制<br>3，为了讲明白，作者讲了哪些要点?有哪些亮点？<br>（1）首先声明“redis单线程”这个概念的具体含义<br>（2）引入具体业务场景：redis的数据读取，事件处理机制模型<br>（3）解析单线程相对多线程带来的优势，已及多线程所特有的问题<br>（4）基于redis单线程的，设计机制，引出了网络socket的问题</p>
<h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>在“Redis 基本 IO 模型”图中，你觉得还有哪些潜在的性能瓶颈吗？</p>
<h3 id="解答"><a href="#解答" class="headerlink" title="解答"></a>解答</h3><p>Redis单线程处理IO请求性能瓶颈主要包括2个方面：</p>
<ol>
<li>任意一个请求在server中一旦发生耗时，都会影响整个server的性能，也就是说后面的请求都要等前面这个耗时请求处理完成，自己才能被处理到。耗时的操作包括以下几种：<br>a. 操作bigkey：写入一个bigkey在分配内存时需要消耗更多的时间，同样，删除bigkey释放内存同样会产生耗时；<br>b. 使用复杂度过高的命令：例如SORT/SUNION/ZUNIONSTORE，或者O(N)命令，但是N很大，例如lrange key 0 -1一次查询全量数据；<br>c. 大量key集中过期：Redis的过期机制也是在主线程中执行的，大量key集中过期会导致处理一个请求时，耗时都在删除过期key，耗时变长；<br>d. 淘汰策略：淘汰策略也是在主线程执行的，当内存超过Redis内存上限后，每次写入都需要淘汰一些key，也会造成耗时变长；<br>e. AOF刷盘开启always机制：每次写入都需要把这个操作刷到磁盘，写磁盘的速度远比写内存慢，会拖慢Redis的性能；<br>f. 主从全量同步生成RDB：虽然采用fork子进程生成数据快照，但fork这一瞬间也是会阻塞整个线程的，实例越大，阻塞时间越久；</li>
<li>并发量非常大时，单线程读写客户端IO数据存在性能瓶颈，虽然采用IO多路复用机制，但是读写客户端数据依旧是同步IO，只能单线程依次读取客户端的数据，无法利用到CPU多核。</li>
</ol>
<p>针对问题1，一方面需要业务人员去规避，一方面Redis在4.0推出了lazy-free机制，把bigkey释放内存的耗时操作放在了异步线程中执行，降低对主线程的影响。</p>
<p>针对问题2，Redis在6.0推出了多线程，可以在高并发场景下利用CPU多核多线程读写客户端数据，进一步提升server性能，当然，只是针对客户端的读写是并行的，每个命令的真正操作依旧是单线程的。</p>
<h2 id="AOF日志，宕机了，如何避免数据丢失"><a href="#AOF日志，宕机了，如何避免数据丢失" class="headerlink" title="AOF日志，宕机了，如何避免数据丢失"></a>AOF日志，宕机了，如何避免数据丢失</h2><h3 id="总结1-2"><a href="#总结1-2" class="headerlink" title="总结1"></a>总结1</h3><p>这个方法看似“简单”，但也是充分考虑了对 Redis 性能的影响。总结来说，它提供了 AOF 日志的三种写回策略，分别是 Always、Everysec 和 No，这三种策略在可靠性上是从高到低，而在性能上则是从低到高。</p>
<p>此外，为了避免日志文件过大，Redis 还提供了 AOF 重写机制，直接根据数据库里数据的最新状态，生成这些数据的插入命令，作为新日志。这个过程通过后台线程完成，避免了对主线程的阻塞。</p>
<p>其中，三种写回策略体现了系统设计中的一个重要原则 ，即 trade-off，或者称为“取舍”，指的就是在性能和可靠性保证之间做取舍。我认为，这是做系统设计和开发的一个关键哲学，我也非常希望，你能充分地理解这个原则，并在日常开发中加以应用。</p>
<p>不过，你可能也注意到了，落盘时机和重写机制都是在“记日志”这一过程中发挥作用的。例如，落盘时机的选择可以避免记日志时阻塞主线程，重写可以避免日志文件过大。但是，在“用日志”的过程中，也就是使用 AOF 进行故障恢复时，我们仍然需要把所有的操作记录都运行一遍。再加上 Redis 的单线程设计，这些命令操作只能一条一条按顺序执行，这个“重放”的过程就会很慢了。</p>
<h3 id="总结2-1"><a href="#总结2-1" class="headerlink" title="总结2"></a>总结2</h3><p>1，作者讲了什么？<br>本章讲了Redis两种持久化机制之一：AOF机制原理<br>aof日志记录了redis所有增删改的操作，保存在磁盘上，当redis宕机，需要恢复内存中的数据时，可以通过读取aop日志恢复数据，从而避免因redis异常导致的数据丢失</p>
<p>2，作者是怎么把这事给讲明白的？<br>（1）作者先讲述redis宕机会导致内存数据丢失，需要有一种机制在redis重启后恢复数据。<br>（2）介绍了AOF通过记录每一个对redis数据进行增删改的操作日志，可以实现这种功能<br>（2）介绍了AOF的运行机制，数据保存机制，以及由此带来的优点和缺点<br>3，为了讲明白，作者讲了哪些要点，有哪些亮点？<br>（1）亮点：记录操作的时机分为：“写前日志和写后日志”，这个是我之前所不知道的<br>（2）要点1：AOF是写后日志，这样带来的好处是，记录的所有操作命令都是正确的，不需要额外的语法检查，确保redis重启时能够正确的读取回复数据<br>（3）要点2：AOF日志写入磁盘是比较影响性能的，为了平衡性能与数据安全，开发了三种机制：①：立即写入②：按秒写入③：系统写入<br>（4）要点3：AOF日志会变得巨大，所以Redis提供了日志重整的机制，通过读取内存中的数据重新产生一份数据写入日志<br>4，对于作者所讲，我有哪些发散性的思考？<br>作者说系统设计“取舍”二字非常重要，这是我之前未曾意识到的。作者讲了fork子进程机制，是Linux系统的一个能力，在刘超的课中讲过，这鼓舞了我继续学习的信心<br>5，将来有哪些场景，我可以应用上它？<br>目前还没有机会直接操作生产的redis配置，但现在要学习，争取将来可以直接操作</p>
<h3 id="问题1"><a href="#问题1" class="headerlink" title="问题1"></a>问题1</h3><ol>
<li>AOF 日志重写的时候，是由 bgrewriteaof 子进程来完成的，不用主线程参与，我们今天说的非阻塞也是指子进程的执行不阻塞主线程。但是，你觉得，这个重写过程有没有其他潜在的阻塞风险呢？如果有的话，会在哪里阻塞？</li>
</ol>
<h3 id="解答1"><a href="#解答1" class="headerlink" title="解答1"></a>解答1</h3><p>Redis采用fork子进程重写AOF文件时，潜在的阻塞风险包括：fork子进程 和 AOF重写过程中父进程产生写入的场景，下面依次介绍。</p>
<p>a、fork子进程，fork这个瞬间一定是会阻塞主线程的（注意，fork时并不会一次性拷贝所有内存数据给子进程，老师文章写的是拷贝所有内存数据给子进程，我个人认为是有歧义的），fork采用操作系统提供的写实复制(Copy On Write)机制，就是为了避免一次性拷贝大量内存数据给子进程造成的长时间阻塞问题，但fork子进程需要拷贝进程必要的数据结构，其中有一项就是拷贝内存页表（虚拟内存和物理内存的映射索引表），这个拷贝过程会消耗大量CPU资源，拷贝完成之前整个进程是会阻塞的，阻塞时间取决于整个实例的内存大小，实例越大，内存页表越大，fork阻塞时间越久。拷贝内存页表完成后，子进程与父进程指向相同的内存地址空间，也就是说此时虽然产生了子进程，但是并没有申请与父进程相同的内存大小。那什么时候父子进程才会真正内存分离呢？“写实复制”顾名思义，就是在写发生时，才真正拷贝内存真正的数据，这个过程中，父进程也可能会产生阻塞的风险，就是下面介绍的场景。</p>
<p>b、fork出的子进程指向与父进程相同的内存地址空间，此时子进程就可以执行AOF重写，把内存中的所有数据写入到AOF文件中。但是此时父进程依旧是会有流量写入的，如果父进程操作的是一个已经存在的key，那么这个时候父进程就会真正拷贝这个key对应的内存数据，申请新的内存空间，这样逐渐地，父子进程内存数据开始分离，父子进程逐渐拥有各自独立的内存空间。因为内存分配是以页为单位进行分配的，默认4k，如果父进程此时操作的是一个bigkey，重新申请大块内存耗时会变长，可能会产阻塞风险。另外，如果操作系统开启了内存大页机制(Huge Page，页面大小2M)，那么父进程申请内存时阻塞的概率将会大大提高，所以在Redis机器上需要关闭Huge Page机制。Redis每次fork生成RDB或AOF重写完成后，都可以在Redis log中看到父进程重新申请了多大的内存空间。</p>
<h3 id="问题2"><a href="#问题2" class="headerlink" title="问题2"></a>问题2</h3><ol start="2">
<li>AOF 重写也有一个重写日志，为什么它不共享使用 AOF 本身的日志呢？</li>
</ol>
<h3 id="解答2"><a href="#解答2" class="headerlink" title="解答2"></a>解答2</h3><p>AOF重写不复用AOF本身的日志，一个原因是父子进程写同一个文件必然会产生竞争问题，控制竞争就意味着会影响父进程的性能。二是如果AOF重写过程中失败了，那么原本的AOF文件相当于被污染了，无法做恢复使用。所以Redis AOF重写一个新文件，重写失败的话，直接删除这个文件就好了，不会对原先的AOF文件产生影响。等重写完成之后，直接替换旧文件即可。</p>
<p>这里要谢谢Kaito同学指出的文章中的歧义：fork子进程时，子进程是会拷贝父进程的页表，即虚实映射关系，而不会拷贝物理内存。子进程复制了父进程页表，也能共享访问父进程的内存数据了，此时，类似于有了父进程的所有内存数据。我的描述不太严谨了，非常感谢指出！</p>
<p>Kaito同学还提到了Huge page。这个特性大家在使用Redis也要注意。Huge page对提升TLB命中率比较友好，因为在相同的内存容量下，使用huge page可以减少页表项，TLB就可以缓存更多的页表项，能减少TLB miss的开销。</p>
<p>但是，这个机制对于Redis这种喜欢用fork的系统来说，的确不太友好，尤其是在Redis的写入请求比较多的情况下。因为fork后，父进程修改数据采用写时复制，复制的粒度为一个内存页。如果只是修改一个256B的数据，父进程需要读原来的内存页，然后再映射到新的物理地址写入。一读一写会造成读写放大。如果内存页越大（例如2MB的大页），那么读写放大也就越严重，对Redis性能造成影响。</p>
<p>Huge page在实际使用Redis时是建议关掉的。</p>
<h2 id="内存快照：宕机后，Redis如何实现快速恢复？"><a href="#内存快照：宕机后，Redis如何实现快速恢复？" class="headerlink" title="内存快照：宕机后，Redis如何实现快速恢复？"></a>内存快照：宕机后，Redis如何实现快速恢复？</h2><h3 id="总结1-3"><a href="#总结1-3" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我们学习了 Redis 用于避免数据丢失的内存快照方法。这个方法的优势在于，可以快速恢复数据库，也就是只需要把 RDB 文件直接读入内存，这就避免了 AOF 需要顺序、逐一重新执行操作命令带来的低效性能问题。</p>
<p>不过，内存快照也有它的局限性。它拍的是一张内存的“大合影”，不可避免地会耗时耗力。虽然，Redis 设计了 bgsave 和写时复制方式，尽可能减少了内存快照对正常读写的影响，但是，频繁快照仍然是不太能接受的。而混合使用 RDB 和 AOF，正好可以取两者之长，避两者之短，以较小的性能开销保证数据可靠性和性能。</p>
<p>最后，关于 AOF 和 RDB 的选择问题，我想再给你提三点建议：</p>
<ul>
<li>数据不能丢失时，内存快照和 AOF 的混合使用是一个很好的选择；</li>
<li>如果允许分钟级别的数据丢失，可以只使用 RDB；</li>
<li>如果只用 AOF，优先使用 everysec 的配置选项，因为它在可靠性和性能之间取了一个平衡。</li>
</ul>
<h3 id="总结2-2"><a href="#总结2-2" class="headerlink" title="总结2"></a>总结2</h3><p>1，作者讲了什么？<br>作者在本章讲了redis两种持久化方式中的RDB方式<br>2，作者是怎么把这事给讲明白的？<br>为了让大家明白RDB的快照的概念，作者举了拍照片，照合影的例子<br>3，为了讲明白，作者讲了哪些要点，有哪些亮点？<br>（1）亮点1：作者解释快照使用了拍合影的例子，让我很好的理解快照的概念，以及内存数据大小对快照产生的影响<br>（2）要点1：RDB快照，将此时内存中的所有的数据写入磁盘<br>（3）要点2：生成快照有两种方式：sava和bgsava，save是主进程执行，生成时会阻塞redis，只能执行查找。bgsave是由主进程fork出子进程执行，<br>（4）要点3：子进程在被fork处理时，与主进程共享同一份内存，但在生成快照时采取COW机制，确保不会阻塞主进程的数据读写<br>（5）要点4：RDB的执行频率很重要，这会影响到数据的完整性和Redis的性能稳定性。所以4.0后有了aof和rdb混合的数据持久化机制<br>4，对于作者所讲，我有哪些发散性思考？<br>作者开篇提到的两个问题：快照什么数据，快照有何影响，具体的场景，才能讨论出具体的技术方案，我个人认为，脱离场景谈方案是在自嗨</p>
<p>5，将来有哪些场景，我能够使用到它？<br>我们项目的redis持久化使用的方式就是aof和rdb混合，前一段时间，做过集群升级扩容。把每台8c,30G内存,5主5从，升级改造成为8c,15G内存,15主15从。这样搞主要是因为之前的集群内存占用太高，导致数据持久化失败<br>6，读者评论的收获：<br>定这个专栏，真是觉得捡到宝了，大神@Kaito写的评论实在漂亮，每次都要读好几遍，读完都有赏心悦目的愉悦感，期望自己有一天也可像他那样出色</p>
<h3 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h3><p>我曾碰到过这么一个场景：<br>我们使用一个 2 核 CPU、4GB 内存、500GB 磁盘的云主机运行 Redis，Redis 数据库的数据量大小差不多是 2GB，我们使用了 RDB 做持久化保证。当时 Redis 的运行负载以修改操作为主，写读比例差不多在 8:2 左右，也就是说，如果有 100 个请求，80 个请求执行的是修改操作。你觉得，在这个场景下，用 RDB 做持久化有什么风险吗？你能帮着一起分析分析吗？</p>
<h3 id="解答-1"><a href="#解答-1" class="headerlink" title="解答"></a>解答</h3><p>2核CPU、4GB内存、500G磁盘，Redis实例占用2GB，写读比例为8:2，此时做RDB持久化，产生的风险主要在于 CPU资源 和 内存资源 这2方面：</p>
<p>a、内存资源风险：Redis fork子进程做RDB持久化，由于写的比例为80%，那么在持久化过程中，“写实复制”会重新分配整个实例80%的内存副本，大约需要重新分配1.6GB内存空间，这样整个系统的内存使用接近饱和，如果此时父进程又有大量新key写入，很快机器内存就会被吃光，如果机器开启了Swap机制，那么Redis会有一部分数据被换到磁盘上，当Redis访问这部分在磁盘上的数据时，性能会急剧下降，已经达不到高性能的标准（可以理解为武功被废）。如果机器没有开启Swap，会直接触发OOM，父子进程会面临被系统kill掉的风险。</p>
<p>b、CPU资源风险：虽然子进程在做RDB持久化，但生成RDB快照过程会消耗大量的CPU资源，虽然Redis处理处理请求是单线程的，但Redis Server还有其他线程在后台工作，例如AOF每秒刷盘、异步关闭文件描述符这些操作。由于机器只有2核CPU，这也就意味着父进程占用了超过一半的CPU资源，此时子进程做RDB持久化，可能会产生CPU竞争，导致的结果就是父进程处理请求延迟增大，子进程生成RDB快照的时间也会变长，整个Redis Server性能下降。</p>
<p>c、另外，可以再延伸一下，老师的问题没有提到Redis进程是否绑定了CPU，如果绑定了CPU，那么子进程会继承父进程的CPU亲和性属性，子进程必然会与父进程争夺同一个CPU资源，整个Redis Server的性能必然会受到影响！所以如果Redis需要开启定时RDB和AOF重写，进程一定不要绑定CPU。</p>
<h2 id="数据复制-主从同步"><a href="#数据复制-主从同步" class="headerlink" title="数据复制-主从同步"></a>数据复制-主从同步</h2><h3 id="总结1-4"><a href="#总结1-4" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我们一起学习了 Redis 的主从库同步的基本原理，总结来说，有三种模式：全量复制、基于长连接的命令传播，以及增量复制。</p>
<p>全量复制虽然耗时，但是对于从库来说，如果是第一次同步，全量复制是无法避免的，所以，我给你一个小建议：一个 Redis 实例的数据库不要太大，一个实例大小在几 GB 级别比较合适，这样可以减少 RDB 文件生成、传输和重新加载的开销。另外，为了避免多个从库同时和主库进行全量复制，给主库过大的同步压力，我们也可以采用“主 - 从 - 从”这一级联模式，来缓解主库的压力。</p>
<p>长连接复制是主从库正常运行后的常规同步阶段。在这个阶段中，主从库之间通过命令传播实现同步。不过，这期间如果遇到了网络断连，增量复制就派上用场了。我特别建议你留意一下 repl_backlog_size 这个配置参数。如果它配置得过小，在增量复制阶段，可能会导致从库的复制进度赶不上主库，进而导致从库重新进行全量复制。所以，通过调大这个参数，可以减少从库在网络断连时全量复制的风险。</p>
<p>不过，主从库模式使用读写分离虽然避免了同时写多个实例带来的数据不一致问题，但是还面临主库故障的潜在风险。主库故障了从库该怎么办，数据还能保持一致吗，Redis 还能正常提供服务吗？在接下来的两节课里，我会和你具体聊聊主库故障后，保证服务可靠性的解决方案。</p>
<h3 id="总结2-3"><a href="#总结2-3" class="headerlink" title="总结2"></a>总结2</h3><p>一，作者讲了什么？<br>Redis的主从库数据同步机制的诞生背景和运行机制</p>
<p>二，作者是怎么把这事给讲明白的？<br>1， 作者首先介绍了主从库诞生需求背景：（写到这让我想起许式伟在架构课中提到的：拆解架构的两个核心：需求和规格）<br>为了实现Redis的高可用性，需要有多个redis实例，并且要保证多个实例数据一致（CAP定理：一致性，可用性，分区容错性）<br>2，介绍Redis的主从库间的工作机制：读写分离，主库负责接收读写请求，从库负责接收读请求，为保证从库可以正确的响应读请求，主库需要向从库同步数据<br>3，详细介绍了主从同步的机制：同步时间，同步内容，异常处理，失败补偿</p>
<p>三，作者为了讲明白，讲了哪些要点？有哪些亮点？<br>1，亮点1：Redis采用读写分离的好处：避免了加锁，实例间协商是否完成修改等复杂操作<br>1，亮点2：全量同步的发生时机：首次上线 和 从库的环形缓冲区位置标识被覆盖<br>2，亮点3：增量同步保障机制依赖于一个特殊的数据结构：环形缓冲区<br>3，要点1：首次同步分为三个阶段，①：建立连接，②：同步RDB文件，③：同步增量数据<br>4，要点2：全量同步需要主机fork子进程，产生全量RDB文件，并发送，为了减轻主机的压力，从机之间也可用互相同步<br>5，要点3：增量同步可以缓解主机全量同步的压力，它需要特殊机制保障：replication buffer，环形缓冲区，master_repl_offset，slave_repl_offset<br>6，要点4：从机的同步位置标识，在环形缓冲区被覆盖后，会触发新的一轮全量同步，所repl_backlog_buffer的大小是redis重要的调优参数<br>7，要点5：主从同步有三种机制：全量同步，基于长链接的命令传播（在写这个笔记时把它忽略了），增量同步</p>
<p>四，对于作者所讲，我有哪些发散性思考？<br>1，作者在介绍数据备份和数据同步时，都提到了单个redis的实例不宜过大<br>2，同步机制不止是redis需要，kafka，mysql中也需要，这个需要去看看他们是怎么设计的<br>3，作者介绍的redis数据一致性保障机制是很有趣，对于异常的处理机制值得学习</p>
<p>五，在未来的哪些场景里，我能够使用它？<br>1，以后面试，redis的数据备份和数同步可以不怂了<br>2，分布式系统的三定律有了联系对象</p>
<p>六，评论区的收获<br>从@Kaito 大神 那里了解到，<br>1，repl_backlog_buffer，是随着主机一起诞生的<br>2，主机和所有的clent端（包括从机）都会建立一个对应的buffer<br>3，replication buffer是与每个clent端一一对应<br>4，redis的所有写命令除了用于长链接广播，还都会写入repl_backlog_buffer</p>
<h3 id="问题-2"><a href="#问题-2" class="headerlink" title="问题"></a>问题</h3><p>按照惯例，我给你提一个小问题。这节课，我提到，主从库间的数据复制同步使用的是 RDB 文件，前面我们学习过，AOF 记录的操作命令更全，相比于 RDB 丢失的数据更少。那么，为什么主从库间的复制不使用 AOF 呢？</p>
<h3 id="解答-2"><a href="#解答-2" class="headerlink" title="解答"></a>解答</h3><p>主从全量同步使用RDB而不使用AOF的原因：</p>
<p>1、RDB文件内容是经过压缩的二进制数据（不同数据类型数据做了针对性优化），文件很小。而AOF文件记录的是每一次写操作的命令，写操作越多文件会变得很大，其中还包括很多对同一个key的多次冗余操作。在主从全量数据同步时，传输RDB文件可以尽量降低对主库机器网络带宽的消耗，从库在加载RDB文件时，一是文件小，读取整个文件的速度会很快，二是因为RDB文件存储的都是二进制数据，从库直接按照RDB协议解析还原数据即可，速度会非常快，而AOF需要依次重放每个写命令，这个过程会经历冗长的处理逻辑，恢复速度相比RDB会慢得多，所以使用RDB进行主从全量同步的成本最低。</p>
<p>2、假设要使用AOF做全量同步，意味着必须打开AOF功能，打开AOF就要选择文件刷盘的策略，选择不当会严重影响Redis性能。而RDB只有在需要定时备份和主从全量同步数据时才会触发生成一次快照。而在很多丢失数据不敏感的业务场景，其实是不需要开启AOF的。</p>
<p>另外，需要指出老师文章的错误：“当主从库断连后，主库会把断连期间收到的写操作命令，写入 replication buffer，同时也会把这些操作命令也写入 repl_backlog_buffer 这个缓冲区。”</p>
<p>1、主从库连接都断开了，哪里来replication buffer呢？</p>
<p>2、应该不是“主从库断连后”主库才把写操作写入repl_backlog_buffer，只要有从库存在，这个repl_backlog_buffer就会存在。主库的所有写命令除了传播给从库之外，都会在这个repl_backlog_buffer中记录一份，缓存起来，只有预先缓存了这些命令，当从库断连后，从库重新发送psync $master_runid $offset，主库才能通过$offset在repl_backlog_buffer中找到从库断开的位置，只发送$offset之后的增量数据给从库即可。</p>
<p>有同学对repl_backlog_buffer和replication buffer理解比较混淆，我大概解释一下：</p>
<p>1、repl_backlog_buffer：就是上面我解释到的，它是为了从库断开之后，如何找到主从差异数据而设计的环形缓冲区，从而避免全量同步带来的性能开销。如果从库断开时间太久，repl_backlog_buffer环形缓冲区被主库的写命令覆盖了，那么从库连上主库后只能乖乖地进行一次全量同步，所以repl_backlog_buffer配置尽量大一些，可以降低主从断开后全量同步的概率。而在repl_backlog_buffer中找主从差异的数据后，如何发给从库呢？这就用到了replication buffer。</p>
<p>2、replication buffer：Redis和客户端通信也好，和从库通信也好，Redis都需要给分配一个 内存buffer进行数据交互，客户端是一个client，从库也是一个client，我们每个client连上Redis后，Redis都会分配一个client buffer，所有数据交互都是通过这个buffer进行的：Redis先把数据写到这个buffer中，然后再把buffer中的数据发到client socket中再通过网络发送出去，这样就完成了数据交互。所以主从在增量同步时，从库作为一个client，也会分配一个buffer，只不过这个buffer专门用来传播用户的写命令到从库，保证主从数据一致，我们通常把它叫做replication buffer。</p>
<p>3、再延伸一下，既然有这个内存buffer存在，那么这个buffer有没有限制呢？如果主从在传播命令时，因为某些原因从库处理得非常慢，那么主库上的这个buffer就会持续增长，消耗大量的内存资源，甚至OOM。所以Redis提供了client-output-buffer-limit参数限制这个buffer的大小，如果超过限制，主库会强制断开这个client的连接，也就是说从库处理慢导致主库内存buffer的积压达到限制后，主库会强制断开从库的连接，此时主从复制会中断，中断后如果从库再次发起复制请求，那么此时可能会导致恶性循环，引发复制风暴，这种情况需要格外注意。</p>
<h2 id="哨兵机制：主库挂了，如何不间断服务"><a href="#哨兵机制：主库挂了，如何不间断服务" class="headerlink" title="哨兵机制：主库挂了，如何不间断服务"></a>哨兵机制：主库挂了，如何不间断服务</h2><h3 id="总结1-5"><a href="#总结1-5" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我们一起学习了哨兵机制，它是实现 Redis 不间断服务的重要保证。具体来说，主从集群的数据同步，是数据可靠的基础保证；而在主库发生故障时，自动的主从切换是服务不间断的关键支撑。</p>
<p>Redis 的哨兵机制自动完成了以下三大功能，从而实现了主从库的自动切换，可以降低 Redis 集群的运维开销：</p>
<ul>
<li>监控主库运行状态，并判断主库是否客观下线；</li>
<li>在主库客观下线后，选取新主库；</li>
<li>选出新主库后，通知从库和客户端。</li>
</ul>
<p>为了降低误判率，在实际应用时，哨兵机制通常采用多实例的方式进行部署，多个哨兵实例通过“少数服从多数”的原则，来判断主库是否客观下线。一般来说，我们可以部署三个哨兵，如果有两个哨兵认定主库“主观下线”，就可以开始切换过程。当然，如果你希望进一步提升判断准确率，也可以再适当增加哨兵个数，比如说使用五个哨兵。<br>但是，使用多个哨兵实例来降低误判率，其实相当于组成了一个哨兵集群，我们会因此面临着一些新的挑战，例如：</p>
<ul>
<li>哨兵集群中有实例挂了，怎么办，会影响主库状态判断和选主吗？</li>
<li>哨兵集群多数实例达成共识，判断出主库“客观下线”后，由哪个实例来执行主从切换呢？</li>
</ul>
<p>要搞懂这些问题，就不得不提哨兵集群了，下节课，我们来具体聊聊哨兵集群的机制和问题。</p>
<h3 id="总结2-4"><a href="#总结2-4" class="headerlink" title="总结2"></a>总结2</h3><p>一，作者讲了什么？<br>Redis故障转移：主从切换机制哨兵</p>
<p>二，作者是怎么把这事给讲明白的？<br>1，提出主从切换的三个问题：a，主机状态确认 b，新主库选举 c，新主库通知<br>2，讲解了哨兵的本质是一个特殊的redis进程（实例），有三个职责：监控，选主，通知</p>
<p>三，为了讲明白，作者讲了哪些要点，有哪些亮点？<br>1，亮点1：哨兵的本质：是一个redis实例，要做三件事：监控主库，选举新主库，通知客户端和从机（这让我对哨兵理解清晰了很多）<br>2，要点1：哨兵是通过心跳检测，监控主库状态，主库下线被分为：主观下线和客观下线、<br>3，要点2：哨兵监控是可能误判的，所以哨兵一般是集群部署，采取投票的形式减少误判<br>4，要点3：选定新主库规则是先筛选在打分，得分高的会被选为新主库，<br>5，要点4：筛选规则：从库当前的网络连接状况，以及之前的网络连接状况，筛选中断次数标准可以配置<br>6，要点5：打分规则：从库的优先级，数据同步状况，Id号大小，可以分为三轮，只要有一轮出现得分高的，就能选出</p>
<p>四，对作者所讲，我有哪些发散性思考？<br>选举机制，在分布式的场景中经常出现。我在刚开始学习这一类知识的时候，经常会想：那些大神是怎么会想到这种解决方案的？<br>后来读了一些西方社会运行机制的书，我有所释然。得到一些感悟：大神思考的技术问题解决方案，和他所生活的社会环境有着莫大的关系</p>
<p>五，将来在哪些场景，我能够使用到它？</p>
<p>六，留言区的收获<br>1，数据同步状况的判断：（感谢@Monday 同学的提问）<br>a：判断哪个从库的数据同步最接近主库，不是拿从库与主库比较，而是从库之间互相比较，谁大谁就是最接近的<br>b：这样做的原因有二：主库已下线无法获取主库信息，环形缓冲区的位置偏移量是单调递增的（主库的被称为：master_repl_offset，从库的被称为：slave_repl_offset，其实两者本质是相同的，叫不同的名字只是为了区分）<br>2，哨兵的使用：（感谢 @Kaito 大神简洁明了，无私的分享）<br>a：主库下线，可读不可写，写失败的时间=哨兵切换主从的时间+客户端感知新主库时间<br>b：主库下线无感知，需要客户端与哨兵配合改造：<br>1：哨兵主动通知：哨兵需要将最新的主库地址写入自己的pubsub中，客户端需要订阅这个pubsub，当这个pubsub有数据时，客户端就能感知到<br>2：客户端主动获取：客户端不将主从库写死，而是从哨兵集群中获取，从而始终获取最新的主从地址<br>c：集群分片模式的Redis集群，可以不使用哨兵机制（我们项目组就是这样的）</p>
<h3 id="问题-3"><a href="#问题-3" class="headerlink" title="问题"></a>问题</h3><p>按照惯例，我给你提个小问题。这节课，我提到，通过哨兵机制，可以实现主从库的自动切换，这是实现服务不间断的关键支撑，同时，我也提到了主从库切换是需要一定时间的。所以，请你考虑下，在这个切换过程中，客户端能否正常地进行请求操作呢？如果想要应用程序不感知服务的中断，还需要哨兵或需要客户端再做些什么吗？</p>
<h3 id="解答-3"><a href="#解答-3" class="headerlink" title="解答"></a>解答</h3><p>哨兵在操作主从切换的过程中，客户端能否正常地进行请求操作？</p>
<p>如果客户端使用了读写分离，那么读请求可以在从库上正常执行，不会受到影响。但是由于此时主库已经挂了，而且哨兵还没有选出新的主库，所以在这期间写请求会失败，失败持续的时间 = 哨兵切换主从的时间 + 客户端感知到新主库 的时间。</p>
<p>如果不想让业务感知到异常，客户端只能把写失败的请求先缓存起来或写入消息队列中间件中，等哨兵切换完主从后，再把这些写请求发给新的主库，但这种场景只适合对写入请求返回值不敏感的业务，而且还需要业务层做适配，另外主从切换时间过长，也会导致客户端或消息队列中间件缓存写请求过多，切换完成之后重放这些请求的时间变长。</p>
<p>哨兵检测主库多久没有响应就提升从库为新的主库，这个时间是可以配置的（down-after-milliseconds参数）。配置的时间越短，哨兵越敏感，哨兵集群认为主库在短时间内连不上就会发起主从切换，这种配置很可能因为网络拥塞但主库正常而发生不必要的切换，当然，当主库真正故障时，因为切换得及时，对业务的影响最小。如果配置的时间比较长，哨兵越保守，这种情况可以减少哨兵误判的概率，但是主库故障发生时，业务写失败的时间也会比较久，缓存写请求数据量越多。</p>
<p>应用程序不感知服务的中断，还需要哨兵和客户端做些什么？当哨兵完成主从切换后，客户端需要及时感知到主库发生了变更，然后把缓存的写请求写入到新库中，保证后续写请求不会再受到影响，具体做法如下：</p>
<p>哨兵提升一个从库为新主库后，哨兵会把新主库的地址写入自己实例的pubsub（switch-master）中。客户端需要订阅这个pubsub，当这个pubsub有数据时，客户端就能感知到主库发生变更，同时可以拿到最新的主库地址，然后把写请求写到这个新主库即可，这种机制属于哨兵主动通知客户端。</p>
<p>如果客户端因为某些原因错过了哨兵的通知，或者哨兵通知后客户端处理失败了，安全起见，客户端也需要支持主动去获取最新主从的地址进行访问。</p>
<p>所以，客户端需要访问主从库时，不能直接写死主从库的地址了，而是需要从哨兵集群中获取最新的地址（sentinel get-master-addr-by-name命令），这样当实例异常时，哨兵切换后或者客户端断开重连，都可以从哨兵集群中拿到最新的实例地址。</p>
<p>一般Redis的SDK都提供了通过哨兵拿到实例地址，再访问实例的方式，我们直接使用即可，不需要自己实现这些逻辑。当然，对于只有主从实例的情况，客户端需要和哨兵配合使用，而在分片集群模式下，这些逻辑都可以做在proxy层，这样客户端也不需要关心这些逻辑了，Codis就是这么做的。</p>
<p>另外再简单回答下哨兵相关的问题：</p>
<p>1、哨兵集群中有实例挂了，怎么办，会影响主库状态判断和选主吗？</p>
<p>这个属于分布式系统领域的问题了，指的是在分布式系统中，如果存在故障节点，整个集群是否还可以提供服务？而且提供的服务是正确的？</p>
<p>这是一个分布式系统容错问题，这方面最著名的就是分布式领域中的“拜占庭将军”问题了，“拜占庭将军问题”不仅解决了容错问题，还可以解决错误节点的问题，虽然比较复杂，但还是值得研究的，有兴趣的同学可以去了解下。</p>
<p>简单说结论：存在故障节点时，只要集群中大多数节点状态正常，集群依旧可以对外提供服务。具体推导过程细节很多，大家去查前面的资料了解就好。</p>
<p>2、哨兵集群多数实例达成共识，判断出主库“客观下线”后，由哪个实例来执行主从切换呢？</p>
<p>哨兵集群判断出主库“主观下线”后，会选出一个“哨兵领导者”，之后整个过程由它来完成主从切换。</p>
<p>但是如何选出“哨兵领导者”？这个问题也是一个分布式系统中的问题，就是我们经常听说的共识算法，指的是集群中多个节点如何就一个问题达成共识。共识算法有很多种，例如Paxos、Raft，这里哨兵集群采用的类似于Raft的共识算法。</p>
<p>简单来说就是每个哨兵设置一个随机超时时间，超时后每个哨兵会请求其他哨兵为自己投票，其他哨兵节点对收到的第一个请求进行投票确认，一轮投票下来后，首先达到多数选票的哨兵节点成为“哨兵领导者”，如果没有达到多数选票的哨兵节点，那么会重新选举，直到能够成功选出“哨兵领导者”。</p>
<h2 id="哨兵集群：哨兵挂了，如何服务"><a href="#哨兵集群：哨兵挂了，如何服务" class="headerlink" title="哨兵集群：哨兵挂了，如何服务"></a>哨兵集群：哨兵挂了，如何服务</h2><h3 id="总结1-6"><a href="#总结1-6" class="headerlink" title="总结1"></a>总结1</h3><p>通常，我们在解决一个系统问题的时候，会引入一个新机制，或者设计一层新功能，就像我们在这两节课学习的内容：为了实现主从切换，我们引入了哨兵；为了避免单个哨兵故障后无法进行主从切换，以及为了减少误判率，又引入了哨兵集群；哨兵集群又需要有一些机制来支撑它的正常运行。</p>
<p>这节课上，我就向你介绍了支持哨兵集群的这些关键机制，包括：</p>
<ul>
<li>基于 pub/sub 机制的哨兵集群组成过程；</li>
<li>基于 INFO 命令的从库列表，这可以帮助哨兵和从库建立连接；</li>
<li>基于哨兵自身的 pub/sub 功能，这实现了客户端和哨兵之间的事件通知。</li>
</ul>
<p>对于主从切换，当然不是哪个哨兵想执行就可以执行的，否则就乱套了。所以，这就需要哨兵集群在判断了主库“客观下线”后，经过投票仲裁，选举一个 Leader 出来，由它负责实际的主从切换，即由它来完成新主库的选择以及通知从库与客户端。</p>
<p>最后，我想再给你分享一个经验：要保证所有哨兵实例的配置是一致的，尤其是主观下线的判断值 down-after-milliseconds。我们曾经就踩过一个“坑”。当时，在我们的项目中，因为这个值在不同的哨兵实例上配置不一致，导致哨兵集群一直没有对有故障的主库形成共识，也就没有及时切换主库，最终的结果就是集群服务不稳定。所以，你一定不要忽略这条看似简单的经验。</p>
<h3 id="总结2-5"><a href="#总结2-5" class="headerlink" title="总结2"></a>总结2</h3><p>一，作者讲了什么？<br>哨兵集群的工作机制</p>
<p>二，作者是怎么把这事给讲明白的？<br>1，哨兵之间互通机制：基于pub/sub机制，在主库中有一个”<strong>sentinel</strong>:hello”的频道，哨兵之间互相发现通信<br>2，哨兵与主从库互通机制：哨兵向主库发送INFO指令，可以获取所有从库的信息，实现对主库，从库的监控<br>3，哨兵判定主库异常机制：哨兵集群中任意一个实例都可以发起主库异常“投票仲裁”流程</p>
<p>三，为了讲明白，作者都讲了哪些要点？有哪些亮点？<br>1，亮点1：哨兵之间的互动是通过发布订阅机制完成的，利用自身的特性来实现。这让我联想到kafka对于日息位置偏移量的管理<br>2，要点1：哨兵之间通信不是哨兵之间之间联系，而是通过订阅主库的同一频道来获取彼此的信息<br>3，要点2：哨兵是通过INFO指令，从主库获取从库信息，并与每个从库建立连接，监控所有主从库状态<br>4，要点3：哨兵是一个特殊的redis实例，所以客户端可以订阅哨兵的指定频道获得redis主从库的信息<br>5，要点4：哨兵集群执行主从切换机制：谁发现，谁就发起投票流程，谁获得多数票，谁就是哨兵Leader，由Leader负责主从库切换<br>6，要点5：哨兵集群Leader选举成功与否，依赖于网络通信状况，网络拥塞会导致选举失败，重新进行新一轮选举</p>
<p>四，对于作者所讲，我有哪些发散性思考？</p>
<p>五，在未来的哪些场景里，我可以使用它？</p>
<p>六，留言区的收获：（感谢 @ 小喵喵 的提问）<br>1，哨兵投票机制：<br>a：哨兵实例只有在自己判定主库下线时，才会给自己投票，而其他的哨兵实例会把票投给第一个来要票的请求，其后的都拒绝<br>b：如果出现多个哨兵同时发现主库下线并给自己投票，导致投票选举失败，就会触发新一轮投票，直至成功</p>
<p>2，哨兵Leader切换主从库的机制：（感谢 @Kaito ，@Darren 大神的解答）<br>        哨兵成为Leader的必要条件：a：获得半数以上的票数，b：得到的票数要达到配置的quorum阀值<br>        主从切换只能由Leader执行，而成为Leader有两个必要的条件，所以当哨兵集群中实例异常过多时，会导致主从库无法切换</p>
<h3 id="问题-4"><a href="#问题-4" class="headerlink" title="问题"></a>问题</h3><p>假设有一个 Redis 集群，是“一主四从”，同时配置了包含 5 个哨兵实例的集群，quorum 值设为 2。在运行过程中，如果有 3 个哨兵实例都发生故障了，此时，Redis 主库如果有故障，还能正确地判断主库“客观下线”吗？如果可以的话，还能进行主从库自动切换吗？此外，哨兵实例是不是越多越好呢，如果同时调大 down-after-milliseconds 值，对减少误判是不是也有好处呢？</p>
<h3 id="解答-4"><a href="#解答-4" class="headerlink" title="解答"></a>解答</h3><p>Redis 1主4从，5个哨兵，哨兵配置quorum为2，如果3个哨兵故障，当主库宕机时，哨兵能否判断主库“客观下线”？能否自动切换？</p>
<p>经过实际测试，我的结论如下：</p>
<p>1、哨兵集群可以判定主库“主观下线”。由于quorum=2，所以当一个哨兵判断主库“主观下线”后，询问另外一个哨兵后也会得到同样的结果，2个哨兵都判定“主观下线”，达到了quorum的值，因此，哨兵集群可以判定主库为“客观下线”。</p>
<p>2、但哨兵不能完成主从切换。哨兵标记主库“客观下线后”，在选举“哨兵领导者”时，一个哨兵必须拿到超过多数的选票(5/2+1=3票)。但目前只有2个哨兵活着，无论怎么投票，一个哨兵最多只能拿到2票，永远无法达到多数选票的结果。</p>
<p>但是投票选举过程的细节并不是大家认为的：每个哨兵各自1票，这个情况是不一定的。下面具体说一下：</p>
<p>场景a：哨兵A先判定主库“主观下线”，然后马上询问哨兵B（注意，此时哨兵B只是被动接受询问，并没有去询问哨兵A，也就是它还没有进入判定“客观下线”的流程），哨兵B回复主库已“主观下线”，达到quorum=2后哨兵A此时可以判定主库“客观下线”。此时，哨兵A马上可以向其他哨兵发起成为“哨兵领导者”的投票，哨兵B收到投票请求后，由于自己还没有询问哨兵A进入判定“客观下线”的流程，所以哨兵B是可以给哨兵A投票确认的，这样哨兵A就已经拿到2票了。等稍后哨兵B也判定“主观下线”后想成为领导者时，因为它已经给别人投过票了，所以这一轮自己就不能再成为领导者了。</p>
<p>场景b：哨兵A和哨兵B同时判定主库“主观下线”，然后同时询问对方后都得到可以“客观下线”的结论，此时它们各自给自己投上1票后，然后向其他哨兵发起投票请求，但是因为各自都给自己投过票了，因此各自都拒绝了对方的投票请求，这样2个哨兵各自持有1票。</p>
<p>场景a是1个哨兵拿到2票，场景b是2个哨兵各自有1票，这2种情况都不满足大多数选票(3票)的结果，因此无法完成主从切换。</p>
<p>经过测试发现，场景b发生的概率非常小，只有2个哨兵同时进入判定“主观下线”的流程时才可以发生。我测试几次后发现，都是复现的场景a。</p>
<p>哨兵实例是不是越多越好？</p>
<p>并不是，我们也看到了，哨兵在判定“主观下线”和选举“哨兵领导者”时，都需要和其他节点进行通信，交换信息，哨兵实例越多，通信的次数也就越多，而且部署多个哨兵时，会分布在不同机器上，节点越多带来的机器故障风险也会越大，这些问题都会影响到哨兵的通信和选举，出问题时也就意味着选举时间会变长，切换主从的时间变久。</p>
<p>调大down-after-milliseconds值，对减少误判是不是有好处？</p>
<p>是有好处的，适当调大down-after-milliseconds值，当哨兵与主库之间网络存在短时波动时，可以降低误判的概率。但是调大down-after-milliseconds值也意味着主从切换的时间会变长，对业务的影响时间越久，我们需要根据实际场景进行权衡，设置合理的阈值。</p>
<h2 id="切片集群：是增加内存还是增加实例"><a href="#切片集群：是增加内存还是增加实例" class="headerlink" title="切片集群：是增加内存还是增加实例"></a>切片集群：是增加内存还是增加实例</h2><h3 id="总结1-7"><a href="#总结1-7" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我们学习了切片集群在保存大量数据方面的优势，以及基于哈希槽的数据分布机制和客户端定位键值对的方法。</p>
<p>在应对数据量扩容时，虽然增加内存这种纵向扩展的方法简单直接，但是会造成数据库的内存过大，导致性能变慢。Redis 切片集群提供了横向扩展的模式，也就是使用多个实例，并给每个实例配置一定数量的哈希槽，数据可以通过键的哈希值映射到哈希槽，再通过哈希槽分散保存到不同的实例上。这样做的好处是扩展性好，不管有多少数据，切片集群都能应对。</p>
<p>另外，集群的实例增减，或者是为了实现负载均衡而进行的数据重新分布，会导致哈希槽和实例的映射关系发生变化，客户端发送请求时，会收到命令执行报错信息。了解了 MOVED 和 ASK 命令，你就不会为这类报错而头疼了。</p>
<p>我刚刚说过，在 Redis 3.0 之前，Redis 官方并没有提供切片集群方案，但是，其实当时业界已经有了一些切片集群的方案，例如基于客户端分区的 ShardedJedis，基于代理的 Codis、Twemproxy 等。这些方案的应用早于 Redis Cluster 方案，在支撑的集群实例规模、集群稳定性、客户端友好性方面也都有着各自的优势，我会在后面的课程中，专门和你聊聊这些方案的实现机制，以及实践经验。这样一来，当你再碰到业务发展带来的数据量巨大的难题时，就可以根据这些方案的特点，选择合适的方案实现切片集群，以应对业务需求了。</p>
<h3 id="总结2-6"><a href="#总结2-6" class="headerlink" title="总结2"></a>总结2</h3><p>1，作者讲了什么？<br>切片集群</p>
<p>2，作者是怎么把事给讲明白的？<br>从一个案例入手，讲到单实例内存过大在数据备份时会导致Redis性能下降，<br>引出redis分片集群来解决大数据量，高性能的设计<br>提出两个关键问题：数据分片与实例间如何建立对应关系，2，客户端如何知晓去哪个实例中获取数据</p>
<p>3，为了讲明白，作者讲了哪些要点？有哪些亮点？<br>1，亮点1：这一课我更加清晰的明白了之前别人聊Redis扩容中的纵向扩容和横向扩容的真实含义和区别<br>2，要点1：数据分片和实例的对应关系建立：按照CRC16算法计算一个key的16bit的值，在将这值对16384取模<br>3，要点2：一个切片集群的槽位是固定的16384个，可手动分配每个实例的槽位，但必须将槽位全部分完<br>4，要点3：客户端如何确定要访问那个实例获取数据：1从任意个实例获取并缓存在自己本地，2，重定向机制<br>5，要点4：重定向机制：客户端访问的实例没有数据，被访问实例响应move命令，告诉客户端指向新的实例地址<br>6，要点5：ASK命令：1，表明数据正在迁移 2，告知客户端数据所在的实例<br>7，要点6：ASK命令和MOVE命令的区别：<br>move命令是在数据迁移完毕后被响应，客户端会更新本地缓存。<br>ASK命令是在数据迁移中被响应，不会让客户端更新缓存</p>
<p>4，对作者所讲，我有哪些发散性思考？<br>对于CRC16算法，应该可以用到我们系统当中，对所有手机的设备号进行计算取模，用于分表存储数据<br>在系统设计时，可以通过分层或增加一层来提升系统设计的弹性</p>
<p>5，在将来的那些场景中，我能够使用它？</p>
<p>6，留言区的收获（来自 @Kaito 大神）<br>1，Redis Cluster不采用直接把key映射到实例，而采用哈希槽的方式原因：可用使Redis集群设计：简洁，高效，有弹性<br>不使用的劣势<br>①：集群中的key无法预估，直接存key对应实例的映射关系，需占用的内存空间不可控<br>②：Cluster是去中心化设计，所有实例都需保存完整的映射关系，<br>采用直接的映射，会导致节点间信息交换成本高昂<br>③：key与实例直接映射，在集群扩缩容时，需要数据迁移，所有的key都需要重新映射<br>使用的好处<br>①：在中间增加一层哈希槽，可以将数据与节点解耦，使数据分配均匀<br>key通过hsah计算在取模，可以把数据打的更散，<br>只需要关心映射到了哪个哈希槽，通过哈希槽映射表找到对应的实例<br>②：增加哈希槽可以使得映射表比较小，有利于客户端和服务端保存，节点间信息交换<br>③：集群扩缩容，数据均衡时，操作单位是哈希槽，可以简化操作难度</p>
<p>2，Redis集群方案的两个关键问题：<br>    ①：请求路由<br>    ②：数据迁移</p>
<h3 id="问题-5"><a href="#问题-5" class="headerlink" title="问题"></a>问题</h3><p>Redis Cluster 方案通过哈希槽的方式把键值对分配到不同的实例上，这个过程需要对键值对的 key 做 CRC 计算，然后再和哈希槽做映射，这样做有什么好处吗？如果用一个表直接把键值对和实例的对应关系记录下来（例如键值对 1 在实例 2 上，键值对 2 在实例 1 上），这样就不用计算 key 和哈希槽的对应关系了，只用查表就行了，Redis 为什么不这么做呢？</p>
<h3 id="解答-5"><a href="#解答-5" class="headerlink" title="解答"></a>解答</h3><p>Redis Cluster不采用把key直接映射到实例的方式，而采用哈希槽的方式原因：</p>
<p>1、整个集群存储key的数量是无法预估的，key的数量非常多时，直接记录每个key对应的实例映射关系，这个映射表会非常庞大，这个映射表无论是存储在服务端还是客户端都占用了非常大的内存空间。</p>
<p>2、Redis Cluster采用无中心化的模式（无proxy，客户端与服务端直连），客户端在某个节点访问一个key，如果这个key不在这个节点上，这个节点需要有纠正客户端路由到正确节点的能力（MOVED响应），这就需要节点之间互相交换路由表，每个节点拥有整个集群完整的路由关系。如果存储的都是key与实例的对应关系，节点之间交换信息也会变得非常庞大，消耗过多的网络资源，而且就算交换完成，相当于每个节点都需要额外存储其他节点的路由表，内存占用过大造成资源浪费。</p>
<p>3、当集群在扩容、缩容、数据均衡时，节点之间会发生数据迁移，迁移时需要修改每个key的映射关系，维护成本高。</p>
<p>4、而在中间增加一层哈希槽，可以把数据和节点解耦，key通过Hash计算，只需要关心映射到了哪个哈希槽，然后再通过哈希槽和节点的映射表找到节点，相当于消耗了很少的CPU资源，不但让数据分布更均匀，还可以让这个映射表变得很小，利于客户端和服务端保存，节点之间交换信息时也变得轻量。</p>
<p>5、当集群在扩容、缩容、数据均衡时，节点之间的操作例如数据迁移，都以哈希槽为基本单位进行操作，简化了节点扩容、缩容的难度，便于集群的维护和管理。</p>
<p>另外，我想补充一下Redis集群相关的知识，以及我的理解：</p>
<p>Redis使用集群方案就是为了解决单个节点数据量大、写入量大产生的性能瓶颈的问题。多个节点组成一个集群，可以提高集群的性能和可靠性，但随之而来的就是集群的管理问题，最核心问题有2个：请求路由、数据迁移（扩容/缩容/数据平衡）。</p>
<p>1、请求路由：一般都是采用哈希槽的映射关系表找到指定节点，然后在这个节点上操作的方案。</p>
<p>Redis Cluster在每个节点记录完整的映射关系(便于纠正客户端的错误路由请求)，同时也发给客户端让客户端缓存一份，便于客户端直接找到指定节点，客户端与服务端配合完成数据的路由，这需要业务在使用Redis Cluster时，必须升级为集群版的SDK才支持客户端和服务端的协议交互。</p>
<p>其他Redis集群化方案例如Twemproxy、Codis都是中心化模式（增加Proxy层），客户端通过Proxy对整个集群进行操作，Proxy后面可以挂N多个Redis实例，Proxy层维护了路由的转发逻辑。操作Proxy就像是操作一个普通Redis一样，客户端也不需要更换SDK，而Redis Cluster是把这些路由逻辑做在了SDK中。当然，增加一层Proxy也会带来一定的性能损耗。</p>
<p>2、数据迁移：当集群节点不足以支撑业务需求时，就需要扩容节点，扩容就意味着节点之间的数据需要做迁移，而迁移过程中是否会影响到业务，这也是判定一个集群方案是否成熟的标准。</p>
<p>Twemproxy不支持在线扩容，它只解决了请求路由的问题，扩容时需要停机做数据重新分配。而Redis Cluster和Codis都做到了在线扩容（不影响业务或对业务的影响非常小），重点就是在数据迁移过程中，客户端对于正在迁移的key进行操作时，集群如何处理？还要保证响应正确的结果？</p>
<p>Redis Cluster和Codis都需要服务端和客户端/Proxy层互相配合，迁移过程中，服务端针对正在迁移的key，需要让客户端或Proxy去新节点访问（重定向），这个过程就是为了保证业务在访问这些key时依旧不受影响，而且可以得到正确的结果。由于重定向的存在，所以这个期间的访问延迟会变大。等迁移完成之后，Redis Cluster每个节点会更新路由映射表，同时也会让客户端感知到，更新客户端缓存。Codis会在Proxy层更新路由表，客户端在整个过程中无感知。</p>
<p>除了访问正确的节点之外，数据迁移过程中还需要解决异常情况（迁移超时、迁移失败）、性能问题（如何让数据迁移更快、bigkey如何处理），这个过程中的细节也很多。</p>
<p>Redis Cluster的数据迁移是同步的，迁移一个key会同时阻塞源节点和目标节点，迁移过程中会有性能问题。而Codis提供了异步迁移数据的方案，迁移速度更快，对性能影响最小，当然，实现方案也比较复杂。</p>
<h2 id="string为什么不好用了"><a href="#string为什么不好用了" class="headerlink" title="string为什么不好用了"></a>string为什么不好用了</h2><h3 id="总结1-8"><a href="#总结1-8" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我们打破了对 String 的认知误区，以前，我们认为 String 是“万金油”，什么场合都适用，但是，在保存的键值对本身占用的内存空间不大时（例如这节课里提到的的图片 ID 和图片存储对象 ID），String 类型的元数据开销就占据主导了，这里面包括了 RedisObject 结构、SDS 结构、dictEntry 结构的内存开销。</p>
<p>针对这种情况，我们可以使用压缩列表保存数据。当然，使用 Hash 这种集合类型保存单值键值对的数据时，我们需要将单值数据拆分成两部分，分别作为 Hash 集合的键和值，就像刚才案例中用二级编码来表示图片 ID，希望你能把这个方法用到自己的场景中。</p>
<p>最后，我还想再给你提供一个小方法：如果你想知道键值对采用不同类型保存时的内存开销，可以在这个网址里输入你的键值对长度和使用的数据类型，这样就能知道实际消耗的内存大小了。建议你把这个小工具用起来，它可以帮助你充分地节省内存。</p>
<h3 id="总结2-7"><a href="#总结2-7" class="headerlink" title="总结2"></a>总结2</h3><p>一，作者讲了什么？<br>Redis的String类型数据结构，及其底层实现<br>二，作者是怎么把这事给说明白的？<br>1，通过一个图片存储的案例，讲通过合理利用Redis的数据结构，降低资源消耗</p>
<p>三，为了讲明白，作者讲了哪些要点？有哪些亮点？<br>1，亮点1：String类型的数据占用内存，分别是被谁占用了<br>2，亮点2：可以巧妙的利用Redis的底层数据结构特性，降低资源消耗<br>3，要点1： Simple Dynamic String结构体（<br>buf：字节数组，为了表示字节结束，会在结尾增加“\0”<br>len： 占4个字节，表示buf的已用长度<br>alloc：占4个字节，表示buf实际分配的长度，一般大于len）</p>
<p>4，要点2： RedisObject 结构体（<br>元数据：8字节（用于记录最后一次访问时间，被引用次数。。。）<br>指针：8字节，指向具体数据类型的实际数据所在 ）</p>
<p>5，要点3：dicEntry 结构体（<br>key：8个字节指针，指向key<br>value：8个字节指针，指向value<br>next：指向下一个dicEntry）<br>6，要点4：ziplist(压缩列表)（<br>zlbytes：在表头，表示列表长度<br>zltail：在表头，表示列尾偏移量<br>zllen：在表头，表示列表中<br>entry：保存数据对象模型<br>zlend：在表尾，表示列表结束）<br>entry：（<br>prev_len：表示一个entry的长度，有两种取值方式：1字节或5字节。<br>1字节表示一个entry小于254字节，255是zlend的默认值，所以不使用。<br>len：表示自身长度，4字节<br>encodeing：表示编码方式，1字节<br>content：保存实际数据）</p>
<p>5，要点4：String类型的内存空间消耗<br>①，保存Long类型时，指针直接保存整数数据值，可以节省空间开销（被称为：int编码）<br>②，保存字符串，且不大于44字节时，RedisObject的元数据，指针和SDS是连续的，可以避免内存碎片（被称为：embstr编码）<br>③，当保存的字符串大于44字节时，SDS的数据量变多，Redis会给SDS分配独立的空间，并用指针指向SDS结构（被称为：raw编码）<br>④，Redis使用一个全局哈希表保存所以键值对，哈希表的每一项都是一个dicEntry，每个dicEntry占用32字节空间<br>⑤，dicEntry自身24字节，但会占用32字节空间，是因为Redis使用了内存分配库jemalloc。<br>jemalloc在分配内存时，会根据申请的字节数N，找一个比N大，但最接近N的2的幂次数作为分配空间，这样可以减少频繁分配内存的次数</p>
<p>4，要点5：使用什么数据结构可以节省内存？<br>①， 压缩列表，是一种非常节省内存的数据结构，因为他使用连续的内存空间保存数据，不需要额外的指针进行连接<br>②，Redis基于压缩列表实现List，Hash，Sorted Set集合类型，最大的好处是节省了dicEntry开销</p>
<p>5，要点6：如何使用集合类型保存键值对？<br>①，Hash类型设置了用压缩列表保存数据时的两个阀值，一旦超过就会将压缩列表转为哈希表，且不可回退<br>②，hash-max-ziplist-entries：表示用压缩列表保存哈希集合中的最大元素个数<br>③，hash-max-ziplist-value：表示用压缩列表保存时，哈希集合中单个元素的最大长度</p>
<p>四，对于作者所讲，我有哪些发散性思考？<br>看了老师讲解，做了笔记，又看了黄建宏写的《Redis 设计与实现》<br>有这样的讲解：<br>当哈希对象可以同时满足以下两个条件时， 哈希对象使用 ziplist 编码：</p>
<ol>
<li>哈希对象保存的所有键值对的键和值的字符串长度都小于 64 字节；</li>
<li>哈希对象保存的键值对数量小于 512 个；</li>
</ol>
<p>五，在将来的哪些场景中，我能够使用它？<br>这次学习Redis数据结构特性有了更多了解，在以后可以更加有信心根据业务需要，选取特定的数据结构</p>
<h3 id="问题-6"><a href="#问题-6" class="headerlink" title="问题"></a>问题</h3><p>除了 String 类型和 Hash 类型，你觉得，还有其他合适的类型可以应用在这节课所说的保存图片的例子吗？</p>
<h3 id="解答-6"><a href="#解答-6" class="headerlink" title="解答"></a>解答</h3><p>保存图片的例子，除了用String和Hash存储之外，还可以用Sorted Set存储（勉强）。</p>
<p>Sorted Set与Hash类似，当元素数量少于zset-max-ziplist-entries，并且每个元素内存占用小于zset-max-ziplist-value时，默认也采用ziplist结构存储。我们可以把zset-max-ziplist-entries参数设置为1000，这样Sorted Set默认就会使用ziplist存储了，member和score也会紧凑排列存储，可以节省内存空间。</p>
<p>使用zadd 1101000 3302000080 060命令存储图片ID和对象ID的映射关系，查询时使用zscore 1101000 060获取结果。</p>
<p>但是Sorted Set使用ziplist存储时的缺点是，这个ziplist是需要按照score排序的（为了方便zrange和zrevrange命令的使用），所以在插入一个元素时，需要先根据score找到对应的位置，然后把member和score插入进去，这也意味着Sorted Set插入元素的性能没有Hash高（这也是前面说勉强能用Sorte Set存储的原因）。而Hash在插入元素时，只需要将新的元素插入到ziplist的尾部即可，不需要定位到指定位置。</p>
<p>不管是使用Hash还是Sorted Set，当采用ziplist方式存储时，虽然可以节省内存空间，但是在查询指定元素时，都要遍历整个ziplist，找到指定的元素。所以使用ziplist方式存储时，虽然可以利用CPU高速缓存，但也不适合存储过多的数据（hash-max-ziplist-entries和zset-max-ziplist-entries不宜设置过大），否则查询性能就会下降比较厉害。整体来说，这样的方案就是时间换空间，我们需要权衡使用。</p>
<p>当使用ziplist存储时，我们尽量存储int数据，ziplist在设计时每个entry都进行了优化，针对要存储的数据，会尽量选择占用内存小的方式存储（整数比字符串在存储时占用内存更小），这也有利于我们节省Redis的内存。还有，因为ziplist是每个元素紧凑排列，而且每个元素存储了上一个元素的长度，所以当修改其中一个元素超过一定大小时，会引发多个元素的级联调整（前面一个元素发生大的变动，后面的元素都要重新排列位置，重新分配内存），这也会引发性能问题，需要注意。</p>
<p>另外，使用Hash和Sorted Set存储时，虽然节省了内存空间，但是设置过期变得困难（无法控制每个元素的过期，只能整个key设置过期，或者业务层单独维护每个元素过期删除的逻辑，但比较复杂）。而使用String虽然占用内存多，但是每个key都可以单独设置过期时间，还可以设置maxmemory和淘汰策略，以这种方式控制整个实例的内存上限。</p>
<p>所以在选用Hash和Sorted Set存储时，意味着把Redis当做数据库使用，这样就需要务必保证Redis的可靠性（做好备份、主从副本），防止实例宕机引发数据丢失的风险。而采用String存储时，可以把Redis当做缓存使用，每个key设置过期时间，同时设置maxmemory和淘汰策略，控制整个实例的内存上限，这种方案需要在数据库层（例如MySQL）也存储一份映射关系，当Redis中的缓存过期或被淘汰时，需要从数据库中重新查询重建缓存，同时需要保证数据库和缓存的一致性，这些逻辑也需要编写业务代码实现。</p>
<p>总之，各有利弊，我们需要根据实际场景进行选择。</p>
<h2 id="一亿keys要统计，用哪种集合"><a href="#一亿keys要统计，用哪种集合" class="headerlink" title="一亿keys要统计，用哪种集合"></a>一亿keys要统计，用哪种集合</h2><h3 id="总结1-9"><a href="#总结1-9" class="headerlink" title="总结1"></a>总结1</h3><p><img src="/images/redis/datastruct-02.png" alt="img.png"><br>可以看到，Set 和 Sorted Set 都支持多种聚合统计，不过，对于差集计算来说，只有 Set 支持。Bitmap 也能做多个 Bitmap 间的聚合计算，包括与、或和异或操作。</p>
<p>当需要进行排序统计时，List 中的元素虽然有序，但是一旦有新元素插入，原来的元素在 List 中的位置就会移动，那么，按位置读取的排序结果可能就不准确了。而 Sorted Set 本身是按照集合元素的权重排序，可以准确地按序获取结果，所以建议你优先使用它。</p>
<p>如果我们记录的数据只有 0 和 1 两个值的状态，Bitmap 会是一个很好的选择，这主要归功于 Bitmap 对于一个数据只用 1 个 bit 记录，可以节省内存。</p>
<p>对于基数统计来说，如果集合元素量达到亿级别而且不需要精确统计时，我建议你使用 HyperLogLog。</p>
<h3 id="总结2-8"><a href="#总结2-8" class="headerlink" title="总结2"></a>总结2</h3><p>1，作者讲了什么？<br>1，Redis有那些数据结构适合做统计</p>
<p>2，作者是怎么把这事给讲明白的？<br>1，列举了常见的数据统计需求。从实际需求出发，推荐适合的数据类型，讲解了怎么用，并解答这种数据结构为什么可以<br>2，将数据统计需求，分了四类，分类分别讲解</p>
<p>3，为了讲明白，作者讲了哪些要点，有哪些亮点？<br>1，亮点1：BITMAP的特性和使用场景，方式<br>2，亮点2：HyperLogLog的特性和使用场景，方式<br>3，要点1：日常的统计需求可以分为四类：聚合，排序，二值状态，基数，选用适合的数据类型可以实现即快速又节省内存<br>4，要点2：聚合统计，可以选用Set类型完成，但Set的差，并，交集操作复杂度高，在数据量大的时候会阻塞主进程<br>5，要点3：排序统计，可以选用List和Sorted Set<br>6，要点4：二值状态统计：Bitmap本身是用String类型作为底层数据结构实现，String类型会保存为二进制字节数组，所以可以看作是一个bit数组<br>7，要点5：基数统计：HyperLogLog ,计算基数所需空间总是固定的，而且很小。但要注意，HyperLogLog是统计规则是基于概率完成的，不是非常准确</p>
<p>4，对于作者所讲，我有那些发散性思考？<br>1，对于统计用户的打卡情况，我们项目组也做了这个需求，但遗憾的是我们没有采用bitmap这种方案，而是使用了 sortSet<br>2，HyperLogLog可以考虑使用到，我们项目中的统计视频播放次数，现在这块，我们的方案是，每天产生一个key，单调递增。在通过定时任务，将缓存中的结果，每天一条数据记录，存入数据库</p>
<p>5，在将来的那些场景中，我能够使用它？</p>
<p>6，留言区的收获</p>
<p>1，主从库模式使用Set数据类型聚合命令(来自 @kaito 大神)<br>①：使用SUNIONSTORE，SDIFFSTORE，SINTERSTOR做并集，差集，交集时，这三个命令都会在Redis中生成一个新key,而从库默认是readOnly。所以这些命令只能在主库上使用<br>②：SUNION，SDIFF,SINTER，这些命令可以计算出结果，不产生新的key可以在从库使用</p>
<h3 id="问题-7"><a href="#问题-7" class="headerlink" title="问题"></a>问题</h3><p>这节课，我们学习了 4 种典型的统计模式，以及各种集合类型的支持情况和优缺点，我想请你聊一聊，你还遇到过其他的统计场景吗？用的是怎样的集合类型呢？</p>
<h3 id="解答-7"><a href="#解答-7" class="headerlink" title="解答"></a>解答</h3><p>使用Sorted Set可以实现统计一段时间内的在线用户数：用户上线时使用zadd online_users $timestamp $user_id把用户添加到Sorted Set中，使用zcount online_users $start_timestamp $end_timestamp就可以得出指定时间段内的在线用户数。</p>
<p>如果key是以天划分的，还可以执行zinterstore online_users_tmp 2 online_users_{date1} online_users_{date2} aggregate max，把结果存储到online_users_tmp中，然后通过zrange online_users_tmp 0 -1 withscores就可以得到这2天都在线过的用户，并且score就是这些用户最近一次的上线时间。</p>
<p>还有一个有意思的方式，使用Set记录数据，再使用zunionstore命令求并集。例如sadd user1 apple orange banana、sadd user2 apple banana peach记录2个用户喜欢的水果，使用zunionstore fruits_union 2 user1 user2把结果存储到fruits_union这个key中，zrange fruits_union 0 -1 withscores可以得出每种水果被喜欢的次数。</p>
<p>使用HyperLogLog计算UV时，补充一点，还可以使用pfcount page1:uv page2:uv page3:uv或pfmerge page_union:uv page1:uv page2:uv page3:uv得出3个页面的UV总和。</p>
<p>另外，需要指出老师文章描述不严谨的地方：“Set数据类型，使用SUNIONSTORE、SDIFFSTORE、SINTERSTORE做并集、差集、交集时，选择一个从库进行聚合计算”。这3个命令都会在Redis中生成一个新key，而从库默认是readonly不可写的，所以这些命令只能在主库使用。想在从库上操作，可以使用SUNION、SDIFF、SINTER，这些命令可以计算出结果，但不会生成新key。</p>
<p>最后需要提醒一下：</p>
<p>1、如果是在集群模式使用多个key聚合计算的命令，一定要注意，因为这些key可能分布在不同的实例上，多个实例之间是无法做聚合运算的，这样操作可能会直接报错或者得到的结果是错误的！</p>
<p>2、当数据量非常大时，使用这些统计命令，因为复杂度较高，可能会有阻塞Redis的风险，建议把这些统计数据与在线业务数据拆分开，实例单独部署，防止在做统计操作时影响到在线业务。</p>
<h2 id="GEO"><a href="#GEO" class="headerlink" title="GEO"></a>GEO</h2><h3 id="总结1-10"><a href="#总结1-10" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我们学习了 Redis 的扩展数据类型 GEO。GEO 可以记录经纬度形式的地理位置信息，被广泛地应用在 LBS 服务中。GEO 本身并没有设计新的底层数据结构，而是直接使用了 Sorted Set 集合类型。</p>
<p>GEO 类型使用 GeoHash 编码方法实现了经纬度到 Sorted Set 中元素权重分数的转换，这其中的两个关键机制就是对二维地图做区间划分，以及对区间进行编码。一组经纬度落在某个区间后，就用区间的编码值来表示，并把编码值作为 Sorted Set 元素的权重分数。这样一来，我们就可以把经纬度保存到 Sorted Set 中，利用 Sorted Set 提供的“按权重进行有序范围查找”的特性，实现 LBS 服务中频繁使用的“搜索附近”的需求。</p>
<p>GEO 属于 Redis 提供的扩展数据类型。扩展数据类型有两种实现途径：一种是基于现有的数据类型，通过数据编码或是实现新的操作的方式，来实现扩展数据类型，例如基于 Sorted Set 和 GeoHash 编码实现 GEO，以及基于 String 和位操作实现 Bitmap；另一种就是开发自定义的数据类型，具体的操作是增加新数据类型的定义，实现创建和释放函数，实现新数据类型支持的命令操作，建议你尝试着把今天学到的内容灵活地应用到你的工作场景中。</p>
<h3 id="总结2-9"><a href="#总结2-9" class="headerlink" title="总结2"></a>总结2</h3><p>1，作者讲了什么？<br>Redis的三种扩展数据类型之一：GEO，一种可以实现LBS服务的数据结构</p>
<p>2，作者是怎么把这事给讲明白的？<br>1，提出一个真问题：打车软件是怎么基于位置提供服务的<br>2，通过GEO原理讲解，说明GEO为什么可以</p>
<p>3，作者为了把这事给讲清楚，讲了那些要点？有哪些亮点？<br>1，亮点1：GEO的原理，这个是我之前所不知道的，学完后对GEO有了一些认知<br>2，亮点2：Redis居然支持自定义数据存储结构，这打开了我的眼界<br>3，要点1：GEO的底层实现，是sortSet，元素是车辆信息，权重是车辆经纬度转换过来的float值<br>4，要点2：GEOHash编码，基本原理“二分区间，区间编码”（二分法的应用，将一个值编码成N位的二进制值）<br>5，要点3：GEO使用GEOHash编码后，将经纬度，按照纬奇经偶位分别填充组合，得到一个车辆的经纬度编码值<br>6，要点4：GEOHash编码实现的效果是将一个空间分割成为一个个方块，可以实现LBS服务（但编码值相近，不一定位置相近）</p>
<p>4，对于作者所讲，我有哪些发散性思考？<br>①：这一篇讲了通过Redis的GEO数据类型可以实现LBS服务，让我体验到了算法的巧妙应用带来的巨大便利（这应是科技让生活更美好的实例）。<br>②：不过，我觉得最大的惊喜在于作者介绍了如何自定义一种新的数据类型，虽然我尚未掌握开发新数据类型的能力。<br>③：通过作者的讲解，拓宽了我了见识，这让我体验到了购买专栏的价值（如果都是搜索引擎能解决的事，何必买专栏）。<br>④：作者细致的讲解开发过程，也让我对Redis的数据结构，RedisObjecti有了进一步认识（面向对象等）</p>
<p>5，在未来的那些场景中，我能够使用它？<br>redis采用的GEOHash算法，貌似可以协助我们处理分省的一些业务</p>
<h3 id="问题-8"><a href="#问题-8" class="headerlink" title="问题"></a>问题</h3><p>我想请你来聊一聊，你在日常的实践过程中，还用过 Redis 的其他数据类型吗？</p>
<h3 id="解答-8"><a href="#解答-8" class="headerlink" title="解答"></a>解答</h3><p>Redis也可以使用List数据类型当做队列使用，一个客户端使用rpush生产数据到Redis中，另一个客户端使用lpop取出数据进行消费，非常方便。但要注意的是，使用List当做队列，缺点是没有ack机制和不支持多个消费者。没有ack机制会导致从Redis中取出的数据后，如果客户端处理失败了，取出的这个数据相当于丢失了，无法重新消费。所以使用List用作队列适合于对于丢失数据不敏感的业务场景，但它的优点是，因为都是内存操作，所以非常快和轻量。</p>
<p>而Redis提供的PubSub，可以支持多个消费者进行消费，生产者发布一条消息，多个消费者同时订阅消费。但是它的缺点是，如果任意一个消费者挂了，等恢复过来后，在这期间的生产者的数据就丢失了。PubSub只把数据发给在线的消费者，消费者一旦下线，就会丢弃数据。另一个缺点是，PubSub中的数据不支持数据持久化，当Redis宕机恢复后，其他类型的数据都可以从RDB和AOF中恢复回来，但PubSub不行，它就是简单的基于内存的多播机制。</p>
<p>之后Redis 5.0推出了Stream数据结构，它借鉴了Kafka的设计思想，弥补了List和PubSub的不足。Stream类型数据可以持久化、支持ack机制、支持多个消费者、支持回溯消费，基本上实现了队列中间件大部分功能，比List和PubSub更可靠。</p>
<p>另一个经常使用的是基于Redis实现的布隆过滤器，其底层实现利用的是String数据结构和位运算，可以解决业务层缓存穿透的问题，而且内存占用非常小，操作非常高效。</p>
<h2 id="时间序列数据"><a href="#时间序列数据" class="headerlink" title="时间序列数据"></a>时间序列数据</h2><h3 id="总结1-11"><a href="#总结1-11" class="headerlink" title="总结1"></a>总结1</h3><p>在这节课，我们一起学习了如何用 Redis 保存时间序列数据。时间序列数据的写入特点是要能快速写入，而查询的特点有三个：</p>
<ul>
<li>点查询，根据一个时间戳，查询相应时间的数据；</li>
<li>范围查询，查询起始和截止时间戳范围内的数据；</li>
<li>聚合计算，针对起始和截止时间戳范围内的所有数据进行计算，例如求最大 / 最小值，求均值等。</li>
</ul>
<p>关于快速写入的要求，Redis 的高性能写特性足以应对了；而针对多样化的查询需求，Redis 提供了两种方案。</p>
<p>第一种方案是，组合使用 Redis 内置的 Hash 和 Sorted Set 类型，把数据同时保存在 Hash 集合和 Sorted Set 集合中。这种方案既可以利用 Hash 类型实现对单键的快速查询，还能利用 Sorted Set 实现对范围查询的高效支持，一下子满足了时间序列数据的两大查询需求。</p>
<p>不过，第一种方案也有两个不足：一个是，在执行聚合计算时，我们需要把数据读取到客户端再进行聚合，当有大量数据要聚合时，数据传输开销大；另一个是，所有的数据会在两个数据类型中各保存一份，内存开销不小。不过，我们可以通过设置适当的数据过期时间，释放内存，减小内存压力。</p>
<p>我们学习的第二种实现方案是使用 RedisTimeSeries 模块。这是专门为存取时间序列数据而设计的扩展模块。和第一种方案相比，RedisTimeSeries 能支持直接在 Redis 实例上进行多种数据聚合计算，避免了大量数据在实例和客户端间传输。不过，RedisTimeSeries 的底层数据结构使用了链表，它的范围查询的复杂度是 O(N) 级别的，同时，它的 TS.GET 查询只能返回最新的数据，没有办法像第一种方案的 Hash 类型一样，可以返回任一时间点的数据。</p>
<p>所以，组合使用 Hash 和 Sorted Set，或者使用 RedisTimeSeries，在支持时间序列数据存取上各有优劣势。我给你的建议是：</p>
<ul>
<li>如果你的部署环境中网络带宽高、Redis 实例内存大，可以优先考虑第一种方案；</li>
<li>如果你的部署环境中网络、内存资源有限，而且数据量大，聚合计算频繁，需要按数据集合属性查询，可以优先考虑第二种方案。</li>
</ul>
<h3 id="总结2-10"><a href="#总结2-10" class="headerlink" title="总结2"></a>总结2</h3><p>1，作者讲了什么？<br>根据时间序列数据的特点，选择合适的存储方案</p>
<p>2，作者是怎么把这事给讲明白的？<br>结合具体场景，探讨解决方案<br>1，介绍需求背景，用户行为，设备监控数据分析<br>2，介绍数据特点，时间线连续，没有逻辑关系，数据量大<br>3，介绍操作场景，插入多且快，常单点查询，分组统计聚合</p>
<p>3，作者为了把这事给讲清楚，讲了那些要点？有哪些亮点？<br>1，亮点1：先讲清楚需求背景，从实际问题出发，推演出存储时间序列数据适合使用sort set 和hash解决点查询和范围查询的需求<br>2，要点1：同时写入sort set和hash 两种数据类型的存储，需要使用原子操作，可以借助MULTI和 EXEC命令<br>3，要点2：大数据量的聚合统计，会非常消耗网络带宽，所以可以使用RedisTimeSeries模块处理</p>
<p>4，对于作者所讲，我有哪些发散性思考？</p>
<p>5，在未来的那些场景中，我能够使用它？</p>
<p>6，留言区的收获</p>
<h3 id="问题-9"><a href="#问题-9" class="headerlink" title="问题"></a>问题</h3><p>在这节课上，我提到，我们可以使用 Sorted Set 保存时间序列数据，把时间戳作为 score，把实际的数据作为 member，你觉得这样保存数据有没有潜在的风险？另外，如果你是 Redis 的开发维护者，你会把聚合计算也设计为 Sorted Set 的一个内在功能吗？</p>
<h3 id="解答-9"><a href="#解答-9" class="headerlink" title="解答"></a>解答</h3><p>使用Sorted Set保存时序数据，把时间戳作为score，把实际的数据作为member，有什么潜在的风险？</p>
<p>我目前能想到的风险是，如果对某一个对象的时序数据记录很频繁的话，那么这个key很容易变成一个bigkey，在key过期释放内存时可能引发阻塞风险。所以不能把这个对象的所有时序数据存储在一个key上，而是需要拆分存储，例如可以按天/周/月拆分（根据具体查询需求来定）。当然，拆分key的缺点是，在查询时，可能需要客户端查询多个key后再做聚合才能得到结果。</p>
<p>如果你是Redis的开发维护者，你会把聚合计算也设计为Sorted Set的内在功能吗？</p>
<p>不会。因为聚合计算是CPU密集型任务，Redis在处理请求时是单线程的，也就是它在做聚合计算时无法利用到多核CPU来提升计算速度，如果计算量太大，这也会导致Redis的响应延迟变长，影响Redis的性能。Redis的定位就是高性能的内存数据库，要求访问速度极快。所以对于时序数据的存储和聚合计算，我觉得更好的方式是交给时序数据库去做，时序数据库会针对这些存储和计算的场景做针对性优化。</p>
<p>另外，在使用MULTI和EXEC命令时，建议客户端使用pipeline，当使用pipeline时，客户端会把命令一次性批量发送给服务端，然后让服务端执行，这样可以减少客户端和服务端的来回网络IO次数，提升访问性能。</p>
<h2 id="redis消息队列"><a href="#redis消息队列" class="headerlink" title="redis消息队列"></a>redis消息队列</h2><h3 id="总结1-12"><a href="#总结1-12" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我们学习了分布式系统组件使用消息队列时的三大需求：消息保序、重复消息处理和消息可靠性保证，这三大需求可以进一步转换为对消息队列的三大要求：消息数据有序存取，消息数据具有全局唯一编号，以及消息数据在消费完成后被删除。</p>
<p>我画了一张表格，汇总了用 List 和 Streams 实现消息队列的特点和区别。当然，在实践的过程中，你也可以根据新的积累，进一步补充和完善这张表。<br><img src="/images/redis/list-01.png" alt="img.png"></p>
<p>其实，关于 Redis 是否适合做消息队列，业界一直是有争论的。很多人认为，要使用消息队列，就应该采用 Kafka、RabbitMQ 这些专门面向消息队列场景的软件，而 Redis 更加适合做缓存。</p>
<p>根据这些年做 Redis 研发工作的经验，我的看法是：Redis 是一个非常轻量级的键值数据库，部署一个 Redis 实例就是启动一个进程，部署 Redis 集群，也就是部署多个 Redis 实例。而 Kafka、RabbitMQ 部署时，涉及额外的组件，例如 Kafka 的运行就需要再部署 ZooKeeper。相比 Redis 来说，Kafka 和 RabbitMQ 一般被认为是重量级的消息队列。</p>
<p>所以，关于是否用 Redis 做消息队列的问题，不能一概而论，我们需要考虑业务层面的数据体量，以及对性能、可靠性、可扩展性的需求。如果分布式系统中的组件消息通信量不大，那么，Redis 只需要使用有限的内存空间就能满足消息存储的需求，而且，Redis 的高性能特性能支持快速的消息读写，不失为消息队列的一个好的解决方案。</p>
<h3 id="总结2-11"><a href="#总结2-11" class="headerlink" title="总结2"></a>总结2</h3><p>1，作者讲了什么？<br>如何使用redis实现消息队列的需求</p>
<p>2，作者是怎么把这事给说明白的？<br>1，将一个问题拆解为两个具体的小问题：消息队列应具备哪些特性，Redis能否实现这些特性</p>
<p>3，为了讲明白，作者讲了哪些要点？，有哪些亮点？<br>1，亮点1：作者首先将一个相对模糊的问题，拆解成为两个问题更精确的问题<br>2，要点1：消息队列读取需求有三点：消息保存，消息唯一，消息可靠性<br>3，要点2：消息还要确保有序，削峰平谷，消费性能有弹性<br>4，要点3：Redis的list和5.0后的Stream数据结构可以满足<br>5，要点4：消息队列的三大要求：消息数据有序存取，消息数据具有全局唯一编号，消息数据在消费完成后被删除</p>
<p>4，对于作者所讲，我有哪些发散性思考？<br>解决问题的前提是搞清楚问题是什么<br>开篇：“Redis适合做消息队列吗”？对于这样的问题，我本能的就会直接想：“用Redis做消息队列？应该可以吧，很多资料上都这么说的”。<br>这样的回答，证明我并没有思考，只是陈述了我所知道的一点东西。我总是渴求快速有个答案，没有在意答案是否正确，更没有思考该如何回答问题。<br>虽然我总会说要想解决问题，首先要搞清楚问题是什么。这个句话似乎有点白痴，自己遇到的问题，这个问题不就它本身吗？怎么还会需要搞清楚呢？<br>其实不然，我们遇到的往往未必是问题的真身，而只是问题的表面现象或衍生出的问题。其实一个好问题的本身，就是一个好答案，而一个好问题胜过无数好答案。<br>那什么才是真正的解答问题？这需要先回答如何回答这个问题，也就是要先搞清楚要从哪些方面解释问题，而不是铺陈信息。<br>老师开篇对问题的回答方法，就是个非常好的范例<br>他是怎么解答的呢？<br>他并没有立即回答行或不行（这是我们最常有的反应），而是向后退了一步，问这个问题真正的问题是啥呢？消息队列存取消息需要哪些特性？Redis如何实现这些特性？<br>这就将一个相对模糊的问题拆解为两个较清晰的小问题，分别作答，最终得到一篇很好的文章</p>
<p>5，将来在哪些场景里，我能够使用它？</p>
<p>6，留言区收获<br>1，Redis是否可以作为消息队列？如果可以，哪些场景适合使用Redis，而不是消息中间件？<br>答：这个问题应当进一步拆分为：消息队列读写消息有哪些需求和Redis如何实现这些需求。<br>首先消息队列的消息读写有三大需求：消息读写的有序性，消息数据的唯一性，消息消费后数据删除。<br>针对这三大需求，Redis的List和5.0后的Stream数据结构，可以支持。<br>对于List，POP和PUSH命令，还有阻塞式的，备份式的。<br>对于Stream，是Redis5.0后提供新的数据结构，专门用户消息队列，他可以生成全局唯一id，还有能够创建消费者组，多个消费者同时消费<br>Stream类型，使用了应答机制，消费者消费完毕后会给Streams发送XACK命令，否则消息将会保存Streams的内部队列中，使用XPENDING命令可以查看<br>就Redis的相关数据结构而言，是可以作为消息队列的。但也要注意使用它的场景，虽然它性能很高，部署维护也轻量，但缺点是无法严格保证数据的完整性。<br>他适用于消息量并不是非常巨大，数据不是非常重要，从而不必引入其他消息组件的场景，如发短信，站内信</p>
<p>2，如果一个生产者发送给消息队列的消息，需要被多个消费者进行读取和处理，Redis的什么数据类型可以解决这个问题？<br>答：如果要使用Redis实现这个需求，Redis的Streams数据类型可以实现。<br>Streams可以使用XADD向队列中写入消息，XGOURP创建消费者组，XREADGROUP已消费者组形式消费消息，XACK向消息队列确认处理完成，XPENDING查询已消费待确认的消息</p>
<p>3，如果使用Redis作为消息队列，有哪些事项需要注意？<br>答：消息的可靠性，重点需要关注的是如何保证不丢消息</p>
<p>4，在使用消息队列时，如何保证不丢消息？<br>答：消息丢失可能会发生在三个环节：生产者发布消息，消息者消费消息，消息中间件丢失消息<br>生产者丢失消息一般通过重试机制和全局唯一id来解决，<br>消费者消费消息一般通过ack方式问询上报消费进度，<br>消息中间件宕机，一般通过主从备份，分布式集群来解决</p>
<h3 id="问题1-1"><a href="#问题1-1" class="headerlink" title="问题1"></a>问题1</h3><p>按照惯例，我给你提个小问题。如果一个生产者发送给消息队列的消息，需要被多个消费者进行读取和处理（例如，一个消息是一条从业务系统采集的数据，既要被消费者 1 读取进行实时计算，也要被消费者 2 读取并留存到分布式文件系统 HDFS 中，以便后续进行历史查询），你会使用 Redis 的什么数据类型来解决这个问题呢？</p>
<h3 id="解答1-1"><a href="#解答1-1" class="headerlink" title="解答1"></a>解答1</h3><p>如果一个生产者发送给消息队列的消息，需要被多个消费者进行读取和处理，你会使用Redis的什么数据类型来解决这个问题？</p>
<p>这种情况下，只能使用Streams数据类型来解决。使用Streams数据类型，创建多个消费者组，就可以实现同时消费生产者的数据。每个消费者组内可以再挂多个消费者分担读取消息进行消费，消费完成后，各自向Redis发送XACK，标记自己的消费组已经消费到了哪个位置，而且消费组之间互不影响。</p>
<p>另外，老师在介绍使用List用作队列时，为了保证消息可靠性，使用BRPOPLPUSH命令把消息取出的同时，还把消息插入到备份队列中，从而防止消费者故障导致消息丢失。</p>
<p>这种情况下，还需要额外做一些工作，也就是维护这个备份队列：每次执行BRPOPLPUSH命令后，因为都会把消息插入一份到备份队列中，所以当消费者成功消费取出的消息后，最好把备份队列中的消息删除，防止备份队列存储过多无用的数据，导致内存浪费。</p>
<p>这篇文章主要是讲消息队列的使用，借这个机会，也顺便总结一下使用消息队列时的注意点：</p>
<p>在使用消息队列时，重点需要关注的是如何保证不丢消息？</p>
<p>那么下面就来分析一下，哪些情况下，会丢消息，以及如何解决？</p>
<p>1、生产者在发布消息时异常：</p>
<p>a) 网络故障或其他问题导致发布失败（直接返回错误，消息根本没发出去）<br>b) 网络抖动导致发布超时（可能发送数据包成功，但读取响应结果超时了，不知道结果如何）</p>
<p>情况a还好，消息根本没发出去，那么重新发一次就好了。但是情况b没办法知道到底有没有发布成功，所以也只能再发一次。所以这两种情况，生产者都需要重新发布消息，直到成功为止（一般设定一个最大重试次数，超过最大次数依旧失败的需要报警处理）。这就会导致消费者可能会收到重复消息的问题，所以消费者需要保证在收到重复消息时，依旧能保证业务的正确性（设计幂等逻辑），一般需要根据具体业务来做，例如使用消息的唯一ID，或者版本号配合业务逻辑来处理。</p>
<p>2、消费者在处理消息时异常：</p>
<p>也就是消费者把消息拿出来了，但是还没处理完，消费者就挂了。这种情况，需要消费者恢复时，依旧能处理之前没有消费成功的消息。使用List当作队列时，也就是利用老师文章所讲的备份队列来保证，代价是增加了维护这个备份队列的成本。而Streams则是采用ack的方式，消费成功后告知中间件，这种方式处理起来更优雅，成熟的队列中间件例如RabbitMQ、Kafka都是采用这种方式来保证消费者不丢消息的。</p>
<p>3、消息队列中间件丢失消息</p>
<p>上面2个层面都比较好处理，只要客户端和服务端配合好，就能保证生产者和消费者都不丢消息。但是，如果消息队列中间件本身就不可靠，也有可能会丢失消息，毕竟生产者和消费这都依赖它，如果它不可靠，那么生产者和消费者无论怎么做，都无法保证数据不丢失。</p>
<p>a) 在用Redis当作队列或存储数据时，是有可能丢失数据的：一个场景是，如果打开AOF并且是每秒写盘，因为这个写盘过程是异步的，Redis宕机时会丢失1秒的数据。而如果AOF改为同步写盘，那么写入性能会下降。另一个场景是，如果采用主从集群，如果写入量比较大，从库同步存在延迟，此时进行主从切换，也存在丢失数据的可能（从库还未同步完成主库发来的数据就被提成主库）。总的来说，Redis不保证严格的数据完整性和主从切换时的一致性。我们在使用Redis时需要注意。</p>
<p>b) 而采用RabbitMQ和Kafka这些专业的队列中间件时，就没有这个问题了。这些组件一般是部署一个集群，生产者在发布消息时，队列中间件一般会采用写多个节点+预写磁盘的方式保证消息的完整性，即便其中一个节点挂了，也能保证集群的数据不丢失。当然，为了做到这些，方案肯定比Redis设计的要复杂（毕竟是专们针对队列场景设计的）。</p>
<p>综上，Redis可以用作队列，而且性能很高，部署维护也很轻量，但缺点是无法严格保数据的完整性（个人认为这就是业界有争议要不要使用Redis当作队列的地方）。而使用专业的队列中间件，可以严格保证数据的完整性，但缺点是，部署维护成本高，用起来比较重。</p>
<p>所以我们需要根据具体情况进行选择，如果对于丢数据不敏感的业务，例如发短信、发通知的场景，可以采用Redis作队列。如果是金融相关的业务场景，例如交易、支付这类，建议还是使用专业的队列中间件。</p>
<h2 id="异步机制：如何避免单线程模型的阻塞？"><a href="#异步机制：如何避免单线程模型的阻塞？" class="headerlink" title="异步机制：如何避免单线程模型的阻塞？"></a>异步机制：如何避免单线程模型的阻塞？</h2><h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结 1"></a>总结 1</h3><p>这节课，我们学习了 Redis 实例运行时的 4 大类交互对象：客户端、磁盘、主从库实例、切片集群实例。基于这 4 大类交互对象，我们梳理了会导致 Redis 性能受损的 5 大阻塞点，包括集合全量查询和聚合操作、bigkey 删除、清空数据库、AOF 日志同步写，以及从库加载 RDB 文件。</p>
<p>在这 5 大阻塞点中，bigkey 删除、清空数据库、AOF 日志同步写不属于关键路径操作，可以使用异步子线程机制来完成。Redis 在运行时会创建三个子线程，主线程会通过一个任务队列和三个子线程进行交互。子线程会根据任务的具体类型，来执行相应的异步操作。</p>
<p>不过，异步删除操作是 Redis 4.0 以后才有的功能，如果你使用的是 4.0 之前的版本，当你遇到 bigkey 删除时，我给你个小建议：先使用集合类型提供的 SCAN 命令读取数据，然后再进行删除。因为用 SCAN 命令可以每次只读取一部分数据并进行删除，这样可以避免一次性删除大量 key 给主线程带来的阻塞。</p>
<p>例如，对于 Hash 类型的 bigkey 删除，你可以使用 HSCAN 命令，每次从 Hash 集合中获取一部分键值对（例如 200 个），再使用 HDEL 删除这些键值对，这样就可以把删除压力分摊到多次操作中，那么，每次删除操作的耗时就不会太长，也就不会阻塞主线程了。</p>
<p>最后，我想再提一下，集合全量查询和聚合操作、从库加载 RDB 文件是在关键路径上，无法使用异步操作来完成。对于这两个阻塞点，我也给你两个小建议。</p>
<ul>
<li>集合全量查询和聚合操作：可以使用 SCAN 命令，分批读取数据，再在客户端进行聚合计算；</li>
<li>从库加载 RDB 文件：把主库的数据量大小控制在 2~4GB 左右，以保证 RDB 文件能以较快的速度加载。</li>
</ul>
<h3 id="问题1-2"><a href="#问题1-2" class="headerlink" title="问题1"></a>问题1</h3><p>按照惯例，我给你提一个小问题：我们今天学习了关键路径上的操作，你觉得，Redis 的写操作（例如 SET、HSET、SADD 等）是在关键路径上吗？</p>
<h3 id="解答1-2"><a href="#解答1-2" class="headerlink" title="解答1"></a>解答1</h3><p>Redis的写操作（例如SET，HSET，SADD等）是在关键路径上吗？</p>
<p>我觉得这需要客户端根据业务需要来区分：</p>
<p>1、如果客户端依赖操作返回值的不同，进而需要处理不同的业务逻辑，那么HSET和SADD操作算关键路径，而SET操作不算关键路径。因为HSET和SADD操作，如果field或member不存在时，Redis结果会返回1，否则返回0。而SET操作返回的结果都是OK，客户端不需要关心结果有什么不同。</p>
<p>2、如果客户端不关心返回值，只关心数据是否写入成功，那么SET/HSET/SADD不算关键路径，多次执行这些命令都是幂等的，这种情况下可以放到异步线程中执行。</p>
<p>3、但是有种例外情况，如果Redis设置了maxmemory，但是却没有设置淘汰策略，这三个操作也都算关键路径。因为如果Redis内存超过了maxmemory，再写入数据时，Redis返回的结果是OOM error，这种情况下，客户端需要感知有错误发生才行。</p>
<p>另外，我查阅了lazy-free相关的源码，发现有很多细节需要补充下：</p>
<p>1、lazy-free是4.0新增的功能，但是默认是关闭的，需要手动开启。</p>
<p>2、手动开启lazy-free时，有4个选项可以控制，分别对应不同场景下，要不要开启异步释放内存机制：<br>a) lazyfree-lazy-expire：key在过期删除时尝试异步释放内存<br>b) lazyfree-lazy-eviction：内存达到maxmemory并设置了淘汰策略时尝试异步释放内存<br>c) lazyfree-lazy-server-del：执行RENAME/MOVE等命令或需要覆盖一个key时，删除旧key尝试异步释放内存<br>d) replica-lazy-flush：主从全量同步，从库清空数据库时异步释放内存</p>
<p>3、即使开启了lazy-free，如果直接使用DEL命令还是会同步删除key，只有使用UNLINK命令才会可能异步删除key。</p>
<p>4、这也是最关键的一点，上面提到开启lazy-free的场景，除了replica-lazy-flush之外，其他情况都只是<em>可能</em>去异步释放key的内存，并不是每次必定异步释放内存的。</p>
<p>开启lazy-free后，Redis在释放一个key的内存时，首先会评估代价，如果释放内存的代价很小，那么就直接在主线程中操作了，没必要放到异步线程中执行（不同线程传递数据也会有性能消耗）。</p>
<p>什么情况才会真正异步释放内存？这和key的类型、编码方式、元素数量都有关系（详细可参考源码中的lazyfreeGetFreeEffort函数）：</p>
<p>a) 当Hash/Set底层采用哈希表存储（非ziplist/int编码存储）时，并且元素数量超过64个<br>b) 当ZSet底层采用跳表存储（非ziplist编码存储）时，并且元素数量超过64个<br>c) 当List链表节点数量超过64个（注意，不是元素数量，而是链表节点的数量，List的实现是在每个节点包含了若干个元素的数据，这些元素采用ziplist存储）</p>
<p>只有以上这些情况，在删除key释放内存时，才会真正放到异步线程中执行，其他情况一律还是在主线程操作。</p>
<p>也就是说String（不管内存占用多大）、List（少量元素）、Set（int编码存储）、Hash/ZSet（ziplist编码存储）这些情况下的key在释放内存时，依旧在主线程中操作。</p>
<p>可见，即使开启了lazy-free，String类型的bigkey，在删除时依旧有阻塞主线程的风险。所以，即便Redis提供了lazy-free，我建议还是尽量不要在Redis中存储bigkey。</p>
<p>个人理解Redis在设计评估释放内存的代价时，不是看key的内存占用有多少，而是关注释放内存时的工作量有多大。从上面分析基本能看出，如果需要释放的内存是连续的，Redis作者认为释放内存的代价比较低，就放在主线程做。如果释放的内存不连续（大量指针类型的数据），这个代价就比较高，所以才会放在异步线程中去执行。</p>
<p>如果我的理解有偏差，还请老师和大家指出！</p>
<h2 id="为什么CPU结构也会影响Redis的性能？"><a href="#为什么CPU结构也会影响Redis的性能？" class="headerlink" title="为什么CPU结构也会影响Redis的性能？"></a>为什么CPU结构也会影响Redis的性能？</h2><h3 id="总结1-13"><a href="#总结1-13" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我们学习了 CPU 架构对 Redis 性能的影响。首先，我们了解了目前主流的多核 CPU 架构，以及 NUMA 架构。</p>
<p>在多核 CPU 架构下，Redis 如果在不同的核上运行，就需要频繁地进行上下文切换，这个过程会增加 Redis 的执行时间，客户端也会观察到较高的尾延迟了。所以，建议你在 Redis 运行时，把实例和某个核绑定，这样，就能重复利用核上的 L1、L2 缓存，可以降低响应延迟。</p>
<p>为了提升 Redis 的网络性能，我们有时还会把网络中断处理程序和 CPU 核绑定。在这种情况下，如果服务器使用的是 NUMA 架构，Redis 实例一旦被调度到和中断处理程序不在同一个 CPU Socket，就要跨 CPU Socket 访问网络数据，这就会降低 Redis 的性能。所以，我建议你把 Redis 实例和网络中断处理程序绑在同一个 CPU Socket 下的不同核上，这样可以提升 Redis 的运行性能。</p>
<p>虽然绑核可以帮助 Redis 降低请求执行时间，但是，除了主线程，Redis 还有用于 RDB 和 AOF 重写的子进程，以及 4.0 版本之后提供的用于惰性删除的后台线程。当 Redis 实例和一个逻辑核绑定后，这些子进程和后台线程会和主线程竞争 CPU 资源，也会对 Redis 性能造成影响。所以，我给了你两个建议：</p>
<ul>
<li>如果你不想修改 Redis 代码，可以把按一个 Redis 实例一个物理核方式进行绑定，这样，Redis 的主线程、子进程和后台线程可以共享使用一个物理核上的两个逻辑核。</li>
<li>如果你很熟悉 Redis 的源码，就可以在源码中增加绑核操作，把子进程和后台线程绑到不同的核上，这样可以避免对主线程的 CPU 资源竞争。不过，如果你不熟悉 Redis 源码，也不用太担心，Redis 6.0 出来后，可以支持 CPU 核绑定的配置操作了，我将在第 38 讲中向你介绍 Redis 6.0 的最新特性。</li>
</ul>
<p>Redis 的低延迟是我们永恒的追求目标，而多核 CPU 和 NUMA 架构已经成为了目前服务器的主流配置，所以，希望你能掌握绑核优化方案，并把它应用到实践中。</p>
<h3 id="总结2-12"><a href="#总结2-12" class="headerlink" title="总结2"></a>总结2</h3><p>1.作者讲了什么？<br>在多核CPU架构和NUMA架构下，如何对redis进行优化配置<br>2.作者是怎么把这件事将明白的？<br>1，讲解了主流的CPU架构，主要有多核CPU架构和NUMA架构两个架构<br>多核CPU架构： 多个物理核，各物理核使用私有的1、2级缓存，共享3级缓存。物理核可包含2个超线程，称为逻辑核<br>NUMA架构： 一个服务器上多个cpu，称为CPU Socket，每个cpu socker存在多个物理核。每个socket通过总线连接，并且有用私有的内存空间<br>3.为了讲明白，作者讲了哪些要点，哪些亮点？<br>1、亮点：将主流的CPU架构进行剖析，使人更好理解cpu的原理，有助于后续redis性能的优化<br>2、要点：cpu架构：一个cpu一般拥有多个物理核，每个物理核都拥有私有的一级缓存，二级缓存。三级缓存是各物理核共享的缓存空间。而物理核又可以分为多个超线程，称为逻辑核，同一个物理核的逻辑核会共享使用 L1、L2 缓存。<br>3、要点：一级缓存和二级缓存访问延迟不超过10纳秒，但空间很小，只是KB单位。而应用程序访问内存延迟是百纳秒级别，基本上是一二级缓存的10倍<br>4、要点：不同的物理核还会共享一个共同的三级缓存，三级缓存空间比较多，为几到几十MB，当 L1、L2 缓存中没有数据缓存时，可以访问 L3，尽可能避免访问内存。<br>5、要点：多核CPU运行redis实例，会导致context switch，导致增加延迟，可以通过taskset 命令把redis进程绑定到某个cup物理核上。<br>6、要点：NUMA架构运行redis实例，如果网络中断程序和redis实例运行在不同的socket上，就需要跨 CPU Socket 访问内存，这个过程会花费较多时间。<br>7、要点：绑核的风险和解决方案：<br>一个 Redis 实例对应绑一个物理核 ： 将redis服务绑定到一个物理核上，而不是一个逻辑核上，如 taskset -c 0,12 ./redis-server<br>优化 Redis 源码。<br>4.对于作者所讲的，我有哪些发散性思考？<br>给自己提了几个问题：<br>1，在多核CPU架构和NUMA架构，那个对于redis来说性能比较好<br>2，如何设置网络中断处理和redis绑定设置在同个socket上呢？</p>
<p>5.将来在哪些场景里，我能够使用它？</p>
<p>6.留言区收获<br>如果redis实例中内存不足以使用时，会用到swap那会怎么样？（答案来自@kaito 大佬）<br>因为Redis要求性能非常高，如果从Swap中读取数据，此时Redis的性能就会急剧下降，延迟变大。</p>
<h3 id="问题1-3"><a href="#问题1-3" class="headerlink" title="问题1"></a>问题1</h3><p>在一台有 2 个 CPU Socket（每个 Socket 8 个物理核）的服务器上，我们部署了有 8 个实例的 Redis 切片集群（8 个实例都为主节点，没有主备关系），现在有两个方案：</p>
<ol>
<li>在同一个 CPU Socket 上运行 8 个实例，并和 8 个 CPU 核绑定；</li>
<li>在 2 个 CPU Socket 上各运行 4 个实例，并和相应 Socket 上的核绑定。</li>
</ol>
<p>如果不考虑网络数据读取的影响，你会选择哪个方案呢？</p>
<h3 id="解答1-3"><a href="#解答1-3" class="headerlink" title="解答1"></a>解答1</h3><p>这篇文章收获很大！对于CPU结构和如何绑核有了进一步了解。其实在NUMA架构下，不光对于CPU的绑核需要注意，对于内存的使用，也有很多注意点，下面回答课后问题，也会提到NUMA架构下内存方面的注意事项。</p>
<p>在一台有2个CPU Socket（每个Socket 8个物理核）的服务器上，我们部署了有8个实例的Redis切片集群（8个实例都为主节点，没有主备关系），采用哪种方案绑核最佳？</p>
<p>我更倾向于的方案是：在两个CPU Socket上各运行4个实例，并和相应Socket上的核绑定。这么做的原因主要从L3 Cache的命中率、内存利用率、避免使用到Swap这三个方面考虑：</p>
<p>1、由于CPU Socket1和2分别有自己的L3 Cache，如果把所有实例都绑定在同一个CPU Socket上，相当于这些实例共用这一个L3 Cache，另一个CPU Socket的L3 Cache浪费了。这些实例共用一个L3 Cache，会导致Cache中的数据频繁被替换，访问命中率下降，之后只能从内存中读取数据，这会增加访问的延迟。而8个实例分别绑定CPU Socket，可以充分使用2个L3 Cache，提高L3 Cache的命中率，减少从内存读取数据的开销，从而降低延迟。</p>
<p>2、如果这些实例都绑定在一个CPU Socket，由于采用NUMA架构的原因，所有实例会优先使用这一个节点的内存，当这个节点内存不足时，再经过总线去申请另一个CPU Socket下的内存，此时也会增加延迟。而8个实例分别使用2个CPU Socket，各自在访问内存时都是就近访问，延迟最低。</p>
<p>3、如果这些实例都绑定在一个CPU Socket，还有一个比较大的风险是：用到Swap的概率将会大大提高。如果这个CPU Socket对应的内存不够了，也可能不会去另一个节点申请内存（操作系统可以配置内存回收策略和Swap使用倾向：本节点回收内存/其他节点申请内存/内存数据换到Swap的倾向程度），而操作系统可能会把这个节点的一部分内存数据换到Swap上从而释放出内存给进程使用（如果没开启Swap可会导致直接OOM）。因为Redis要求性能非常高，如果从Swap中读取数据，此时Redis的性能就会急剧下降，延迟变大。所以8个实例分别绑定CPU Socket，既可以充分使用2个节点的内存，提高内存使用率，而且触发使用Swap的风险也会降低。</p>
<p>其实我们可以查一下，在NUMA架构下，也经常发生某一个节点内存不够，但其他节点内存充足的情况下，依旧使用到了Swap，进而导致软件性能急剧下降的例子。所以在运维层面，我们也需要关注NUMA架构下的内存使用情况（多个内存节点使用可能不均衡），并合理配置系统参数（内存回收策略/Swap使用倾向），尽量去避免使用到Swap。</p>
<h2 id="波动的响应延迟：如何应对变慢的Redis？（上）"><a href="#波动的响应延迟：如何应对变慢的Redis？（上）" class="headerlink" title="波动的响应延迟：如何应对变慢的Redis？（上）"></a>波动的响应延迟：如何应对变慢的Redis？（上）</h2><h3 id="总结1-14"><a href="#总结1-14" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我首先给你介绍了 Redis 性能变慢带来的重要影响，希望你能充分重视这个问题。我重点介绍了判断 Redis 变慢的方法，一个是看响应延迟，一个是看基线性能。同时，我还给了你两种排查和解决 Redis 变慢这个问题的方法：</p>
<ul>
<li>从慢查询命令开始排查，并且根据业务需求替换慢查询命令；</li>
<li>排查过期 key 的时间设置，并根据实际使用需求，设置不同的过期时间。</li>
</ul>
<p>性能诊断通常是一件困难的事，所以我们一定不能毫无目标地“乱找”。这节课给你介绍的内容，就是排查和解决 Redis 性能变慢的章法，你一定要按照章法逐一排查，这样才可能尽快地找出原因。</p>
<p>当然，要真正把 Redis 用好，除了要了解 Redis 本身的原理，还要了解和 Redis 交互的各底层系统的关键机制，包括操作系统和文件系统。通常情况下，一些难以排查的问题是 Redis 的用法或设置和底层系统的工作机制不协调导致的。下节课，我会着重给你介绍文件系统、操作系统对 Redis 性能的影响，以及相应的排查方法和解决方案。</p>
<h3 id="总结2-13"><a href="#总结2-13" class="headerlink" title="总结2"></a>总结2</h3><p>第十八课：<br>1.作者讲了什么？<br>当redis查询变慢了怎么办，如何排查，如何进行处理？<br>2.作者是怎么把这件事将明白的？<br>1、通过分析redis各组件及硬件，找出问题所在<br>3.为了讲明白，作者讲了哪些要点，哪些亮点？<br>1、亮点：通过redis-cli –intrinsic-latency 120可以得知redis的基准线。后续可以根据基准线的响应速度进行判断是否查询慢，这是我之前所不知道的判断方法<br>2、要点：基于自己对 Redis 本身的工作原理的理解，并且结合和它交互的操作系统、存储以及网络等外部系统关键机制，再借助一些辅助工具来定位原因，并制定行之有效的解决方案<br>3、要点：Redis 自身操作特性的影响</p>
<ol>
<li>慢查询命令：命令操作的复杂度有关<br>排查方法：通过 Redis 日志，或者是 latency monitor 工具，查询变慢的请求<br>解决方法：1.用其他高效命令代替。如不要使用keys查询所有key，可以使用scan进行查询，不会阻塞线程<br>2.当你需要执行排序、交集、并集操作时，可以在客户端完成，而不要用 SORT、SUNION、SINTER 这些命令，以免拖慢 Redis 实例。<br>2.过期 key 操作：redis本身的内存回收机制会造成redis操作阻塞，导致性能变慢（Redis 4.0 后可以用异步线程机制来减少阻塞影响）<br>导致原因：大批量的key同时间内过期，导致删除过期key的机制一直触发，引起redis操作阻塞<br>解决方法：对key设定过期时间时，添加一个删除的时间随机数，能避免key存在同一时间过期<br>4、要点：redis删除过期key的机制，每100毫秒对一些key进行删除。算法如下<br>1.采样 ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP 个数的 key，并将其中过期的 key 全部删除；<br>2.如果超过 25% 的 key 过期了，则重复删除的过程，直到过期 key 的比例降至 25% 以下。</li>
</ol>
<p>4.对于作者所讲的，我有哪些发散性思考？</p>
<p>5.将来在哪些场景里，我能够使用它？</p>
<p>6.留言区收获<br>1.在生产环境中，可以使用scan替代keys命令（答案来自@kaito 大佬）<br>当scan在Redis在做Rehash时，会不会漏key或返回重复的key？<br>1.不漏keys：Redis在SCAN遍历全局哈希表时，采用<em>高位进位法</em>的方式遍历哈希桶（可网上查询图例，一看就明白），当哈希表扩容后，通过这种算法遍历，旧哈希表中的数据映射到新哈希表，依旧会保留原来的先后顺序，这样就可以保证遍历时不会遗漏也不会重复。<br>2.key重复：这个情况主要发生在哈希表缩容。已经遍历过的哈希桶在缩容时，会映射到新哈希表没有遍历到的位置，所以继续遍历就会对同一个key返回多次。处理方法是在客户端直接做重复过滤<br>2.在redis-cluster中，不能使用一次scan在整个集群中获取所有的key，只能通过在每个实例上单独执行scan才可以，再到客户端进行合并</p>
<h3 id="问题1-4"><a href="#问题1-4" class="headerlink" title="问题1"></a>问题1</h3><p>这节课，我提到了 KEYS 命令，因为它的复杂度很高，容易引起 Redis 线程操作阻塞，不适用于生产环境。但是，KEYS 命令本身提供的功能是上层业务应用经常需要的，即返回与输入模式匹配的 keys。</p>
<p>请思考一下，在 Redis 中，还有哪些其他命令可以代替 KEYS 命令，实现同样的功能呢？这些命令的复杂度会导致 Redis 变慢吗？</p>
<h3 id="解答1-4"><a href="#解答1-4" class="headerlink" title="解答1"></a>解答1</h3><p>在 Redis 中，还有哪些其他命令可以代替 KEYS 命令，实现同样的功能呢？这些命令的复杂度会导致 Redis 变慢吗？</p>
<p>如果想要获取整个实例的所有key，建议使用SCAN命令代替。客户端通过执行SCAN $cursor COUNT $count可以得到一批key以及下一个游标$cursor，然后把这个$cursor当作SCAN的参数，再次执行，以此往复，直到返回的$cursor为0时，就把整个实例中的所有key遍历出来了。</p>
<p>关于SCAN讨论最多的问题就是，Redis在做Rehash时，会不会漏key或返回重复的key。</p>
<p>在使用SCAN命令时，不会漏key，但可能会得到重复的key，这主要和Redis的Rehash机制有关。Redis的所有key存在一个全局的哈希表中，如果存入的key慢慢变多，在达到一定阈值后，为了避免哈希冲突导致查询效率降低，这个哈希表会进行扩容。与之对应的，key数量逐渐变少时，这个哈希表会缩容以节省空间。</p>
<p>1、为什么不会漏key？Redis在SCAN遍历全局哈希表时，采用<em>高位进位法</em>的方式遍历哈希桶（可网上查询图例，一看就明白），当哈希表扩容后，通过这种算法遍历，旧哈希表中的数据映射到新哈希表，依旧会保留原来的先后顺序，这样就可以保证遍历时不会遗漏也不会重复。</p>
<p>2、为什么SCAN会得到重复的key？这个情况主要发生在哈希表缩容。已经遍历过的哈希桶在缩容时，会映射到新哈希表没有遍历到的位置，所以继续遍历就会对同一个key返回多次。</p>
<p>SCAN是遍历整个实例的所有key，另外Redis针对Hash/Set/Sorted Set也提供了HSCAN/SSCAN/ZSCAN命令，用于遍历一个key中的所有元素，建议在获取一个bigkey的所有数据时使用，避免发生阻塞风险。</p>
<p>但是使用HSCAN/SSCAN/ZSCAN命令，返回的元素数量与执行SCAN逻辑可能不同。执行SCAN $cursor COUNT $count时一次最多返回count个数的key，数量不会超过count。</p>
<p>但Hash/Set/Sorted Set元素数量比较少时，底层会采用intset/ziplist方式存储，如果以这种方式存储，在执行HSCAN/SSCAN/ZSCAN命令时，会无视count参数，直接把所有元素一次性返回，也就是说，得到的元素数量是会大于count参数的。当底层转为哈希表或跳表存储时，才会真正使用发count参数，最多返回count个元素。</p>
<h2 id="波动的响应延迟：如何应对变慢的Redis？（下）"><a href="#波动的响应延迟：如何应对变慢的Redis？（下）" class="headerlink" title="波动的响应延迟：如何应对变慢的Redis？（下）"></a>波动的响应延迟：如何应对变慢的Redis？（下）</h2><h3 id="总结1-15"><a href="#总结1-15" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我从文件系统和操作系统两个维度，给你介绍了应对 Redis 变慢的方法。</p>
<p>为了方便你应用，我给你梳理了一个包含 9 个检查点的 Checklist，希望你在遇到 Redis 性能变慢时，按照这些步骤逐一检查，高效地解决问题。</p>
<ol>
<li>获取 Redis 实例在当前环境下的基线性能。</li>
<li>是否用了慢查询命令？如果是的话，就使用其他命令替代慢查询命令，或者把聚合计算命令放在客户端做。</li>
<li>是否对过期 key 设置了相同的过期时间？对于批量删除的 key，可以在每个 key 的过期时间上加一个随机数，避免同时删除。</li>
<li>是否存在 bigkey？ 对于 bigkey 的删除操作，如果你的 Redis 是 4.0 及以上的版本，可以直接利用异步线程机制减少主线程阻塞；如果是 Redis 4.0 以前的版本，可以使用 SCAN 命令迭代删除；对于 bigkey 的集合查询和聚合操作，可以使用 SCAN 命令在客户端完成。</li>
<li>Redis AOF 配置级别是什么？业务层面是否的确需要这一可靠性级别？如果我们需要高性能，同时也允许数据丢失，可以将配置项 no-appendfsync-on-rewrite 设置为 yes，避免 AOF 重写和 fsync 竞争磁盘 IO 资源，导致 Redis 延迟增加。当然， 如果既需要高性能又需要高可靠性，最好使用高速固态盘作为 AOF 日志的写入盘。</li>
<li>Redis 实例的内存使用是否过大？发生 swap 了吗？如果是的话，就增加机器内存，或者是使用 Redis 集群，分摊单机 Redis 的键值对数量和内存压力。同时，要避免出现 Redis 和其他内存需求大的应用共享机器的情况。</li>
<li>在 Redis 实例的运行环境中，是否启用了透明大页机制？如果是的话，直接关闭内存大页机制就行了。</li>
<li>是否运行了 Redis 主从集群？如果是的话，把主库实例的数据量大小控制在 2~4GB，以免主从复制时，从库因加载大的 RDB 文件而阻塞。</li>
<li>是否使用了多核 CPU 或 NUMA 架构的机器运行 Redis 实例？使用多核 CPU 时，可以给 Redis 实例绑定物理核；使用 NUMA 架构时，注意把 Redis 实例和网络中断处理程序运行在同一个 CPU Socket 上。</li>
</ol>
<p>实际上，影响系统性能的因素还有很多，这两节课给你讲的都是应对最常见问题的解决方案。</p>
<p>如果你遇到了一些特殊情况，也不要慌，我再给你分享一个小技巧：仔细检查下有没有恼人的“邻居”，具体点说，就是 Redis 所在的机器上有没有一些其他占内存、磁盘 IO 和网络 IO 的程序，比如说数据库程序或者数据采集程序。如果有的话，我建议你将这些程序迁移到其他机器上运行。</p>
<p>为了保证 Redis 高性能，我们需要给 Redis 充足的计算、内存和 IO 资源，给它提供一个“安静”的环境。</p>
<h3 id="总结2-14"><a href="#总结2-14" class="headerlink" title="总结2"></a>总结2</h3><h3 id="问题1-5"><a href="#问题1-5" class="headerlink" title="问题1"></a>问题1</h3><p>这两节课，我向你介绍了系统性定位、排查和解决 Redis 变慢的方法。所以，我想请你聊一聊，你遇到过 Redis 变慢的情况吗？如果有的话，你是怎么解决的呢？</p>
<h3 id="解答1-5"><a href="#解答1-5" class="headerlink" title="解答1"></a>解答1</h3><p>关于如何分析、排查、解决Redis变慢问题，我总结的checklist如下：</p>
<p>1、使用复杂度过高的命令（例如SORT/SUION/ZUNIONSTORE/KEYS），或一次查询全量数据（例如LRANGE key 0 N，但N很大）</p>
<p>分析：a) 查看slowlog是否存在这些命令 b) Redis进程CPU使用率是否飙升（聚合运算命令导致）</p>
<p>解决：a) 不使用复杂度过高的命令，或用其他方式代替实现（放在客户端做） b) 数据尽量分批查询（LRANGE key 0 N，建议N&lt;=100，查询全量数据建议使用HSCAN/SSCAN/ZSCAN）</p>
<p>2、操作bigkey</p>
<p>分析：a) slowlog出现很多SET/DELETE变慢命令（bigkey分配内存和释放内存变慢） b) 使用redis-cli -h $host -p $port –bigkeys扫描出很多bigkey</p>
<p>解决：a) 优化业务，避免存储bigkey b) Redis 4.0+可开启lazy-free机制</p>
<p>3、大量key集中过期</p>
<p>分析：a) 业务使用EXPIREAT/PEXPIREAT命令 b) Redis info中的expired_keys指标短期突增</p>
<p>解决：a) 优化业务，过期增加随机时间，把时间打散，减轻删除过期key的压力 b) 运维层面，监控expired_keys指标，有短期突增及时报警排查</p>
<p>4、Redis内存达到maxmemory</p>
<p>分析：a) 实例内存达到maxmemory，且写入量大，淘汰key压力变大 b) Redis info中的evicted_keys指标短期突增</p>
<p>解决：a) 业务层面，根据情况调整淘汰策略（随机比LRU快） b) 运维层面，监控evicted_keys指标，有短期突增及时报警 c) 集群扩容，多个实例减轻淘汰key的压力</p>
<p>5、大量短连接请求</p>
<p>分析：Redis处理大量短连接请求，TCP三次握手和四次挥手也会增加耗时</p>
<p>解决：使用长连接操作Redis</p>
<p>6、生成RDB和AOF重写fork耗时严重</p>
<p>分析：a) Redis变慢只发生在生成RDB和AOF重写期间 b) 实例占用内存越大，fork拷贝内存页表越久 c) Redis info中latest_fork_usec耗时变长</p>
<p>解决：a) 实例尽量小 b) Redis尽量部署在物理机上 c) 优化备份策略（例如低峰期备份） d) 合理配置repl-backlog和slave client-output-buffer-limit，避免主从全量同步 e) 视情况考虑关闭AOF f) 监控latest_fork_usec耗时是否变长</p>
<p>7、AOF使用awalys机制</p>
<p>分析：磁盘IO负载变高</p>
<p>解决：a) 使用everysec机制 b) 丢失数据不敏感的业务不开启AOF</p>
<p>8、使用Swap</p>
<p>分析：a) 所有请求全部开始变慢 b) slowlog大量慢日志 c) 查看Redis进程是否使用到了Swap</p>
<p>解决：a) 增加机器内存 b) 集群扩容 c) Swap使用时监控报警</p>
<p>9、进程绑定CPU不合理</p>
<p>分析：a) Redis进程只绑定一个CPU逻辑核 b) NUMA架构下，网络中断处理程序和Redis进程没有绑定在同一个Socket下</p>
<p>解决：a) Redis进程绑定多个CPU逻辑核 b) 网络中断处理程序和Redis进程绑定在同一个Socket下</p>
<p>10、开启透明大页机制</p>
<p>分析：生成RDB和AOF重写期间，主线程处理写请求耗时变长（拷贝内存副本耗时变长）</p>
<p>解决：关闭透明大页机制</p>
<p>11、网卡负载过高</p>
<p>分析：a) TCP/IP层延迟变大，丢包重传变多 b) 是否存在流量过大的实例占满带宽</p>
<p>解决：a) 机器网络资源监控，负载过高及时报警 b) 提前规划部署策略，访问量大的实例隔离部署</p>
<p>总之，Redis的性能与CPU、内存、网络、磁盘都息息相关，任何一处发生问题，都会影响到Redis的性能。</p>
<p>主要涉及到的包括业务使用层面和运维层面：业务人员需要了解Redis基本的运行原理，使用合理的命令、规避bigke问题和集中过期问题。运维层面需要DBA提前规划好部署策略，预留足够的资源，同时做好监控，这样当发生问题时，能够及时发现并尽快处理。</p>
<h2 id="删除数据后，为什么内存占用率还是很高？"><a href="#删除数据后，为什么内存占用率还是很高？" class="headerlink" title="删除数据后，为什么内存占用率还是很高？"></a>删除数据后，为什么内存占用率还是很高？</h2><h3 id="总结1-16"><a href="#总结1-16" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我和你一起了解了 Redis 的内存空间效率问题，这里面的一个关键技术点就是要识别和处理内存碎片。简单来说，就是“三个一”：</p>
<ul>
<li>info memory 命令是一个好工具，可以帮助你查看碎片率的情况；</li>
<li>碎片率阈值是一个好经验，可以帮忙你有效地判断是否要进行碎片清理了；</li>
<li>内存碎片自动清理是一个好方法，可以避免因为碎片导致 Redis 的内存实际利用率降低，提升成本收益率。</li>
</ul>
<p>内存碎片并不可怕，我们要做的就是了解它，重视它，并借用高效的方法解决它。</p>
<p>最后，我再给你提供一个小贴士：内存碎片自动清理涉及内存拷贝，这对 Redis 而言，是个潜在的风险。如果你在实践过程中遇到 Redis 性能变慢，记得通过日志看下是否正在进行碎片清理。如果 Redis 的确正在清理碎片，那么，我建议你调小 active-defrag-cycle-max 的值，以减轻对正常请求处理的影响。</p>
<h3 id="总结2-15"><a href="#总结2-15" class="headerlink" title="总结2"></a>总结2</h3><h3 id="问题1-6"><a href="#问题1-6" class="headerlink" title="问题1"></a>问题1</h3><p>按照惯例，我给你提一个小问题。在这节课中，我提到，可以使用 mem_fragmentation_ratio 来判断 Redis 当前的内存碎片率是否严重，我给出的经验阈值都是大于 1 的。那么，我想请你来聊一聊，如果 mem_fragmentation_ratio 小于 1 了，Redis 的内存使用是什么情况呢？会对 Redis 的性能和内存空间利用率造成什么影响呢？</p>
<h3 id="解答1-6"><a href="#解答1-6" class="headerlink" title="解答1"></a>解答1</h3><p>如果 mem_fragmentation_ratio 小于 1 了，Redis 的内存使用是什么情况呢？会对 Redis 的性能和内存空间利用率造成什么影响？</p>
<p>mem_fragmentation_ratio小于1，说明used_memory_rss小于了used_memory，这意味着操作系统分配给Redis进程的物理内存，要小于Redis实际存储数据的内存，也就是说Redis没有足够的物理内存可以使用了，这会导致Redis一部分内存数据会被换到Swap中，之后当Redis访问Swap中的数据时，延迟会变大，性能下降。</p>
<p>通过这篇文章了解到，Redis在进行内存碎片整理时，由于是主线程操作的，所以这块也是一个影响Redis性能的风险点。</p>
<p>其中active-defrag-ignore-bytes和active-defrag-threshold-lower参数主要用于控制达到什么阈值后开始碎片整理，如果配置的碎片大小和碎片率在可接受的范围内，那么Redis不会进行碎片整理，也就不会对Redis产生性能影响。</p>
<p>而达到设定阈值开始碎片整理后，active-defrag-cycle-min和active-defrag-cycle-max参数则用来控制在这期间，Redis主线程资源使用的上下限，这个需要根据碎片整理的时间、Redis的响应延迟进行权衡，合理配置。</p>
<p>我个人认为，应该优先保证Redis性能尽量不受影响，让碎片整理期间的资源消耗控制在稳定的范围内，并尽量缩短碎片整理的时间。</p>
<h2 id="缓冲区：一个可能引发“惨案”的地方"><a href="#缓冲区：一个可能引发“惨案”的地方" class="headerlink" title="缓冲区：一个可能引发“惨案”的地方"></a>缓冲区：一个可能引发“惨案”的地方</h2><h3 id="总结1-17"><a href="#总结1-17" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我们一起学习了 Redis 中使用的缓冲区。使用缓冲区以后，当命令数据的接收方处理速度跟不上发送方的发送速度时，缓冲区可以避免命令数据的丢失。</p>
<p>按照缓冲区的用途，例如是用于客户端通信还是用于主从节点复制，我把缓冲区分成了客户端的输入和输出缓冲区，以及主从集群中主节点上的复制缓冲区和复制积压缓冲区。这样学习的好处是，你可以很清楚 Redis 中到底有哪些地方使用了缓冲区，那么在排查问题的时候，就可以快速找到方向——从客户端和服务器端的通信过程以及主从节点的复制过程中分析原因。</p>
<p>现在，从缓冲区溢出对 Redis 的影响的角度，我再把这四个缓冲区分成两类做个总结。</p>
<ul>
<li>缓冲区溢出导致网络连接关闭：普通客户端、订阅客户端，以及从节点客户端，它们使用的缓冲区，本质上都是 Redis 客户端和服务器端之间，或是主从节点之间为了传输命令数据而维护的。这些缓冲区一旦发生溢出，处理机制都是直接把客户端和服务器端的连接，或是主从节点间的连接关闭。网络连接关闭造成的直接影响，就是业务程序无法读写 Redis，或者是主从节点全量同步失败，需要重新执行。</li>
<li>缓冲区溢出导致命令数据丢失：主节点上的复制积压缓冲区属于环形缓冲区，一旦发生溢出，新写入的命令数据就会覆盖旧的命令数据，导致旧命令数据的丢失，进而导致主从节点重新进行全量复制。</li>
</ul>
<p>从本质上看，缓冲区溢出，无非就是三个原因：命令数据发送过快过大；命令数据处理较慢；缓冲区空间过小。明白了这个，我们就可以有针对性地拿出应对策略了。</p>
<ul>
<li>针对命令数据发送过快过大的问题，对于普通客户端来说可以避免 bigkey，而对于复制缓冲区来说，就是避免过大的 RDB 文件。</li>
<li>针对命令数据处理较慢的问题，解决方案就是减少 Redis 主线程上的阻塞操作，例如使用异步的删除操作。</li>
<li>针对缓冲区空间过小的问题，解决方案就是使用 client-output-buffer-limit 配置项设置合理的输出缓冲区、复制缓冲区和复制积压缓冲区大小。当然，我们不要忘了，输入缓冲区的大小默认是固定的，我们无法通过配置来修改它，除非直接去修改 Redis 源码。</li>
</ul>
<h3 id="总结2-16"><a href="#总结2-16" class="headerlink" title="总结2"></a>总结2</h3><h3 id="问题1-7"><a href="#问题1-7" class="headerlink" title="问题1"></a>问题1</h3><p>在这节课上，我们提到 Redis 采用了 client-server 架构，服务器端会为每个客户端维护输入、输出缓冲区。那么，应用程序和 Redis 实例交互时，应用程序中使用的客户端需要使用缓冲区吗？如果使用的话，对 Redis 的性能和内存使用会有影响吗？</p>
<h3 id="解答1-7"><a href="#解答1-7" class="headerlink" title="解答1"></a>解答1</h3><p>应用程序和Redis实例交互时，应用程序中使用的客户端需要使用缓冲区吗？如果使用的话，对Redis的性能和内存使用有什么影响？</p>
<p>客户端需要使用缓冲区，好处如下。</p>
<p>1、客户端和服务端交互，一般都会制定一个交互协议，客户端给服务端发数据时，都会按照这个协议把数据拼装好，然后写到客户端buffer中，客户端再一次性把buffer数据写到操作系统的网络缓冲区中，最后由操作系统发送给服务端。这样服务端就能从网络缓冲区中读取到一整块数据，然后按照协议解析数据即可。使用buffer发送数据会比一个个发送数据到服务端效率要高很多。</p>
<p>2、客户端还可以使用Pipeline批量发送命令到服务端，以提高访问性能。不使用Pipeline时，客户端是发送一个命令、读取一次结果。而使用Pipeline时，客户端先把一批命令暂存到buffer中，然后一次性把buffer中的命令发送到服务端，服务端处理多个命令后批量返回结果，这样做的好处是可以减少来回网络IO的次数，降低延迟，提高访问性能。当然，Redis服务端的buffer内存也会相应增长，可以控制好Pipeline命令的数量防止buffer超限。</p>
<p>缓冲区其实无处不在，客户端缓冲区、服务端缓冲区、操作系统网络缓冲区等等，凡是进行数据交互的两端，一般都会利用缓冲区来降低两端速度不匹配的影响。没有缓冲区，就好比一个个工人搬运货物到目的地，每个工人不仅成本高，而且运输效率低。而有了缓冲区后，相当于把这些货物先装到一个集装箱里，然后以集装箱为单位，开车运送到目的地，这样既降低了成本，又提高了运输效率。缓冲区相当于把需要运送的零散数据，进行一块块规整化，然后分批运输。</p>
<p>另外，关于Redis服务端为客户端分配的输出缓冲区，我想补充一点：主库上的从库输出缓冲区（slave client-output-buffer）是不计算在Redis使用的总内存中的，也就是说主从同步延迟，数据积压在主库上的从库输出缓冲区中，这个缓冲区内存占用变大，不会超过maxmemory导致淘汰数据。只有普通客户端和订阅客户端的输出缓冲区内存增长，超过maxmemory时，才会淘汰数据。</p>
<h2 id="旁路缓存：Redis是如何工作的？"><a href="#旁路缓存：Redis是如何工作的？" class="headerlink" title="旁路缓存：Redis是如何工作的？"></a>旁路缓存：Redis是如何工作的？</h2><h3 id="总结1-18"><a href="#总结1-18" class="headerlink" title="总结1"></a>总结1</h3><p>今天，我们学习了缓存的两个特征，分别是在分层系统中，数据暂存在快速子系统中有助于加速访问；缓存容量有限，缓存写满时，数据需要被淘汰。而 Redis 天然就具有高性能访问和数据淘汰机制，正好符合缓存的这两个特征的要求，所以非常适合用作缓存。</p>
<p>另外，我们还学习了 Redis 作为旁路缓存的特性，旁路缓存就意味着需要在应用程序中新增缓存逻辑处理的代码。当然，如果是无法修改源码的应用场景，就不能使用 Redis 做缓存了。</p>
<p>Redis 做缓存时，还有两种模式，分别是只读缓存和读写缓存。其中，读写缓存还提供了同步直写和异步写回这两种模式，同步直写模式侧重于保证数据可靠性，而异步写回模式则侧重于提供低延迟访问，我们要根据实际的业务场景需求来进行选择。</p>
<p>这节课，虽然我提到了 Redis 有数据淘汰机制，但是并没有展开讲具体的淘汰策略。那么，Redis 究竟是怎么淘汰数据的呢？我会在下节课给你具体介绍。</p>
<h3 id="总结2-17"><a href="#总结2-17" class="headerlink" title="总结2"></a>总结2</h3><h3 id="问题1-8"><a href="#问题1-8" class="headerlink" title="问题1"></a>问题1</h3><p>按照惯例，我给你提一个小问题。这节课，我提到了 Redis 只读缓存和使用直写策略的读写缓存，这两种缓存都会把数据同步写到后端数据库中，你觉得，它们有什么区别吗？</p>
<h3 id="解答1-8"><a href="#解答1-8" class="headerlink" title="解答1"></a>解答1</h3><p>Redis只读缓存和使用直写策略的读写缓存，这两种缓存都会把数据同步写到后端数据库中，它们的区别在于：</p>
<p>1、使用只读缓存时，是先把修改写到后端数据库中，再把缓存中的数据删除。当下次访问这个数据时，会以后端数据库中的值为准，重新加载到缓存中。这样做的优点是，数据库和缓存可以保证完全一致，并且缓存中永远保留的是经常访问的热点数据。缺点是每次修改操作都会把缓存中的数据删除，之后访问时都会先触发一次缓存缺失，然后从后端数据库加载数据到缓存中，这个过程访问延迟会变大。</p>
<p>2、使用读写缓存时，是同时修改数据库和缓存中的值。这样做的优点是，被修改后的数据永远在缓存中存在，下次访问时，能够直接命中缓存，不用再从后端数据库中查询，这个过程拥有比较好的性能，比较适合先修改又立即访问的业务场景。但缺点是在高并发场景下，如果存在多个操作同时修改同一个值的情况，可能会导致缓存和数据库的不一致。</p>
<p>3、当使用只读缓存时，如果修改数据库失败了，那么缓存中的数据也不会被删除，此时数据库和缓存中的数据依旧保持一致。而使用读写缓存时，如果是先修改缓存，后修改数据库，如果缓存修改成功，而数据库修改失败了，那么此时数据库和缓存数据就不一致了。如果先修改数据库，再修改缓存，也会产生上面所说的并发场景下的不一致。</p>
<p>我个人总结，只读缓存是牺牲了一定的性能，优先保证数据库和缓存的一致性，它更适合对于一致性要求比较要高的业务场景。而如果对于数据库和缓存一致性要求不高，或者不存在并发修改同一个值的情况，那么使用读写缓存就比较合适，它可以保证更好的访问性能。</p>
<h2 id="替换策略：缓存满了怎么办？"><a href="#替换策略：缓存满了怎么办？" class="headerlink" title="替换策略：缓存满了怎么办？"></a>替换策略：缓存满了怎么办？</h2><h3 id="总结1-19"><a href="#总结1-19" class="headerlink" title="总结1"></a>总结1</h3><p>在这节课上，我围绕着“缓存满了该怎么办”这一问题，向你介绍了缓存替换时的数据淘汰策略，以及被淘汰数据的处理方法。</p>
<p>Redis 4.0 版本以后一共提供了 8 种数据淘汰策略，从淘汰数据的候选集范围来看，我们有两种候选范围：一种是所有数据都是候选集，一种是设置了过期时间的数据是候选集。另外，无论是面向哪种候选数据集进行淘汰数据选择，我们都有三种策略，分别是随机选择，根据 LRU 算法选择，以及根据 LFU 算法选择。当然，当面向设置了过期时间的数据集选择淘汰数据时，我们还可以根据数据离过期时间的远近来决定。</p>
<p>一般来说，缓存系统对于选定的被淘汰数据，会根据其是干净数据还是脏数据，选择直接删除还是写回数据库。但是，在 Redis 中，被淘汰数据无论干净与否都会被删除，所以，这是我们在使用 Redis 缓存时要特别注意的：当数据修改成为脏数据时，需要在数据库中也把数据修改过来。</p>
<p>选择哪种缓存策略是值得我们多加琢磨的，它在筛选数据方面是否能筛选出可能被再次访问的数据，直接决定了缓存效率的高与低。</p>
<p>很简单的一个对比，如果我们使用随机策略，刚筛选出来的要被删除的数据可能正好又被访问了，此时应用就只能花费几毫秒从数据库中读取数据了。而如果使用 LRU 策略，被筛选出来的数据往往是经过时间验证了，如果在一段时间内一直没有访问，本身被再次访问的概率也很低了。</p>
<p>所以，我给你的建议是，先根据是否有始终会被频繁访问的数据（例如置顶消息），来选择淘汰数据的候选集，也就是决定是针对所有数据进行淘汰，还是针对设置了过期时间的数据进行淘汰。候选数据集范围选定后，建议优先使用 LRU 算法，也就是，allkeys-lru 或 volatile-lru 策略。</p>
<p>当然，设置缓存容量的大小也很重要，我的建议是：结合实际应用的数据总量、热数据的体量，以及成本预算，把缓存空间大小设置在总数据量的 15% 到 30% 这个区间就可以。</p>
<h3 id="总结2-18"><a href="#总结2-18" class="headerlink" title="总结2"></a>总结2</h3><h3 id="问题1-9"><a href="#问题1-9" class="headerlink" title="问题1"></a>问题1</h3><p>按照惯例，我给你提一个小问题。这节课，我向你介绍了 Redis 缓存在应对脏数据时，需要在数据修改的同时，也把它写回数据库，针对我们上节课介绍的缓存读写模式：只读缓存，以及读写缓存中的两种写回策略，请你思考下，Redis 缓存对应哪一种或哪几种模式？</p>
<h3 id="解答1-9"><a href="#解答1-9" class="headerlink" title="解答1"></a>解答1</h3><p>Redis在用作缓存时，使用只读缓存或读写缓存的哪种模式？</p>
<p>1、只读缓存模式：每次修改直接写入后端数据库，如果Redis缓存不命中，则什么都不用操作，如果Redis缓存命中，则删除缓存中的数据，待下次读取时从后端数据库中加载最新值到缓存中。</p>
<p>2、读写缓存模式+同步直写策略：由于Redis在淘汰数据时，直接在内部删除键值对，外部无法介入处理脏数据写回数据库，所以使用Redis作读写缓存时，只能采用同步直写策略，修改缓存的同时也要写入到后端数据库中，从而保证修改操作不被丢失。但这种方案在并发场景下会导致数据库和缓存的不一致，需要在特定业务场景下或者配合分布式锁使用。</p>
<p>当一个系统引入缓存时，需要面临最大的问题就是，如何保证缓存和后端数据库的一致性问题，最常见的3个解决方案分别是Cache Aside、Read/Write Throught和Write Back缓存更新策略。</p>
<p>1、Cache Aside策略：就是文章所讲的只读缓存模式。读操作命中缓存直接返回，否则从后端数据库加载到缓存再返回。写操作直接更新数据库，然后删除缓存。这种策略的优点是一切以后端数据库为准，可以保证缓存和数据库的一致性。缺点是写操作会让缓存失效，再次读取时需要从数据库中加载。这种策略是我们在开发软件时最常用的，在使用Memcached或Redis时一般都采用这种方案。</p>
<p>2、Read/Write Throught策略：应用层读写只需要操作缓存，不需要关心后端数据库。应用层在操作缓存时，缓存层会自动从数据库中加载或写回到数据库中，这种策略的优点是，对于应用层的使用非常友好，只需要操作缓存即可，缺点是需要缓存层支持和后端数据库的联动。</p>
<p>3、Write Back策略：类似于文章所讲的读写缓存模式+异步写回策略。写操作只写缓存，比较简单。而读操作如果命中缓存则直接返回，否则需要从数据库中加载到缓存中，在加载之前，如果缓存已满，则先把需要淘汰的缓存数据写回到后端数据库中，再把对应的数据放入到缓存中。这种策略的优点是，写操作飞快（只写缓存），缺点是如果数据还未来得及写入后端数据库，系统发生异常会导致缓存和数据库的不一致。这种策略经常使用在操作系统Page Cache中，或者应对大量写操作的数据库引擎中。</p>
<p>除了以上提到的缓存和数据库的更新策略之外，还有一个问题就是操作缓存或数据库发生异常时如何处理？例如缓存操作成功，数据库操作失败，或者反过来，还是有可能会产生不一致的情况。</p>
<p>比较简单的解决方案是，根据业务设计好更新缓存和数据库的先后顺序来降低影响，或者给缓存设置较短的有效期来降低不一致的时间。如果需要严格保证缓存和数据库的一致性，即保证两者操作的原子性，这就涉及到分布式事务问题了，常见的解决方案就是我们经常听到的两阶段提交（2PC）、三阶段提交（3PC）、TCC、消息队列等方式来保证了，方案也会比较复杂，一般用在对于一致性要求较高的业务场景中。</p>
<h2 id="缓存异常（上）：如何解决缓存和数据库的数据不一致问题？"><a href="#缓存异常（上）：如何解决缓存和数据库的数据不一致问题？" class="headerlink" title="缓存异常（上）：如何解决缓存和数据库的数据不一致问题？"></a>缓存异常（上）：如何解决缓存和数据库的数据不一致问题？</h2><h3 id="总结1-20"><a href="#总结1-20" class="headerlink" title="总结1"></a>总结1</h3><p>在这节课，我们学习了在使用 Redis 缓存时，最常遇见的一个问题，也就是缓存和数据库不一致的问题。针对这个问题，我们可以分成读写缓存和只读缓存两种情况进行分析。</p>
<p>对于读写缓存来说，如果我们采用同步写回策略，那么可以保证缓存和数据库中的数据一致。只读缓存的情况比较复杂，我总结了一张表，以便于你更加清晰地了解数据不一致的问题原因、现象和应对方案。</p>
<p><img src="/images/redis/mysql-and-redis-01.png" alt="img.png"></p>
<p>希望你能把我总结的这张表格放入到你的学习笔记中，时不时复习一下。</p>
<p>最后，我还想再多说几句。在大多数业务场景下，我们会把 Redis 作为只读缓存使用。针对只读缓存来说，我们既可以先删除缓存值再更新数据库，也可以先更新数据库再删除缓存。我的建议是，优先使用先更新数据库再删除缓存的方法，原因主要有两个：</p>
<ol>
<li>先删除缓存值再更新数据库，有可能导致请求因缓存缺失而访问数据库，给数据库带来压力；</li>
<li>如果业务应用中读取数据库和写缓存的时间不好估算，那么，延迟双删中的等待时间就不好设置。</li>
</ol>
<p>不过，当使用先更新数据库再删除缓存时，也有个地方需要注意，如果业务层要求必须读取一致的数据，那么，我们就需要在更新数据库时，先在 Redis 缓存客户端暂存并发读请求，等数据库更新完、缓存值删除后，再读取数据，从而保证数据一致性。</p>
<h3 id="总结2-19"><a href="#总结2-19" class="headerlink" title="总结2"></a>总结2</h3><h3 id="问题1-10"><a href="#问题1-10" class="headerlink" title="问题1"></a>问题1</h3><p>按照惯例，我给你提个小问题。这节课，我提到，在只读缓存中进行数据的删改操作时，需要在缓存中删除相应的缓存值。我想请你思考一下，如果在这个过程中，我们不是删除缓存值，而是直接更新缓存的值，你觉得和删除缓存值相比，有什么好处和不足吗？</p>
<h3 id="解答1-10"><a href="#解答1-10" class="headerlink" title="解答1"></a>解答1</h3><p>数据在删改操作时，如果不是删除缓存值，而是直接更新缓存的值，你觉得和删除缓存值相比，有什么好处和不足？</p>
<p>这种情况相当于把Redis当做读写缓存使用，删改操作同时操作数据库和缓存。</p>
<p>1、先更新数据库，再更新缓存：如果更新数据库成功，但缓存更新失败，此时数据库中是最新值，但缓存中是旧值，后续的读请求会直接命中缓存，得到的是旧值。</p>
<p>2、先更新缓存，再更新数据库：如果更新缓存成功，但数据库更新失败，此时缓存中是最新值，数据库中是旧值，后续读请求会直接命中缓存，但得到的是最新值，短期对业务影响不大。但是，一旦缓存过期或者满容后被淘汰，读请求就会从数据库中重新加载旧值到缓存中，之后的读请求会从缓存中得到旧值，对业务产生影响。</p>
<p>同样地，针对这种其中一个操作可能失败的情况，也可以使用重试机制解决，把第二步操作放入到消息队列中，消费者从消息队列取出消息，再更新缓存或数据库，成功后把消息从消息队列删除，否则进行重试，以此达到数据库和缓存的最终一致。</p>
<p>以上是没有并发请求的情况。如果存在并发读写，也会产生不一致，分为以下4种场景。</p>
<p>1、先更新数据库，再更新缓存，写+读并发：线程A先更新数据库，之后线程B读取数据，此时线程B会命中缓存，读取到旧值，之后线程A更新缓存成功，后续的读请求会命中缓存得到最新值。这种场景下，线程A未更新完缓存之前，在这期间的读请求会短暂读到旧值，对业务短暂影响。</p>
<p>2、先更新缓存，再更新数据库，写+读并发：线程A先更新缓存成功，之后线程B读取数据，此时线程B命中缓存，读取到最新值后返回，之后线程A更新数据库成功。这种场景下，虽然线程A还未更新完数据库，数据库会与缓存存在短暂不一致，但在这之前进来的读请求都能直接命中缓存，获取到最新值，所以对业务没影响。</p>
<p>3、先更新数据库，再更新缓存，写+写并发：线程A和线程B同时更新同一条数据，更新数据库的顺序是先A后B，但更新缓存时顺序是先B后A，这会导致数据库和缓存的不一致。</p>
<p>4、先更新缓存，再更新数据库，写+写并发：与场景3类似，线程A和线程B同时更新同一条数据，更新缓存的顺序是先A后B，但是更新数据库的顺序是先B后A，这也会导致数据库和缓存的不一致。</p>
<p>场景1和2对业务影响较小，场景3和4会造成数据库和缓存不一致，影响较大。也就是说，在读写缓存模式下，写+读并发对业务的影响较小，而写+写并发时，会造成数据库和缓存的不一致。</p>
<p>针对场景3和4的解决方案是，对于写请求，需要配合分布式锁使用。写请求进来时，针对同一个资源的修改操作，先加分布式锁，这样同一时间只允许一个线程去更新数据库和缓存，没有拿到锁的线程把操作放入到队列中，延时处理。用这种方式保证多个线程操作同一资源的顺序性，以此保证一致性。</p>
<p>综上，使用读写缓存同时操作数据库和缓存时，因为其中一个操作失败导致不一致的问题，同样可以通过消息队列重试来解决。而在并发的场景下，读+写并发对业务没有影响或者影响较小，而写+写并发时需要配合分布式锁的使用，才能保证缓存和数据库的一致性。</p>
<p>另外，读写缓存模式由于会同时更新数据库和缓存，优点是，缓存中一直会有数据，如果更新操作后会立即再次访问，可以直接命中缓存，能够降低读请求对于数据库的压力（没有了只读缓存的删除缓存导致缓存缺失和再加载的过程）。缺点是，如果更新后的数据，之后很少再被访问到，会导致缓存中保留的不是最热的数据，缓存利用率不高（只读缓存中保留的都是热数据），所以读写缓存比较适合用于读写相当的业务场景。</p>
<h2 id="缓存异常（下）：如何解决缓存雪崩、击穿、穿透难题？"><a href="#缓存异常（下）：如何解决缓存雪崩、击穿、穿透难题？" class="headerlink" title="缓存异常（下）：如何解决缓存雪崩、击穿、穿透难题？"></a>缓存异常（下）：如何解决缓存雪崩、击穿、穿透难题？</h2><h3 id="总结1-21"><a href="#总结1-21" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我们学习了缓存雪崩、击穿和穿透这三类异常问题。从问题成因来看，缓存雪崩和击穿主要是因为数据不在缓存中了，而缓存穿透则是因为数据既不在缓存中，也不在数据库中。所以，缓存雪崩或击穿时，一旦数据库中的数据被再次写入到缓存后，应用又可以在缓存中快速访问数据了，数据库的压力也会相应地降低下来，而缓存穿透发生时，Redis 缓存和数据库会同时持续承受请求压力。</p>
<p>为了方便你掌握，我把这三大问题的原因和应对方案总结到了一张表格，你可以再复习一下。</p>
<p><img src="/images/redis/mysql-and-redis-02.png" alt="img.png"></p>
<p>最后，我想强调一下，服务熔断、服务降级、请求限流这些方法都是属于“有损”方案，在保证数据库和整体系统稳定的同时，会对业务应用带来负面影响。例如使用服务降级时，有部分数据的请求就只能得到错误返回信息，无法正常处理。如果使用了服务熔断，那么，整个缓存系统的服务都被暂停了，影响的业务范围更大。而使用了请求限流机制后，整个业务系统的吞吐率会降低，能并发处理的用户请求会减少，会影响到用户体验。</p>
<p>所以，我给你的建议是，尽量使用预防式方案：</p>
<ul>
<li>针对缓存雪崩，合理地设置数据过期时间，以及搭建高可靠缓存集群；</li>
<li>针对缓存击穿，在缓存访问非常频繁的热点数据时，不要设置过期时间；</li>
<li>针对缓存穿透，提前在入口前端实现恶意请求检测，或者规范数据库的数据删除操作，避免误删除。</li>
</ul>
<h3 id="总结2-20"><a href="#总结2-20" class="headerlink" title="总结2"></a>总结2</h3><h3 id="问题1-11"><a href="#问题1-11" class="headerlink" title="问题1"></a>问题1</h3><p>按照惯例，我给你提个小问题。在讲到缓存雪崩时，我提到，可以采用服务熔断、服务降级、请求限流的方法来应对。请你思考下，这三个机制可以用来应对缓存穿透问题吗？</p>
<h3 id="解答1-11"><a href="#解答1-11" class="headerlink" title="解答1"></a>解答1</h3><p>是否可以采用服务熔断、服务降级、请求限流的方法来应对缓存穿透问题？</p>
<p>我觉得需要区分场景来看。</p>
<p>如果缓存穿透的原因是恶意攻击，攻击者故意访问数据库中不存在的数据。这种情况可以先使用服务熔断、服务降级、请求限流的方式，对缓存和数据库层增加保护，防止大量恶意请求把缓存和数据库压垮。在这期间可以对攻击者进行防护，例如封禁IP等操作。</p>
<p>如果缓存穿透的原因是，业务层误操作把数据从缓存和数据库都删除了，如果误删除的数据很少，不会导致大量请求压到数据库的情况，那么快速恢复误删的数据就好了，不需要使用服务熔断、服务降级、请求限流。如果误操作删除的数据范围比较广，导致大量请求压到数据库层，此时使用服务熔断、服务降级、请求限流的方法来应对是有帮助的，使用这些方法先把缓存和数据库保护起来，然后使用备份库快速恢复数据，在数据恢复期间，这些保护方法可以为数据库恢复提供保障。</p>
<p>还有一种缓存穿透的场景，我们平时会遇到的，和大家分享一下。</p>
<p>对于一个刚上线的新业务模块，如果还没有用户在这个模块内产生业务数据，当用户需要查询这个业务模块自己的数据时，由于缓存和数据库都没有这个用户的数据，此时也会产生缓存穿透，但这种场景不像误删数据和恶意攻击那样，而是属于正常的用户行为。</p>
<p>这种场景采用服务熔断、服务降级、请求限流的方式就没有任何意义了，反而会影响正常用户的访问。这种场景只能使用缓存回种空值、布隆过滤器来解决。</p>
<p>可见，服务熔断、服务降级、请求限流的作用是，当系统内部发生故障或潜在问题时，为了防止系统内部的问题进一步恶化，所以会采用这些方式对系统增加保护，待系统内部故障恢复后，可以依旧继续对外提供服务，这些方法属于服务治理的范畴，在任何可能导致系统故障的场景下，都可以选择性配合使用。</p>
<p>另外，关于文章所讲的由于“Redis缓存实例发生故障宕机”导致缓存雪崩的问题，我觉得一个可以优化的方案是，当Redis实例故障宕机后，业务请求可以直接返回错误，没必要再去请求数据库了，这样就不会导致数据库层压力变大。当然，最好的方式还是Redis部署主从集群+哨兵，主节点宕机后，哨兵可以及时把从节点提升为主，继续提供服务。</p>
<p>关于布隆过滤器的使用，还有几点和大家分享。</p>
<p>1、布隆过滤器会有误判：由于采用固定bit的数组，使用多个哈希函数映射到多个bit上，有可能会导致两个不同的值都映射到相同的一组bit上。虽然有误判，但对于业务没有影响，无非就是还存在一些穿透而已，但整体上已经过滤了大多数无效穿透请求。</p>
<p>2、布隆过滤器误判率和空间使用的计算：误判本质是因为哈希冲突，降低误判的方法是增加哈希函数 + 扩大整个bit数组的长度，但增加哈希函数意味着影响性能，扩大数组长度意味着空间占用变大，所以使用布隆过滤器，需要在误判率和性能、空间作一个平衡，具体的误判率是有一个计算公式可以推导出来的（比较复杂）。但我们在使用开源的布隆过滤器时比较简单，通常会提供2个参数：预估存入的数据量大小、要求的误判率，输入这些参数后，布隆过滤器会有自动计算出最佳的哈希函数数量和数组占用的空间大小，直接使用即可。</p>
<p>3、布隆过滤器可以放在缓存和数据库的最前面：把Redis当作布隆过滤器时（4.0提供了布隆过滤器模块，4.0以下需要引入第三方库），当用户产生业务数据写入缓存和数据库后，同时也写入布隆过滤器，之后当用户访问自己的业务数据时，先检查布隆过滤器，如果过滤器不存在，就不需要查询缓存和数据库了，可以同时降低缓存和数据库的压力。</p>
<p>4、Redis实现的布隆过滤器bigkey问题：Redis布隆过滤器是使用String类型实现的，存储的方式是一个bigkey，建议使用时单独部署一个实例，专门存放布隆过滤器的数据，不要和业务数据混用，否则在集群环境下，数据迁移时会导致Redis阻塞问题。</p>
<h2 id="缓存被污染了，该怎么办？"><a href="#缓存被污染了，该怎么办？" class="headerlink" title="缓存被污染了，该怎么办？"></a>缓存被污染了，该怎么办？</h2><h3 id="总结1-22"><a href="#总结1-22" class="headerlink" title="总结1"></a>总结1</h3><p>今天这节课，我们学习的是“如何解决缓存污染”这个问题。</p>
<p>缓存污染问题指的是留存在缓存中的数据，实际不会被再次访问了，但是又占据了缓存空间。如果这样的数据体量很大，甚至占满了缓存，每次有新数据写入缓存时，还需要把这些数据逐步淘汰出缓存，就会增加缓存操作的时间开销。</p>
<p>因此，要解决缓存污染问题，最关键的技术点就是能识别出这些只访问一次或是访问次数很少的数据，在淘汰数据时，优先把它们筛选出来并淘汰掉。因为 noviction 策略不涉及数据淘汰，所以这节课，我们就从能否有效解决缓存污染这个维度，分析了 Redis 的其他 7 种数据淘汰策略。</p>
<p>volatile-random 和 allkeys-random 是随机选择数据进行淘汰，无法把不再访问的数据筛选出来，可能会造成缓存污染。如果业务层明确知道数据的访问时长，可以给数据设置合理的过期时间，再设置 Redis 缓存使用 volatile-ttl 策略。当缓存写满时，剩余存活时间最短的数据就会被淘汰出缓存，避免滞留在缓存中，造成污染。</p>
<p>当我们使用 LRU 策略时，由于 LRU 策略只考虑数据的访问时效，对于只访问一次的数据来说，LRU 策略无法很快将其筛选出来。而 LFU 策略在 LRU 策略基础上进行了优化，在筛选数据时，首先会筛选并淘汰访问次数少的数据，然后针对访问次数相同的数据，再筛选并淘汰访问时间最久远的数据。</p>
<p>在具体实现上，相对于 LRU 策略，Redis 只是把原来 24bit 大小的 lru 字段，又进一步拆分成了 16bit 的 ldt 和 8bit 的 counter，分别用来表示数据的访问时间戳和访问次数。为了避开 8bit 最大只能记录 255 的限制，LFU 策略设计使用非线性增长的计数器来表示数据的访问次数。</p>
<p>在实际业务应用中，LRU 和 LFU 两个策略都有应用。LRU 和 LFU 两个策略关注的数据访问特征各有侧重，LRU 策略更加关注数据的时效性，而 LFU 策略更加关注数据的访问频次。通常情况下，实际应用的负载具有较好的时间局部性，所以 LRU 策略的应用会更加广泛。但是，在扫描式查询的应用场景中，LFU 策略就可以很好地应对缓存污染问题了，建议你优先使用。</p>
<p>此外，如果业务应用中有短时高频访问的数据，除了 LFU 策略本身会对数据的访问次数进行自动衰减以外，我再给你个小建议：你可以优先使用 volatile-lfu 策略，并根据这些数据的访问时限设置它们的过期时间，以免它们留存在缓存中造成污染。</p>
<h3 id="总结2-21"><a href="#总结2-21" class="headerlink" title="总结2"></a>总结2</h3><h3 id="问题1-12"><a href="#问题1-12" class="headerlink" title="问题1"></a>问题1</h3><p>按照惯例，我给你提个小问题。使用了 LFU 策略后，你觉得缓存还会被污染吗？</p>
<h3 id="解答1-12"><a href="#解答1-12" class="headerlink" title="解答1"></a>解答1</h3><p>使用了 LFU 策略后，缓存还会被污染吗？</p>
<p>我觉得还是有被污染的可能性，被污染的概率取决于LFU的配置，也就是lfu-log-factor和lfu-decay-time参数。</p>
<p>1、根据LRU counter计数规则可以得出，counter递增的概率取决于2个因素：</p>
<p>a) counter值越大，递增概率越低<br>b) lfu-log-factor设置越大，递增概率越低</p>
<p>所以当访问次数counter越来越大时，或者lfu-log-factor参数配置过大时，counter递增的概率都会越来越低，这种情况下可能会导致一些key虽然访问次数较高，但是counter值却递增困难，进而导致这些访问频次较高的key却优先被淘汰掉了。</p>
<p>另外由于counter在递增时，有随机数比较的逻辑，这也会存在一定概率导致访问频次低的key的counter反而大于访问频次高的key的counter情况出现。</p>
<p>2、如果lfu-decay-time配置过大，则counter衰减会变慢，也会导致数据淘汰发生推迟的情况。</p>
<p>3、另外，由于LRU的ldt字段只采用了16位存储，其精度是分钟级别的，在counter衰减时可能会产生同一分钟内，后访问的key比先访问的key的counter值优先衰减，进而先被淘汰掉的情况。</p>
<p>可见，Redis实现的LFU策略，也是近似的LFU算法。Redis在实现时，权衡了内存使用、性能开销、LFU的正确性，通过复用并拆分lru字段的方式，配合算法策略来实现近似的结果，虽然会有一定概率的偏差，但在内存数据库这种场景下，已经做得足够好了。</p>
<h2 id="Pika：如何基于SSD实现大容量Redis？"><a href="#Pika：如何基于SSD实现大容量Redis？" class="headerlink" title="Pika：如何基于SSD实现大容量Redis？"></a>Pika：如何基于SSD实现大容量Redis？</h2><h3 id="总结1-23"><a href="#总结1-23" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我们学习了基于 SSD 给 Redis 单实例进行扩容的技术方案 Pika。跟 Redis 相比，Pika 的好处非常明显：既支持 Redis 操作接口，又能支持保存大容量的数据。如果你原来就在应用 Redis，现在想进行扩容，那么，Pika 无疑是一个很好的选择，无论是代码迁移还是运维管理，Pika 基本不需要额外的工作量。</p>
<p>不过，Pika 毕竟是把数据保存到了 SSD 上，数据访问要读写 SSD，所以，读写性能要弱于 Redis。针对这一点，我给你提供两个降低读写 SSD 对 Pika 的性能影响的小建议：</p>
<ol>
<li>利用 Pika 的多线程模型，增加线程数量，提升 Pika 的并发请求处理能力；</li>
<li>为 Pika 配置高配的 SSD，提升 SSD 自身的访问性能。</li>
</ol>
<p>最后，我想再给你一个小提示。Pika 本身提供了很多工具，可以帮助我们把 Redis 数据迁移到 Pika，或者是把 Redis 请求转发给 Pika。比如说，我们使用 aof_to_pika 命令，并且指定 Redis 的 AOF 文件以及 Pika 的连接信息，就可以把 Redis 数据迁移到 Pika 中了，如下所示：</p>
<div class="code-wrapper"><pre><code class="hljs css"><span class="hljs-selector-tag">aof_to_pika</span> <span class="hljs-selector-tag">-i</span> <span class="hljs-selector-attr">[Redis AOF文件]</span> <span class="hljs-selector-tag">-h</span> <span class="hljs-selector-attr">[Pika IP]</span> <span class="hljs-selector-tag">-p</span> <span class="hljs-selector-attr">[Pika port]</span> <span class="hljs-selector-tag">-a</span> <span class="hljs-selector-attr">[认证信息]</span></code></pre></div>

<p>关于这些工具的信息，你都可以直接在 Pika 的<a target="_blank" rel="noopener" href="https://github.com/OpenAtomFoundation/pika/wiki">GitHub</a>上找到。而且，Pika 本身也还在迭代开发中，我也建议你多去看看 GitHub，进一步地了解它。这样，你就可以获得 Pika 的最新进展，也能更好地把它应用到你的业务实践中。</p>
<h3 id="总结2-22"><a href="#总结2-22" class="headerlink" title="总结2"></a>总结2</h3><h3 id="问题1-13"><a href="#问题1-13" class="headerlink" title="问题1"></a>问题1</h3><p>按照惯例，我给你提个小问题。这节课，我向你介绍的是使用 SSD 作为内存容量的扩展，增加 Redis 实例的数据保存量，我想请你来聊一聊，我们可以使用机械硬盘来作为实例容量扩展吗，有什么好处或不足吗？</p>
<h3 id="解答1-13"><a href="#解答1-13" class="headerlink" title="解答1"></a>解答1</h3><p>是否可以使用机械硬盘作为Redis的内存容量的扩展？</p>
<p>我觉得也是可以的。机械硬盘相较于固态硬盘的优点是，成本更低、容量更大、寿命更长。</p>
<p>1、成本：机械硬盘是电磁存储，固态硬盘是半导体电容颗粒组成，相同容量下机械硬盘成本是固态硬盘的1/3。<br>2、容量：相同成本下，机械硬盘可使用的容量更大。<br>3、寿命：固态硬盘的电容颗粒擦写次数有限，超过一定次数后会不可用。相同ops情况下，机械硬盘的寿命要比固态硬盘的寿命更长。</p>
<p>但机械硬盘相较于固态硬盘的缺点也很明显，就是速度慢。</p>
<p>机械硬盘在读写数据时，需要通过转动磁盘和磁头等机械方式完成，而固态硬盘是直接通过电信号保存和控制数据的读写，速度非常快。</p>
<p>如果对于访问延迟要求不高，对容量和成本比较关注的场景，可以把Pika部署在机械硬盘上使用。</p>
<p>另外，关于Pika的使用场景，它并不能代替Redis，而是作为Redis的补充，在需要大容量存储（50G数据量以上）、访问延迟要求不苛刻的业务场景下使用。在使用之前，最好是根据自己的业务情况，先做好调研和性能测试，评估后决定是否使用。</p>
<h2 id="无锁的原子操作：Redis如何应对并发访问？"><a href="#无锁的原子操作：Redis如何应对并发访问？" class="headerlink" title="无锁的原子操作：Redis如何应对并发访问？"></a>无锁的原子操作：Redis如何应对并发访问？</h2><h3 id="总结1-24"><a href="#总结1-24" class="headerlink" title="总结1"></a>总结1</h3><p>在并发访问时，并发的 RMW 操作会导致数据错误，所以需要进行并发控制。所谓并发控制，就是要保证临界区代码的互斥执行。</p>
<p>Redis 提供了两种原子操作的方法来实现并发控制，分别是单命令操作和 Lua 脚本。因为原子操作本身不会对太多的资源限制访问，可以维持较高的系统并发性能。</p>
<p>但是，单命令原子操作的适用范围较小，并不是所有的 RMW 操作都能转变成单命令的原子操作（例如 INCR/DECR 命令只能在读取数据后做原子增减），当我们需要对读取的数据做更多判断，或者是我们对数据的修改不是简单的增减时，单命令操作就不适用了。</p>
<p>而 Redis 的 Lua 脚本可以包含多个操作，这些操作都会以原子性的方式执行，绕开了单命令操作的限制。不过，如果把很多操作都放在 Lua 脚本中原子执行，会导致 Redis 执行脚本的时间增加，同样也会降低 Redis 的并发性能。所以，我给你一个小建议：在编写 Lua 脚本时，你要避免把不需要做并发控制的操作写入脚本中。</p>
<p>当然，加锁也能实现临界区代码的互斥执行，只是如果有多个客户端加锁时，就需要分布式锁的支持了。所以，下节课，我就来和你聊聊分布式锁的实现。</p>
<h3 id="总结2-23"><a href="#总结2-23" class="headerlink" title="总结2"></a>总结2</h3><h3 id="问题1-14"><a href="#问题1-14" class="headerlink" title="问题1"></a>问题1</h3><p>按照惯例，我向你提个小问题，Redis 在执行 Lua 脚本时，是可以保证原子性的，那么，在我举的 Lua 脚本例子（lua.script）中，你觉得是否需要把读取客户端 ip 的访问次数，也就是 GET(ip)，以及判断访问次数是否超过 20 的判断逻辑，也加到 Lua 脚本中吗？</p>
<h3 id="解答1-14"><a href="#解答1-14" class="headerlink" title="解答1"></a>解答1</h3><p>是否需要把读取客户端 ip 的访问次数 GET(ip)，以及判断访问次数是否超过 20 的判断逻辑，也加到 Lua 脚本中？</p>
<p>我觉得不需要，理由主要有2个。</p>
<p>1、这2个逻辑都是读操作，不会对资源临界区产生修改，所以不需要做并发控制。</p>
<p>2、减少 lua 脚本中的命令，可以降低Redis执行脚本的时间，避免阻塞 Redis。</p>
<p>另外使用lua脚本时，还有一些注意点：</p>
<p>1、lua 脚本尽量只编写通用的逻辑代码，避免直接写死变量。变量通过外部调用方传递进来，这样 lua 脚本的可复用度更高。</p>
<p>2、建议先使用SCRIPT LOAD命令把 lua 脚本加载到 Redis 中，然后得到一个脚本唯一摘要值，再通过EVALSHA命令 + 脚本摘要值来执行脚本，这样可以避免每次发送脚本内容到 Redis，减少网络开销。</p>
<h2 id="如何使用Redis实现分布式锁？"><a href="#如何使用Redis实现分布式锁？" class="headerlink" title="如何使用Redis实现分布式锁？"></a>如何使用Redis实现分布式锁？</h2><h3 id="总结1-25"><a href="#总结1-25" class="headerlink" title="总结1"></a>总结1</h3><p>分布式锁是由共享存储系统维护的变量，多个客户端可以向共享存储系统发送命令进行加锁或释放锁操作。Redis 作为一个共享存储系统，可以用来实现分布式锁。</p>
<p>在基于单个 Redis 实例实现分布式锁时，对于加锁操作，我们需要满足三个条件。</p>
<ol>
<li>加锁包括了读取锁变量、检查锁变量值和设置锁变量值三个操作，但需要以原子操作的方式完成，所以，我们使用 SET 命令带上 NX 选项来实现加锁；</li>
<li>锁变量需要设置过期时间，以免客户端拿到锁后发生异常，导致锁一直无法释放，所以，我们在 SET 命令执行时加上 EX/PX 选项，设置其过期时间；</li>
<li>锁变量的值需要能区分来自不同客户端的加锁操作，以免在释放锁时，出现误释放操作，所以，我们使用 SET 命令设置锁变量值时，每个客户端设置的值是一个唯一值，用于标识客户端。</li>
</ol>
<p>和加锁类似，释放锁也包含了读取锁变量值、判断锁变量值和删除锁变量三个操作，不过，我们无法使用单个命令来实现，所以，我们可以采用 Lua 脚本执行释放锁操作，通过 Redis 原子性地执行 Lua 脚本，来保证释放锁操作的原子性。</p>
<p>不过，基于单个 Redis 实例实现分布式锁时，会面临实例异常或崩溃的情况，这会导致实例无法提供锁操作，正因为此，Redis 也提供了 Redlock 算法，用来实现基于多个实例的分布式锁。这样一来，锁变量由多个实例维护，即使有实例发生了故障，锁变量仍然是存在的，客户端还是可以完成锁操作。Redlock 算法是实现高可靠分布式锁的一种有效解决方案，你可以在实际应用中把它用起来。</p>
<h3 id="总结2-24"><a href="#总结2-24" class="headerlink" title="总结2"></a>总结2</h3><h3 id="问题1-15"><a href="#问题1-15" class="headerlink" title="问题1"></a>问题1</h3><p>按照惯例，我给你提个小问题。这节课，我提到，我们可以使用 SET 命令带上 NX 和 EX/PX 选项进行加锁操作，那么，我想请你再思考一下，我们是否可以用下面的方式来实现加锁操作呢？</p>
<div class="code-wrapper"><pre><code class="hljs awk"><span class="hljs-regexp">//</span> 加锁
SETNX lock_key unique_value
EXPIRE lock_key <span class="hljs-number">10</span>S
<span class="hljs-regexp">//</span> 业务逻辑
DO THINGS</code></pre></div>

<h3 id="解答1-15"><a href="#解答1-15" class="headerlink" title="解答1"></a>解答1</h3><p>是否可以使用 SETNX + EXPIRE 来完成加锁操作？</p>
<p>不可以这么使用。使用 2 个命令无法保证操作的原子性，在异常情况下，加锁结果会不符合预期。异常情况主要分为以下几种情况：</p>
<p>1、SETNX 执行成功，执行 EXPIRE 时由于网络问题设置过期失败</p>
<p>2、SETNX 执行成功，此时 Redis 实例宕机，EXPIRE 没有机会执行</p>
<p>3、SETNX 执行成功，客户端异常崩溃，EXPIRE 没有机会执行</p>
<p>如果发生以上情况，并且客户端在释放锁时发生异常，没有正常释放锁，那么这把锁就会一直无法释放，其他线程都无法再获得锁。</p>
<p>下面说一下关于 Redis 分布式锁可靠性的问题。</p>
<p>使用单个 Redis 节点（只有一个master）使用分布锁，如果实例宕机，那么无法进行锁操作了。那么采用主从集群模式部署是否可以保证锁的可靠性？</p>
<p>答案是也很难保证。如果在 master 上加锁成功，此时 master 宕机，由于主从复制是异步的，加锁操作的命令还未同步到 slave，此时主从切换，新 master 节点依旧会丢失该锁，对业务来说相当于锁失效了。</p>
<p>所以 Redis 作者才提出基于多个 Redis 节点（master节点）的 Redlock 算法，但这个算法涉及的细节很多，作者在提出这个算法时，业界的分布式系统专家还与 Redis 作者发生过一场争论，来评估这个算法的可靠性，争论的细节都是关于异常情况可能导致 Redlock 失效的场景，例如加锁过程中客户端发生了阻塞、机器时钟发生跳跃等等。</p>
<p>感兴趣的可以看下这篇文章，详细介绍了争论的细节，以及 Redis 分布式锁在各种异常情况是否安全的分析，收益会非常大：<a target="_blank" rel="noopener" href="http://zhangtielei.com/posts/blog-redlock-reasoning.html%E3%80%82">http://zhangtielei.com/posts/blog-redlock-reasoning.html。</a></p>
<p>简单总结，基于 Redis 使用分布锁的注意点：</p>
<p>1、使用 SET $lock_key $unique_val EX $second NX 命令保证加锁原子性，并为锁设置过期时间</p>
<p>2、锁的过期时间要提前评估好，要大于操作共享资源的时间</p>
<p>3、每个线程加锁时设置随机值，释放锁时判断是否和加锁设置的值一致，防止自己的锁被别人释放</p>
<p>4、释放锁时使用 Lua 脚本，保证操作的原子性</p>
<p>5、基于多个节点的 Redlock，加锁时超过半数节点操作成功，并且获取锁的耗时没有超过锁的有效时间才算加锁成功</p>
<p>6、Redlock 释放锁时，要对所有节点释放（即使某个节点加锁失败了），因为加锁时可能发生服务端加锁成功，由于网络问题，给客户端回复网络包失败的情况，所以需要把所有节点可能存的锁都释放掉</p>
<p>7、使用 Redlock 时要避免机器时钟发生跳跃，需要运维来保证，对运维有一定要求，否则可能会导致 Redlock 失效。例如共 3 个节点，线程 A 操作 2 个节点加锁成功，但其中 1 个节点机器时钟发生跳跃，锁提前过期，线程 B 正好在另外 2 个节点也加锁成功，此时 Redlock 相当于失效了（Redis 作者和分布式系统专家争论的重要点就在这）</p>
<p>8、如果为了效率，使用基于单个 Redis 节点的分布式锁即可，此方案缺点是允许锁偶尔失效，优点是简单效率高</p>
<p>9、如果是为了正确性，业务对于结果要求非常严格，建议使用 Redlock，但缺点是使用比较重，部署成本高</p>
<h2 id="事务机制：Redis能实现ACID属性吗？"><a href="#事务机制：Redis能实现ACID属性吗？" class="headerlink" title="事务机制：Redis能实现ACID属性吗？"></a>事务机制：Redis能实现ACID属性吗？</h2><h3 id="总结1-26"><a href="#总结1-26" class="headerlink" title="总结1"></a>总结1</h3><p>在这节课上，我们学习了 Redis 中的事务实现。Redis 通过 MULTI、EXEC、DISCARD 和 WATCH 四个命令来支持事务机制，这 4 个命令的作用，我总结在下面的表中，你可以再看下。</p>
<p><img src="/images/redis/acid-01.png" alt="img.png"></p>
<p>事务的 ACID 属性是我们使用事务进行正确操作的基本要求。通过这节课的分析，我们了解到了，Redis 的事务机制可以保证一致性和隔离性，但是无法保证持久性。不过，因为 Redis 本身是内存数据库，持久性并不是一个必须的属性，我们更加关注的还是原子性、一致性和隔离性这三个属性。</p>
<p>原子性的情况比较复杂，只有当事务中使用的命令语法有误时，原子性得不到保证，在其它情况下，事务都可以原子性执行。</p>
<p>所以，我给你一个小建议：严格按照 Redis 的命令规范进行程序开发，并且通过 code review 确保命令的正确性。这样一来，Redis 的事务机制就能被应用在实践中，保证多操作的正确执行。</p>
<h3 id="总结2-25"><a href="#总结2-25" class="headerlink" title="总结2"></a>总结2</h3><p>1、作者讲了什么？<br>作者通过本文讨论，Redis 是否可以保证 ACID 的事务功能。事务是对数据进行一系列操作。<br>2、作者是怎么把事情说明白的？<br>作者先讨论 事务ACID 属性的要求：然后作者说明了 Redis 的 API ：MULTI 和 EXEC 是如何完成事务的；完成说明后，作者开始针对事务的每个特性，讨论 Redis 是否已经完成达成。<br>2.1 原子性。原子性的保证分三种情况<br>2.1.1 队列中有命令存在错误，队列清空；（可保证原子）<br>2.1.2 队列中命令到执行的时候才被发现有错误，不会滚，执行多少算多少；（不保证原子）<br>2.1.3 EXEC 时， Redis 实例发生故障。这个涉及到日志，AOF 的 redis-check-aof 可以发现没执行完成的操作，进而清除；（可以保证原子）<br>2.2 一致性。作者分三种情况说明，并且确认都可以提供一致性。<br>2.3 隔离性。WATCH 机制提供事务隔离性。<br>2.4 持久性。Redis 任何时候都无法提供持久性保障。</p>
<p>3、为了讲明白，作者讲了哪些要点？哪些是亮点？<br>在 Redis 的事务上，作者通过 三种情况 ，分别说明了 Redis 是否满足 ACID 特性，这个划分方法是一个亮点；</p>
<p>4、对于作者所讲，我有哪些发散性思考？<br>Redis 始终坚持是一个高性能的内存数据库，并没有因为事务的重要性而放弃这一个宗旨，故在内存中实现了隔离性，一致性，有条件原子性，不实现持久性。这个也可以放映出 Redis 的定位和一般数据库 MySQL 是不一样的；</p>
<p>5、在未来哪些场景，我可以使用它？<br>在高并发，竞争环境下，需要保证数据正确时，可以考虑 Redis 的事务性实现。</p>
<h3 id="问题1-16"><a href="#问题1-16" class="headerlink" title="问题1"></a>问题1</h3><p>按照惯例，我给你提个小问题，在执行事务时，如果 Redis 实例发生故障，而 Redis 使用了 RDB 机制，那么，事务的原子性还能得到保证吗？</p>
<h3 id="解答1-16"><a href="#解答1-16" class="headerlink" title="解答1"></a>解答1</h3><p>在执行事务时，如果 Redis 实例发生故障，而 Redis 使用的 RDB 机制，事务的原子性还能否得到保证？</p>
<p>我觉得是可以保证原子性的。</p>
<p>如果一个事务只执行了一半，然后 Redis 实例故障宕机了，由于 RDB 不会在事务执行时执行，所以 RDB 文件中不会记录只执行了一部分的结果数据。之后用 RDB 恢复实例数据，恢复的还是事务之前的数据。但 RDB 本身是快照持久化，所以会存在数据丢失，丢失的是距离上一次 RDB 之间的所有更改操作。</p>
<p>关于 Redis 事务的使用，有几个细节我觉得有必要补充下，关于 Pipeline 和 WATCH 命令的使用。</p>
<p>1、在使用事务时，建议配合 Pipeline 使用。</p>
<p>a) 如果不使用 Pipeline，客户端是先发一个 MULTI 命令到服务端，客户端收到 OK，然后客户端再发送一个个操作命令，客户端依次收到 QUEUED，最后客户端发送 EXEC 执行整个事务（文章例子就是这样演示的），这样消息每次都是一来一回，效率比较低，而且在这多次操作之间，别的客户端可能就把原本准备修改的值给修改了，所以无法保证隔离性。</p>
<p>b) 而使用 Pipeline 是一次性把所有命令打包好全部发送到服务端，服务端全部处理完成后返回。这么做好的好处，一是减少了来回网络 IO 次数，提高操作性能。二是一次性发送所有命令到服务端，服务端在处理过程中，是不会被别的请求打断的（Redis单线程特性，此时别的请求进不来），这本身就保证了隔离性。我们平时使用的 Redis SDK 在使用开启事务时，一般都会默认开启 Pipeline 的，可以留意观察一下。</p>
<p>2、关于 WATCH 命令的使用场景。</p>
<p>a) 在上面 1-a 场景中，也就是使用了事务命令，但没有配合 Pipeline 使用，如果想要保证隔离性，需要使用 WATCH 命令保证，也就是文章中讲 WATCH 的例子。但如果是 1-b 场景，使用了 Pipeline 一次发送所有命令到服务端，那么就不需要使用 WATCH 了，因为服务端本身就保证了隔离性。</p>
<p>b) 如果事务 + Pipeline 就可以保证隔离性，那 WATCH 还有没有使用的必要？答案是有的。对于一个资源操作为读取、修改、写回这种场景，如果需要保证事物的原子性，此时就需要用到 WATCH 了。例如想要修改某个资源，但需要事先读取它的值，再基于这个值进行计算后写回，如果在这期间担心这个资源被其他客户端修改了，那么可以先 WATCH 这个资源，再读取、修改、写回，如果写回成功，说明其他客户端在这期间没有修改这个资源。如果其他客户端修改了这个资源，那么这个事务操作会返回失败，不会执行，从而保证了原子性。</p>
<p>细节比较多，如果不太好理解，最好亲自动手试一下。</p>
<h2 id="Redis主从同步与故障切换，有哪些坑？"><a href="#Redis主从同步与故障切换，有哪些坑？" class="headerlink" title="Redis主从同步与故障切换，有哪些坑？"></a>Redis主从同步与故障切换，有哪些坑？</h2><h3 id="总结1-27"><a href="#总结1-27" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我们学习了 Redis 主从库同步时可能出现的 3 个坑，分别是主从数据不一致、读取到过期数据和不合理配置项导致服务挂掉。</p>
<p>为了方便你掌握，我把这些坑的成因和解决方法汇总在下面的这张表中，你可以再回顾下。</p>
<p><img src="/images/redis/master-slave-01.png" alt="img.png"></p>
<p>最后，关于主从库数据不一致的问题，我还想再给你提一个小建议：Redis 中的 slave-serve-stale-data 配置项设置了从库能否处理数据读写命令，你可以把它设置为 no。这样一来，从库只能服务 INFO、SLAVEOF 命令，这就可以避免在从库中读到不一致的数据了。</p>
<p>不过，你要注意下这个配置项和 slave-read-only 的区别，slave-read-only 是设置从库能否处理写命令，slave-read-only 设置为 yes 时，从库只能处理读请求，无法处理写请求，你可不要搞混了。</p>
<h3 id="总结2-26"><a href="#总结2-26" class="headerlink" title="总结2"></a>总结2</h3><h3 id="问题1-17"><a href="#问题1-17" class="headerlink" title="问题1"></a>问题1</h3><p>按照惯例，我给你提个小问题，我们把 slave-read-only 设置为 no，让从库也能直接删除数据，以此来避免读到过期数据，你觉得，这是一个好方法吗？</p>
<h3 id="解答1-17"><a href="#解答1-17" class="headerlink" title="解答1"></a>解答1</h3><p>把 slave-read-only 设置为 no，让从库也能直接删除数据，以此来避免读到过期数据，这种方案是否可行？</p>
<p>我个人觉得这个问题有些歧义，因为尽管把 slave-read-only 设置为 no，其实 slave 也不会主动过期删除从 master 同步过来的数据的。</p>
<p>我猜老师想问的应该是：假设让 slave 也可以自动删除过期数据，是否可以保证主从库的一致性？</p>
<p>其实这样也无法保证，例如以下场景：</p>
<p>1、主从同步存在网络延迟。例如 master 先执行 SET key 1 10，这个 key 同步到了 slave，此时 key 在主从库都是 10s 后过期，之后这个 key 还剩 1s 过期时，master 又执行了 expire key 60，重设这个 key 的过期时间。但 expire 命令向 slave 同步时，发生了网络延迟并且超过了 1s，如果 slave 可以自动删除过期 key，那么这个 key 正好达到过期时间，就会被 slave 删除了，之后 slave 再收到 expire 命令时，执行会失败。最后的结果是这个 key 在 slave 上丢失了，主从库发生了不一致。</p>
<p>2、主从机器时钟不一致。同样 master 执行 SET key 1 10，然后把这个 key 同步到 slave，但是此时 slave 机器时钟如果发生跳跃，优先把这个 key 过期删除了，也会发生上面说的不一致问题。</p>
<p>所以 Redis 为了保证主从同步的一致性，不会让 slave 自动删除过期 key，而只在 master 删除过期 key，之后 master 会向 slave 发送一个 DEL，slave 再把这个 key 删除掉，这种方式可以解决主从网络延迟和机器时钟不一致带来的影响。</p>
<p>再解释一下 slave-read-only 的作用，它主要用来控制 slave 是否可写，但是否主动删除过期 key，根据 Redis 版本不同，执行逻辑也不同。</p>
<p>1、如果版本低于 Redis 4.0，slave-read-only 设置为 no，此时 slave 允许写入数据，但如果 key 设置了过期时间，那么这个 key 过期后，虽然在 slave 上查询不到了，但并不会在内存中删除，这些过期 key 会一直占着 Redis 内存无法释放。</p>
<p>2、Redis 4.0 版本解决了上述问题，在 slave 写入带过期时间的 key，slave 会记下这些 key，并且在后台定时检测这些 key 是否已过期，过期后从内存中删除。</p>
<p>但是请注意，这 2 种情况，slave 都不会主动删除由 <em>master 同步过来带有过期时间的 key</em>。也就是 master 带有过期时间的 key，什么时候删除由 master 自己维护，slave 不会介入。如果 slave 设置了 slave-read-only = no，而且是 4.0+ 版本，slave 也只维护直接向自己写入 的带有过期的 key，过期时只删除这些 key。</p>
<p>另外，我还能想到的主从同步的 2 个问题:</p>
<p>1、主从库设置的 maxmemory 不同，如果 slave 比 master 小，那么 slave 内存就会优先达到 maxmemroy，然后开始淘汰数据，此时主从库也会产生不一致。</p>
<p>2、如果主从同步的 client-output-buffer-limit 设置过小，并且 master 数据量很大，主从全量同步时可能会导致 buffer 溢出，溢出后主从全量同步就会失败。如果主从集群配置了哨兵，那么哨兵会让 slave 继续向 master 发起全量同步请求，然后 buffer 又溢出同步失败，如此反复，会形成复制风暴，这会浪费 master 大量的 CPU、内存、带宽资源，也会让 master 产生阻塞的风险。</p>
<p>感谢Kaito同学的回复和详细分析！很赞！</p>
<p>我也解释下，到时出这道题的一个考虑出发点。</p>
<p>这道题我其实是想问大家，假设从库也能直接删除过期数据的话，是不是一个好方法。其实，是想提醒下同学们，主从复制中的增删改都需要在主库执行，即使从库能做删除，也不要在从库删除。否则会造成数据不一致。例如，假设主从库上都能做写操作的话，主从库上有a:stock的键，客户端A给主库发送一个SET命令，修改a:stock的值，客户端B给从库发送了一个SET命令，也修改a:stock的值，此时，相同键的值就不一样了。所以，让从库可以做写操作会造成主从数据不一致。</p>
<h2 id="脑裂：一次奇怪的数据丢失"><a href="#脑裂：一次奇怪的数据丢失" class="headerlink" title="脑裂：一次奇怪的数据丢失"></a>脑裂：一次奇怪的数据丢失</h2><h3 id="总结1-28"><a href="#总结1-28" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我们学习了主从切换时可能遇到的脑裂问题。脑裂是指在主从集群中，同时有两个主库都能接收写请求。在 Redis 的主从切换过程中，如果发生了脑裂，客户端数据就会写入到原主库，如果原主库被降为从库，这些新写入的数据就丢失了。</p>
<p>脑裂发生的原因主要是原主库发生了假故障，我们来总结下假故障的两个原因。</p>
<p>和主库部署在同一台服务器上的其他程序临时占用了大量资源（例如 CPU 资源），导致主库资源使用受限，短时间内无法响应心跳。其它程序不再使用资源时，主库又恢复正常。<br>主库自身遇到了阻塞的情况，例如，处理 bigkey 或是发生内存 swap（你可以复习下第 19 讲中总结的导致实例阻塞的原因），短时间内无法响应心跳，等主库阻塞解除后，又恢复正常的请求处理了。</p>
<p>为了应对脑裂，你可以在主从集群部署时，通过合理地配置参数 min-slaves-to-write 和 min-slaves-max-lag，来预防脑裂的发生。</p>
<p>在实际应用中，可能会因为网络暂时拥塞导致从库暂时和主库的 ACK 消息超时。在这种情况下，并不是主库假故障，我们也不用禁止主库接收请求。</p>
<p>所以，我给你的建议是，假设从库有 K 个，可以将 min-slaves-to-write 设置为 K/2+1（如果 K 等于 1，就设为 1），将 min-slaves-max-lag 设置为十几秒（例如 10～20s），在这个配置下，如果有一半以上的从库和主库进行的 ACK 消息延迟超过十几秒，我们就禁止主库接收客户端写请求。</p>
<p>这样一来，我们可以避免脑裂带来数据丢失的情况，而且，也不会因为只有少数几个从库因为网络阻塞连不上主库，就禁止主库接收请求，增加了系统的鲁棒性。</p>
<h3 id="总结2-27"><a href="#总结2-27" class="headerlink" title="总结2"></a>总结2</h3><h3 id="问题1-18"><a href="#问题1-18" class="headerlink" title="问题1"></a>问题1</h3><p>按照惯例，我给你提个小问题，假设我们将 min-slaves-to-write 设置为 1，min-slaves-max-lag 设置为 15s，哨兵的 down-after-milliseconds 设置为 10s，哨兵主从切换需要 5s。主库因为某些原因卡住了 12s，此时，还会发生脑裂吗？主从切换完成后，数据会丢失吗？</p>
<h3 id="解答1-18"><a href="#解答1-18" class="headerlink" title="解答1"></a>解答1</h3><p>假设我们将 min-slaves-to-write 设置为 1，min-slaves-max-lag 设置为 15s，哨兵的 down-after-milliseconds 设置为 10s，哨兵主从切换需要 5s。主库因为某些原因卡住了 12s，此时，还会发生脑裂吗？主从切换完成后，数据会丢失吗？</p>
<p>主库卡住 12s，达到了哨兵设定的切换阈值，所以哨兵会触发主从切换。但哨兵切换的时间是 5s，也就是说哨兵还未切换完成，主库就会从阻塞状态中恢复回来，而且也没有触发 min-slaves-max-lag 阈值，所以主库在哨兵切换剩下的 3s 内，依旧可以接收客户端的写操作，如果这些写操作还未同步到从库，哨兵就把从库提升为主库了，那么此时也会出现脑裂的情况，之后旧主库降级为从库，重新同步新主库的数据，新主库也会发生数据丢失。</p>
<p>由此也可以看出，即使 Redis 配置了 min-slaves-to-write 和 min-slaves-max-lag，当脑裂发生时，还是无法严格保证数据不丢失，它只能是尽量减少数据的丢失。</p>
<p>其实在这种情况下，新主库之所以会发生数据丢失，是因为旧主库从阻塞中恢复过来后，收到的写请求还没同步到从库，从库就被哨兵提升为主库了。如果哨兵在提升从库为新主库前，主库及时把数据同步到从库了，那么从库提升为主库后，也不会发生数据丢失。但这种临界点的情况还是有发生的可能性，因为 Redis 本身不保证主从同步的强一致。</p>
<p>还有一种发生脑裂的情况，就是网络分区：主库和客户端、哨兵和从库被分割成了 2 个网络，主库和客户端处在一个网络中，从库和哨兵在另一个网络中，此时哨兵也会发起主从切换，出现 2 个主库的情况，而且客户端依旧可以向旧主库写入数据。等网络恢复后，主库降级为从库，新主库丢失了这期间写操作的数据。</p>
<p>脑裂产生问题的本质原因是，Redis 主从集群内部没有通过共识算法，来维护多个节点数据的强一致性。它不像 Zookeeper 那样，每次写请求必须大多数节点写成功后才认为成功。当脑裂发生时，Zookeeper 主节点被孤立，此时无法写入大多数节点，写请求会直接返回失败，因此它可以保证集群数据的一致性。</p>
<p>另外关于 min-slaves-to-write，有一点也需要注意：如果只有 1 个从库，当把 min-slaves-to-write 设置为 1 时，在运维时需要小心一些，当日常对从库做维护时，例如更换从库的实例，需要先添加新的从库，再移除旧的从库才可以，或者使用 config set 修改 min-slaves-to-write 为 0 再做操作，否则会导致主库拒绝写，影响到业务。</p>
<h2 id="Codis-VS-Redis-Cluster：我该选择哪一个集群方案？"><a href="#Codis-VS-Redis-Cluster：我该选择哪一个集群方案？" class="headerlink" title="Codis VS Redis Cluster：我该选择哪一个集群方案？"></a>Codis VS Redis Cluster：我该选择哪一个集群方案？</h2><h3 id="总结1-29"><a href="#总结1-29" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我们学习了 Redis 切片集群的 Codis 方案。Codis 集群包含 codis server、codis proxy、Zookeeper、codis dashboard 和 codis fe 这四大类组件。我们再来回顾下它们的主要功能。</p>
<ul>
<li>codis proxy 和 codis server 负责处理数据读写请求，其中，codis proxy 和客户端连接，接收请求，并转发请求给 codis server，而 codis server 负责具体处理请求。</li>
<li>codis dashboard 和 codis fe 负责集群管理，其中，codis dashboard 执行管理操作，而 codis fe 提供 Web 管理界面。</li>
<li>Zookeeper 集群负责保存集群的所有元数据信息，包括路由表、proxy 实例信息等。这里，有个地方需要你注意，除了使用 Zookeeper，Codis 还可以使用 etcd 或本地文件系统保存元数据信息。</li>
</ul>
<p>关于 Codis 和 Redis Cluster 的选型考虑，我从稳定性成熟度、客户端兼容性、Redis 新特性使用以及数据迁移性能四个方面给你提供了建议，希望能帮助到你。</p>
<p>最后，我再给你提供一个 Codis 使用上的小建议：当你有多条业务线要使用 Codis 时，可以启动多个 codis dashboard，每个 dashboard 管理一部分 codis server，同时，再用一个 dashboard 对应负责一个业务线的集群管理，这样，就可以做到用一个 Codis 集群实现多条业务线的隔离管理了。</p>
<h3 id="总结2-28"><a href="#总结2-28" class="headerlink" title="总结2"></a>总结2</h3><h3 id="问题1-19"><a href="#问题1-19" class="headerlink" title="问题1"></a>问题1</h3><p>按照惯例，我会给你提个小问题。假设 Codis 集群中保存的 80% 的键值对都是 Hash 类型，每个 Hash 集合的元素数量在 10 万～20 万个，每个集合元素的大小是 2KB。你觉得，迁移一个这样的 Hash 集合数据，会对 Codis 的性能造成影响吗？</p>
<h3 id="解答1-19"><a href="#解答1-19" class="headerlink" title="解答1"></a>解答1</h3><p>假设 Codis 集群中保存的 80% 的键值对都是 Hash 类型，每个 Hash 集合的元素数量在 10 万 ～ 20 万个，每个集合元素的大小是 2KB。迁移一个这样的 Hash 集合数据，是否会对 Codis 的性能造成影响？</p>
<p>不会有性能影响。</p>
<p>Codis 在迁移数据时，设计的方案可以保证迁移性能不受影响。</p>
<p>1、异步迁移：源节点把迁移的数据发送给目标节点后就返回，之后接着处理客户端请求，这个阶段不会长时间阻塞源节点。目标节点加载迁移的数据成功后，向源节点发送 ACK 命令，告知其迁移成功。</p>
<p>2、源节点异步释放 key：源节点收到目标节点 ACK 后，在源实例删除这个 key，释放 key 内存的操作，会放到后台线程中执行，不会阻塞源实例。（没错，Codis 比 Redis 更早地支持了 lazy-free，只不过只用在了数据迁移中）。</p>
<p>3、小对象序列化传输：小对象依旧采用序列化方式迁移，节省网络流量。</p>
<p>4、bigkey 分批迁移：bigkey 拆分成一条条命令，打包分批迁移（利用了 Pipeline 的优势），提升迁移速度。</p>
<p>5、一次迁移多个 key：一次发送多个 key 进行迁移，提升迁移效率。</p>
<p>6、迁移流量控制：迁移时会控制缓冲区大小，避免占满网络带宽。</p>
<p>7、bigkey 迁移原子性保证（兼容迁移失败情况）：迁移前先发一个 DEL 命令到目标节点（重试可保证幂等性），然后把 bigkey 拆分成一条条命令，并设置一个临时过期时间（防止迁移失败在目标节点遗留垃圾数据），迁移成功后在目标节点设置真实的过期时间。</p>
<p>Codis 在数据迁移方面要比 Redis Cluster 做得更优秀，而且 Codis 还带了一个非常友好的运维界面，方便 DBA 执行增删节点、主从切换、数据迁移等操作。</p>
<p>我当时在对 Codis 开发新的组件时，被 Codis 的优秀设计深深折服。当然，它的缺点也很明显，组件比较多，部署略复杂。另外，因为是基于 Redis 3.2.8 做的二次开发，所以升级 Redis Server 比较困难，新特性也就自然无法使用。</p>
<p>现在 Codis 已经不再维护，但是作为国人开发的 Redis 集群解决方案，其设计思想还是非常值得学习的。也推荐 Go 开发者，读一读 Codis 源码，质量非常高，对于 Go 语言的进阶也会有很大收获！</p>
<h2 id="Redis支撑秒杀场景的关键技术和实践都有哪些？"><a href="#Redis支撑秒杀场景的关键技术和实践都有哪些？" class="headerlink" title="Redis支撑秒杀场景的关键技术和实践都有哪些？"></a>Redis支撑秒杀场景的关键技术和实践都有哪些？</h2><h3 id="总结1-30"><a href="#总结1-30" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我们学习了 Redis 在秒杀场景中的具体应用。秒杀场景有 2 个负载特征，分别是瞬时高并发请求和读多写少。Redis 良好的高并发处理能力，以及高效的键值对读写特性，正好可以满足秒杀场景的需求。</p>
<p>在秒杀场景中，我们可以通过前端 CDN 和浏览器缓存拦截大量秒杀前的请求。在实际秒杀活动进行时，库存查验和库存扣减是承受巨大并发请求压力的两个操作，同时，这两个操作的执行需要保证原子性。Redis 的原子操作、分布式锁这两个功能特性可以有效地来支撑秒杀场景的需求。</p>
<p>当然，对于秒杀场景来说，只用 Redis 是不够的。秒杀系统是一个系统性工程，Redis 实现了对库存查验和扣减这个环节的支撑，除此之外，还有 4 个环节需要我们处理好。</p>
<ol>
<li>前端静态页面的设计。秒杀页面上能静态化处理的页面元素，我们都要尽量静态化，这样可以充分利用 CDN 或浏览器缓存服务秒杀开始前的请求。</li>
<li>请求拦截和流控。在秒杀系统的接入层，对恶意请求进行拦截，避免对系统的恶意攻击，例如使用黑名单禁止恶意 IP 进行访问。如果 Redis 实例的访问压力过大，为了避免实例崩溃，我们也需要在接入层进行限流，控制进入秒杀系统的请求数量。</li>
<li>库存信息过期时间处理。Redis 中保存的库存信息其实是数据库的缓存，为了避免缓存击穿问题，我们不要给库存信息设置过期时间。</li>
<li>数据库订单异常处理。如果数据库没能成功处理订单，可以增加订单重试功能，保证订单最终能被成功处理。</li>
</ol>
<p>最后，我也再给你一个小建议：秒杀活动带来的请求流量巨大，我们需要把秒杀商品的库存信息用单独的实例保存，而不要和日常业务系统的数据保存在同一个实例上，这样可以避免干扰业务系统的正常运行。</p>
<h3 id="总结2-29"><a href="#总结2-29" class="headerlink" title="总结2"></a>总结2</h3><h3 id="问题1-20"><a href="#问题1-20" class="headerlink" title="问题1"></a>问题1</h3><p>按照惯例，我给你提个小问题，假设一个商品的库存量是 800，我们使用一个包含了 4 个实例的切片集群来服务秒杀请求。我们让每个实例各自维护库存量 200，然后，客户端的秒杀请求可以分发到不同的实例上进行处理，你觉得这是一个好方法吗？</p>
<h3 id="解答1-20"><a href="#解答1-20" class="headerlink" title="解答1"></a>解答1</h3><p>使用多个实例的切片集群来分担秒杀请求，是否是一个好方法？</p>
<p>使用切片集群分担秒杀请求，可以降低每个实例的请求压力，前提是秒杀请求可以平均打到每个实例上，否则会出现秒杀请求倾斜的情况，反而会增加某个实例的压力，而且会导致商品没有全部卖出的情况。</p>
<p>但用切片集群分别存储库存信息，缺点是如果需要向用户展示剩余库存，要分别查询多个切片，最后聚合结果后返回给客户端。这种情况下，建议不展示剩余库存信息，直接针对秒杀请求返回是否秒杀成功即可。</p>
<p>秒杀系统最重要的是，把大部分请求拦截在最前面，只让很少请求能够真正进入到后端系统，降低后端服务的压力，常见的方案包括：页面静态化（推送到CDN）、网关恶意请求拦截、请求分段放行、缓存校验和扣减库存、消息队列处理订单。</p>
<p>另外，为了不影响其他业务系统，秒杀系统最好和业务系统隔离，主要包括应用隔离、部署隔离、数据存储隔离。</p>
<h2 id="数据分布优化：如何应对数据倾斜？"><a href="#数据分布优化：如何应对数据倾斜？" class="headerlink" title="数据分布优化：如何应对数据倾斜？"></a>数据分布优化：如何应对数据倾斜？</h2><h3 id="总结1-31"><a href="#总结1-31" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我向你介绍了数据倾斜的两种情况：数据量倾斜和数据访问倾斜。</p>
<p>造成数据量倾斜的原因主要有三个：</p>
<ol>
<li>数据中有 bigkey，导致某个实例的数据量增加；</li>
<li>Slot 手工分配不均，导致某个或某些实例上有大量数据；</li>
<li>使用了 Hash Tag，导致数据集中到某些实例上。</li>
</ol>
<p>而数据访问倾斜的主要原因就是有热点数据存在，导致大量访问请求集中到了热点数据所在的实例上。</p>
<p>为了应对数据倾斜问题，我给你介绍了四个方法，也分别对应了造成数据倾斜的四个原因。我把它们总结在下表中，你可以看下。</p>
<p><img src="/images/redis/q-a-01.png" alt="img.png"></p>
<p>当然，如果已经发生了数据倾斜，我们可以通过数据迁移来缓解数据倾斜的影响。Redis Cluster 和 Codis 集群都提供了查看 Slot 分配和手工迁移 Slot 的命令，你可以把它们应用起来。</p>
<p>最后，关于集群的实例资源配置，我再给你一个小建议：在构建切片集群时，尽量使用大小配置相同的实例（例如实例内存配置保持相同），这样可以避免因实例资源不均衡而在不同实例上分配不同数量的 Slot。</p>
<h3 id="总结2-30"><a href="#总结2-30" class="headerlink" title="总结2"></a>总结2</h3><h3 id="问题1-21"><a href="#问题1-21" class="headerlink" title="问题1"></a>问题1</h3><p>按照惯例，我给你提个小问题，在有数据访问倾斜时，如果热点数据突然过期了，而 Redis 中的数据是缓存，数据的最终值保存在后端数据库，此时会发生什么问题？</p>
<h3 id="解答1-21"><a href="#解答1-21" class="headerlink" title="解答1"></a>解答1</h3><p>在有数据访问倾斜时，如果热点数据突然过期了，而 Redis 中的数据是缓存，数据的最终值保存在后端数据库，此时会发生什么问题？</p>
<p>此时会发生缓存击穿，热点请求会直接打到后端数据库上，数据库的压力剧增，可能会压垮数据库。</p>
<p>Redis 的很多性能问题，例如导致 Redis 阻塞的场景：bigkey、集中过期、大实例 RDB 等等，这些场景都与数据倾斜类似，都是因为数据集中、处理逻辑集中导致的耗时变长。其解决思路也类似，都是把集中变分散，例如 bigkey 拆分为小 key、单个大实例拆分为切片集群等。</p>
<p>从软件架构演进过程来看，从单机到分布式，再到后来出现的消息队列、负载均衡等技术，也都是为了将请求压力分散开，避免数据集中、请求集中的问题，这样既可以让系统承载更大的请求量，同时还保证了系统的稳定性。</p>
<h2 id="通信开销：限制Redis-Cluster规模的关键因素"><a href="#通信开销：限制Redis-Cluster规模的关键因素" class="headerlink" title="通信开销：限制Redis Cluster规模的关键因素"></a>通信开销：限制Redis Cluster规模的关键因素</h2><h3 id="总结1-32"><a href="#总结1-32" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我向你介绍了 Redis Cluster 实例间以 Gossip 协议进行通信的机制。Redis Cluster 运行时，各实例间需要通过 PING、PONG 消息进行信息交换，这些心跳消息包含了当前实例和部分其它实例的状态信息，以及 Slot 分配信息。这种通信机制有助于 Redis Cluster 中的所有实例都拥有完整的集群状态信息。</p>
<p>但是，随着集群规模的增加，实例间的通信量也会增加。如果我们盲目地对 Redis Cluster 进行扩容，就可能会遇到集群性能变慢的情况。这是因为，集群中大规模的实例间心跳消息会挤占集群处理正常请求的带宽。而且，有些实例可能因为网络拥塞导致无法及时收到 PONG 消息，每个实例在运行时会周期性地（每秒 10 次）检测是否有这种情况发生，一旦发生，就会立即给这些 PONG 消息超时的实例发送心跳消息。集群规模越大，网络拥塞的概率就越高，相应的，PONG 消息超时的发生概率就越高，这就会导致集群中有大量的心跳消息，影响集群服务正常请求。</p>
<p>最后，我也给你一个小建议，虽然我们可以通过调整 cluster-node-timeout 配置项减少心跳消息的占用带宽情况，但是，在实际应用中，如果不是特别需要大容量集群，我建议你把 Redis Cluster 的规模控制在 400~500 个实例。</p>
<p>假设单个实例每秒能支撑 8 万请求操作（8 万 QPS），每个主实例配置 1 个从实例，那么，400~ 500 个实例可支持 1600 万~2000 万 QPS（200/250 个主实例 *8 万 QPS=1600/2000 万 QPS），这个吞吐量性能可以满足不少业务应用的需求。</p>
<h3 id="总结2-31"><a href="#总结2-31" class="headerlink" title="总结2"></a>总结2</h3><h3 id="问题1-22"><a href="#问题1-22" class="headerlink" title="问题1"></a>问题1</h3><p>按照惯例，我给你提个小问题，如果我们采用跟 Codis 保存 Slot 分配信息相类似的方法，把集群实例状态信息和 Slot 分配信息保存在第三方的存储系统上（例如 Zookeeper），这种方法会对集群规模产生什么影响吗？</p>
<h3 id="解答1-22"><a href="#解答1-22" class="headerlink" title="解答1"></a>解答1</h3><p>如果采用类似 Codis 保存 Slot 信息的方法，把集群实例状态信息和 Slot 分配信息保存在第三方的存储系统上（例如Zookeeper），这种方法会对集群规模产生什么影响？</p>
<p>由于 Redis Cluster 每个实例需要保存集群完整的路由信息，所以每增加一个实例，都需要多一次与其他实例的通信开销，如果有 N 个实例，集群就要存储 N 份完整的路由信息。而如果像 Codis 那样，把 Slot 信息存储在第三方存储上，那么无论集群实例有多少，这些信息在第三方存储上只会存储一份，也就是说，集群内的通信开销，不会随着实例的增加而增长。当集群需要用到这些信息时，直接从第三方存储上获取即可。</p>
<p>Redis Cluster 把所有功能都集成在了 Redis 实例上，包括路由表的交换、实例健康检查、故障自动切换等等，这么做的好处是，部署和使用非常简单，只需要部署实例，然后让多个实例组成切片集群即可提供服务。但缺点也很明显，每个实例负责的工作比较重，如果看源码实现，也不太容易理解，而且如果其中一个功能出现 bug，只能升级整个 Redis Server 来解决。</p>
<p>而 Codis 把这些功能拆分成多个组件，每个组件负责的工作都非常纯粹，codis-proxy 负责转发请求，codis-dashboard 负责路由表的分发、数据迁移控制，codis-server 负责数据存储和数据迁移，哨兵负责故障自动切换，codis-fe 负责提供友好的运维界面，每个组件都可以单独升级，这些组件相互配合，完成整个集群的对外服务。但其缺点是组件比较多，部署和维护比较复杂。</p>
<p>在实际的业务场景下，我觉得应该尽量避免非常大的分片集群，太大的分片集群一方面存在通信开销大的问题，另一方面也会导致集群变得越来越难以维护。而且当集群出问题时，对业务的影响也比较集中。建议针对不同的业务线、业务模块，单独部署不同的分片集群，这样方便运维和管理的同时，出现问题也只会影响某一个业务模块。</p>
<h2 id="Redis-6-0的新特性：多线程、客户端缓存与安全"><a href="#Redis-6-0的新特性：多线程、客户端缓存与安全" class="headerlink" title="Redis 6.0的新特性：多线程、客户端缓存与安全"></a>Redis 6.0的新特性：多线程、客户端缓存与安全</h2><h3 id="总结1-33"><a href="#总结1-33" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我向你介绍了 Redis 6.0 的新特性，我把这些新特性总结在了一张表里，你可以再回顾巩固下。</p>
<p><img src="/images/redis/redis6-01.png" alt="img.png"></p>
<p>最后，我也再给你一个小建议：因为 Redis 6.0 是刚刚推出的，新的功能特性还需要在实际应用中进行部署和验证，所以，如果你想试用 Redis 6.0，可以尝试先在非核心业务上使用 Redis 6.0，一方面可以验证新特性带来的性能或功能优势，另一方面，也可以避免因为新特性不稳定而导致核心业务受到影响。</p>
<h3 id="总结2-32"><a href="#总结2-32" class="headerlink" title="总结2"></a>总结2</h3><h3 id="问题1-23"><a href="#问题1-23" class="headerlink" title="问题1"></a>问题1</h3><p>你觉得，Redis 6.0 的哪个或哪些新特性会对你有帮助呢？</p>
<h3 id="解答1-23"><a href="#解答1-23" class="headerlink" title="解答1"></a>解答1</h3><p>Redis 6.0 的哪些新特性帮助最大？</p>
<p>我觉得 Redis 6.0 提供的多 IO 线程和客户端缓存这两大特性，对于我们使用 Redis 帮助最大。</p>
<p>多 IO 线程可以让 Redis 在并发量非常大时，让其性能再上一个台阶，性能提升近 1 倍，对于单机 Redis 性能要求更高的业务场景，非常有帮助。</p>
<p>而客户端缓存可以让 Redis 的数据缓存在客户端，相当于每个应用进程多了一个本地缓存，Redis 数据没有变化时，业务直接在应用进程内就能拿到数据，这不仅节省了网络带宽，降低了 Redis 的请求压力，还充分利用了业务应用的资源，对应用性能的提升也非常大。</p>
<h2 id="Redis的下一步：基于NVM内存的实践"><a href="#Redis的下一步：基于NVM内存的实践" class="headerlink" title="Redis的下一步：基于NVM内存的实践"></a>Redis的下一步：基于NVM内存的实践</h2><h3 id="总结1-34"><a href="#总结1-34" class="headerlink" title="总结1"></a>总结1</h3><p>这节课我向你介绍了 NVM 的三大特点：性能高、容量大、数据可以持久化保存。软件系统可以像访问传统 DRAM 内存一样，访问 NVM 内存。目前，Intel 已经推出了 NVM 内存产品 Optane AEP。</p>
<p>这款 NVM 内存产品给软件提供了两种使用模式，分别是 Memory 模式和 App Direct 模式。在 Memory 模式时，Redis 可以利用 NVM 容量大的特点，实现大容量实例，保存更多数据。在使用 App Direct 模式时，Redis 可以直接在持久化内存上进行数据读写，在这种情况下，Redis 不用再使用 RDB 或 AOF 文件了，数据在机器掉电后也不会丢失。而且，实例可以直接使用持久化内存上的数据进行恢复，恢复速度特别快。</p>
<p>NVM 内存是近年来存储设备领域中一个非常大的变化，它既能持久化保存数据，还能像内存一样快速访问，这必然会给当前基于 DRAM 和硬盘的系统软件优化带来新的机遇。现在，很多互联网大厂已经开始使用 NVM 内存了，希望你能够关注这个重要趋势，为未来的发展做好准备。</p>
<h3 id="总结2-33"><a href="#总结2-33" class="headerlink" title="总结2"></a>总结2</h3><h3 id="问题1-24"><a href="#问题1-24" class="headerlink" title="问题1"></a>问题1</h3><p>按照惯例，我给你提个小问题，你觉得有了持久化内存后，还需要 Redis 主从集群吗?</p>
<h3 id="解答1-24"><a href="#解答1-24" class="headerlink" title="解答1"></a>解答1</h3><p>有了持久化内存，是否还需要 Redis 主从集群？</p>
<p>肯定还是需要主从集群的。持久化内存只能解决存储容量和数据恢复问题，关注点在于单个实例。</p>
<p>而 Redis 主从集群，既可以提升集群的访问性能，还能提高集群的可靠性。</p>
<p>例如部署多个从节点，采用读写分离的方式，可以分担单个实例的请求压力，提升集群的访问性能。而且当主节点故障时，可以提升从节点为新的主节点，降低故障对应用的影响。</p>
<p>两者属于不同维度的东西，互不影响。</p>
<h2 id="Redis有哪些好用的运维工具？"><a href="#Redis有哪些好用的运维工具？" class="headerlink" title="Redis有哪些好用的运维工具？"></a>Redis有哪些好用的运维工具？</h2><h3 id="总结1-35"><a href="#总结1-35" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我给你介绍了几种 Redis 的运维工具。</p>
<p>我们先了解了 Redis 的 INFO 命令，这个命令是监控工具的基础，监控工具都会基于 INFO 命令提供的信息进行二次加工。我们还学习了 3 种用来监控 Redis 实时运行状态的运维工具，分别是 Redis-exporter、redis-stat 和 Redis Live。</p>
<p>关于数据迁移，我们既可以使用 Redis-shake 工具，也可以通过 RDB 文件或是 AOF 文件进行迁移。</p>
<p>在运维 Redis 时，刚刚讲到的多款开源工具，已经可以满足我们的不少需求了。但是，有时候，不同业务线对 Redis 运维的需求可能并不一样，直接使用现成的开源工具可能无法满足全部需求，在这种情况下，建议你基于开源工具进行二次开发或是自研，从而更好地满足业务使用需求。</p>
<h3 id="总结2-34"><a href="#总结2-34" class="headerlink" title="总结2"></a>总结2</h3><h3 id="问题1-25"><a href="#问题1-25" class="headerlink" title="问题1"></a>问题1</h3><p>按照惯例，我给你提个小问题：你在实际应用中还使用过什么好的运维工具吗？</p>
<h3 id="解答1-25"><a href="#解答1-25" class="headerlink" title="解答1"></a>解答1</h3><p>老师这节课讲的工具很实用。</p>
<p>平时我们遇到的 Redis 变慢问题，有时觉得很难定位原因，其实是因为我们没有做好完善的监控。</p>
<p>Redis INFO 信息看似简单，但是这些信息记录着 Redis 运行时的各种状态数据，如果我们把这些数据采集到并监控到位，80% 的异常情况能在第一时间发现。</p>
<p>机器的 CPU、内存、网络、磁盘，都影响着 Redis 的性能。</p>
<p>监控时我们最好重点关注以下指标：</p>
<p>1、客户端相关：当前连接数、总连接数、输入缓冲大小、OPS</p>
<p>2、CPU相关：主进程 CPU 使用率、子进程 CPU 使用率</p>
<p>3、内存相关：当前内存、峰值内存、内存碎片率</p>
<p>4、网络相关：输入、输出网络流量</p>
<p>5、持久化相关：最后一次 RDB 时间、RDB fork 耗时、最后一次 AOF rewrite 时间、AOF rewrite 耗时</p>
<p>6、key 相关：过期 key 数量、淘汰 key 数量、key 命中率</p>
<p>7、复制相关：主从节点复制偏移量、主库复制缓冲区</p>
<p>能够查询这些指标的当前状态是最基本的，更好的方案是，能够计算出这些指标的波动情况，然后生成动态的图表展示出来，这样当某一刻指标突增时，监控能帮我们快速捕捉到，降低问题定位的难度。</p>
<p>目前业界比较主流的监控系统，都会使用 Prometheus 来做，插件也很丰富，监控报警也方便集成，推荐用起来。</p>
<h2 id="Redis有哪些好用的运维工具？-1"><a href="#Redis有哪些好用的运维工具？-1" class="headerlink" title="Redis有哪些好用的运维工具？"></a>Redis有哪些好用的运维工具？</h2><h3 id="总结1-36"><a href="#总结1-36" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我围绕 Redis 应用时的高性能访问和节省内存空间这两个目标，分别在键值对使用、命令使用和数据保存三方面向你介绍了 11 个规范。</p>
<p>我按照强制、推荐、建议这三个类别，把这些规范分了下类，如下表所示：</p>
<p><img src="/images/redis/tips-01.png" alt="img.png"></p>
<p>我来解释一下这 3 个类别的规范。</p>
<ul>
<li>强制类别的规范：这表示，如果不按照规范内容来执行，就会给 Redis 的应用带来极大的负面影响，例如性能受损。</li>
<li>推荐类别的规范：这个规范的内容能有效提升性能、节省内存空间，或者是增加开发和运维的便捷性，你可以直接应用到实践中。</li>
<li>建议类别的规范：这类规范内容和实际业务应用相关，我只是从我的经历或经验给你一个建议，你需要结合自己的业务场景参考使用。</li>
</ul>
<h3 id="总结2-35"><a href="#总结2-35" class="headerlink" title="总结2"></a>总结2</h3><h3 id="问题1-26"><a href="#问题1-26" class="headerlink" title="问题1"></a>问题1</h3><p>按照惯例，我给你提个小问题，你在日常应用 Redis 时，有遵循过什么好的使用规范吗？</p>
<h3 id="解答1-26"><a href="#解答1-26" class="headerlink" title="解答1"></a>解答1</h3><p>我总结的 Redis 使用规范分为两大方面，主要包括业务层面和运维层面。</p>
<p>业务层面主要面向的业务开发人员：</p>
<p>1、key 的长度尽量短，节省内存空间<br>2、避免 bigkey，防止阻塞主线程<br>3、4.0+版本建议开启 lazy-free<br>4、把 Redis 当作缓存使用，设置过期时间<br>5、不使用复杂度过高的命令，例如SORT、SINTER、SINTERSTORE、ZUNIONSTORE、ZINTERSTORE<br>6、查询数据尽量不一次性查询全量，写入大量数据建议分多批写入<br>7、批量操作建议 MGET/MSET 替代 GET/SET，HMGET/HMSET 替代 HGET/HSET<br>8、禁止使用 KEYS/FLUSHALL/FLUSHDB 命令<br>9、避免集中过期 key<br>10、根据业务场景选择合适的淘汰策略<br>11、使用连接池操作 Redis，并设置合理的参数，避免短连接<br>12、只使用 db0，减少 SELECT 命令的消耗<br>13、读请求量很大时，建议读写分离，写请求量很大，建议使用切片集群</p>
<p>运维层面主要面向的是 DBA 运维人员：</p>
<p>1、按业务线部署实例，避免多个业务线混合部署，出问题影响其他业务<br>2、保证机器有足够的 CPU、内存、带宽、磁盘资源<br>3、建议部署主从集群，并分布在不同机器上，slave 设置为 readonly<br>4、主从节点所部署的机器各自独立，尽量避免交叉部署，对从节点做维护时，不会影响到主节点<br>5、推荐部署哨兵集群实现故障自动切换，哨兵节点分布在不同机器上<br>6、提前做好容量规划，防止主从全量同步时，实例使用内存突增导致内存不足<br>7、做好机器 CPU、内存、带宽、磁盘监控，资源不足时及时报警，任意资源不足都会影响 Redis 性能<br>8、实例设置最大连接数，防止过多客户端连接导致实例负载过高，影响性能<br>9、单个实例内存建议控制在 10G 以下，大实例在主从全量同步、备份时有阻塞风险<br>10、设置合理的 slowlog 阈值，并对其进行监控，slowlog 过多需及时报警<br>11、设置合理的 repl-backlog，降低主从全量同步的概率<br>12、设置合理的 slave client-output-buffer-limit，避免主从复制中断情况发生<br>13、推荐在从节点上备份，不影响主节点性能<br>14、不开启 AOF 或开启 AOF 配置为每秒刷盘，避免磁盘 IO 拖慢 Redis 性能<br>15、调整 maxmemory 时，注意主从节点的调整顺序，顺序错误会导致主从数据不一致<br>16、对实例部署监控，采集 INFO 信息时采用长连接，避免频繁的短连接<br>17、做好实例运行时监控，重点关注 expired_keys、evicted_keys、latest_fork_usec，这些指标短时突增可能会有阻塞风险<br>18、扫描线上实例时，记得设置休眠时间，避免过高 OPS 产生性能抖动</p>
<h2 id="Redis有哪些好用的运维工具？-2"><a href="#Redis有哪些好用的运维工具？-2" class="headerlink" title="Redis有哪些好用的运维工具？"></a>Redis有哪些好用的运维工具？</h2><h3 id="总结1-37"><a href="#总结1-37" class="headerlink" title="总结1"></a>总结1</h3><p>今天这节课，我们学习了微博的 Redis 实践，从中总结了许多经验。总结来说，微博对 Redis 的技术需求可以概括为 3 点，分别是高性能、大容量和易扩展。</p>
<p>为了满足这些需求，除了对 Redis 进行优化，微博也在自研扩展系统，包括基于 RocksDB 的容量扩展机制，以及服务化的 RedisService 集群。</p>
<p>最后，我还想再跟你分享一下我自己的两个感受。</p>
<p>第一个是关于微博做的 RedisService 集群，这个优化方向是大厂平台部门同学的主要工作方向。</p>
<p>业务纵切、平台横切是当前构建大规模系统的基本思路。所谓业务纵切，是指把不同的业务数据单独部署，这样可以避免相互之间的干扰。而平台横切是指，当不同业务线对运行平台具有相同需求时，可以统一起来，通过构建平台级集群服务来进行支撑。Redis 就是典型的多个业务线都需要的基础性服务，所以将其以集群方式服务化，有助于提升业务的整体效率。</p>
<p>第二个是代码实践在我们成长为 Redis 高手过程中的重要作用。</p>
<p>我发现，对 Redis 的二次改造或开发，是大厂的一个必经之路，这和大厂业务多、需求广有密切关系。</p>
<p>微博做的定制化数据结构、RedRock 和 RedisService 都是非常典型的例子。所以，如果我们想要成为 Redis 高手，成为大厂中的一员，那么，先原理后代码，边学习边实践，就是一个不错的方法。原理用来指导代码阅读的聚焦点，而动手实践至关重要，需要我们同时开展部署操作实践和阅读代码实践。纸上得来终觉浅，绝知此事要躬行，希望你不仅重视学习原理，还要真正地用原理来指导实践，提升自己的实战能力。</p>
<h3 id="总结2-36"><a href="#总结2-36" class="headerlink" title="总结2"></a>总结2</h3><h3 id="问题1-27"><a href="#问题1-27" class="headerlink" title="问题1"></a>问题1</h3><p>按照惯例，我给你提个小问题，你在实际应用 Redis 时，有没有一些经典的优化改进或二次开发经验？</p>
<h3 id="解答1-27"><a href="#解答1-27" class="headerlink" title="解答1"></a>解答1</h3><p>在实际应用 Redis 时，你有哪些优化和二次开发的经验？</p>
<p>分享一下我们对 Redis 的二次开发经验。</p>
<p>由于我们采用的 Redis 集群方案是 Codis，我们主要对 Codis 下的 Redis Server 进行了二次开发。</p>
<p>我们在做服务跨机房容灾和多活时，需要在两个机房各自部署 Codis/Redis 实例，并且两个机房的实例数据需要实时同步，以支持任意机房故障时，可随时切换应用流量到另一个机房继续提供服务。</p>
<p>但由于两个机房之间的网络是通过专线连通的，而专线的质量和稳定性是不如同机房内的，如果使用原生 的 Redis 主从复制方案，当专线长时间故障再恢复时，原生 Redis 主从复制会进行全量的数据同步。全量同步不仅对 master 节点有阻塞风险，同时也会对机房之间的专线的带宽产生巨大的压力，还会影响应用的机房流量切换。</p>
<p>所以我们对 Codis 下的 Redis 做了二次开发，对其增加了类似于 MySQL 的 binlog 模块，把实时的写命令通过异步线程写入到 binlog 文件中，然后开发了数据同步中间件去读取 Redis 的 binlog，向另一个机房实时同步数据，并且支持增量同步、断点续传，这样就可以兼容专线任意时间的故障，故障恢复后我们的同步中间件会从断点处继续增量同步 Redis 数据到另一个机房，避免了全量复制的风险。</p>
<p>同时，我们还对 Codis 进行了二次开发，在集成数据同步中间件时，兼容了 Codis 的日常运维和故障容错，例如集群内节点主从切换、故障转移、数据迁移等操作，保证了机房之间数据同步的最终一致性。</p>
<p>最后，我想说的是，对 Redis 进行改造，优点是可以更加适配自己的业务场景，但缺点是维护和升级成本较高，改造 Redis 相当于自己开辟了一个新的分支，公司内部需要投入人力去持续维护，需要平衡投入产出比。如果没有特别复杂的需求，一般使用官方版本即可，好处是可以第一时间使用最新版本的特性。</p>

            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/redis/">redis</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/%E4%BD%BF%E7%94%A8/">使用</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">
                  
                    本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！
                  
                </p>
              
              
                <div class="post-prevnext">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/redis/source-code/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Redis源码剖析与实战</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/redis/config/">
                        <span class="hidden-mobile">Redis配置</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
              <!-- Comments -->
              <article class="comments" id="comments">
                
                  
                
                
  <div id="gitalk-container"></div>
  <script type="text/javascript">
    Fluid.utils.loadComments('#gitalk-container', function() {
      Fluid.utils.createCssLink('/css/gitalk.css')
      Fluid.utils.createScript('https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.min.js', function() {
        var options = Object.assign(
          {"clientID":"1545f02c9a677f0bd433","clientSecret":"57b1b2091f1c8788e4a2722c7b05ba53bc1e6b18","repo":"zuoshuwen.github.io","owner":"zuoshuwen","admin":["zuoshuwen"],"language":"zh-CN","labels":["Gitalk"],"perPage":10,"pagerDirection":"last","distractionFreeMode":false,"createIssueManually":true,"proxy":"<your own proxy>/https://github.com/login/oauth/access_token"},
          {
            id: 'be3829fa822868d071dd749c012ab112'
          }
        )
        var gitalk = new Gitalk(options);
        gitalk.render('gitalk-container');
      });
    });
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


              </article>
            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
  </div>
  
  <div class="statistics">
    
    

    
      
        <!-- LeanCloud 统计PV -->
        <span id="leancloud-site-pv-container" style="display: none">
            总访问量 
            <span id="leancloud-site-pv"></span>
             次
          </span>
      
      
        <!-- LeanCloud 统计UV -->
        <span id="leancloud-site-uv-container" style="display: none">
            总访客数 
            <span id="leancloud-site-uv"></span>
             人
          </span>
      

    
  </div>


  
  <!-- 备案信息 -->
  <div class="beian">
    <span>
      <a href="http://beian.miit.gov.cn/" target="_blank" rel="nofollow noopener">
        京ICP备18026333号-1
      </a>
    </span>
    
  </div>


  
</footer>


  <!-- SCRIPTS -->
  
  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>

<!-- Plugins -->


  <script  src="/js/local-search.js" ></script>





  



  
    <script  src="https://cdn.jsdelivr.net/npm/tocbot@4.12.2/dist/tocbot.min.js" ></script>
  
  
    <script  src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js" ></script>
  
  
    <script  src="https://cdn.jsdelivr.net/npm/anchor-js@4.3.0/anchor.min.js" ></script>
  
  
    <script defer src="https://cdn.jsdelivr.net/npm/clipboard@2.0.8/dist/clipboard.min.js" ></script>
  




  <script defer src="/js/leancloud.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/typed.js@2.0.11/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var title = document.getElementById('subtitle').title;
      
      typing(title)
      
    })(window, document);
  </script>












  
    <!-- Baidu Analytics -->
    <script defer>
      var _hmt = _hmt || [];
      (function () {
        var hm = document.createElement("script");
        hm.src = "https://hm.baidu.com/hm.js?97f60cea7055dca81a77d34bd50655bf";
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(hm, s);
      })();
    </script>
  

  

  

  

  

  





<!-- 主题的启动项 保持在最底部 -->
<script  src="/js/boot.js" ></script>


</body>
</html>
