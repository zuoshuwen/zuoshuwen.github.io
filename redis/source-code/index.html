

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/avatar.png">
  <link rel="icon" href="/img/avatar.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="sown">
  <meta name="keywords" content="go,golang,技术,后端,php,linux,redis,kubernetes,k8s,nginx,docker,网络,算法,">
  
    <meta name="description" content="数据结构动态字符串、SDS总结1因此这节课，你需要重点关注三个要点，分别是：  C 语言中使用 char* 实现字符串的不足，主要是因为使用“\0”表示字符串结束，操作时需遍历字符串，效率不高，并且无法完整表示包含“\0”的数据，因而这就无法满足 Redis 的需求。 Redis 中字符串的设计思想与实现方法。Redis 专门设计了 SDS 数据结构，在字符数组的基础上，增加了字符数组长度和分配空">
<meta property="og:type" content="article">
<meta property="og:title" content="Redis源码剖析与实战">
<meta property="og:url" content="https://ilifes.com/redis/source-code/index.html">
<meta property="og:site_name" content="Sown">
<meta property="og:description" content="数据结构动态字符串、SDS总结1因此这节课，你需要重点关注三个要点，分别是：  C 语言中使用 char* 实现字符串的不足，主要是因为使用“\0”表示字符串结束，操作时需遍历字符串，效率不高，并且无法完整表示包含“\0”的数据，因而这就无法满足 Redis 的需求。 Redis 中字符串的设计思想与实现方法。Redis 专门设计了 SDS 数据结构，在字符数组的基础上，增加了字符数组长度和分配空">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://ilifes.com/images/design-pattern/a-cover.png">
<meta property="article:published_time" content="2021-06-16T00:00:00.000Z">
<meta property="article:modified_time" content="2021-10-27T05:58:51.109Z">
<meta property="article:author" content="sown">
<meta property="article:tag" content="源码">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://ilifes.com/images/design-pattern/a-cover.png">
  
  
  <title>Redis源码剖析与实战 - Sown</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10.6.0/styles/github-gist.min.css" />
    
  

  
    <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" />
  


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"ilifes.com","root":"/","version":"1.8.13","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"copy_btn":true,"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":false,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"baidu":"97f60cea7055dca81a77d34bd50655bf","google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":"ButetqzXxYeinA3YL6tt2SI5-gzGzoHsz","app_key":"IQfQbzCDGqirp6rGE7bmsnzS","server_url":"https://butetqzx.lc-cn-n1-shared.com","path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 5.4.0"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Sown</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" target="_self" href="javascript:;" role="button"
                 data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                <i class="iconfont icon-books"></i>
                程序设计
              </a>
              <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                
                  
                  
                  
                  <a class="dropdown-item" href="/datastruct-algorithm/a/">
                    <i class="iconfont icon-notebook"></i>
                    数据结构与算法
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/design-pattern/a/">
                    <i class="iconfont icon-notebook"></i>
                    设计模式
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/program/a/">
                    <i class="iconfont icon-notebook"></i>
                    方案
                  </a>
                
              </div>
            </li>
          
        
          
          
          
          
            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" target="_self" href="javascript:;" role="button"
                 data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                <i class="iconfont icon-books"></i>
                编程
              </a>
              <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                
                  
                  
                  
                  <a class="dropdown-item" href="/netprogram/a/">
                    <i class="iconfont icon-notebook"></i>
                    网络编程
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/golang/a/">
                    <i class="iconfont icon-notebook"></i>
                    Go
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/ios/a/">
                    <i class="iconfont icon-notebook"></i>
                    iOS
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/html5/a/">
                    <i class="iconfont icon-notebook"></i>
                    H5
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/applet/a/">
                    <i class="iconfont icon-notebook"></i>
                    小程序
                  </a>
                
              </div>
            </li>
          
        
          
          
          
          
            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" target="_self" href="javascript:;" role="button"
                 data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                <i class="iconfont icon-books"></i>
                架构
              </a>
              <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                
                  
                  
                  
                  <a class="dropdown-item" href="/distributed/a/">
                    <i class="iconfont icon-notebook"></i>
                    分布式
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/microservices/a/">
                    <i class="iconfont icon-notebook"></i>
                    微服务
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/example/a/">
                    <i class="iconfont icon-notebook"></i>
                    方案设计
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/microservices/a/">
                    <i class="iconfont icon-notebook"></i>
                    架构模式
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/ddd/a/">
                    <i class="iconfont icon-notebook"></i>
                    领域驱动设计
                  </a>
                
              </div>
            </li>
          
        
          
          
          
          
            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" target="_self" href="javascript:;" role="button"
                 data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                <i class="iconfont icon-books"></i>
                开源学习
              </a>
              <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                
                  
                  
                  
                  <a class="dropdown-item" href="/redis/a/">
                    <i class="iconfont icon-notebook"></i>
                    Redis
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/mysql/a/">
                    <i class="iconfont icon-notebook"></i>
                    MySQL
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/etcd/a/">
                    <i class="iconfont icon-notebook"></i>
                    Etcd
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/Redigo/a/">
                    <i class="iconfont icon-notebook"></i>
                    Redigo
                  </a>
                
              </div>
            </li>
          
        
          
          
          
          
            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" target="_self" href="javascript:;" role="button"
                 data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                <i class="iconfont icon-books"></i>
                数据
              </a>
              <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                
                  
                  
                  
                  <a class="dropdown-item" href="/datadev/a/">
                    <i class="iconfont icon-notebook"></i>
                    数据开发
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/datanal/a/">
                    <i class="iconfont icon-notebook"></i>
                    数据分析
                  </a>
                
              </div>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner" id="banner" parallax=true
         style="background: url('/images/default.jpg') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="page-header text-center fade-in-up">
            <span class="h2" id="subtitle" title="Redis源码剖析与实战">
              
            </span>

            
              <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2021-06-16 08:00" pubdate>
        2021年6月16日 早上
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      44k 字
    </span>
  

  
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      369 分钟
    </span>
  

  
  
    
      <!-- LeanCloud 统计文章PV -->
      <span id="leancloud-page-views-container" class="post-meta" style="display: none">
        <i class="iconfont icon-eye" aria-hidden="true"></i>
        <span id="leancloud-page-views"></span> 次
      </span>
    
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">Redis源码剖析与实战</h1>
            
            <div class="markdown-body">
              <h1 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h1><h2 id="动态字符串、SDS"><a href="#动态字符串、SDS" class="headerlink" title="动态字符串、SDS"></a>动态字符串、SDS</h2><h3 id="总结1"><a href="#总结1" class="headerlink" title="总结1"></a>总结1</h3><p>因此这节课，你需要重点关注三个要点，分别是：</p>
<ul>
<li>C 语言中使用 char* 实现字符串的不足，主要是因为使用“\0”表示字符串结束，操作时需遍历字符串，效率不高，并且无法完整表示包含“\0”的数据，因而这就无法满足 Redis 的需求。</li>
<li>Redis 中字符串的设计思想与实现方法。Redis 专门设计了 SDS 数据结构，在字符数组的基础上，增加了字符数组长度和分配空间大小等元数据。这样一来，需要基于字符串长度进行的追加、复制、比较等操作，就可以直接读取元数据，效率也就提升了。而且，SDS 不通过字符串中的“\0”字符判断字符串结束，而是直接将其作为二进制数据处理，可以用来保存图片等二进制数据。</li>
<li>SDS 中是通过设计不同 SDS 类型来表示不同大小的字符串，并使用__attribute__ ((<strong>packed</strong>))这个编程小技巧，来实现紧凑型内存布局，达到节省内存的目的。</li>
</ul>
<p>字符串看起来简单，但通过今天这节课的学习，你可以看到实现字符串有很多需要精巧设计的地方。C 语言字符串的实现方法和 SDS 的联系与区别，也是 Redis 面试时经常会被问到的问题，所以我也希望你能通过今天这节课，掌握好它俩的区别。</p>
<h3 id="总结2"><a href="#总结2" class="headerlink" title="总结2"></a>总结2</h3><p>char* 的不足：</p>
<ul>
<li>操作效率低：获取长度需遍历，O(N)复杂度</li>
<li>二进制不安全：无法存储包含 \0 的数据</li>
</ul>
<p>SDS 的优势：</p>
<ul>
<li>操作效率高：获取长度无需遍历，O(1)复杂度</li>
<li>二进制安全：因单独记录长度字段，所以可存储包含 \0 的数据</li>
<li>兼容 C 字符串函数，可直接使用字符串 API</li>
</ul>
<p>另外 Redis 在操作 SDS 时，为了避免频繁操作字符串时，每次「申请、释放」内存的开销，还做了这些优化：</p>
<ul>
<li>内存预分配：SDS 扩容，会多申请一些内存（小于 1MB 翻倍扩容，大于 1MB 按 1MB 扩容）</li>
<li>多余内存不释放：SDS 缩容，不释放多余的内存，下次使用可直接复用这些内存</li>
</ul>
<p>这种策略，是以多占一些内存的方式，换取「追加」操作的速度。</p>
<p>这个内存预分配策略，详细逻辑可以看 sds.c 的 sdsMakeRoomFor 函数。</p>
<p>课后题：SDS 字符串在 Redis 内部模块实现中也被广泛使用，你能在 Redis server 和客户端的实现中，找到使用 SDS 字符串的地方么？</p>
<ol>
<li>Redis 中所有 key 的类型就是 SDS（详见 db.c 的 dbAdd 函数）</li>
<li>Redis Server 在读取 Client 发来的请求时，会先读到一个缓冲区中，这个缓冲区也是 SDS（详见 server.h 中 struct client 的 querybuf 字段）</li>
<li>写操作追加到 AOF 时，也会先写到 AOF 缓冲区，这个缓冲区也是 SDS （详见 server.h 中 struct client 的 aof_buf 字段）</li>
</ol>
<h2 id="Hash"><a href="#Hash" class="headerlink" title="Hash"></a>Hash</h2><h3 id="总结1-1"><a href="#总结1-1" class="headerlink" title="总结1"></a>总结1</h3><p>实现一个高性能的 Hash 表不仅是 Redis 的需求，也是很多计算机系统开发过程中的重要目标。而要想实现一个性能优异的 Hash 表，就需要重点解决哈希冲突和 rehash 开销这两个问题。</p>
<p>今天这节课，我带你学习了 Redis 中 Hash 表的结构设计、链式哈希方法的实现，以及渐进式 rehash 方法的设计实现。Redis 中 Hash 表的结构设计很特别，它的每个哈希项都包含了一个指针，用于实现链式哈希。同时，Redis 在全局哈希表中还包含了两个 Hash 表，这种设计思路也是为了在实现 rehash 时，帮助数据从一个表迁移到另一个表。</p>
<p>此外，Redis 实现的渐进式 rehash 是一个用于 Hash 表扩容的通用方法，非常值得我们学习。这个设计方法的关键是每次仅迁移有限个数的 bucket，避免一次性迁移给所有 bucket 带来的性能影响。当你掌握了渐进式 rehash 这个设计思想和实现方法，你就可以把它应用到自己的 Hash 表实现场景中。</p>
<h3 id="总结2-1"><a href="#总结2-1" class="headerlink" title="总结2"></a>总结2</h3><ol>
<li><p>Redis 中的 dict 数据结构，采用「链式哈希」的方式存储，当哈希冲突严重时，会开辟一个新的哈希表，翻倍扩容，并采用「渐进式 rehash」的方式迁移数据</p>
</li>
<li><p>所谓「渐进式 rehash」是指，把很大块迁移数据的开销，平摊到多次小的操作中，目的是降低主线程的性能影响</p>
</li>
<li><p>Redis 中凡是需要 O(1) 时间获取 k-v 数据的场景，都使用了 dict 这个数据结构，也就是说 dict 是 Redis 中重中之重的「底层数据结构」</p>
</li>
<li><p>dict 封装好了友好的「增删改查」API，并在适当时机「自动扩容、缩容」，这给上层数据类型（Hash/Set/Sorted Set）、全局哈希表的实现提供了非常大的便利</p>
</li>
<li><p>例如，Redis 中每个 DB 存放数据的「全局哈希表、过期key」都用到了 dict：</p>
<div class="code-wrapper"><pre><code class="hljs c"><span class="hljs-comment">// server.h</span>
<span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">redisDb</span> &#123;</span>
   dict *dict; <span class="hljs-comment">// 全局哈希表，数据键值对存在这</span>
   dict *expires; <span class="hljs-comment">// 过期 key + 过期时间 存在这</span>
   ...
&#125;</code></pre></div></li>
<li><p>「全局哈希表」在触发渐进式 rehash 的情况有 2 个：</p>
</li>
</ol>
<ul>
<li>增删改查哈希表时：每次迁移 1 个哈希桶（文章提到的 dict.c 中的 _dictRehashStep 函数）</li>
<li>定时 rehash：如果 dict 一直没有操作，无法渐进式迁移数据，那主线程会默认每间隔 100ms 执行一次迁移操作。这里一次会以 100 个桶为基本单位迁移数据，并限制如果一次操作耗时超时 1ms 就结束本次任务，待下次再次触发迁移（文章没提到这个，详见 dict.c 的 dictRehashMilliseconds 函数）</li>
</ul>
<p>（注意：定时 rehash 只会迁移全局哈希表中的数据，不会定时迁移 Hash/Set/Sorted Set 下的哈希表的数据，这些哈希表只会在操作数据时做实时的渐进式 rehash）</p>
<ol start="7">
<li>dict 在负载因子超过 1 时（used: bucket size &gt;= 1），会触发 rehash。但如果 Redis 正在 RDB 或 AOF rewrite，为避免父进程大量写时复制，会暂时关闭触发 rehash。但这里有个例外，如果负载因子超过了 5（哈希冲突已非常严重），依旧会强制做 rehash（重点）</li>
<li>dict 在 rehash 期间，查询旧哈希表找不到结果，还需要在新哈希表查询一次</li>
</ol>
<p>课后题：Hash 函数会影响 Hash 表的查询效率及哈希冲突情况，那么，你能从 Redis 的源码中，找到 Hash 表使用的是哪一种 Hash 函数吗？</p>
<p>找到 dict.c 的 dictFind 函数，可以看到查询一个 key 在哈希表的位置时，调用了 dictHashKey 计算 key 的哈希值：</p>
<div class="code-wrapper"><pre><code class="hljs c"><span class="hljs-function">dictEntry *<span class="hljs-title">dictFind</span><span class="hljs-params">(dict *d, <span class="hljs-keyword">const</span> <span class="hljs-keyword">void</span> *key)</span> </span>&#123;
   <span class="hljs-comment">// 计算 key 的哈希值</span>
   h = dictHashKey(d, key);
   ...
&#125;</code></pre></div>

<p>继续跟代码可以看到 dictHashKey 调用了 struct dict 下 dictType 的 hashFunction 函数：</p>
<div class="code-wrapper"><pre><code class="hljs c"><span class="hljs-comment">// dict.h</span>
dictHashKey(d, key) (d)-&gt;type-&gt;hashFunction(key)</code></pre></div>

<p>而这个 hashFunction 是在初始化一个 dict 时，才会指定使用哪个哈希函数的。</p>
<p>当 Redis Server 在启动时会创建「全局哈希表」：</p>
<div class="code-wrapper"><pre><code class="hljs c"><span class="hljs-comment">// 初始化 db 下的全局哈希表</span>
<span class="hljs-keyword">for</span> (j = <span class="hljs-number">0</span>; j &lt; server.dbnum; j++) &#123;
   <span class="hljs-comment">// dbDictType 中指定了哈希函数</span>
   server.db[j].dict = dictCreate(&amp;dbDictType,<span class="hljs-literal">NULL</span>);
...
&#125;</code></pre></div>

<p>这个 dbDictType struct 指定了具体的哈希函数，跟代码进去能看到，使用了 SipHash 算法，具体实现逻辑在 siphash.c。</p>
<p>（SipHash 哈希算法是在 Redis 4.0 才开始使用的，3.0-4.0 使用的是 MurmurHash2 哈希算法，3.0 之前是 DJBX33A 哈希算法）</p>
<h2 id="RedisObject"><a href="#RedisObject" class="headerlink" title="RedisObject"></a>RedisObject</h2><h3 id="总结1-2"><a href="#总结1-2" class="headerlink" title="总结1"></a>总结1</h3><p>降低内存开销，对于 Redis 这样的内存数据库来说非常重要。今天这节课，我们了解了 Redis 用于优化内存使用效率的两种方法：内存优化的数据结构设计和节省内存的共享数据访问。</p>
<p>那么，对于实现数据结构来说，如果想要节省内存，Redis 就给我们提供了两个优秀的设计思想：一个是使用连续的内存空间，避免内存碎片开销；二个是针对不同长度的数据，采用不同大小的元数据，以避免使用统一大小的元数据，造成内存空间的浪费。</p>
<p>另外在数据访问方面，你也要知道，使用共享对象其实可以避免重复创建冗余的数据，从而也可以有效地节省内存空间。不过，共享对象主要适用于只读场景，如果一个字符串被反复地修改，就无法被多个请求共享访问了。所以这一点，你在应用时也需要注意一下。</p>
<h3 id="总结2-2"><a href="#总结2-2" class="headerlink" title="总结2"></a>总结2</h3><ol>
<li>要想理解 Redis 数据类型的设计，必须要先了解 redisObject。</li>
</ol>
<p>Redis 的 key 是 String 类型，但 value 可以是很多类型（String/List/Hash/Set/ZSet等），所以 Redis 要想存储多种数据类型，就要设计一个通用的对象进行封装，这个对象就是 redisObject。</p>
<div class="code-wrapper"><pre><code class="hljs c"><span class="hljs-comment">// server.h</span>
<span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">redisObject</span> &#123;</span>
   <span class="hljs-keyword">unsigned</span> type:<span class="hljs-number">4</span>;
   <span class="hljs-keyword">unsigned</span> encoding:<span class="hljs-number">4</span>;
   <span class="hljs-keyword">unsigned</span> lru:LRU_BITS;
   <span class="hljs-keyword">int</span> refcount;
   <span class="hljs-keyword">void</span> *ptr;
&#125; robj;</code></pre></div>

<p>其中，最重要的 2 个字段：</p>
<ul>
<li>type：面向用户的数据类型（String/List/Hash/Set/ZSet等）</li>
<li>encoding：每一种数据类型，可以对应不同的底层数据结构来实现（SDS/ziplist/intset/hashtable/skiplist等）</li>
</ul>
<p>例如 String，可以用 embstr（嵌入式字符串，redisObject 和 SDS 一起分配内存），也可以用 rawstr（redisObject 和 SDS 分开存储）实现。</p>
<p>又或者，当用户写入的是一个「数字」时，底层会转成 long 来存储，节省内存。</p>
<p>同理，Hash/Set/ZSet 在数据量少时，采用 ziplist 存储，否则就转为 hashtable 来存。</p>
<p>所以，redisObject 的作用在于：</p>
<ul>
<li>为多种数据类型提供统一的表示方式</li>
<li>同一种数据类型，底层可以对应不同实现，节省内存</li>
<li>支持对象共享和引用计数，共享对象存储一份，可多次使用，节省内存</li>
</ul>
<p>redisObject 更像是连接「上层数据类型」和「底层数据结构」之间的桥梁。</p>
<ol start="2">
<li>关于 String 类型的实现，底层对应 3 种数据结构：</li>
</ol>
<ul>
<li>embstr：小于 44 字节，嵌入式存储，redisObject 和 SDS 一起分配内存，只分配 1 次内存</li>
<li>rawstr：大于 44 字节，redisObject 和 SDS 分开存储，需分配 2 次内存</li>
<li>long：整数存储（小于 10000，使用共享对象池存储，但有个前提：Redis 没有设置淘汰策略，详见 object.c 的 tryObjectEncoding 函数）</li>
</ul>
<ol start="3">
<li>ziplist 的特点：</li>
</ol>
<ul>
<li>连续内存存储：每个元素紧凑排列，内存利用率高</li>
<li>变长编码：存储数据时，采用变长编码（满足数据长度的前提下，尽可能少分配内存）</li>
<li>寻找元素需遍历：存放太多元素，性能会下降（适合少量数据存储）</li>
<li>级联更新：更新、删除元素，会引发级联更新（因为内存连续，前面数据膨胀/删除了，后面要跟着一起动）</li>
</ul>
<p>List、Hash、Set、ZSet 底层都用到了 ziplist。</p>
<ol start="4">
<li>intset 的特点：</li>
</ol>
<ul>
<li>Set 存储如果都是数字，采用 intset 存储</li>
<li>变长编码：数字范围不同，intset 会选择 int16/int32/int64 编码（intset.c 的 _intsetValueEncoding 函数）</li>
<li>有序：intset 在存储时是有序的，这意味着查找一个元素，可使用「二分查找」（intset.c 的 intsetSearch 函数）</li>
<li>编码升级/降级：添加、更新、删除元素，数据范围发生变化，会引发编码长度升级或降级</li>
</ul>
<p>课后题：SDS 判断是否使用嵌入式字符串的条件是 44 字节，你知道为什么是 44 字节吗？</p>
<p>嵌入式字符串会把 redisObject 和 SDS 一起分配内存，那在存储时结构是这样的：</p>
<ul>
<li>redisObject：16 个字节</li>
<li>SDS：sdshdr8（3 个字节）+ SDS 字符数组（N 字节 + \0 结束符 1 个字节）</li>
</ul>
<p>Redis 规定嵌入式字符串最大以 64 字节存储，所以 N = 64 - 16(redisObject) - 3(sdshr8) - 1(\0)， N = 44 字节。</p>
<h2 id="ZSet"><a href="#ZSet" class="headerlink" title="ZSet"></a>ZSet</h2><h3 id="总结1-3"><a href="#总结1-3" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我给你介绍了 Sorted Set 数据类型的底层实现。Sorted Set 为了能同时支持按照权重的范围查询，以及针对元素权重的单点查询，在底层数据结构上设计了组合使用跳表和哈希表的方法。</p>
<p>跳表是一个多层的有序链表，在跳表中进行查询操作时，查询代码可以从最高层开始查询。层数越高，结点数越少，同时高层结点的跨度会比较大。因此，在高层查询结点时，查询一个结点可能就已经查到了链表的中间位置了。</p>
<p>这样一来，跳表就会先查高层，如果高层直接查到了等于待查元素的结点，那么就可以直接返回。如果查到第一个大于待查元素的结点后，就转向下一层查询。下层上的结点数多于上层，所以这样可以在更多的结点中进一步查找待查元素是否存在。</p>
<p>跳表的这种设计方法就可以节省查询开销，同时，跳表设计采用随机的方法来确定每个结点的层数，这样就可以避免新增结点时，引起结点连锁更新问题。</p>
<p>此外，Sorted Set 中还将元素保存在了哈希表中，作为哈希表的 key，同时将 value 指向元素在跳表中的权重。使用了哈希表后，Sorted Set 可以通过哈希计算直接查找到某个元素及其权重值，相较于通过跳表查找单个元素，使用哈希表就有效提升了查询效率。</p>
<p>总之，组合使用两种索引结构来对数据进行管理，比如 Sorted Set 中组合使用跳表和哈希表，这是一个很好的设计思路，希望你也能应用在日常的系统开发中。</p>
<h3 id="总结2-3"><a href="#总结2-3" class="headerlink" title="总结2"></a>总结2</h3><ol>
<li>ZSet 当数据比较少时，采用 ziplist 存储，每个 member/score 元素紧凑排列，节省内存</li>
<li>当数据超过阈值（zset-max-ziplist-entries、zset-max-ziplist-value）后，转为 hashtable + skiplist 存储，降低查询的时间复杂度</li>
<li>hashtable 存储 member-&gt;score 的关系，所以 ZSCORE 的时间复杂度为 O(1)</li>
<li>skiplist 是一个「有序链表 + 多层索引」的结构，把查询元素的复杂度降到了 O(logN)，服务于 ZRANGE/ZREVRANGE 这类命令</li>
<li>skiplist 的多层索引，采用「随机」的方式来构建，也就是说每次添加一个元素进来，要不要对这个元素建立「多层索引」？建立「几层索引」？都要通过「随机数」的方式来决定</li>
<li>每次随机一个 0-1 之间的数，如果这个数小于 0.25（25% 概率），那就给这个元素加一层指针，持续随机直到大于 0.25 结束，最终确定这个元素的层数（层数越高，概率越低，且限制最多 64 层，详见 t_zset.c 的 zslRandomLevel 函数）</li>
<li>这个预设「概率」决定了一个跳表的内存占用和查询复杂度：概率设置越低，层数越少，元素指针越少，内存占用也就越少，但查询复杂会变高，反之亦然。这也是 skiplist 的一大特点，可通过控制概率，进而控制内存和查询效率</li>
<li>skiplist 新插入一个节点，只需修改这一层前后节点的指针，不影响其它节点的层数，降低了操作复杂度（相比平衡二叉树的再平衡，skiplist 插入性能更优）</li>
</ol>
<p>关于 Redis 的 ZSet 为什么用 skiplist 而不用平衡二叉树实现的问题，原因是：</p>
<ul>
<li>skiplist 更省内存：25% 概率的随机层数，可通过公式计算出 skiplist 平均每个节点的指针数是 1.33 个，平衡二叉树每个节点指针是 2 个（左右子树）</li>
<li>skiplist 遍历更友好：skiplist 找到大于目标元素后，向后遍历链表即可，平衡树需要通过中序遍历方式来完成，实现也略复杂</li>
<li>skiplist 更易实现和维护：扩展 skiplist 只需要改少量代码即可完成，平衡树维护起来较复杂</li>
</ul>
<p>课后题：在使用跳表和哈希表相结合的双索引机制时，在获得高效范围查询和单点查询的同时，你能想到有哪些不足之处么？</p>
<p>这种发挥「多个数据结构」的优势，来完成某个功能的场景，最大的特点就是「空间换时间」，所以内存占用多是它的不足。</p>
<p>不过也没办法，想要高效率查询，就得牺牲内存，鱼和熊掌不可兼得。</p>
<p>不过 skiplist 在实现时，Redis 作者应该也考虑到这个问题了，就是上面提到的这个「随机概率」，Redis 后期维护可以通过调整这个概率，进而达到「控制」查询效率和内存平衡的结果。当然，这个预设值是固定写死的，不可配置，应该是 Redis 作者经过测试和权衡后的设定，我们这里只需要知晓原理就好。</p>
<h2 id="ZipList、QuickList、ListPack"><a href="#ZipList、QuickList、ListPack" class="headerlink" title="ZipList、QuickList、ListPack"></a>ZipList、QuickList、ListPack</h2><h3 id="总结1-4"><a href="#总结1-4" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我从 ziplist 的设计不足出发，依次给你介绍了 quicklist 和 listpack 的设计思想。</p>
<p>你要知道，ziplist 的不足主要在于一旦 ziplist 中元素个数多了，它的查找效率就会降低。而且如果在 ziplist 里新增或修改数据，ziplist 占用的内存空间还需要重新分配；更糟糕的是，ziplist 新增某个元素或修改某个元素时，可能会导致后续元素的 prevlen 占用空间都发生变化，从而引起连锁更新问题，导致每个元素的空间都要重新分配，这就会导致 ziplist 的访问性能下降。</p>
<p>所以，为了应对 ziplist 的问题，Redis 先是在 3.0 版本中设计实现了 quicklist。quicklist 结构在 ziplist 基础上，使用链表将 ziplist 串联起来，链表的每个元素就是一个 ziplist。这种设计减少了数据插入时内存空间的重新分配，以及内存数据的拷贝。同时，quicklist 限制了每个节点上 ziplist 的大小，一旦一个 ziplist 过大，就会采用新增 quicklist 节点的方法。</p>
<p>不过，又因为 quicklist 使用 quicklistNode 结构指向每个 ziplist，无疑增加了内存开销。为了减少内存开销，并进一步避免 ziplist 连锁更新问题，Redis 在 5.0 版本中，就设计实现了 listpack 结构。listpack 结构沿用了 ziplist 紧凑型的内存布局，把每个元素都紧挨着放置。</p>
<p>listpack 中每个列表项不再包含前一项的长度了，因此当某个列表项中的数据发生变化，导致列表项长度变化时，其他列表项的长度是不会受影响的，因而这就避免了 ziplist 面临的连锁更新问题。</p>
<p>总而言之，Redis 在内存紧凑型列表的设计与实现上，从 ziplist 到 quicklist，再到 listpack，你可以看到 Redis 在内存空间开销和访问性能之间的设计取舍，这一系列的设计变化，是非常值得你学习的。</p>
<h3 id="总结2-4"><a href="#总结2-4" class="headerlink" title="总结2"></a>总结2</h3><ol>
<li>ziplist 设计的初衷就是「节省内存」，在存储数据时，把内存利用率发挥到了极致：</li>
</ol>
<ul>
<li>数字按「整型」编码存储，比直接当字符串存内存占用少</li>
<li>数据「长度」字段，会根据内容的大小选择最小的长度编码</li>
<li>甚至对于极小的数据，干脆把内容直接放到了「长度」字段中（前几个位表示长度，后几个位存数据）</li>
</ul>
<ol start="2">
<li>但 ziplist 的劣势也很明显：</li>
</ol>
<ul>
<li>寻找元素只能挨个遍历，存储过长数据，查询性能很低</li>
<li>每个元素中保存了「上一个」元素的长度（为了方便反向遍历），这会导致上一个元素内容发生修改，长度超过了原来的编码长度，下一个元素的内容也要跟着变，重新分配内存，进而就有可能再次引起下一级的变化，一级级更新下去，频繁申请内存</li>
</ul>
<ol start="3">
<li>想要缓解 ziplist 的问题，比较简单直接的方案就是，多个数据项，不再用一个 ziplist 来存，而是分拆到多个 ziplist 中，每个 ziplist 用指针串起来，这样修改其中一个数据项，即便发生级联更新，也只会影响这一个 ziplist，其它 ziplist 不受影响，这种方案就是 quicklist：</li>
</ol>
<p>qucklist: ziplist1(也叫quicklistNode) &lt;-&gt; ziplist2 &lt;-&gt; ziplist3 &lt;-&gt; …</p>
<ol start="4">
<li>List 数据类型底层实现，就是用的 quicklist，因为它是一个链表，所以 LPUSH/LPOP/RPUSH/RPOP 的复杂度是 O(1)</li>
<li>List 中每个 ziplist 节点可以存的元素个数/总大小，可以通过 list-max-ziplist-size 配置：</li>
</ol>
<ul>
<li>正数：ziplist 最多包含几个数据项</li>
<li>负数：取值 -1 ~ -5，表示每个 ziplist 存储最大的字节数，默认 -2，每个ziplist 8KB</li>
</ul>
<p>ziplist 超过上述任一配置，添加新元素就会新建 ziplist 插入到链表中。</p>
<ol start="6">
<li>List 因为更多是两头操作，为了节省内存，还可以把中间的 ziplist「压缩」，具体可看 list-compress-depth 配置项，默认配置不压缩</li>
<li>要想彻底解决 ziplist 级联更新问题，本质上要修改 ziplist 的存储结构，也就是不要让每个元素保存「上一个」元素的长度即可，所以才有了 listpack</li>
<li>listpack 每个元素项不再保存上一个元素的长度，而是优化元素内字段的顺序，来保证既可以从前也可以向后遍历</li>
<li>listpack 是为了替代 ziplist 为设计的，但因为 List/Hash/Set/ZSet 都严重依赖 ziplist，所以这个替换之路很漫长，目前只有 Stream 数据类型用到了 listpack</li>
</ol>
<h2 id="Radix-Tree"><a href="#Radix-Tree" class="headerlink" title="Radix Tree"></a>Radix Tree</h2><h3 id="总结1-5"><a href="#总结1-5" class="headerlink" title="总结1"></a>总结1</h3><p>今天这节课上，我带你学习了 Redis Stream 数据类型的底层实现结构。现在你已经知道，Stream 最主要的作用就是可以用来保存消息数据。</p>
<p>每条消息都会有一个时间戳和序号组成的消息 ID，以及键值对组成的消息内容。而因为不同消息 ID 中的时间戳，通常会共享部分相同的前缀，如果采用诸如哈希表的结构来保存消息，每个消息 ID 都单独保存，容易造成空间浪费。因此，Stream 为了节省内存空间，采用了 Radix Tree 来保存消息 ID，同时使用 listpack 来保存消息本身的内容。</p>
<p>在 Radix Tree 的设计实现中，它的整体结构和节点数据结构是理解 Radix Tree 的重要基础，所以，你要重点关注 Radix Tree 的非压缩节点和压缩节点类型，以及源码中的实际数据结构 raxNode。</p>
<p>另外，为了方便你更好地掌握非压缩节点和压缩节点，我再给你总结下它们的相同之处和区别，你也可以来整体回顾下。</p>
<p>它们的相同之处在于：</p>
<ul>
<li>都有保存元数据的节点头 HDR；</li>
<li>都会包含指向子节点的指针，以及子节点所代表的字符串。</li>
<li>从根节点到当前节点路径上的字符串如果是 Radix Tree 的一个 key，它们都会包含指向 key 对应 value 的指针。</li>
</ul>
<p>不同之处在于：</p>
<ul>
<li>非压缩节点指向的子节点，每个子节点代表一个字符，非压缩节点可以指向多个子节点；</li>
<li>压缩节点指向的子节点，代表的是一个合并字符串，压缩节点只能指向一个子节点。</li>
</ul>
<p>而除了学习 raxNode，我还给你介绍了下 Radix Tree 中几个基本操作函数的作用，并展示了 Stream 类型是如何把消息 ID 和消息内容，分别保存在 Radix Tree 和 listpack 中的。</p>
<p>这里你要注意的是，因为 Radix Tree 在保存具有公共前缀的数据时，能有效节省内存开销。同时，Radix Tree 本身也是有序的树型索引，可以支持单点和范围查询。所以，Redis 把消息 ID 保存在 Radix Tree 中，既可以节省内存空间，也能高效支持消息 ID 的查询。而 listpack 本身是紧凑列表，在保存大量消息内容的同时，也能有效节省内存。</p>
<p>所以我希望，你能通过 Stream 对 Radix Tree 和 listpack 的使用，举一反三，把它们用在相应的消息存取或是大量字符串存取的场景中。</p>
<h3 id="总结2-5"><a href="#总结2-5" class="headerlink" title="总结2"></a>总结2</h3><p>作为有序索引，Radix Tree 也能提供范围查询，和我们日常使用的 B+ 树，以及第5讲中介绍的跳表相比，你觉得 Radix Tree 有什么优势和不足么？</p>
<ol>
<li>Radix Tree 优势</li>
</ol>
<ul>
<li>本质上是前缀树，所以存储有「公共前缀」的数据时，比 B+ 树、跳表节省内存</li>
<li>没有公共前缀的数据项，压缩存储，value 用 listpack 存储，也可以节省内存</li>
<li>查询复杂度是 O(K)，只与「目标长度」有关，与总数据量无关</li>
<li>这种数据结构也经常用在搜索引擎提示、文字自动补全等场景</li>
</ul>
<p>Stream 在存消息时，推荐使用默认自动生成的「时间戳+序号」作为消息 ID，不建议自己指定消息 ID，这样才能发挥 Radix Tree 公共前缀的优势。</p>
<ol start="2">
<li>Radix Tree 不足</li>
</ol>
<ul>
<li>如果数据集公共前缀较少，会导致内存占用多</li>
<li>增删节点需要处理其它节点的「分裂、合并」，跳表只需调整前后指针即可</li>
<li>B+ 树、跳表范围查询友好，直接遍历链表即可，Radix Tree 需遍历树结构</li>
<li>实现难度高比 B+ 树、跳表复杂</li>
</ul>
<p>每种数据结构都是在面对不同问题场景下，才被设计出来的，结合各自场景中的数据特点，使用优势最大的数据结构才是正解。</p>
<h1 id="事件驱动"><a href="#事件驱动" class="headerlink" title="事件驱动"></a>事件驱动</h1><h2 id="Redis-Server"><a href="#Redis-Server" class="headerlink" title="Redis Server"></a>Redis Server</h2><h3 id="总结1-6"><a href="#总结1-6" class="headerlink" title="总结1"></a>总结1</h3><p>今天这节课，我们通过 server.c 文件中 main 函数的设计和实现思路，了解了 Redis server 启动后的五个主要阶段。在这五个阶段中，运行参数解析、server 初始化和执行事件驱动框架则是 Redis sever 启动过程中的三个关键阶段。所以相应的，我们需要重点关注以下三个要点。</p>
<p>第一，main 函数是使用 initServerConfig 给 server 运行参数设置默认值，然后会解析命令行参数，并通过 loadServerConfig 读取配置文件参数值，将命令行参数追加至配置项字符串。最后，Redis 会调用 loadServerConfigFromString 函数，来完成配置文件参数和命令行参数的设置。</p>
<p>第二，在 Redis server 完成参数设置后，initServer 函数会被调用，用来初始化 server 资源管理的主要结构，同时会初始化数据库启动状态，以及完成 server 监听 IP 和端口的设置。</p>
<p>第三，一旦 server 可以接收外部客户端的请求后，main 函数会把程序的主体控制权，交给事件驱动框架的入口函数，也就 aeMain 函数。aeMain 函数会一直循环执行，处理收到的客户端请求。到此为止，server.c 中的 main 函数功能就已经全部完成了，程序控制权也交给了事件驱动循环框架，Redis 也就可以正常处理客户端请求了。</p>
<p>实际上，Redis server 的启动过程从基本的初始化操作，到命令行和配置文件的参数解析设置，再到初始化 server 各种数据结构，以及最后的执行事件驱动框架，这是一个典型的网络服务器执行过程，你在开发网络服务器时，就可以作为参考。</p>
<p>而且，掌握了启动过程中的初始化操作，还可以帮你解答一些使用中的疑惑。比如，Redis 启动时是先读取 RDB 文件，还是先读取 AOF 文件。如果你了解了 Redis server 的启动过程，就可以从 loadDataFromDisk 函数中看到，Redis server 会先读取 AOF；而如果没有 AOF，则再读取 RDB。</p>
<p>所以，掌握 Redis server 启动过程，有助于你更好地了解 Redis 运行细节，这样当你遇到问题时，就知道还可以从启动过程中去溯源 server 的各种初始状态，从而助力你更好地解决问题。</p>
<h3 id="总结2-6"><a href="#总结2-6" class="headerlink" title="总结2"></a>总结2</h3><p>Redis 启动流程，主要的工作有：</p>
<ol>
<li>初始化前置操作（设置时区、随机种子）</li>
<li>初始化 Server 的各种默认配置（server.c 的 initServerConfig 函数），默认配置见 server.h 中的 CONFIG_DEFAULT_XXX，比较典型的配置有：</li>
</ol>
<ul>
<li>默认端口</li>
<li>定时任务频率</li>
<li>数据库数量</li>
<li>AOF 刷盘策略</li>
<li>淘汰策略</li>
<li>数据结构转换阈值</li>
<li>主从复制参数</li>
</ul>
<ol start="3">
<li>加载配置启动参数，覆盖默认配置（config.c 的 loadServerConfig 函数）：</li>
</ol>
<ul>
<li>解析命令行参数</li>
<li>解析配置文件</li>
</ul>
<ol start="3">
<li>初始化 Server（server.c 的 initServer 函数），例如会初始化：</li>
</ol>
<ul>
<li>共享对象池</li>
<li>客户端链表</li>
<li>从库链表</li>
<li>监听端口</li>
<li>全局哈希表</li>
<li>LRU 池</li>
<li>注册定时任务函数</li>
<li>注册监听请求函数</li>
</ul>
<ol start="4">
<li>启动事件循环（ae.c 的 aeMain 函数）</li>
</ol>
<ul>
<li>处理请求</li>
<li>处理定时任务</li>
</ul>
<p>这里补充一下，初始化 Server 完成后，Redis 还会启动 3 类后台线程（server.c 的 InitServerLast 函数），协助主线程工作（异步释放 fd、AOF 每秒刷盘、lazyfree）。</p>
<p>课后题：Redis 源码的 main 函数在调用 initServer 函数之前，会执行如下的代码片段，你知道这个代码片段的作用是什么吗？</p>
<div class="code-wrapper"><pre><code class="hljs c"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">main</span><span class="hljs-params">(<span class="hljs-keyword">int</span> argc, <span class="hljs-keyword">char</span> **argv)</span> </span>&#123;
   ...
   server.supervised = redisIsSupervised(server.supervised_mode);
   <span class="hljs-keyword">int</span> background = server.daemonize &amp;&amp; !server.supervised;
   <span class="hljs-keyword">if</span> (background) daemonize();
   ...
&#125;</code></pre></div>

<p>Redis 可以配置以守护进程的方式启动（配置文件 daemonize = yes），也可以把 Redis 托管给 upstart 或 systemd 来启动 / 停止（supervised = upstart|systemd|auto）。</p>
<h2 id="IO多路复用"><a href="#IO多路复用" class="headerlink" title="IO多路复用"></a>IO多路复用</h2><h3 id="总结1-7"><a href="#总结1-7" class="headerlink" title="总结1"></a>总结1</h3><p>今天这节课，我给你介绍了 Redis 网络通信依赖的操作系统底层机制，也就是 IO 多路复用机制。</p>
<p>由于 Redis 是单线程程序，如果使用基本的 Socket 编程模型的话，只能对一个监听套接字或一个已连接套接字进行监听。而当 Redis 实例面临很多并发的客户端时，这种处理方式的效率就会很低。</p>
<p>所以，和基本的 Socket 通信相比，使用 IO 多路复用机制，就可以一次性获得就绪的多个套接字，从而避免了逐个检测套接字的开销。</p>
<p>这节课，我是以最常用的 Linux 操作系统为例，给你具体介绍了 Linux 系统提供的三种 IO 多路复用机制，分别是 select、poll 和 epoll。这三种机制在能监听的描述符数量和查找就绪描述符的方法上是不一样的，你可以重点参考下图，来掌握它们的不同之处。这些差异，其实也决定了 epoll 相比于 select 和 poll 来说，效率更高，也应用更广泛。<br><img src="/images/redis/io-epoll-02.png" alt="img.png"></p>
<p>最后我想说的是，虽然这节课我没有给你介绍 Redis 的源码，但是学习 IO 多路复用的机制和使用流程，其实就是掌握 Redis 事件驱动框架的基础。Redis 的ae_select.c和ae_epoll.c文件，就分别使用了 select 和 epoll 这两种机制，实现 IO 多路复用。而在接下来的第 10、11 两节课上，我还会给分别你介绍，Redis 事件驱动框架是如何基于 epoll 进行封装开发和运行的，以及 Redis 事件驱动框架的事件类型和处理方法。这样一来，你就能对 Redis 事件驱动框架的底层支撑、框架运行和事件类型与处理，有个全面的掌握了。</p>
<h3 id="总结2-7"><a href="#总结2-7" class="headerlink" title="总结2"></a>总结2</h3><ol>
<li>单线程服务器模型，面临的最大的问题就是，一个线程如何处理多个客户端请求？解决这种问题的办法就是「IO 多路复用」。它本质上是应用层不用维护多个客户端的连接状态，而是把它们「托管」给了操作系统，操作系统维护这些连接的状态变化，之后应用层只管问操作系统，哪些 socket 有数据可读/可写就好了，大大简化了应用层的复杂度</li>
<li>IO 多路复用机制要想高效使用，一般还需要把 socket 设置成「非阻塞」模式，即 socket 没有数据可读/可写时，应用层去 read/write socket 也不会阻塞住（内核会返回指定错误，应用层可继续重试），这样应用层就可以去处理其它业务逻辑，不会阻塞影响性能</li>
<li>为什么 Redis 要使用「单线程」处理客户端请求？本质上是因为，Redis 操作的是内存，操作内存数据是极快的，所以 Redis 的瓶颈不在 CPU，优化的重点就在网络 IO 上，高效的 IO 多路复用机制，正好可以满足这种需求，模型简单，性能也极高</li>
<li>但成也萧何败也萧何，因为 Redis 处理请求是「单线程」，所以如果有任意请求在 Server 端发生耗时（例如操作 bigkey，或一次请求数据过多），就会导致后面的请求发生「排队」，业务端就会感知到延迟增大，性能下降</li>
<li>基于此，Redis 又做了很多优化：一些耗时的操作，不再放在主线程处理，而是丢到后台线程慢慢执行。例如，异步关闭 fd，异步释放内存、后台 AOF 刷盘这些操作。所以 Redis Server 其实是「多线程」的，只不过最核心的处理请求逻辑是单线程的，这点一定要区分开</li>
</ol>
<p>课后题：在 Redis 事件驱动框架代码中，分别使用了 Linux 系统上的 select 和 epoll 两种机制，你知道为什么 Redis 没有使用 poll 这一机制吗？</p>
<p>首先要明确一点，select 并不是只有 Linux 才支持的，Windows 平台也支持。</p>
<p>而 Redis 针对不同操作系统，会选择不同的 IO 多路复用机制来封装事件驱动框架，具体代码见 ae.c。</p>
<div class="code-wrapper"><pre><code class="hljs c"><span class="hljs-comment">// ae.c</span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">ifdef</span> HAVE_EVPORT</span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&quot;ae_evport.c&quot;</span> <span class="hljs-comment">// Solaris</span></span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">else</span></span>
    <span class="hljs-meta">#<span class="hljs-meta-keyword">ifdef</span> HAVE_EPOLL</span>
    <span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&quot;ae_epoll.c&quot;</span> <span class="hljs-comment">// Linux</span></span>
    <span class="hljs-meta">#<span class="hljs-meta-keyword">else</span></span>
        <span class="hljs-meta">#<span class="hljs-meta-keyword">ifdef</span> HAVE_KQUEUE</span>
        <span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&quot;ae_kqueue.c&quot;</span> <span class="hljs-comment">// MacOS</span></span>
        <span class="hljs-meta">#<span class="hljs-meta-keyword">else</span></span>
        <span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&quot;ae_select.c&quot;</span> <span class="hljs-comment">// Windows</span></span>
        <span class="hljs-meta">#<span class="hljs-meta-keyword">endif</span></span>
    <span class="hljs-meta">#<span class="hljs-meta-keyword">endif</span></span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">endif</span></span></code></pre></div>

<p>仔细看上面的代码逻辑，先判断了 Solaris/Linux/MacOS 系统，选择对应的多路复用模型，最后剩下的系统都用 select 模型。</p>
<p>所以我理解，select 并不是为 Linux 服务的，而是在 Windows 下使用的。</p>
<p>因为 epoll 性能优于 select 和 poll，所以 Linux 平台下，Redis 直接会选择 epoll。而 Windows 不支持 epoll 和 poll，所以会用 select 模型。</p>
<h2 id="进程模型"><a href="#进程模型" class="headerlink" title="进程模型"></a>进程模型</h2><h3 id="总结1-8"><a href="#总结1-8" class="headerlink" title="总结1"></a>总结1</h3><p>Redis 一直被称为单线程架构，按照我们通常的理解，单个线程只能处理单个客户端的请求，但是在实际使用时，我们会看到 Redis 能同时和成百上千个客户端进行交互，这就是因为 Redis 基于 Reactor 模型，实现了高性能的网络框架，通过事件驱动框架，Redis 可以使用一个循环来不断捕获、分发和处理客户端产生的网络连接、数据读写事件。</p>
<p>为了方便你从代码层面掌握 Redis 事件驱动框架的实现，我总结了一个表格，其中列出了 Redis 事件驱动框架的主要函数和功能、它们所属的 C 文件，以及这些函数本身是在 Redis 代码结构中的哪里被调用。你可以使用这张表格，来巩固今天这节课学习的事件驱动框架。</p>
<p><img src="/images/redis/process-model-01.png" alt="img.png"></p>
<p>最后，我也再强调下，这节课我们主要关注的是，事件驱动框架的基本运行流程，并以客户端连接事件为例，将框架主循环、事件捕获分发和事件注册的关键步骤串起来，给你做了介绍。Redis 事件驱动框架监听处理的事件，还包括客户端请求、服务器端写数据以及周期性操作等，这也是我下一节课要和你一起学习的主要内容。</p>
<h3 id="总结2-8"><a href="#总结2-8" class="headerlink" title="总结2"></a>总结2</h3><ol>
<li><p>为了高效处理网络 IO 的「连接事件」、「读事件」、「写事件」，演化出了 Reactor 模型</p>
</li>
<li><p>Reactor 模型主要有 reactor、acceptor、handler 三类角色：</p>
</li>
</ol>
<ul>
<li>reactor：分配事件</li>
<li>acceptor：接收连接请求</li>
<li>handler：处理业务逻辑</li>
</ul>
<ol start="3">
<li>Reactor 模型又分为 3 类：</li>
</ol>
<ul>
<li>单 Reactor 单线程：accept -&gt; read -&gt; 处理业务逻辑 -&gt; write 都在一个线程</li>
<li>单 Reactor 多线程：accept/read/write 在一个线程，处理业务逻辑在另一个线程</li>
<li>多 Reactor 多线程 / 进程：accept 在一个线程/进程，read/处理业务逻辑/write 在另一个线程/进程</li>
</ul>
<ol start="4">
<li>Redis 6.0 以下版本，属于单 Reactor 单线程模型，监听请求、读取数据、处理请求、写回数据都在一个线程中执行，这样会有 3 个问题：</li>
</ol>
<ul>
<li>单线程无法利用多核</li>
<li>处理请求发生耗时，会阻塞整个线程，影响整体性能</li>
<li>并发请求过高，读取/写回数据存在瓶颈</li>
</ul>
<ol start="5">
<li>针对问题 3，Redis 6.0 进行了优化，引入了 IO 多线程，把读写请求数据的逻辑，用多线程处理，提升并发性能，但处理请求的逻辑依旧是单线程处理</li>
</ol>
<p>课后题：除了 Redis，你还了解什么软件系统使用了 Reactor 模型吗？</p>
<p>Netty、Memcached 采用多 Reactor 多线程模型。</p>
<p>Nginx 采用多 Reactor 多进程模型，不过与标准的多 Reactor 多进程模型有些许差异。Nginx 的主进程只用来初始化 socket，不会 accept 连接，而是由子进程 accept 连接，之后这个连接的所有处理都在子进程中完成。</p>
<h2 id="事件"><a href="#事件" class="headerlink" title="事件"></a>事件</h2><h3 id="总结1-9"><a href="#总结1-9" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我给你介绍了 Redis 事件驱动框架中的两类事件：IO 事件和时间事件。</p>
<p>对于 IO 事件来说，它可以进一步分成可读、可写和屏障事件。因为可读、可写事件在 Redis 和客户端通信处理请求过程中使用广泛，所以今天我们重点学习了这两种 IO 事件。当 Redis server 创建 Socket 后，就会注册可读事件，并使用 acceptTCPHandler 回调函数处理客户端的连接请求。</p>
<p>当 server 和客户端完成连接建立后，server 会在已连接套接字上监听可读事件，并使用 readQueryFromClient 函数处理客户端读写请求。这里，你需要再注意下，无论客户端发送的请求是读或写操作，对于 server 来说，都是要读取客户端的请求并解析处理。所以，server 在客户端的已连接套接字上注册的是可读事件。</p>
<p>而当实例需要向客户端写回数据时，实例会在事件驱动框架中注册可写事件，并使用 sendReplyToClient 作为回调函数，将缓冲区中数据写回客户端。我总结了一张表格，以便你再回顾下 IO 事件和相应套接字、回调函数的对应关系。</p>
<p><img src="/images/redis/event-model-01.png" alt="img.png"></p>
<p>然后，对于时间事件来说，它主要是用于在事件驱动框架中注册一些周期性执行的任务，以便 Redis server 进行后台处理。时间事件的回调函数是 serverCron 函数，你可以做进一步阅读了解其中的具体任务。</p>
<p>好了，从第 9 讲开始，我用了 3 节课，向你介绍 Redis 事件驱动框架的运行机制，本质上来说，事件驱动框架是基于操作系统提供的 IO 多路复用机制进行了封装，并加上了时间事件的处理。这是一个非常经典的事件框架实现，我希望你可以学习并掌握好它，然后用在你自己的系统开发中。</p>
<h3 id="总结2-9"><a href="#总结2-9" class="headerlink" title="总结2"></a>总结2</h3><ol>
<li>Redis 事件循环主要处理两类事件：文件事件、时间事件</li>
</ol>
<ul>
<li>文件事件包括：client 发起新连接、client 向 server 写数据、server 向 client 响应数据</li>
<li>时间事件：Redis 的各种定时任务（主线程中执行）</li>
</ul>
<ol start="2">
<li>Redis 在启动时，会创建 aeEventLoop，初始化 epoll 对象，监听端口，之后会注册文件事件、时间事件：</li>
</ol>
<ul>
<li>文件事件：把 listen socket fd 注册到 epoll 中，回调函数是 acceptTcpHandler（新连接事件）</li>
<li>时间事件：把 serverCron 函数注册到 aeEventLoop 中，并指定执行频率</li>
</ul>
<ol start="3">
<li>Redis Server 启动后，会启动一个死循环，持续处理事件（ae.c 的 aeProcessEvents 函数）</li>
<li>有文件事件（网络 IO)，则优先处理。例如，client 到 server 的新连接，会调用 acceptTcpHandler 函数，之后会注册读事件 readQueryFromClient 函数，client 发给 server 的数据，都会在这个函数处理，这个函数会解析 client 的数据，找到对应的 cmd 函数执行</li>
<li>cmd 逻辑执行完成后，server 需要写回数据给 client，会先把响应数据写到对应 client 的 内存 buffer 中，在下一次处理 IO 事件之前，Redis 会把每个 client 的 buffer 数据写到 client 的 socket 中，给 client 响应</li>
<li>如果响应给 client 的数据过多，则会分多次发送，待发送的数据会暂存到 buffer，然后会向 epoll 注册回调函数 sendReplyToClient，待 socket 可写时，继续调用回调函数向 client 写回剩余数据</li>
<li>在这个死循环中处理每次事件时，都会先检查一下，时间事件是否需要执行，因为之前已经注册好了时间事件的回调函数 + 执行频率，所以在执行 aeApiPoll 时，timeout 就是定时任务的周期，这样即使没有 IO 事件，epoll_wait 也可以正常返回，此时就可以执行一次定时任务 serverCron 函数，这样就可以在一个线程中就完成 IO 事件 + 定时任务的处理</li>
</ol>
<p>课后题：Redis 在调用 aeApiCreate、aeApiAddEvent 这些函数时，是根据什么条件来决定，具体调用哪个文件中的 IO 多路复用函数的？</p>
<p>在 ae.c 中，根据不同平台，首先定义好了要导入的封装好的 IO 多路复用函数，每个平台对应的文件中都定义了 aeApiCreate、aeApiAddEvent 这类函数，在执行时就会执行对应平台的函数逻辑。</p>
<div class="code-wrapper"><pre><code class="hljs c"><span class="hljs-comment">// ae.c</span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">ifdef</span> HAVE_EVPORT</span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&quot;ae_evport.c&quot;</span> <span class="hljs-comment">// Solaris</span></span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">else</span></span>
    <span class="hljs-meta">#<span class="hljs-meta-keyword">ifdef</span> HAVE_EPOLL</span>
    <span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&quot;ae_epoll.c&quot;</span> <span class="hljs-comment">// Linux</span></span>
    <span class="hljs-meta">#<span class="hljs-meta-keyword">else</span></span>
        <span class="hljs-meta">#<span class="hljs-meta-keyword">ifdef</span> HAVE_KQUEUE</span>
        <span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&quot;ae_kqueue.c&quot;</span> <span class="hljs-comment">// MacOS</span></span>
        <span class="hljs-meta">#<span class="hljs-meta-keyword">else</span></span>
        <span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&quot;ae_select.c&quot;</span> <span class="hljs-comment">// Windows</span></span>
        <span class="hljs-meta">#<span class="hljs-meta-keyword">endif</span></span>
    <span class="hljs-meta">#<span class="hljs-meta-keyword">endif</span></span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">endif</span></span></code></pre></div>


<h2 id="多进程"><a href="#多进程" class="headerlink" title="多进程"></a>多进程</h2><h3 id="总结1-10"><a href="#总结1-10" class="headerlink" title="总结1"></a>总结1</h3><p>今天这节课，我给你介绍了 Redis 的执行模型，并且也从源码的角度出发，通过分析代码，带你了解了 Redis 进程创建、以子进程方式创建的守护进程、以及后台线程和它们负责的工作任务。同时，这也解答了你在面试中可能经常会被问到的问题：Redis 是单线程程序吗？</p>
<p>事实上，Redis server 启动后，它的主要工作包括接收客户端请求、解析请求和进行数据读写等操作，是由单线程来执行的，这也是我们常说 Redis 是单线程程序的原因。</p>
<p>但是，学完这节课你应该也知道，Redis 还启动了 3 个线程来执行文件关闭、AOF 同步写和惰性删除等操作，从这个角度来说，Redis 又不能算单线程程序，它还是有多线程的。而且，在下节课，我会给你介绍 Redis 6.0 中多 IO 线程的实现，从多 IO 线程角度看，Redis 也无法称为是单线程程序了。</p>
<p>另外学完了这节课之后，你还需要重点注意下，fork 函数使用和生产者 - 消费者模型这两个关键知识点。</p>
<p>首先是 fork 函数的使用。fork 函数可以在一个进程运行时，再创建一个子进程。当 Redis 被配置为以守护进程方式运行时，Redis 的 main 函数就是调用 fork 函数，创建子进程，让子进程以守护进程形式执行，并让一开始启动执行的父进程退出。因为，子进程会从父进程那继承代码，所以 main 函数中的执行逻辑就交给了子进程继续执行。</p>
<p>其次是生产者 - 消费者模型。Redis 在 bio.c 和 bio.h 文件中创建了后台线程，并实现了后台任务的执行。你要重点关注一下这里使用的生产者 - 消费者执行模型，这也是 bio.c 实现后台任务执行的核心设计思想。而且，当你需要实现异步的任务执行时，生产者 - 消费者模型就是一个很好的解决方案，你可以从 Redis 源码中掌握这个方案的实现思路。</p>
<h3 id="总结2-10"><a href="#总结2-10" class="headerlink" title="总结2"></a>总结2</h3><ol>
<li>很多人认为 Redis 是单线程，这个描述是不准确的。准确来说 Redis 只有在处理「客户端请求」时，是单线程的。但整个 Redis Server 并不是单线程的，还有后台线程在辅助处理一些工作</li>
<li>Redis 选择单线程处理请求，是因为 Redis 操作的是「内存」，加上设计了「高效」的数据结构，所以操作速度极快，利用 IO 多路复用机制，单线程依旧可以有非常高的性能</li>
<li>但如果一个请求发生耗时，单线程的缺点就暴露出来了，后面的请求都要「排队」等待，所以 Redis 在启动时会启动一些「后台线程」来辅助工作，目的是把耗时的操作，放到后台处理，避免主线程操作耗时影响整体性能</li>
<li>例如关闭 fd、AOF 刷盘、释放 key 的内存，这些耗时操作，都可以放到后台线程中处理，对主逻辑没有任何影响</li>
<li>后台线程处理这些任务，就相当于一个消费者，生产者（主线程）把耗时任务丢到队列中（链表），消费者不停轮询这个队列，拿出任务就去执行对应的方法即可：</li>
</ol>
<ul>
<li>BIO_CLOSE_FILE：close(fd)</li>
<li>BIO_AOF_FSYNC：fsync(fd)</li>
<li>BIO_LAZY_FREE：free(obj) / free(dict) / free(skiplist)</li>
</ul>
<p>课后题：Redis 后台任务使用 bio_job 结构体来描述，该结构体用了三个指针变量来表示任务参数，如果我们创建的任务，所需要的参数大于 3 个，你有什么应对方法来传参么？</p>
<p>最直接的方法就是，把参数换成数组类型，这样就可以传递任意数量参数了。因为这里 Redis 的后台任务都比较简单，最多 3 个参数就足够满足需求，所以 job 直接写死了 3 个参数变量，这样做的好处是维护起来简单直接。</p>
<h2 id="多IO线程"><a href="#多IO线程" class="headerlink" title="多IO线程"></a>多IO线程</h2><h3 id="总结1-11"><a href="#总结1-11" class="headerlink" title="总结1"></a>总结1</h3><p>今天这节课，我给你介绍了 Redis 6.0 中新设计实现的多 IO 线程机制。这个机制的设计主要是为了使用多个 IO 线程，来并发处理客户端读取数据、解析命令和写回数据。使用了多线程后，Redis 就可以充分利用服务器的多核特性，从而提高 IO 效率。</p>
<p>总结来说，Redis 6.0 先是在初始化过程中，根据用户设置的 IO 线程数量，创建对应数量的 IO 线程。</p>
<p>当 Redis server 初始化完成后正常运行时，它会在 readQueryFromClient 函数中通过调用 postponeClientRead 函数来决定是否推迟客户端读操作。同时，Redis server 会在 addReply 函数中通过调用 prepareClientToWrite 函数，来决定是否推迟客户端写操作。而待读写的客户端会被分别加入到 clients_pending_read 和 clients_pending_write 两个列表中。</p>
<p>这样，每当 Redis server 要进入事件循环流程前，都会在 beforeSleep 函数中分别调用 handleClientsWithPendingReadsUsingThreads 函数和 handleClientsWithPendingWritesUsingThreads 函数，将待读写客户端以轮询方式分配给 IO 线程，加入到 IO 线程的待处理客户端列表 io_threads_list 中。</p>
<p>而 IO 线程一旦运行后，本身会一直检测 io_threads_list 中的客户端，如果有待读写客户端，IO 线程就会调用 readQueryFromClient 或 writeToClient 函数来进行处理。</p>
<p>最后，我也想再提醒你一下，多 IO 线程本身并不会执行命令，它们只是利用多核并行地读取数据和解析命令，或是将 server 数据写回（下节课我还会结合分布式锁的原子性保证，来给你介绍这一部分的源码实现。）。所以，Redis 执行命令的线程还是主 IO 线程。这一点对于你理解多 IO 线程机制很重要，可以避免你误解 Redis 有多线程同时执行命令。</p>
<p>这样一来，我们原来针对 Redis 单个主 IO 线程做的优化仍然有效，比如避免 bigkey、避免阻塞操作等。</p>
<h3 id="总结2-11"><a href="#总结2-11" class="headerlink" title="总结2"></a>总结2</h3><ol>
<li>Redis 6.0 之前，处理客户端请求是单线程，这种模型的缺点是，只能用到「单核」CPU。如果并发量很高，那么在读写客户端数据时，容易引发性能瓶颈，所以 Redis 6.0 引入了多 IO 线程解决这个问题</li>
<li>配置文件开启 io-threads N 后，Redis Server 启动时，会启动 N - 1 个 IO 线程（主线程也算一个 IO 线程），这些 IO 线程执行的逻辑是 networking.c 的 IOThreadMain 函数。但默认只开启多线程「写」client socket，如果要开启多线程「读」，还需配置 io-threads-do-reads = yes</li>
<li>Redis 在读取客户端请求时，判断如果开启了 IO 多线程，则把这个 client 放到 clients_pending_read 链表中（postponeClientRead 函数），之后主线程在处理每次事件循环之前，把链表数据轮询放到 IO 线程的链表（io_threads_list）中</li>
<li>同样地，在写回响应时，是把 client 放到 clients_pending_write 中（prepareClientToWrite 函数），执行事件循环之前把数据轮询放到 IO 线程的链表（io_threads_list）中</li>
<li>主线程把 client 分发到 IO 线程时，自己也会读写客户端 socket（主线程也要分担一部分读写操作），之后「等待」所有 IO 线程完成读写，再由主线程「串行」执行后续逻辑</li>
<li>每个 IO 线程，不停地从 io_threads_list 链表中取出 client，并根据指定类型读、写 client socket</li>
<li>IO 线程在处理读、写 client 时有些许差异，如果 write_client_pedding &lt; io_threads * 2，则直接由「主线程」负责写，不再交给 IO 线程处理，从而节省 CPU 消耗</li>
<li>Redis 官方建议，服务器最少 4 核 CPU 才建议开启 IO 多线程，4 核 CPU 建议开 2-3 个 IO 线程，8 核 CPU 开 6 个 IO 线程，超过 8 个线程性能提升不大</li>
<li>Redis 官方表示，开启多 IO 线程后，性能可提升 1 倍。当然，如果 Redis 性能足够用，没必要开 IO 线程</li>
</ol>
<p>课后题：为什么 startThreadedIO / stopThreadedIO 要执行加解锁？</p>
<p>既然涉及到加锁操作，必然是为了「互斥」从而控制某些逻辑。可以在代码中检索这个锁变量，看存在哪些逻辑对 io_threads_mutex 操作了加解锁。</p>
<p>跟踪代码可以看到，在 networking.c 的 IOThreadMain 函数，也对这个变量进行了加解锁操作，那就说明 startThreadedIO / stopThreadedIO 函数，可以控制 IOThreadMain 里逻辑的执行，IOThreadMain 代码如下。</p>
<div class="code-wrapper"><pre><code class="hljs c"><span class="hljs-function"><span class="hljs-keyword">void</span> *<span class="hljs-title">IOThreadMain</span><span class="hljs-params">(<span class="hljs-keyword">void</span> *myid)</span> </span>&#123;
    ...
    <span class="hljs-keyword">while</span>(<span class="hljs-number">1</span>) &#123;
    ...
    <span class="hljs-comment">/* Give the main thread a chance to stop this thread. */</span>
    <span class="hljs-keyword">if</span> (io_threads_pending[id] == <span class="hljs-number">0</span>) &#123;
    pthread_mutex_lock(&amp;io_threads_mutex[id]);
    pthread_mutex_unlock(&amp;io_threads_mutex[id]);
    <span class="hljs-keyword">continue</span>;
    &#125;
    <span class="hljs-comment">// 读写 client socket</span>
    <span class="hljs-comment">// ...</span>
&#125;</code></pre></div>

<p>这个函数正是 IO 多线程的主逻辑。</p>
<p>从注释可以看到，这是为了给主线程停止 IO 线程的的机会。也就是说，这里的目的是为了让主线程可以控制 IO 线程的开启 / 暂停。</p>
<p>因为每次 IO 线程在执行时必须先拿到锁，才能执行后面的逻辑，如果主线程执行了 stopThreadedIO，就会先拿到锁，那么 IOThreadMain 函数在执行时就会因为拿不到锁阻塞「等待」，这就达到了 stop IO 线程的目的。</p>
<p>同样地，调用 startThreadedIO 函数后，会释放锁，IO 线程就可以拿到锁，继续「恢复」执行。</p>
<h2 id="分布式的原子性"><a href="#分布式的原子性" class="headerlink" title="分布式的原子性"></a>分布式的原子性</h2><h3 id="总结1-12"><a href="#总结1-12" class="headerlink" title="总结1"></a>总结1</h3><p>今天这节课我主要结合分布式锁的原子性保证需求，带你学习了 Redis 处理一条命令的整个过程。其中，你需要重点关注分布式锁实现的方法。</p>
<p>我们知道，加锁和解锁操作分别可以使用 SET 命令和 Lua 脚本与 EVAL 命令来完成。那么，分布式锁的原子性保证，就主要依赖 SET 和 EVAL 命令在 Redis server 中执行时的原子性保证了。</p>
<p>紧接着，我还带你具体剖析了下 Redis 中命令处理的整个过程。我把这个过程分成了四个阶段，分别是命令读取、命令解析、命令执行和结果返回。所以，你还需要了解这四个阶段中所执行函数的主要流程。</p>
<p>这四个阶段在 Redis 6.0 版本前都是由主 IO 线程来执行完成的。虽然 Redis 使用了 IO 多路复用机制，但是该机制只是一次性获取多个就绪的 socket 描述符，对应了多个发送命令请求的客户端。而 Redis 在主 IO 线程中，还是逐一来处理每个客户端上的命令的，所以命令执行的原子性依然可以得到保证。</p>
<p>而当使用了 Redis 6.0 版本后，命令处理过程中的读取、解析和结果写回，就由多个 IO 线程来处理了。不过你也不用担心，多个 IO 线程只是完成解析第一个读到的命令，命令的实际执行还是由主 IO 线程处理。当多个 IO 线程在并发写回结果时，命令就已经执行完了，不存在多 IO 线程冲突的问题。所以，使用了多 IO 线程后，命令执行的原子性仍然可以得到保证。</p>
<p>好，最后，我也想再说下我对多 IO 线程的看法。从今天课程介绍的内容中，你可以看到，多 IO 线程实际并不会加快命令的执行，而是只会将读取解析命令并行化执行，以及写回结果并行化执行，并且读取解析命令还是针对收到的第一条命令。实际上，这一设计考虑还是由于网络 IO 需要加速处理。那么，如果命令执行本身成为 Redis 运行时瓶颈了，你其实可以考虑使用 Redis 切片集群来提升处理效率。</p>
<h3 id="总结2-12"><a href="#总结2-12" class="headerlink" title="总结2"></a>总结2</h3><ol>
<li>无论是 IO 多路复用，还是 Redis 6.0 的多 IO 线程，Redis 执行具体命令的主逻辑依旧是「单线程」的</li>
<li>执行命令是单线程，本质上就保证了每个命令必定是「串行」执行的，前面请求处理完成，后面请求才能开始处理</li>
<li>所以 Redis 在实现分布式锁时，内部不需要考虑加锁问题，直接在主线程中判断 key 是否存在即可，实现起来非常简单</li>
</ol>
<p>课后题：如果将命令处理过程中的命令执行也交给多 IO 线程执行，除了对原子性会有影响，还会有什么好处和坏处？</p>
<p>好处：</p>
<ul>
<li>每个请求分配给不同的线程处理，一个请求处理慢，并不影响其它请求</li>
<li>请求操作的 key 越分散，性能会变高（并行处理比串行处理性能高）</li>
<li>可充分利用多核 CPU 资源</li>
</ul>
<p>坏处：</p>
<ul>
<li>操作同一个 key 需加锁，加锁会影响性能，如果是热点 key，性能下降明显</li>
<li>多线程上下文切换存在性能损耗</li>
<li>多线程开发和调试不友好</li>
</ul>
<h2 id="LRU"><a href="#LRU" class="headerlink" title="LRU"></a>LRU</h2><h3 id="总结1-13"><a href="#总结1-13" class="headerlink" title="总结1"></a>总结1</h3><p>好了，今天这节课就到这里，我们来总结下。</p>
<p>今天这节课我给你介绍了 Redis 中，是如何实现 LRU 算法来进行缓存数据替换的。其中，我们根据 LRU 算法的基本原理，可以发现如果严格按照原理来实现 LRU 算法，那么开发的系统就需要用额外的内存空间来保存 LRU 链表，而且系统运行时也会受到 LRU 链表操作的开销影响。</p>
<p>而对于 Redis 来说，内存资源和性能都很重要，所以 Redis 实现了近似 LRU 算法。而为了实现近似 LRU 算法，Redis 首先是设置了全局 LRU 时钟，并在键值对创建时获取全局 LRU 时钟值作为访问时间戳，以及在每次访问时获取全局 LRU 时钟值，更新访问时间戳。</p>
<p>然后，当 Redis 每处理一个命令时，都会调用 freeMemoryIfNeeded 函数来判断是否需要释放内存。如果已使用内存超出了 maxmemory，那么，近似 LRU 算法就会随机选择一些键值对，组成待淘汰候选集合，并根据它们的访问时间戳，选出最旧的数据，将其淘汰。</p>
<p>实际上，通过学习这节课的内容，你可以体会到一个算法的基本原理和算法的实际执行，在系统开发中会有一定的折中选择，主要就是因为我们需要综合考虑所开发的系统，在资源和性能方面的要求，以避免严格按照算法实现带来的资源和性能开销。因此，这一点就是你在进行计算机系统开发时，要秉承的一个原则。</p>
<h3 id="总结2-13"><a href="#总结2-13" class="headerlink" title="总结2"></a>总结2</h3><ol>
<li>实现一个严格的 LRU 算法，需要额外的内存构建 LRU 链表，同时维护链表也存在性能开销，Redis 对于内存资源和性能要求极高，所以没有采用严格 LRU 算法，而是采用「近似」LRU 算法实现数据淘汰策略</li>
<li>触发数据淘汰的时机，是每次处理「请求」时判断的。也就是说，执行一个命令之前，首先要判断实例内存是否达到 maxmemory，是的话则先执行数据淘汰，再执行具体的命令</li>
<li>淘汰数据时，会「持续」判断 Redis 内存是否下降到了 maxmemory 以下，不满足的话会继续淘汰数据，直到内存下降到 maxmemory 之下才会停止</li>
<li>可见，如果发生大量淘汰的情况，那么处理客户端请求就会发生「延迟」，影响性能</li>
<li>Redis 计算实例内存时，不会把「主从复制」的缓冲区计算在内，也就是说不管一个实例后面挂了多少个从库，主库不会把主从复制所需的「缓冲区」内存，计算到实例内存中，即这部分内存增加，不会对数据淘汰产生影响</li>
<li>但如果 Redis 内存已达到 maxmemory，要谨慎执行 MONITOR 命令，因为 Redis Server 会向执行 MONITOR 的 client 缓冲区填充数据，这会导致缓冲区内存增长，进而引发数据淘汰</li>
</ol>
<p>课后题：为什么键值对的 LRU 时钟值，不是直接通过调用 getLRUClock 函数来获取？</p>
<p>本质上是为了性能。</p>
<p>Redis 这种对性能要求极高的数据库，在系统调用上的优化也做到了极致。</p>
<p>获取机器时钟本质上也是一个「系统调用」，对于 Redis 这种动不动每秒上万的 QPS，如果每次都触发一次系统调用，这么频繁的操作也是一笔不小的开销。</p>
<p>所以，Redis 用一个定时任务（serverCron 函数），以固定频率触发系统调用获取机器时钟，然后把机器时钟挂到 server 的全局变量下，这相当于维护了一个「本地缓存」，当需要获取时钟时，直接从全局变量获取即可，节省了大量的系统调用开销。</p>
<h2 id="LFU"><a href="#LFU" class="headerlink" title="LFU"></a>LFU</h2><h3 id="总结1-14"><a href="#总结1-14" class="headerlink" title="总结1"></a>总结1</h3><p>这节课我主要是给你介绍了 Redis 使用的 LFU 缓存淘汰策略。LFU 算法会根据键值对的访问频率来淘汰数据，而和使用访问次数淘汰数据不同，使用访问频率，不仅需要统计访问次数，而且还要考虑所记录的访问距离当前时间的时长。</p>
<p>所以，正是基于这样的设计考虑，Redis 源码在实现 LFU 算法时，在键值对的 redisObject 结构体中的 lru 变量里，会同时记录访问次数和访问时间戳。当键值对被再次访问时，lru 变量中的访问次数，会先根据上一次访问距离当前的时长，执行衰减操作，然后才会执行增加操作。</p>
<p>不过，键值对的访问次数只能用 lru 变量中有限的 8 bits 来记录，最大值就是 255。这样一来，如果每访问一次键值对，访问次数就加 1 的话，那么访问次数很容易就达到最大值了，这就无法区分不同的访问频率了。</p>
<p>为了区分不同的访问频率，LFU 算法在实现时是采用了按概率增加访问次数的方法，也就是说，已有访问次数越大的键值对，它的访问次数就越难再增加。</p>
<p>另外你也要知道，对于 LFU 算法的执行流程来说，它和 LRU 算法的基本执行流程是相同的，这包括入口函数、待释放内存空间计算、更新待淘汰候选键值对集合，以及选择实际被淘汰数据这几个关键步骤。不同的是，LFU 算法在待淘汰键值对集合中，是按照键值对的访问频率大小来排序和选择淘汰数据的，这也符合 LFU 算法本身的要求。</p>
<p>而且，正因为 LFU 算法会根据访问频率来淘汰数据，以及访问频率会随时间推移而衰减，所以，LFU 算法相比其他算法来说，更容易把低频访问的冷数据尽早淘汰掉，这也是它的适用场景。</p>
<p>最后，从 LFU 算法的实现代码来看，当我们自己实现按访问频率进行操作的软件模块时，我觉得 Redis 采用的这两种设计方法：访问次数按时间衰减和访问次数按概率增加，其实是一个不错的参考范例。你在自己的实现场景中，就可以借鉴使用。</p>
<h3 id="总结2-14"><a href="#总结2-14" class="headerlink" title="总结2"></a>总结2</h3><ol>
<li>LFU 是在 Redis 4.0 新增的淘汰策略，它涉及的巧妙之处在于，其复用了 redisObject 结构的 lru 字段，把这个字段「一分为二」，保存最后访问时间和访问次数</li>
<li>key 的访问次数不能只增不减，它需要根据时间间隔来做衰减，才能达到 LFU 的目的</li>
<li>每次在访问一个 key 时，会「懒惰」更新这个 key 的访问次数：先衰减访问次数，再更新访问次数</li>
<li>衰减访问次数，会根据时间间隔计算，间隔时间越久，衰减越厉害</li>
<li>因为 redisObject lru 字段宽度限制，这个访问次数是有上限的（8 bit 最大值 255），所以递增访问次数时，会根据「当前」访问次数和「概率」的方式做递增，访问次数越大，递增因子越大，递增概率越低</li>
<li>Redis 实现的 LFU 算法也是「近似」LFU，是在性能和内存方面平衡的结果</li>
</ol>
<p>课后题：LFU 算法在初始化键值对的访问次数时，会将访问次数设置为 LFU_INIT_VAL，默认值是 5 次。如果 LFU_INIT_VAL 设置为 1，会发生什么情况？</p>
<p>如果开启了 LFU，那在写入一个新 key 时，需要初始化访问时间、访问次数（createObject 函数），如果访问次数初始值太小，那这些新 key 的访问次数，很有可能在短时间内就被「衰减」为 0，那就会面临马上被淘汰的风险。</p>
<p>新 key 初始访问次数 LFU_INIT_VAL = 5，就是为了避免一个 key 在创建后，不会面临被立即淘汰的情况发生。</p>
<h2 id="Lazy-Free"><a href="#Lazy-Free" class="headerlink" title="Lazy Free"></a>Lazy Free</h2><h3 id="总结1-15"><a href="#总结1-15" class="headerlink" title="总结1"></a>总结1</h3><p>今天这节课，我给你介绍了 Redis 缓存在淘汰数据时，执行的数据删除流程。因为在 Redis 4.0 版本之后提供了惰性删除的功能，所以 Redis 缓存淘汰数据的时候，就会根据是否启用惰性删除，来决定是执行同步删除还是异步的惰性删除。</p>
<p>而你要知道，无论是同步删除还是异步的惰性删除，它们都会先把被淘汰的键值对从哈希表中移除。然后，同步删除就会紧接着调用 dictFreeKey、dictFreeVal 和 zfree 三个函数来分别释放 key、value 和键值对哈希项的内存空间。而异步的惰性删除，则是把空间释放任务交给了后台线程来完成。</p>
<p>注意，虽然惰性删除是由后台线程异步完成的，但是后台线程启动后会监听惰性删除的任务队列，一旦有了惰性删除任务，后台线程就会执行并释放内存空间。所以，从淘汰数据释放内存空间的角度来说，惰性删除并不会影响缓存淘汰时的空间释放要求。</p>
<p>不过在最后，我也想提醒你一下，就是后台线程需要通过同步机制获取任务，这个过程会引入一些额外的时间开销，会导致内存释放不像同步删除那样非常及时。实际上，这也是 Redis 在被淘汰数据是小集合（元素不超过 64 个）时，仍然使用主线程进行内存释放的设计考虑因素。</p>
<h3 id="总结2-15"><a href="#总结2-15" class="headerlink" title="总结2"></a>总结2</h3><ol>
<li>lazy-free 是 4.0 新增的功能，默认是关闭的，需要手动开启</li>
<li>开启 lazy-free 时，有多个「子选项」可以控制，分别对应不同场景下，是否开启异步释放内存：</li>
</ol>
<ul>
<li>lazyfree-lazy-expire：key 在过期删除时尝试异步释放内存</li>
<li>lazyfree-lazy-eviction：内存达到 maxmemory 并设置了淘汰策略时尝试异步释放内存</li>
<li>lazyfree-lazy-server-del：执行 RENAME/MOVE 等命令或需要覆盖一个 key 时，Redis 内部删除旧 key 尝试异步释放内存</li>
<li>replica-lazy-flush：主从全量同步，从库清空数据库时异步释放内存</li>
</ul>
<ol start="3">
<li>即使开启了 lazy-free，但如果执行的是 DEL 命令，则还是会同步释放 key 内存，只有使用 UNLINK 命令才「可能」异步释放内存</li>
<li>Redis 6.0 版本新增了一个新的选项 lazyfree-lazy-user-del，打开后执行 DEL 就与 UNLINK 效果一样了</li>
<li>最关键的一点，开启 lazy-free 后，除 replica-lazy-flush 之外，其它选项都只是「可能」异步释放 key 的内存，并不是说每次释放 key 内存都是丢到后台线程的</li>
<li>开启 lazy-free 后，Redis 在释放一个 key 内存时，首先会评估「代价」，如果代价很小，那么就直接在「主线程」操作了，「没必要」放到后台线程中执行（不同线程传递数据也会有性能消耗）</li>
<li>什么情况才会真正异步释放内存？这和 key 的类型、编码方式、元素数量都有关系（详见 lazyfreeGetFreeEffort 函数）：</li>
</ol>
<ul>
<li>当 Hash/Set 底层采用哈希表存储（非 ziplist/int 编码存储）时，并且元素数量超过 64 个</li>
<li>当 ZSet 底层采用跳表存储（非 ziplist 编码存储）时，并且元素数量超过 64 个</li>
<li>当 List 链表节点数量超过 64 个（注意，不是元素数量，而是链表节点的数量，List 底层实现是一个链表，链表每个节点是一个 ziplist，一个 ziplist 可能有多个元素数据）</li>
</ul>
<p>只有满足以上条件，在释放 key 内存时，才会真正放到「后台线程」中执行，其它情况一律还是在主线程操作。</p>
<p>也就是说 String（不管内存占用多大）、List（少量元素）、Set（int 编码存储）、Hash/ZSet（ziplist 编码存储）这些情况下的 key，在释放内存时，依旧在「主线程」中操作。</p>
<ol start="8">
<li>可见，即使打开了 lazy-free，String 类型的 bigkey，在删除时依旧有「阻塞」主线程的风险。所以，即便 Redis 提供了 lazy-free，还是不建议在 Redis 存储 bigkey</li>
</ol>
<p>9、Redis 在释放内存「评估」代价时，不是看 key 的内存大小，而是关注释放内存时的「工作量」有多大。从上面分析可以看出，如果 key 内存是连续的，释放内存的代价就比较低，则依旧放在「主线程」处理。如果 key 内存不连续（包含大量指针），这个代价就比较高，这才会放在「后台线程」中执行</p>
<p>课后题：freeMemoryIfNeeded 函数在使用后台线程，删除被淘汰数据的过程中，主线程是否仍然可以处理外部请求？</p>
<p>肯定是可以继续处理请求的。</p>
<p>主线程决定淘汰这个 key 之后，会先把这个 key 从「全局哈希表」中剔除，然后评估释放内存的代价，如果符合条件，则丢到「后台线程」中执行「释放内存」操作。</p>
<p>之后就可以继续处理客户端请求，尽管后台线程还未完成释放内存，但因为 key 已被全局哈希表剔除，所以主线程已查询不到这个 key 了，对客户端来说无影响。</p>
<h2 id="RDB"><a href="#RDB" class="headerlink" title="RDB"></a>RDB</h2><h3 id="总结1-16"><a href="#总结1-16" class="headerlink" title="总结1"></a>总结1</h3><p>今天这节课，我给你介绍了 Redis 内存快照文件 RDB 的生成。你要知道，创建 RDB 文件的三个入口函数分别是 rdbSave、rdbSaveBackground、rdbSaveToSlavesSockets，它们在 Redis 源码中被调用的地方，也就是触发 RDB 文件生成的时机。</p>
<p>另外，你也要重点关注 RDB 文件的基本组成，并且也要结合 rdbSaveRio 函数的执行流程，来掌握 RDB 文件头、文件数据部分和文件尾这三个部分的生成。我总结了以下两点，方便你对 RDB 文件结构和内容有个整体把握：</p>
<ul>
<li>RDB 文件使用多种操作码来标识 Redis 不同的属性信息，以及使用类型码来标识不同 value 类型；</li>
<li>RDB 文件内容是自包含的，也就是说，无论是属性信息还是键值对，RDB 文件都会按照类型、长度、实际数据的格式来记录，这样方便程序对 RDB 文件的解析。</li>
</ul>
<p>最后，我也想再说一下，RDB 文件包含了 Redis 数据库某一时刻的所有键值对，以及这些键值对的类型、大小、过期时间等信息。当你了解了 RDB 文件的格式和生成方法后，其实你就可以根据需求，开发解析 RDB 文件的程序或是加载 RDB 文件的程序了。</p>
<p>比如，你可以在 RDB 文件中查找内存空间消耗大的键值对，也就是在优化 Redis 性能时通常需要查找的 bigkey；你也可以分析不同类型键值对的数量、空间占用等分布情况，来了解业务数据的特点；你还可以自行加载 RDB 文件，用于测试或故障排查。</p>
<p>当然，这里我也再给你一个小提示，就是在你实际开发 RDB 文件分析工具之前，可以看下redis-rdb-tools这个工具，它能够帮助你分析 RDB 文件中的内容。而如果它还不能满足你的定制化需求，你就可以用上这节课学习的内容，来开发自己的 RDB 分析工具了。</p>
<h3 id="总结2-16"><a href="#总结2-16" class="headerlink" title="总结2"></a>总结2</h3><ol>
<li>RDB 文件是 Redis 的数据快照，以「二进制」格式存储，相比 AOF 文件更小，写盘和加载时间更短</li>
<li>RDB 在执行 SAVE / BGSAVE 命令、定时 BGSAVE、主从复制时产生</li>
<li>RDB 文件包含文件头、数据部分、文件尾</li>
<li>文件头主要包括 Redis 的魔数、RDB 版本、Redis 版本、RDB 创建时间、键值对占用的内存大小等信息</li>
<li>文件数据部分包括整个 Redis 数据库中存储的所有键值对信息</li>
</ol>
<ul>
<li>数据库信息：db 编号、db 中 key 的数量、过期 key 的数量、键值数据</li>
<li>键值数据：过期标识、时间戳（绝对时间）、键值对类型、key 长度、key、value 长度、value</li>
</ul>
<ol start="6">
<li>文件尾保存了 RDB 的结束标记、文件校验值</li>
<li>RDB 存储的数据，为了压缩体积，还做了很多优化:</li>
</ol>
<ul>
<li>变长编码存储键值对数据</li>
<li>用操作码标识不同的内容</li>
<li>可整数编码的内容使用整数类型紧凑编码</li>
</ul>
<p>课后题：在 serverCron 函数中，rdbSaveBackground 函数一共会被调用执行几次？这又分别对应了什么场景？</p>
<p>在 serverCron 函数中 rdbSaveBackground 会被调用 2 次。</p>
<p>一次是满足配置的定时 RDB 条件后（save <seconds> &lt;changes），触发子进程生成 RDB。</p>
<p>另一次是客户端执行了 BGSAVE 命令，Redis 会先设置 server.rdb_bgsave_scheduled = 1，之后 serverCron 函数判断这个变量为 1，也会触发子进程生成 RDB。</p>
<h2 id="AOF-上"><a href="#AOF-上" class="headerlink" title="AOF 上"></a>AOF 上</h2><h3 id="总结1-17"><a href="#总结1-17" class="headerlink" title="总结1"></a>总结1</h3><p>今天这节课我给你介绍了 Redis AOF 重写机制的实现，你需要重点关注以下两个要点：</p>
<ul>
<li>AOF 重写的触发时机。这既包括了我们主动执行 bgrewriteaof 命令，也包括了 Redis server 根据 AOF 文件大小而自动触发的重写。此外，在主从复制的过程中，从节点也会启动 AOF 重写，形成一份完整的 AOF 日志，以便后续进行恢复。当然你也要知道，当要触发 AOF 重写时，Redis server 是不能运行 RDB 子进程和 AOF 重写子进程的。</li>
<li>AOF 重写的基本执行过程。AOF 重写和 RDB 创建的过程类似，它也是创建了一个子进程来完成重写工作。这是因为 AOF 重写操作，实际上需要遍历 Redis server 上的所有数据库，把每个键值对以插入操作的形式写入日志文件，而日志文件又要进行写盘操作。所以，Redis 源码使用子进程来实现 AOF 重写，这就避免了阻塞主线程，也减少了对 Redis 整体性能的影响。</li>
</ul>
<p>不过，你需要注意的是，虽然 AOF 重写和 RDB 创建都用了子进程，但是它们也有不同的地方，AOF 重写过程中父进程收到的写操作，也需要尽量写入 AOF 重写日志，在这里，Redis 源码是使用了管道机制来实现父进程和 AOF 重写子进程间的通信的。在下一讲中，我就会重点给你介绍，Redis 是如何使用管道完成父子进程的通信，以及它们通过管道又传递了哪些数据或信息。</p>
<h3 id="总结2-17"><a href="#总结2-17" class="headerlink" title="总结2"></a>总结2</h3><ol>
<li>AOF 记录的是每个命令的「操作历史」，随着时间增长，AOF 文件会越来越大，所以需要 AOF 重写来「瘦身」，减小文件体积</li>
<li>AOF 重写时，会扫描整个实例中的数据，把数据以「命令 + 键值对」的格式，写到 AOF 文件中</li>
<li>触发 AOF 重写的时机有 4 个：</li>
</ol>
<ul>
<li>执行 bgrewriteaof 命令</li>
<li>手动打开 AOF 开关（config set appendonly yes）</li>
<li>从库加载完主库 RDB 后（AOF 被启动的前提下）</li>
<li>定时触发：AOF 文件大小比例超出阈值、AOF 文件大小绝对值超出阈值（AOF 被启动的前提下）</li>
</ul>
<p>这 4 个时机，都不能有 RDB 子进程，否则 AOF 重写会延迟执行。</p>
<ol start="4">
<li>AOF 重写期间会禁用 rehash，不让父进程调整哈希表大小，目的是父进程「写时复制」拷贝大量内存页面</li>
</ol>
<p>课后题：为什么 Redis 源码中在有 RDB 子进程运行时，不会启动 AOF 重写子进程？</p>
<p>无论是生成 RDB 还是 AOF 重写，都需要创建子进程，然后把实例中的所有数据写到磁盘上，这个过程中涉及到两块：</p>
<ul>
<li>CPU：写盘之前需要先迭代实例中的所有数据，在这期间会耗费比较多的 CPU 资源，两者同时进行，CPU 资源消耗大</li>
<li>磁盘：同样地，RDB 和 AOF 重写，都是把内存数据落盘，在这期间 Redis 会持续写磁盘，如果同时进行，磁盘 IO 压力也会较大</li>
</ul>
<p>整体来说都是为了资源考虑，所以不会让它们同时进行。</p>
<h2 id="AOF-下"><a href="#AOF-下" class="headerlink" title="AOF 下"></a>AOF 下</h2><h3 id="总结1-18"><a href="#总结1-18" class="headerlink" title="总结1"></a>总结1</h3><p>今天这节课，我主要给你介绍了在 AOF 重写过程中，主进程和重写子进程间的管道通信。这里，你需要重点关注管道机制的使用，以及主进程和重写子进程使用管道通信的过程。</p>
<p>在这个过程中，AOF 重写子进程和主进程是使用了一个操作命令传输管道和两个 ACK 信息发送管道。操作命令传输管道是用于主进程写入收到的新操作命令，以及用于重写子进程读取操作命令，而 ACK 信息发送管道是在重写结束时，重写子进程和主进程用来相互确认重写过程的结束。最后，重写子进程会进一步将收到的操作命令记录到重写日志文件中。</p>
<p>这样一来，AOF 重写过程中主进程收到的新写操作，就不会被遗漏了。因为一方面，这些新写操作会被记录在正常的 AOF 日志中，另一方面，主进程会将新写操作缓存在 aof_rewrite_buf_blocks 数据块列表中，并通过管道发送给重写子进程。这样，就能尽可能地保证重写日志具有最新、最完整的写操作了。</p>
<p>最后，我也再提醒你一下，今天这节课我们学习的管道其实属于匿名管道，是用在父子进程间进行通信的。如果你在实际开发中，要在非父子进程的两个进程间进行通信，那么你就需要用到命名管道了。而命名管道会以一个文件的形式保存在文件系统中，并会有相应的路径和文件名。这样，非父子进程的两个进程通过命名管道的路径和文件名，就可以打开管道进行通信了。</p>
<h3 id="总结2-18"><a href="#总结2-18" class="headerlink" title="总结2"></a>总结2</h3><ol>
<li>AOF 重写是在子进程中执行，但在此期间父进程还会接收写操作，为了保证新的 AOF 文件数据更完整，所以父进程需要把在这期间的写操作缓存下来，然后发给子进程，让子进程追加到 AOF 文件中</li>
<li>因为需要父子进程传输数据，所以需要用到操作系统提供的进程间通信机制，这里 Redis 用的是「管道」，管道只能是一个进程写，另一个进程读，特点是单向传输</li>
<li>AOF 重写时，父子进程用了 3 个管道，分别传输不同类别的数据：</li>
</ol>
<ul>
<li>父进程传输数据给子进程的管道：发送 AOF 重写期间新的写操作</li>
<li>子进程完成重写后通知父进程的管道：让父进程停止发送新的写操作</li>
<li>父进程确认收到子进程通知的管道：父进程通知子进程已收到通知</li>
</ul>
<ol start="4">
<li>AOF 重写的完整流程是：父进程 fork 出子进程，子进程迭代实例所有数据，写到一个临时 AOF 文件，在写文件期间，父进程收到新的写操作，会先缓存到 buf 中，之后父进程把 buf 中的数据，通过管道发给子进程，子进程写完 AOF 文件后，会从管道中读取这些命令，再追加到 AOF 文件中，最后 rename 这个临时 AOF 文件为新文件，替换旧的 AOF 文件，重写结束</li>
</ol>
<p>课后题：Redis 中其它使用管道的地方还有哪些？</p>
<p>在源码中搜索 pipe 函数，能看到 server.child_info_pipe 和 server.module_blocked_pipe 也使用了管道。</p>
<p>其中 child_info_pipe 管道如下：</p>
<div class="code-wrapper"><pre><code class="hljs c"><span class="hljs-comment">/* Pipe and data structures for child -&gt; parent info sharing. */</span>
<span class="hljs-keyword">int</span> child_info_pipe[<span class="hljs-number">2</span>]; <span class="hljs-comment">/* Pipe used to write the child_info_data. */</span>
<span class="hljs-class"><span class="hljs-keyword">struct</span> &#123;</span>
    <span class="hljs-keyword">int</span> process_type; <span class="hljs-comment">/* AOF or RDB child? */</span>
    <span class="hljs-keyword">size_t</span> cow_size; <span class="hljs-comment">/* Copy on write size. */</span>
    <span class="hljs-keyword">unsigned</span> <span class="hljs-keyword">long</span> <span class="hljs-keyword">long</span> magic; <span class="hljs-comment">/* Magic value to make sure data is valid. */</span>
&#125; child_info_data;</code></pre></div>


<p>从注释能看出，子进程在生成 RDB 或 AOF 重写完成后，子进程通知父进程在这期间，父进程「写时复制」了多少内存，父进程把这个数据记录到 server 的 stat_rdb_cow_bytes / stat_aof_cow_bytes 下（childinfo.c 的 receiveChildInfo 函数），以便客户端可以查询到最后一次 RDB 和 AOF 重写期间写时复制时，新申请的内存大小。</p>
<p>而 module_blocked_pipe 管道主要服务于 Redis module。</p>
<div class="code-wrapper"><pre><code class="hljs c"><span class="hljs-comment">/* Pipe used to awake the event loop if a client blocked on a module command needs to be processed. */</span>
<span class="hljs-keyword">int</span> module_blocked_pipe[<span class="hljs-number">2</span>];</code></pre></div>

<p>看注释是指，如果被 module 命令阻塞的客户端需要处理，则会唤醒事件循环开始处理。</p>
<h2 id="主从复制"><a href="#主从复制" class="headerlink" title="主从复制"></a>主从复制</h2><h3 id="总结1-19"><a href="#总结1-19" class="headerlink" title="总结1"></a>总结1</h3><p>主从复制是 Redis、MySQL 等数据库或存储系统，用来实现高可用性的方法。要实现主从复制，则需要应对整个过程中 Redis 在不同状态下的各种处理逻辑，因此，如何正确实现主从复制，并且不遗漏可能的状态，是我们在实际开发中需要面对的问题。</p>
<p>这节课我们学习了 Redis 主从复制的设计思想与实现方法。Redis 采用了状态机驱动的方法，为从库实例设置状态变量。在整个复制过程中，代码逻辑会根据从库状态机的变迁，处理不同状态下的情况。</p>
<p>为了便于你掌握主从复制的实现，我将整个过程分解成四个阶段：初始化、建立连接、主从握手、复制类型判断与执行。在每个阶段中，从库的状态会不断变化，完成和主库建立网络连接、交换配置信息、发送同步命令，并根据主库对同步请求的返回结果，执行全量同步或增量同步。</p>
<p>状态机驱动的设计方法是一种通用的设计方法，在涉及网络通信的场景中应用广泛。Redis 对主从复制的实现为我们提供了良好的参考示例，当你需要自行设计和实现网络功能时，就可以把状态机驱动的方法使用起来。</p>
<h3 id="总结2-19"><a href="#总结2-19" class="headerlink" title="总结2"></a>总结2</h3><ol>
<li>Redis 主从复制分为 4 个阶段：</li>
</ol>
<ul>
<li>初始化</li>
<li>建立连接</li>
<li>主从握手</li>
<li>数据传输（全量/增量复制）</li>
</ul>
<ol start="2">
<li>主从复制流程由于是是「从库」发起的，所以重点要看从库的执行流程</li>
<li>从库发起复制的方式有 3 个：</li>
</ol>
<ul>
<li>执行 slaveof / replicaof 命令</li>
<li>配置文件配置了主库的 ip port</li>
<li>启动实例时指定了主库的 ip port</li>
</ul>
<ol start="4">
<li>建议从 slaveof / replicaof 命令跟源码进去，来看整个主从复制的流程（入口在 replication.c 的 replicaofCommand 函数）</li>
<li>从库执行这个命令后，会先在 server 结构体上，记录主库的 ip port，然后把 server.repl_state 从 REPL_STATE_NONE 改为 REPL_STATE_CONNECT，「复制状态机」启动</li>
<li>随后从库会在定时任务（server.c 的 serverCron 函数）中会检测 server.repl_state 的状态，然后向主库发起复制请求（replication.c 的 replicationCron 函数），进入复制流程（replication.c 的 connectWithMaster 函数）</li>
<li>从库会与主库建立连接（REPL_STATE_CONNECTING），注册读事件（syncWithMaster 函数），之后主从进入握手认证阶段，从库会告知主库自己的 ip port 等信息，在这期间会流转多个状态（server.h 中定义的复制状态）：</li>
</ol>
<div class="code-wrapper"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> REPL_STATE_RECEIVE_PONG 3 <span class="hljs-comment">/* Wait for PING reply */</span></span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> REPL_STATE_SEND_AUTH 4 <span class="hljs-comment">/* Send AUTH to master */</span></span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> REPL_STATE_RECEIVE_AUTH 5 <span class="hljs-comment">/* Wait for AUTH reply */</span></span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> REPL_STATE_SEND_PORT 6 <span class="hljs-comment">/* Send REPLCONF listening-port */</span></span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> REPL_STATE_RECEIVE_PORT 7 <span class="hljs-comment">/* Wait for REPLCONF reply */</span></span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> REPL_STATE_SEND_IP 8 <span class="hljs-comment">/* Send REPLCONF ip-address */</span></span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> REPL_STATE_RECEIVE_IP 9 <span class="hljs-comment">/* Wait for REPLCONF reply */</span></span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> REPL_STATE_SEND_CAPA 10 <span class="hljs-comment">/* Send REPLCONF capa */</span></span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> REPL_STATE_RECEIVE_CAPA 11 <span class="hljs-comment">/* Wait for REPLCONF reply */</span></span></code></pre></div>

<ol start="8">
<li>完成握手后，从库向主库发送 PSYNC 命令和自己的 offset，首先尝试「增量同步」，如果 offset = -1，主库返回 FULLRESYNC 表示「全量同步」数据，否则返回 CONTINUE 增量同步</li>
<li>如果是全量同步，主库会先生成 RDB，从库等待，主库完成 RDB 后发给从库，从库接收 RDB，然后清空实例数据，加载 RDB，之后读取主库发来的「增量」数据</li>
<li>如果是增量同步，从库只需接收主库传来的增量数据即可</li>
</ol>
<p>课后题：当一个实例是主库时，为什么不需要使用状态机来实现主库在主从复制时的流程流转？</p>
<p>因为复制数据的发起方是从库，从库要求复制数据会经历多个阶段（发起连接、握手认证、请求数据），而主库只需要「被动」接收从库的请求，根据需要「响应数据」即可完成整个流程，所以主库不需要状态机流转。</p>
<h2 id="哨兵"><a href="#哨兵" class="headerlink" title="哨兵"></a>哨兵</h2><h3 id="总结1-20"><a href="#总结1-20" class="headerlink" title="总结1"></a>总结1</h3><p>今天这节课，我给你介绍了哨兵实例的初始化过程。哨兵实例和 Redis 实例使用的是相同的入口 main 函数，但是由于哨兵实例在运行时使用的配置项、运行时信息、支持的可执行命令、事件处理和 Redis 实例又有所区别。</p>
<p>所以，main 函数会先通过 checkForSentinelMode 函数来判断当前运行是否为哨兵实例，并相应地设置全局配置项 server.sentinel_mode，这个配置项就会在源码其他地方被用于标识哨兵实例是否运行。</p>
<p>这样，当启动的是哨兵实例时，main 函数会调用 initSentinelConfig、initSentinel 函数来完成哨兵实例的初始化，然后，main 函数会调用 sentinelIsRunning 函数，来向被监听的主节点发送事件信息，从而开始监听主节点。</p>
<p>最后，我也想再提醒你一下，从今天这节课的内容中，我们可以看到哨兵实例在运行后，开始使用 Pub/Sub 订阅频道模式的通信方法，这种通信方法通常适用于多对多的通信场景中。</p>
<p>因为哨兵实例除了和主节点通信外，还需要和其他哨兵实例、客户端进行通信，而采用 Pub/Sub 通信方法，可以高效地完成这些通信过程。我在接下来的课程中还会给你介绍 Pub/Sub 通信方法在哨兵运行过程中的使用，也希望你在学完这部分课程内容之后，能够掌握这种通信方法的实现。</p>
<h3 id="总结2-20"><a href="#总结2-20" class="headerlink" title="总结2"></a>总结2</h3><ol>
<li>哨兵和 Redis 实例是一套代码，只不过哨兵会根据启动参数（redis-sentinel 或 redis-server –sentinel），设置当前实例为哨兵模式（server.sentinel_mode = 1），然后初始化哨兵相关数据</li>
<li>哨兵模式的实例，只能执行一部分命令（ping、sentinel、subscribe、unsubscribe、psubscribe、punsubscribe、publish、info、role、client、shutdown、auth），其中 sentinel、publish、info、role 都是针对哨兵专门实现的</li>
<li>之后哨兵会初始化各种属性，例如哨兵实例 ID、用于故障切换的当前纪元、监听的主节点、正在执行的脚本数量、与其他哨兵实例发送的 IP 和端口号等信息</li>
<li>启动哨兵后，会检查配置文件是否可写（不可写直接退出，哨兵需把监控的实例信息写入配置文件）、是否配置了哨兵 ID（没配置随机生成一个）</li>
<li>最后哨兵会在监控的 master 实例的 PubSub（+monitor 频道）发布一条消息，表示哨兵开始监控 Redis 实例</li>
<li>哨兵后续会通过 PubSub 的方式，与主从库、其它哨兵实例进行通信</li>
</ol>
<p>课后题：哨兵实例本身是有配置文件 sentinel.conf 的，那么在哨兵实例的初始化过程中，解析这个配置文件的函数在哪？</p>
<p>Redis 启动时，会在 main 函数中调用 loadServerConfig 加载配置文件，loadServerConfig 函数会读取配置文件中的内容，然后调用 loadServerConfigFromString 函数解析具体的配置项。</p>
<p>loadServerConfigFromString 函数中，其中有一个分支，对哨兵模式进行了判断，如果是哨兵模式，则调用 sentinelHandleConfiguration 函数解析哨兵配置项。</p>
<p>所以，函数调用链为 main -&gt; loadServerConfig（读出配置文件内容） -&gt; loadServerConfigFromString（解析配置项） -&gt; sentinelHandleConfiguration（解析哨兵配置项）。</p>
<h2 id="哨兵选举-上"><a href="#哨兵选举-上" class="headerlink" title="哨兵选举 上"></a>哨兵选举 上</h2><h3 id="总结1-21"><a href="#总结1-21" class="headerlink" title="总结1"></a>总结1</h3><p>这节课，我主要是给你介绍了哨兵工作过程中的一个重要环节，也就是哨兵 Leader 的选举。这个选举过程是参考了分布式系统中常用的分布式共识协议 Raft 协议来实现的。所以，你需要先了解 Raft 协议的基本流程，包括 Leader、Follower、Candidate 三种节点类型，Follower 成为 Candidate 的条件和具体操作，以及 Leader 投票的规则。</p>
<p>那么，对于哨兵 Leader 选举来说，它参考了 Raft 协议，但你需要注意的是，哨兵在正常运行时并不像 Raft 协议那样区分了三种节点类型，而是所有哨兵都是对等的。而当哨兵发现主节点故障，要执行故障切换时，会按照 Raft 协议中 Leader 选举的规则，进行投票选出 Leader。这是哨兵 Leader 选举和 Raft 协议的区别与联系。</p>
<p>此外，我还介绍了哨兵的时间事件处理函数 sentinelTimer，这个函数会对哨兵监听的每个主节点，周期性调用 sentinelHandleRedisInstance 函数，来检查主节点在线状态。当主节点客观下线了，哨兵会启动 Leader 选举并执行故障切换。这节课我们是先了解了 sentinelHandleRedisInstance 函数的整体执行流程，这样，你也能掌握哨兵的整体工作过程。同时，针对哨兵和主节点重建连接、发送命令和检查主观下线的三个函数，你也要有所了解，它们也是哨兵工作中的三个重要步骤。</p>
<p>那么，在下节课，我将带你了解哨兵 Leader 选举的具体过程以及故障切换的执行。</p>
<h3 id="总结2-21"><a href="#总结2-21" class="headerlink" title="总结2"></a>总结2</h3><ol>
<li>Redis 为了实现故障自动切换，引入了一个外部「观察者」检测实例的状态，这个观察者就是「哨兵」</li>
<li>但一个哨兵检测实例，有可能因为网络原因导致「误判」，所以需要「多个」哨兵共同判定</li>
<li>多个哨兵共同判定出实例故障后（主观下线、客观下线），会进入故障切换流程，切换时需要「选举」出一个哨兵「领导者」进行操作</li>
<li>这个选举的过程，就是「分布式共识」，即多个哨兵通过「投票」选举出一个都认可的实例当领导者，由这个领导者发起切换，这个选举使用的算法是 Raft 算法</li>
<li>严格来说，Raft 算法的核心流程是这样的：</li>
</ol>
<ul>
<li>集群正常情况下，Leader 会持续给 Follower 发心跳消息，维护 Leader 地位</li>
<li>如果 Follower 一段时间内收不到 Leader 心跳消息，则变为 Candidate 发起选举</li>
<li>Candidate 先给自己投一票，然后向其它节点发送投票请求</li>
<li>Candidate 收到超过半数确认票，则提升为新的 Leader，新 Leader 给其它 Follower 发心跳消息，维护新的 Leader 地位</li>
<li>Candidate 投票期间，收到了 Leader 心跳消息，则自动变为 Follower</li>
<li>投票结束后，没有超过半数确认票的实例，选举失败，会再次发起选举</li>
</ul>
<ol start="6">
<li>但哨兵的选举没有按照严格按照 Raft 实现，因为多个哨兵之间是「对等」关系，没有 Leader 和 Follower 角色，只有当 Redis 实例发生故障时，哨兵才选举领导者进行切换，选举 Leader 的过程是按照 Raft 算法步骤 3-6 实现的</li>
</ol>
<p>课后题：哨兵实例执行的周期性函数 sentinelTimer 的最后，修改 server.hz 的目的是什么？</p>
<p>server.hz 表示执行定时任务函数 serverCron 的频率，哨兵在最后修改 server.hz 增加一个随机值，是为了避免多个哨兵以「相同频率」执行，引发每个哨兵同时发起选举，进而导致没有一个哨兵能拿到多数投票，领导者选举失败的问题。适当打散执行频率，可以有效降低选举失败的概率。</p>
<h2 id="哨兵选举-下"><a href="#哨兵选举-下" class="headerlink" title="哨兵选举 下"></a>哨兵选举 下</h2><h3 id="总结1-22"><a href="#总结1-22" class="headerlink" title="总结1"></a>总结1</h3><p>好了，今天这节课的内容就到这里，我们来小结下。</p>
<p>今天这节课，我在上节课的基础上，重点给你介绍了哨兵工作过程中的客观下线判断，以及 Leader 选举。因为这个过程涉及哨兵之间的交互询问，所以并不容易掌握，你需要好好关注以下我提到的重点内容。</p>
<p>首先，客观下线的判断涉及三个标记的判断，分别是主节点 flags 中的 SRI_S_DOWN 和 SRI_O_DOWN，以及哨兵实例 flags 中的 SRI_MASTER_DOWN，我画了下面这张表，展示了这三个标记的设置函数和条件，你可以再整体回顾下。</p>
<p><img src="/images/redis/sentinel-02.png" alt="img.png"></p>
<p>而一旦哨兵判断主节点客观下线了，那么哨兵就会调用 sentinelAskMasterStateToOtherSentinels 函数进行哨兵 Leader 选举。这里，你需要注意的是，向其他哨兵询问主节点主观下线状态，以及向其他哨兵发起 Leader 投票，都是通过 sentinel is-master-down-by-addr 命令实现的，而 Redis 源码是用了同一个函数 sentinelAskMasterStateToOtherSentinels 来发送该命令，所以你在阅读源码时，要注意区分 sentinelAskMasterStateToOtherSentinels 发送的命令是查询主节点主观下线状态还是进行投票。</p>
<p>最后，哨兵 Leader 选举的投票是在 sentinelVoteLeader 函数中完成的，为了符合 Raft 协议的规定，sentinelVoteLeader 函数在执行时主要是要比较哨兵的纪元，以及 master 记录的 Leader 纪元，这样才能满足 Raft 协议对 Follower 在一轮投票中只能投一票的要求。</p>
<p>好了，到今天这节课，我们就了解了哨兵 Leader 选举的过程，你可以看到，虽然哨兵选举的最后执行逻辑就是在一个函数中，但是哨兵选举的触发逻辑是包含在了哨兵的整个工作过程中的，所以我们也需要掌握这个过程中的其他操作，比如主观下线判断、客观下线判断等。</p>
<h3 id="总结2-22"><a href="#总结2-22" class="headerlink" title="总结2"></a>总结2</h3><ol>
<li>一个哨兵检测判定主库故障，这个过程是「主观下线」，另外这个哨兵还会向其它哨兵询问（发送 sentinel is-master-down-by-addr 命令），多个哨兵都检测主库故障，数量达到配置的 quorum 值，则判定为「客观下线」</li>
<li>首先判定为客观下线的哨兵，会发起选举，让其它哨兵给自己投票成为「领导者」，成为领导者的条件是，拿到超过「半数」的确认票 + 超过预设的 quorum 阈值的赞成票</li>
<li>投票过程中会比较哨兵和主库的「纪元」（主库纪元 &lt; 发起投票哨兵的纪元 + 发起投票哨兵的纪元 &gt; 其它哨兵的纪元），保证一轮投票中一个哨兵只能投一次票</li>
</ol>
<p>课后题：哨兵在 sentinelTimer 函数中调用 sentinelHandleDictOfRedisInstances 函数，对每个主节点都执行 sentinelHandleRedisInstance 函数，并且还会对主节点的所有从节点也执行 sentinelHandleRedisInstance 函数，那么，哨兵会不会判断从节点的主观下线和客观下线？</p>
<p>sentinelHandleRedisInstance 函数逻辑如下：</p>
<div class="code-wrapper"><pre><code class="hljs c"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">sentinelHandleRedisInstance</span><span class="hljs-params">(sentinelRedisInstance *ri)</span> </span>&#123;
    ...

    <span class="hljs-comment">/* Every kind of instance */</span>
    <span class="hljs-comment">// 判断主观下线</span>
    sentinelCheckSubjectivelyDown(ri);

    ...

    <span class="hljs-comment">/* Only masters */</span>
    <span class="hljs-keyword">if</span> (ri-&gt;flags &amp; SRI_MASTER) &#123;
        <span class="hljs-comment">// 判断客观下线</span>
        sentinelCheckObjectivelyDown(ri);
        <span class="hljs-keyword">if</span> (sentinelStartFailoverIfNeeded(ri))
            sentinelAskMasterStateToOtherSentinels(ri,SENTINEL_ASK_FORCED);
        sentinelFailoverStateMachine(ri);
        sentinelAskMasterStateToOtherSentinels(ri,SENTINEL_NO_FLAGS);
    &#125;
&#125;</code></pre></div>

<p>可以看到，无论主库还是从库，哨兵都判断了「主观下线」，但只有主库才判断「客观下线」和「故障切换」。</p>
<h2 id="pub-sub"><a href="#pub-sub" class="headerlink" title="pub/sub"></a>pub/sub</h2><h3 id="总结1-23"><a href="#总结1-23" class="headerlink" title="总结1"></a>总结1</h3><p>今天这节课，我们了解了 Redis 实现的发布订阅通信方法。这个方法是提供了频道的方式，让要通信的双方按照频道来完成消息交互。而不同频道的不同名称，就代表了哨兵工作过程中的不同状态。当客户端需要了解哨兵的工作进度或是主节点的状态判断时，就可以通过订阅哨兵发布消息的频道来完成。</p>
<p>当然，对于一个哨兵来说，它一定会订阅的频道是它所监听的主节点的”<strong>sentinel</strong>:hello”频道。通过这个频道，监听同一主节点的不同哨兵就能通过频道上的 hello 消息，来交互彼此的访问信息了，比如哨兵的 IP、端口号等。</p>
<p>此外，在这节课，我还给你介绍了一个 C 语言函数可变参数的使用小技巧，当你开发发布订阅功能时，都需要生成发布的消息，而可变参数就可以用来生成长度不定的消息。希望你能把这个小技巧应用起来。</p>
<h3 id="总结2-23"><a href="#总结2-23" class="headerlink" title="总结2"></a>总结2</h3><ol>
<li>哨兵是通过 master 的 PubSub 发现其它哨兵的：每个哨兵向 master 的 PubSub（<strong>sentinel</strong>:hello 频道）发布消息，同时也会订阅这个频道，这样每个哨兵就能拿到其它哨兵的 IP、端口等信息</li>
<li>每个哨兵有了其它哨兵的信息后，在判定 Redis 实例状态时，就可以互相通信、交换信息，共同判定实例是否真的故障</li>
<li>哨兵判定 Redis 实例故障、发起切换时，都会向 master 的 PubSub 的频道发布消息</li>
<li>客户端可以订阅 master 的 PubSub，感知到哨兵工作到了哪个状态节点，从而作出自己的反应</li>
<li>PubSub 的实现，其实就是 Redis 在内存中维护了一个「发布-订阅」映射表，订阅者执行 SUBSCRIBE 命令，Redis 会把订阅者加入到指定频道的「链表」下。发布者执行 PUBLISH，Redis 就找到这个映射表中这个频道的所有「订阅者」，把消息「实时转发」给这些订阅者</li>
</ol>
<p>课后题：在哨兵实例上执行 publish 命令，这条命令是不是就是由 pubsub.c 文件中的 publishCommand 函数来处理的?</p>
<p>以哨兵模式启动的 Redis 实例，会使用新「命令表」。</p>
<p>在 server.c 的 main 函数中可以看到，哨兵模式启动后，会调用 initSentinel 函数。</p>
<div class="code-wrapper"><pre><code class="hljs c"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">initSentinel</span><span class="hljs-params">(<span class="hljs-keyword">void</span>)</span> </span>&#123;
    ...

    <span class="hljs-comment">// 只添加 sentinelcmds 下的命令</span>
    <span class="hljs-keyword">for</span> (j = <span class="hljs-number">0</span>; j &lt; <span class="hljs-keyword">sizeof</span>(sentinelcmds)/<span class="hljs-keyword">sizeof</span>(sentinelcmds[<span class="hljs-number">0</span>]); j++) &#123;
        <span class="hljs-keyword">int</span> retval;
        <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">redisCommand</span> *<span class="hljs-title">cmd</span> =</span> sentinelcmds+j;

        retval = dictAdd(server.commands, sdsnew(cmd-&gt;name), cmd);
        serverAssert(retval == DICT_OK);
    &#125;
    ...
&#125;</code></pre></div>

<p>可以看到只把 sentinelcmds 命令表添加到了 server.commands 中。sentinelcmds 如下：</p>
<div class="code-wrapper"><pre><code class="hljs c"><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">redisCommand</span> <span class="hljs-title">sentinelcmds</span>[] =</span> &#123;
    ...
    &#123;<span class="hljs-string">&quot;subscribe&quot;</span>,subscribeCommand,<span class="hljs-number">-2</span>,<span class="hljs-string">&quot;&quot;</span>,<span class="hljs-number">0</span>,<span class="hljs-literal">NULL</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>&#125;,
    &#123;<span class="hljs-string">&quot;publish&quot;</span>,sentinelPublishCommand,<span class="hljs-number">3</span>,<span class="hljs-string">&quot;&quot;</span>,<span class="hljs-number">0</span>,<span class="hljs-literal">NULL</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>&#125;,
    &#123;<span class="hljs-string">&quot;info&quot;</span>,sentinelInfoCommand,<span class="hljs-number">-1</span>,<span class="hljs-string">&quot;&quot;</span>,<span class="hljs-number">0</span>,<span class="hljs-literal">NULL</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>&#125;,
    ...
&#125;;</code></pre></div>

<p>可以看到哨兵的 PUBLISH 命令是由 sentinelPublishCommand 单独实现的，并非普通实例的 publishCommand。</p>
<h2 id="redis-性能测试"><a href="#redis-性能测试" class="headerlink" title="redis 性能测试"></a>redis 性能测试</h2><h3 id="总结1-24"><a href="#总结1-24" class="headerlink" title="总结1"></a>总结1</h3><p>今天这节课我给你介绍了 redis-benchmark 工具的使用。redis-benchmark 是常用的 Redis 性能测试工具，它可以通过设置并发客户端、总操作数、value 大小、key 的随机性、批量发送等配置项，来给 Redis server 施加不同的压力。</p>
<p>redis-benchmark 工具本身提供了一些常见命令的测试，比如 SET、GET、LPUSH，等等。这些命令的测试是 redis-benchmark 在它的实现文件中固定写好的。你可以在 redis-benchmark.c 文件中的 main 函数里面，找到这些命令。而如果我们想要测试不在固定测试命令集中的其他命令，我们可以在 redis-benchmark 命令的最后，设置其他的 Redis 命令，从而可以测试其他命令的性能结果。</p>
<p>最后，我也给你介绍了 redis-benchmark 的基本实现。它其实是启动多个客户端向 Redis server 发送命令操作。这个过程中，redis-benchmark 使用了事件驱动框架。每当启动一个测试客户端，这个客户端会在事件驱动框架中创建写事件和读事件。写事件对应了测试客户端向 Redis server 发送操作命令，而读事件对应了测试客户端从 Redis server 读取响应结果。</p>
<p>从这里，你可以看到，Redis 实现的事件驱动框架不仅用在 server 的运行过程中，而且还用在了性能测试工具实现的客户端中。</p>
<h3 id="总结2-24"><a href="#总结2-24" class="headerlink" title="总结2"></a>总结2</h3><ol>
<li>redis-benchmark 是 Redis 官方提供的性能测试工具，一般都用这个工具测试其性能</li>
<li>测试性能结果，与客户端并发数、value 大小、是否用 pipeline 都有关系</li>
<li>除此之外，性能结果还受系统环境的影响，例如 CPU 负载、网络带宽、客户端和服务端是否在同一机器、实例是否部署在虚拟机、Redis 绑核情况都会影响性能结果</li>
<li>提升 Redis 性能的几点优化：</li>
</ol>
<ul>
<li>控制客户端并发数</li>
<li>value 小于 10KB</li>
<li>推荐使用 pipeline</li>
<li>隔离部署</li>
<li>保证 CPU、网络带宽负载正常</li>
<li>不部署在虚拟机</li>
<li>进程绑核</li>
<li>CPU 绑定网卡队列</li>
<li>Redis 内存碎片</li>
<li>不使用 Swap</li>
</ul>
<h2 id="RDB、AOF文件损坏"><a href="#RDB、AOF文件损坏" class="headerlink" title="RDB、AOF文件损坏"></a>RDB、AOF文件损坏</h2><h3 id="总结1-25"><a href="#总结1-25" class="headerlink" title="总结1"></a>总结1</h3><p>今天这节课，我带你了解了检测 AOF 文件和 RDB 文件正确性和完整性的两个命令，redis-check-aof 和 redis-check-rdb，以及它们各自的实现过程。</p>
<p>对于 redis-check-aof 命令来说，它是根据 AOF 文件中记录的操作命令格式，逐一读取命令，并根据命令参数个数、参数字符串长度等信息，进行命令正确性和完整性的判断。</p>
<p>对于 redis-check-rdb 命令来说，它的实现逻辑较为简单，也就是按照 RDB 文件的组织格式，依次读取 RDB 文件头、数据部分和文件尾，并在读取过程中判断内容是否正确，并进行报错。</p>
<p>事实上，Redis server 在运行时，遇到故障而导致 AOF 文件或 RDB 文件没有记录完整，这种情况有时是不可避免的。当了解了 redis-check-aof 命令的实现后，我们就知道它可以提供出现错误或不完整命令的文件位置，并且，它本身提供了修复功能，可以从出现错误的文件位置处截断后续的文件内容。不过，如果我们不想通过截断来修复 AOF 文件的话，也可以尝试人工修补。</p>
<p>而在了解了 redis-check-rdb 命令的实现后，我们知道它可以发现 RDB 文件的问题所在。不过，redis-check-rdb 命令目前并没有提供修复功能。所以如果我们需要修复的话，就只能通过人工自己来修复了。</p>
<h3 id="总结2-25"><a href="#总结2-25" class="headerlink" title="总结2"></a>总结2</h3><ol>
<li>RDB 和 AOF 文件在写盘故障时，可能发生损坏不完整的情况，那使用其恢复数据就会出现问题，所以 Redis 提供了 2 个命令来检测文件是否有错误</li>
<li>要想检测出文件错误，那说明 RDB 和 AOF 必定是按照某种固定格式写入的，检测是否完整只需要按照其格式规则，发现不符即认为文件不完整</li>
<li>redis-check-rdb 命令检测 RDB，因为 RDB 有明确的文件头、数据部分、文件尾，读取文件发现不完整即报错</li>
<li>redis-check-aof 命令检测 AOF，AOF 按照 RESP 协议写入，按照这个协议可以读取每个命令参数个数、参数字符串长度，如果不符合协议格式，则说明不完整。但这个命令提供了 –fix 命令，可以修复 AOF 文件，实现原理是：把不完整的命令和后续部分，直接从 AOF 中删除</li>
</ol>
<p>课后题：redis_check_aof_main 函数是检测 AOF 文件的入口函数，但是它还会调用检测 RDB 文件的入口函数 redis_check_rdb_main，它的作用是什么？</p>
<p>Redis 在 4.0 版本支持了「混合持久化」，即在 AOF rewrite 期间，先以 RDB 格式写入到 AOF 文件中，再把后续命令追加到 AOF 中，这样 AOF rewrite 后的文件既包括了 RDB 格式，又包含 AOF 格式（目的是为了让 AOF 体积更小），所以 redis_check_rdb_main 在检测 AOF 文件时，RDB 和 AOF 文件格式都需要检测。</p>
<h2 id="Gossip"><a href="#Gossip" class="headerlink" title="Gossip"></a>Gossip</h2><h3 id="总结1-26"><a href="#总结1-26" class="headerlink" title="总结1"></a>总结1</h3><p>今天这节课，我给你介绍了 Redis Cluster 使用的 Gossip 协议的设计和实现。Gossip 协议实现的关键有两个，一个是要通过 Ping-Pong 消息发送节点自身的信息，以及节点已知的其他节点的信息。针对这一点，Redis 是设计了 clusterMsg 结构的消息，其中消息头包含了发送消息节点自身的信息，比如名称、IP、端口号、slots 分布等。</p>
<p>而 clusterMsg 结构中的消息体，是设计使用了 clusterMsgDataGossip 类型的数组，这个数组的每一个元素对应了发送消息节点已知的一个节点的信息。这样一来，发送消息节点通过 Ping 消息可以把自己的信息和已知的其他节点信息传播出去。</p>
<p>同样的，收到 Ping 消息的节点，也会使用同样结构的 Pong 消息将自己的信息和它已知的其他节点信息返回给发送节点。这样一来，就能实现 Gossip 协议的要求。</p>
<p>Gossip 协议实现的另一个关键就是要随机选择节点发送，这一点，Redis Cluster 在源码中就比较容易实现了。其实，就是 clusterCron 函数先通过随机选择五个节点，然后，再在其中挑选和当前节点最长时间没有发送 Pong 消息的节点，作为目标节点，这样一来，也满足了 Gossip 协议的要求。</p>
<p>通过今天这节课的学习，我希望你能了解 Redis Cluster 设计的消息结构、周期发送 Ping 和 Pong 消息的整体执行逻辑。这些都是你可以用在自行开发 Gossip 协议时的经典参考设计。</p>
<h3 id="总结2-26"><a href="#总结2-26" class="headerlink" title="总结2"></a>总结2</h3><ol>
<li>多个节点组成一个分布式系统，它们之间需要交换数据，可以采用中心化的方式（依赖第三方系统，例如ZK），也可以采用非中心化（分布式协议，例如 Gossip）的方式</li>
<li>Redis Cluster 采用非中心化的方式 Gossip 协议，实现多个节点之间信息交换</li>
<li>集群中的每个实例，会按照固定频率，从集群中「随机」挑选部分实例，发送 PING 消息（自身实例状态、已知部分实例信息、slots 分布），用来交换彼此状态信息</li>
<li>收到 PING 的实例，会响应 PONG 消息，PONG 消息和 PING 消息格式一样，包含了自身实例状态、已知部分实例信息、slots 分布</li>
<li>这样经过几次交换后，集群中每个实例都能拿到其它实例的状态信息</li>
<li>即使有节点状态发生变化（新实例加入、节点故障、数据迁移），也可以通过 Gossip 协议的 PING-PONG 消息完成整个集群状态在每个实例上的同步</li>
</ol>
<p>课后题：为什么 clusterSendPing 函数计算 wanted 值时，是用的集群节点个数的十分之一？</p>
<p>这个和 Redis Cluster 判定实例「故障」逻辑有关了。</p>
<p>Redis Cluster 实例在周期性向其它实例交换信息时，会先随机选出 5 个实例，然后从中找出最久没通信过的实例，发送 PING 消息。</p>
<p>但这里有个问题，随机选出的这 5 个实例，有可能并不是整个「集群」中最久没通信过的，为了避免拿不到这些实例的状态，导致集群误以为这些实例已过期，所以制定了一个策略：如果和实例最近通信时间超过了 cluster-node-timeout / 2，那会立即向这个实例发送 PING 消息。</p>
<p>每次 PING 都会收到 PONG 响应，一来一回 2 次心跳包，来回都带有部分实例的状态信息，那在 cluster-node-timeout 时间内会收到 4 次心跳包。</p>
<p>又因为 Redis Cluster 计算故障转移超时时间是 cluster-node-timeout * 2，那这段时间内就能收到 8 个 PING + PONG 心跳包，每个心跳包中实例个数设置为集群的 1/10，那在故障转移期间就能收到集群 80%（8 * 1/10）节点发来的故障状态信息了，满足集群大部分节点发来的节点故障情况。</p>
<h2 id="MOVED、ASK"><a href="#MOVED、ASK" class="headerlink" title="MOVED、ASK"></a>MOVED、ASK</h2><h3 id="总结1-27"><a href="#总结1-27" class="headerlink" title="总结1"></a>总结1</h3><p>今天这节课，我给你介绍了集群节点对客户端命令的处理过程。和单个 Redis server 处理命令的过程相似，集群节点也会经历命令读取、解析、执行和返回结果四个阶段，并且集群节点也使用了和单 Redis server 相同的入口处理函数。</p>
<p>不过你要知道的是，Redis Cluster 会因为负载均衡或节点故障等原因而执行数据迁移，而这就会导致客户端访问的 key 并不在接收到命令的集群节点上。因此，集群节点在命令执行函数 processCommand 中，针对集群模式，就增加了额外的处理逻辑。这主要是包括调用 getNodeByQuery 函数查询访问的 key 实际所属的节点，以及根据查询结果调用 clusterRedirectClient 函数执行请求重定向。</p>
<p>事实上，对于分布式集群来说，Redis Cluster 设计实现的请求重定向机制是一个不错的参考示例。其中，MOVED 和 ASK 两种重定向情况，就充分考虑了数据正在迁移的场景，这种设计值得我们学习。而且，getNodeByQuery 函数在查询 key 所属的 slot 和节点时，也充分考虑了 Redis 的事务操作，在对命令访问 key 进行查询时，巧妙地使用了同一个数据结构 multiState，来封装事务涉及的多条命令和常规的单条命令，增加了代码的复用程度，这一点也非常值得学习。</p>
<p>当然，在这节课里我们也多次提到了数据迁移，那么在下节课，我就会给你介绍 Redis Cluster 中数据迁移的具体实现。</p>
<h3 id="总结2-27"><a href="#总结2-27" class="headerlink" title="总结2"></a>总结2</h3><p>1、cluster 模式的 Redis，在执行命令阶段，需要判断 key 是否属于本实例，不属于会给客户端返回请求重定向的信息</p>
<p>2、判断 key 是否属于本实例，会先计算 key 所属的 slot，再根据 slot 定位属于哪个实例</p>
<p>3、找不到 key 所属的实例，或者操作的多个 key 不在同一个 slot，则会给客户端返回错误；key 正在做数据迁出，并且访问的这个 key 不在本实例中，会给客户端返回 ASK，让客户端去目标节点再次查询一次（临时重定向）；key 所属的 slot 不是本实例，而是其它节点，会给客户端返回 MOVED，告知客户端 key 不在本实例，以后都去目标节点查询（永久重定向）</p>
<p>课后题：processCommand 函数在调用完 getNodeByQuery 函数后，实际调用 clusterRedirectClient 函数进行请求重定向前，会根据当前命令是否是 EXEC，分别调用 discardTransaction 和 flagTransaction 两个函数。这 2 个函数的目的是什么?</p>
<p>看代码逻辑，只有当 n == NULL || n != server.cluster-&gt;myself 时，才会调用这 2 个方法。</p>
<p>其中，如果当前执行的是 EXEC 命令，则调用 discardTransaction。这个函数表示放弃整个事务，它会清空这个 client 之前缓存的命令队列，放弃事务中 watch 的 key，重置 client 的事务标记。</p>
<p>如果当前命令不是 EXEC，而是一个普通命令，则调用 flagTransaction。这个函数会给当前 client 打上一个标记 CLIENT_DIRTY_EXEC，如果后面执行了 EXEC，就会判断这个标记，随即也会放弃执行事务，给客户端返回错误。</p>
<p>也就是说，当集群不可用、key 找不到对应的 slot、key 不在本实例中、操作的 keys 不在同一个 slot、key 正在迁移中，发生这几种情况时，都会放弃整个事务的执行。</p>
<h2 id="Cluster数据迁移会阻塞？"><a href="#Cluster数据迁移会阻塞？" class="headerlink" title="Cluster数据迁移会阻塞？"></a>Cluster数据迁移会阻塞？</h2><h3 id="总结1-28"><a href="#总结1-28" class="headerlink" title="总结1"></a>总结1</h3><p>在今天的课程中，我给你介绍了 Redis Cluster 数据迁移过程的代码实现，你要掌握以下两个要点。</p>
<p>首先是记录集群状态的数据结构 clusterState。这个结构中是使用了 migrating_slots_to 和 importing_slots_from 两个数组，来记录数据迁出迁入情况，使用了 slots 数组记录每个 slot 所属的节点，以及使用 slots_to_keys 字典树记录 slots 中的 keys。你需要掌握这几个数据结构的含义，因为在你阅读集群源码时，这几个结构是会频繁使用到的。</p>
<p>然后是数据迁移过程的五大步骤。分别是：</p>
<ul>
<li>标记迁入、迁出节点；</li>
<li>获取待迁出的 keys；</li>
<li>源节点实际迁移数据；</li>
<li>目的节点处理迁移数据；</li>
<li>标记迁移结果。</li>
</ul>
<p>这五个步骤对应了 CLUSTER 命令的不同选项、MIGRATE 命令以及 RESTORE 命令，所以，它们的实现逻辑就主要对应在 clusterCommand、migrateCommand 和 restoreCommand 函数中。如果你想了解数据迁移的更多细节，你可以从这几个函数入手进一步学习。</p>
<p>最后，我也想再提醒你两个关键点。</p>
<p>一是，Redis Cluster 在执行数据迁移时，会调用 syncWrite 和 syncReadLine 函数，向目的节点同步发送迁移数据，以及同步读取回复结果。而这个同步写和同步读的过程，会阻塞源节点正常处理请求。所以，你在迁移数据时要控制迁移的 key 数量和 key 大小，避免一次性迁移过多的 key 或是过大的 key，而导致 Redis 阻塞。</p>
<p>二是，我们在实际应用中，会用到 redis-cli 工具，或者是 Ruby 开发的 Redis Cluster 集群运维工具 redis-trib，来执行数据迁移。这些工具最终也会调用这节课中，我们介绍的命令来完成数据的实际迁移。所以，学习今天课程的内容，对于你在实际应用中，从代码层面排查 redis-cli、redis-trib 这些工具的问题也是有所帮助的。</p>

            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/redis/">redis</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/%E6%BA%90%E7%A0%81/">源码</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">
                  
                    本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！
                  
                </p>
              
              
                <div class="post-prevnext">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/redis/config/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Redis配置</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/redis/use/">
                        <span class="hidden-mobile">Redis核心技术与实战</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
              <!-- Comments -->
              <article class="comments" id="comments">
                
                  
                
                
  <div id="gitalk-container"></div>
  <script type="text/javascript">
    Fluid.utils.loadComments('#gitalk-container', function() {
      Fluid.utils.createCssLink('/css/gitalk.css')
      Fluid.utils.createScript('https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.min.js', function() {
        var options = Object.assign(
          {"clientID":"1545f02c9a677f0bd433","clientSecret":"57b1b2091f1c8788e4a2722c7b05ba53bc1e6b18","repo":"zuoshuwen.github.io","owner":"zuoshuwen","admin":["zuoshuwen"],"language":"zh-CN","labels":["Gitalk"],"perPage":10,"pagerDirection":"last","distractionFreeMode":false,"createIssueManually":true,"proxy":"<your own proxy>/https://github.com/login/oauth/access_token"},
          {
            id: '0771784e971280f3477259a32fa7a0a0'
          }
        )
        var gitalk = new Gitalk(options);
        gitalk.render('gitalk-container');
      });
    });
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


              </article>
            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
  </div>
  
  <div class="statistics">
    
    

    
      
        <!-- LeanCloud 统计PV -->
        <span id="leancloud-site-pv-container" style="display: none">
            总访问量 
            <span id="leancloud-site-pv"></span>
             次
          </span>
      
      
        <!-- LeanCloud 统计UV -->
        <span id="leancloud-site-uv-container" style="display: none">
            总访客数 
            <span id="leancloud-site-uv"></span>
             人
          </span>
      

    
  </div>


  
  <!-- 备案信息 -->
  <div class="beian">
    <span>
      <a href="http://beian.miit.gov.cn/" target="_blank" rel="nofollow noopener">
        京ICP备18026333号-1
      </a>
    </span>
    
  </div>


  
</footer>


  <!-- SCRIPTS -->
  
  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>

<!-- Plugins -->


  <script  src="/js/local-search.js" ></script>





  



  
    <script  src="https://cdn.jsdelivr.net/npm/tocbot@4.12.2/dist/tocbot.min.js" ></script>
  
  
    <script  src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js" ></script>
  
  
    <script  src="https://cdn.jsdelivr.net/npm/anchor-js@4.3.0/anchor.min.js" ></script>
  
  
    <script defer src="https://cdn.jsdelivr.net/npm/clipboard@2.0.8/dist/clipboard.min.js" ></script>
  




  <script defer src="/js/leancloud.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/typed.js@2.0.11/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var title = document.getElementById('subtitle').title;
      
        typing(title);
      
    })(window, document);
  </script>












  
    <!-- Baidu Analytics -->
    <script defer>
      var _hmt = _hmt || [];
      (function () {
        var hm = document.createElement("script");
        hm.src = "https://hm.baidu.com/hm.js?97f60cea7055dca81a77d34bd50655bf";
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(hm, s);
      })();
    </script>
  

  

  

  

  

  





<!-- 主题的启动项 保持在最底部 -->
<script  src="/js/boot.js" ></script>


</body>
</html>
